<!DOCTYPE html>
<!-- Created by pdf2htmlEX (https://github.com/coolwanglu/pdf2htmlex) -->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="pdf2htmlEX"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
<link rel="stylesheet" href="base.min.css"/>
<link rel="stylesheet" href="fancy.min.css"/>
<link rel="stylesheet" href="main.css"/>
<script src="compatibility.min.js"></script>
<script src="pdf2htmlEX.min.js"></script>
<script>
try{
pdf2htmlEX.defaultViewer = new pdf2htmlEX.Viewer({});
}catch(e){}
</script>
<title></title>
</head>
<body>
<div id="sidebar">
<div id="outline">
<ul><li><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",70.87,577.15,null]'>第一部分 机器学习初步  模型选择与评估</a><ul><li><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,799.37,null]'>误差与过拟合</a><ul><li><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,662.93,null]'>模型的参数和超参数</a></li><li><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,140.42,null]'>误差与过拟合</a></li><li><a class="l" href="#pfa" data-dest-detail='[10,"XYZ",70.87,42.52,null]'>交叉验证</a><ul><li><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,493.06,null]'>简单交叉验证</a></li><li><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,332.06,null]'>K 折交叉验证</a></li><li><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,42.52,null]'>留一法和留 P 法</a></li><li><a class="l" href="#pfc" data-dest-detail='[12,"XYZ",70.87,686.75,null]'>时序交叉验证</a></li></ul></li></ul></li><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,799.37,null]'>性能度量——模型的好坏</a><ul><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,483.26,null]'>均方误差</a></li><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,268.78,null]'>混淆矩阵</a></li><li><a class="l" href="#pff" data-dest-detail='[15,"XYZ",70.87,427.32,null]'>Error Rate与accuracy</a></li><li><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",70.87,647.85,null]'>Precision、Recall</a></li><li><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",70.87,215.37,null]'>TPR、FPR</a></li><li><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",70.87,725.99,null]'>ROC、AUC</a></li><li><a class="l" href="#pf14" data-dest-detail='[20,"XYZ",70.87,468.1,null]'>代价敏感错误率</a></li></ul></li></ul></li><li><a class="l" href="#pf16" data-dest-detail='[22,"XYZ",70.87,577.15,null]'>第二部分 机器学习中阶  传统模型</a><ul><li><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,799.37,null]'>贝叶斯分类器</a><ul><li><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,662.85,null]'>判别规则</a><ul><li><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,42.52,null]'>特殊情形</a></li></ul></li><li><a class="l" href="#pf19" data-dest-detail='[25,"XYZ",70.87,624.89,null]'>参数估计</a><ul><li><a class="l" href="#pf19" data-dest-detail='[25,"XYZ",70.87,39.79,null]'>极大似然估计</a></li></ul></li><li><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",70.87,560.37,null]'>朴素贝叶斯分类器</a><ul><li><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",70.87,464.27,null]'>统计语言模型简述</a></li><li><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",70.87,531.57,null]'>朴素贝叶斯</a></li><li><a class="l" href="#pf1c" data-dest-detail='[28,"XYZ",70.87,731.28,null]'>修正</a></li><li><a class="l" href="#pf1c" data-dest-detail='[28,"XYZ",70.87,243.23,null]'>朴素贝叶斯算法的不同方法</a></li></ul></li><li><a class="l" href="#pf1d" data-dest-detail='[29,"XYZ",70.87,466.86,null]'>python示例</a><ul><li><a class="l" href="#pf1d" data-dest-detail='[29,"XYZ",70.87,408.18,null]'>伯努利朴素贝叶斯的示例</a></li><li><a class="l" href="#pf1e" data-dest-detail='[30,"XYZ",70.87,473.97,null]'>对比</a></li></ul></li></ul></li><li><a class="l" href="#pf22" data-dest-detail='[34,"XYZ",70.87,799.37,null]'>决策树</a></li></ul></li><li><a class="l" href="#pf24" data-dest-detail='[36,"XYZ",70.87,577.15,null]'>第三部分 机器学习高阶  优化方法</a><ul><li><a class="l" href="#pf26" data-dest-detail='[38,"XYZ",70.87,799.37,null]'>梯度下降</a><ul><li><a class="l" href="#pf26" data-dest-detail='[38,"XYZ",70.87,662.93,null]'>梯度下降原理</a></li></ul></li><li><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,799.37,null]'>Backpropagation</a><ul><li><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,660.96,null]'>神经网络</a></li><li><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,391.25,null]'>基本函数</a></li><li><a class="l" href="#pf29" data-dest-detail='[41,"XYZ",70.87,664.07,null]'>前向传播</a></li><li><a class="l" href="#pf2a" data-dest-detail='[42,"XYZ",70.87,41.41,null]'>反向传播</a><ul><li><a class="l" href="#pf2b" data-dest-detail='[43,"XYZ",70.87,650.79,null]'>输出层</a></li><li><a class="l" href="#pf2c" data-dest-detail='[44,"XYZ",70.87,765.85,null]'>隐藏层</a></li></ul></li><li><a class="l" href="#pf2c" data-dest-detail='[44,"XYZ",70.87,214.25,null]'>权值更新归纳</a></li></ul></li></ul></li><li><a class="l" href="#pf2e" data-dest-detail='[46,"XYZ",70.87,568.85,null]'>第四部分 神经网络</a><ul><li><a class="l" href="#pf30" data-dest-detail='[48,"XYZ",70.87,799.37,null]'>Recurrent Neural Networks</a><ul><li><a class="l" href="#pf30" data-dest-detail='[48,"XYZ",70.87,682.86,null]'>Simple Recurrent Network</a><ul><li><a class="l" href="#pf30" data-dest-detail='[48,"XYZ",70.87,640.54,null]'>前向传播</a></li><li><a class="l" href="#pf32" data-dest-detail='[50,"XYZ",70.87,260.69,null]'>反向传播</a></li><li><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,718.64,null]'>title</a></li></ul></li><li><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,665.75,null]'>LSTM </a><ul><li><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,626.63,null]'>LSTM 概述</a></li><li><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,531.4,null]'>LSTM与RNN的区别</a></li><li><a class="l" href="#pf34" data-dest-detail='[52,"XYZ",70.87,398.71,null]'>遗忘门</a></li><li><a class="l" href="#pf34" data-dest-detail='[52,"XYZ",70.87,134.81,null]'>输入门</a></li><li><a class="l" href="#pf35" data-dest-detail='[53,"XYZ",70.87,709.21,null]'>细胞状态更新</a></li><li><a class="l" href="#pf35" data-dest-detail='[53,"XYZ",70.87,559.23,null]'>输出门</a></li></ul></li><li><a class="l" href="#pf35" data-dest-detail='[53,"XYZ",70.87,381.09,null]'>带窥孔的LSTM</a></li><li><a class="l" href="#pf35" data-dest-detail='[53,"XYZ",70.87,238.54,null]'>GRU</a></li></ul></li><li><a class="l" href="#pf38" data-dest-detail='[56,"XYZ",70.87,799.37,null]'>Seq2Seq</a><ul><li><a class="l" href="#pf38" data-dest-detail='[56,"XYZ",70.87,661.1,null]'>Encoder-Decoder</a></li><li><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,525.87,null]'>Seq2Seq</a></li><li><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,29.4,null]'>Attention机制</a></li></ul></li></ul></li></ul></div>
</div>
<div id="page-container">
<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><div class="t m0 x0 h1 y0 ff1 fs0 fc0 sc0 ls0 ws0">机器学习</div><div class="t m0 x1 h2 y1 ff2 fs1 fc0 sc0 ls0 ws0">siwing</div><div class="t m0 x2 h3 y2 ff2 fs1 fc0 sc0 ls0 ws0">2020<span class="_ _0"> </span><span class="ff1">年<span class="_ _0"> </span></span>4<span class="_ _0"> </span><span class="ff1">月<span class="_ _0"> </span></span>7<span class="_ _0"> </span><span class="ff1">日</span></div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">2</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><div class="t m0 x4 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">目录</div><div class="t m0 x3 h5 y5 ff4 fs1 fc0 sc0 ls0 ws0">第一部分 <span class="fs3">机器学习初步</span></div><div class="t m0 x3 h1 y6 ff5 fs0 fc0 sc0 ls0 ws0">模型选择与评估<span class="_ _1"> </span><span class="ff6 fs1">1</span></div><div class="t m0 x3 h6 y7 ff4 fs2 fc0 sc0 ls0 ws0">第一章<span class="_ _2"> </span>误差与过拟合<span class="_ _3"> </span><span class="ff7">3</span></div><div class="t m0 x5 h6 y8 ff3 fs2 fc0 sc0 ls0 ws0">1.1<span class="_ _4"> </span><span class="ff1">模型的参数和超参数<span class="_ _5"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>3</div><div class="t m0 x5 h6 y9 ff3 fs2 fc0 sc0 ls0 ws0">1.2<span class="_ _4"> </span><span class="ff1">误差与过拟合<span class="_ _9"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>3</div><div class="t m0 x5 h6 ya ff3 fs2 fc0 sc0 ls0 ws0">1.3<span class="_ _4"> </span><span class="ff1">交叉验证 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>6</div><div class="t m0 x6 h6 yb ff3 fs2 fc0 sc0 ls0 ws0">1.3.1<span class="_ _a"> </span><span class="ff1">简单交叉验证<span class="_ _b"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>6</div><div class="t m0 x6 h6 yc ff3 fs2 fc0 sc0 ls0 ws0">1.3.2<span class="_ _a"> </span>K<span class="_ _c"> </span><span class="ff1">折交叉验证<span class="_ _0"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>6</div><div class="t m0 x6 h6 yd ff3 fs2 fc0 sc0 ls0 ws0">1.3.3<span class="_ _a"> </span><span class="ff1">留一法和留<span class="_ _c"> </span></span>P<span class="_ _c"> </span><span class="ff1">法<span class="_ _5"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>7</div><div class="t m0 x6 h6 ye ff3 fs2 fc0 sc0 ls0 ws0">1.3.4<span class="_ _a"> </span><span class="ff1">时序交叉验证<span class="_ _b"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>7</div><div class="t m0 x3 h6 yf ff4 fs2 fc0 sc0 ls0 ws0">第二章<span class="_ _2"> </span>性能度量——模型的好坏<span class="_ _d"> </span><span class="ff7">9</span></div><div class="t m0 x5 h6 y10 ff3 fs2 fc0 sc0 ls0 ws0">2.1<span class="_ _4"> </span><span class="ff1">均方误差 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>9</div><div class="t m0 x5 h6 y11 ff3 fs2 fc0 sc0 ls0 ws0">2.2<span class="_ _4"> </span><span class="ff1">混淆矩阵 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _8"> </span>9</div><div class="t m0 x5 h6 y12 ff3 fs2 fc0 sc0 ls0 ws0">2.3<span class="_ _4"> </span>Error<span class="_ _c"> </span>Rate<span class="_ _c"> </span><span class="ff1">与<span class="_ _c"> </span></span>accuracy<span class="_ _e"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>10</div><div class="t m0 x5 h6 y13 ff3 fs2 fc0 sc0 ls0 ws0">2.4<span class="_ _e"> </span>Precision<span class="_ _f"></span><span class="ff1">、</span>Recall<span class="_ _b"> </span>.<span class="_ _b"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>11</div><div class="t m0 x5 h6 y14 ff3 fs2 fc0 sc0 ls0 ws0">2.5<span class="_ _e"> </span>TPR<span class="_ _f"></span><span class="ff1">、</span>FPR<span class="_ _9"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>12</div><div class="t m0 x5 h6 y15 ff3 fs2 fc0 sc0 ls0 ws0">2.6<span class="_ _e"> </span>ROC<span class="ff1">、</span>A<span class="_ _10"></span>UC<span class="_ _11"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>13</div><div class="t m0 x5 h6 y16 ff3 fs2 fc0 sc0 ls0 ws0">2.7<span class="_ _4"> </span><span class="ff1">代价敏感错误率<span class="_ _c"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>15</div><div class="t m0 x3 h5 y17 ff4 fs1 fc0 sc0 ls0 ws0">第二部分 <span class="fs3">机器学习中阶</span></div><div class="t m0 x3 h1 y18 ff5 fs0 fc0 sc0 ls0 ws0">传统模型<span class="_ _13"> </span><span class="ff6 fs1">17</span></div><div class="t m0 x3 h6 y19 ff4 fs2 fc0 sc0 ls0 ws0">第三章<span class="_ _2"> </span>贝叶斯分类器<span class="_ _14"> </span><span class="ff7">19</span></div><div class="t m0 x5 h6 y1a ff3 fs2 fc0 sc0 ls0 ws0">3.1<span class="_ _4"> </span><span class="ff1">判别规则 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>19</div><div class="t m0 x6 h6 y1b ff3 fs2 fc0 sc0 ls0 ws0">3.1.1<span class="_ _a"> </span><span class="ff1">特殊情形<span class="_ _15"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>20</div><div class="t m0 x5 h6 y1c ff3 fs2 fc0 sc0 ls0 ws0">3.2<span class="_ _4"> </span><span class="ff1">参数估计 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>20</div><div class="t m0 x6 h6 y1d ff3 fs2 fc0 sc0 ls0 ws0">3.2.1<span class="_ _a"> </span><span class="ff1">极大似然估计<span class="_ _b"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>21</div><div class="t m0 x7 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">3</div><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:949.791000px;width:183.751000px;height:20.662000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:924.450000px;width:120.508000px;height:17.216000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:874.861500px;width:106.909000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,662.93,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:838.773000px;width:123.272000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,140.42,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:805.131000px;width:90.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfa" data-dest-detail='[10,"XYZ",70.87,42.52,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:771.487500px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,493.06,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:737.844000px;width:100.363000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,332.06,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:704.202000px;width:101.574000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,42.52,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:670.558500px;width:115.058000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfc" data-dest-detail='[12,"XYZ",70.87,686.75,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:636.915000px;width:100.363000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:588.439500px;width:161.412000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,483.26,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:552.352500px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,268.78,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:518.709000px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",70.87,427.32,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:485.067000px;width:136.723000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",70.87,647.85,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:451.423500px;width:108.512000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",70.87,215.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:417.780000px;width:81.916000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",70.87,725.99,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:384.136500px;width:84.022000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf14" data-dest-detail='[20,"XYZ",70.87,468.1,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:350.494500px;width:101.454000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf16" data-dest-detail='[22,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:270.879000px;width:183.751000px;height:20.663000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf16" data-dest-detail='[22,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:245.640000px;width:68.862000px;height:17.216000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:196.050000px;width:106.909000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,662.85,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:159.963000px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,42.52,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:126.319500px;width:78.545000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf19" data-dest-detail='[25,"XYZ",70.87,624.89,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:92.677500px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf19" data-dest-detail='[25,"XYZ",70.87,39.79,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:59.034000px;width:100.363000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><div class="t m0 x3 h7 y1e ff8 fs4 fc0 sc0 ls0 ws0">目录</div><div class="t m0 x5 h6 y1f ff3 fs2 fc0 sc0 ls0 ws0">3.3<span class="_ _4"> </span><span class="ff1">朴素贝叶斯分类器<span class="_ _15"> </span></span>.<span class="_ _b"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>21</div><div class="t m0 x6 h6 y20 ff3 fs2 fc0 sc0 ls0 ws0">3.3.1<span class="_ _a"> </span><span class="ff1">统计语言模型简述<span class="_ _2"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>21</div><div class="t m0 x6 h6 y21 ff3 fs2 fc0 sc0 ls0 ws0">3.3.2<span class="_ _a"> </span><span class="ff1">朴素贝叶斯<span class="_ _5"> </span></span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>22</div><div class="t m0 x6 h6 y22 ff3 fs2 fc0 sc0 ls0 ws0">3.3.3<span class="_ _a"> </span><span class="ff1">修正<span class="_ _9"> </span></span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>23</div><div class="t m0 x6 h6 y23 ff3 fs2 fc0 sc0 ls0 ws0">3.3.4<span class="_ _a"> </span><span class="ff1">朴素贝叶斯算法的不同方法<span class="_ _16"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>23</div><div class="t m0 x5 h6 y24 ff3 fs2 fc0 sc0 ls0 ws0">3.4<span class="_ _e"> </span>python<span class="_ _c"> </span><span class="ff1">示例<span class="_ _11"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>24</div><div class="t m0 x6 h6 y25 ff3 fs2 fc0 sc0 ls0 ws0">3.4.1<span class="_ _a"> </span><span class="ff1">伯努利朴素贝叶斯的示例<span class="_ _15"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>24</div><div class="t m0 x6 h6 y26 ff3 fs2 fc0 sc0 ls0 ws0">3.4.2<span class="_ _a"> </span><span class="ff1">对比<span class="_ _9"> </span></span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>25</div><div class="t m0 x3 h6 y27 ff4 fs2 fc0 sc0 ls0 ws0">第四章<span class="_ _2"> </span>决策树<span class="_ _17"> </span><span class="ff7">29</span></div><div class="t m0 x3 h5 y28 ff4 fs1 fc0 sc0 ls0 ws0">第三部分 <span class="fs3">机器学习高阶</span></div><div class="t m0 x3 h1 y29 ff5 fs0 fc0 sc0 ls0 ws0">优化方法<span class="_ _13"> </span><span class="ff6 fs1">31</span></div><div class="t m0 x3 h6 y2a ff4 fs2 fc0 sc0 ls0 ws0">第五章<span class="_ _2"> </span>梯度下降<span class="_ _18"> </span><span class="ff7">33</span></div><div class="t m0 x5 h6 y2b ff3 fs2 fc0 sc0 ls0 ws0">5.1<span class="_ _4"> </span><span class="ff1">梯度下降原理<span class="_ _9"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>33</div><div class="t m0 x3 h6 y2c ff4 fs2 fc0 sc0 ls0 ws0">第六章<span class="_ _2"> </span><span class="ff7">Bac<span class="_ _10"></span>kpropagation<span class="_ _19"> </span>35</span></div><div class="t m0 x5 h6 y2d ff3 fs2 fc0 sc0 ls0 ws0">6.1<span class="_ _4"> </span><span class="ff1">神经网络 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>35</div><div class="t m0 x5 h6 y2e ff3 fs2 fc0 sc0 ls0 ws0">6.2<span class="_ _4"> </span><span class="ff1">基本函数 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>35</div><div class="t m0 x5 h6 y2f ff3 fs2 fc0 sc0 ls0 ws0">6.3<span class="_ _4"> </span><span class="ff1">前向传播 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>36</div><div class="t m0 x5 h6 y30 ff3 fs2 fc0 sc0 ls0 ws0">6.4<span class="_ _4"> </span><span class="ff1">反向传播 </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>38</div><div class="t m0 x6 h6 y31 ff3 fs2 fc0 sc0 ls0 ws0">6.4.1<span class="_ _a"> </span><span class="ff1">输出层<span class="_ _0"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>38</div><div class="t m0 x6 h6 y32 ff3 fs2 fc0 sc0 ls0 ws0">6.4.2<span class="_ _a"> </span><span class="ff1">隐藏层<span class="_ _0"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>39</div><div class="t m0 x5 h6 y33 ff3 fs2 fc0 sc0 ls0 ws0">6.5<span class="_ _4"> </span><span class="ff1">权值更新归纳<span class="_ _9"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>39</div><div class="t m0 x3 h5 y34 ff4 fs1 fc0 sc0 ls0 ws0">第四部分 <span class="fs3">神经网络<span class="_ _1a"> </span></span><span class="ff6">41</span></div><div class="t m0 x3 h6 y35 ff4 fs2 fc0 sc0 ls0 ws0">第七章<span class="_ _2"> </span><span class="ff7">Recurren<span class="_ _10"></span>t<span class="_ _11"> </span>Neural<span class="_ _11"> </span>Net<span class="_ _10"></span>w<span class="_ _10"></span>orks<span class="_ _1b"> </span>43</span></div><div class="t m0 x5 h4 y36 ff3 fs2 fc0 sc0 ls0 ws0">7.1<span class="_ _e"> </span>Simple<span class="_ _c"> </span>Recurrent<span class="_ _c"> </span>Net<span class="_ _10"></span>w<span class="_ _10"></span>ork<span class="_ _1c"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>43</div><div class="t m0 x6 h6 y37 ff3 fs2 fc0 sc0 ls0 ws0">7.1.1<span class="_ _a"> </span><span class="ff1">前向传播<span class="_ _15"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>43</div><div class="t m0 x6 h6 y38 ff3 fs2 fc0 sc0 ls0 ws0">7.1.2<span class="_ _a"> </span><span class="ff1">反向传播<span class="_ _15"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>45</div><div class="t m0 x5 h4 y39 ff3 fs2 fc0 sc0 ls0 ws0">7.2<span class="_ _e"> </span>LSTM<span class="_ _5"> </span>.<span class="_ _b"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>46</div><div class="t m0 x6 h6 y3a ff3 fs2 fc0 sc0 ls0 ws0">7.2.1<span class="_ _a"> </span>LSTM<span class="_ _c"> </span><span class="ff1">概述<span class="_ _7"> </span></span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>46</div><div class="t m0 x6 h6 y3b ff3 fs2 fc0 sc0 ls0 ws0">7.2.2<span class="_ _a"> </span>LSTM<span class="_ _c"> </span><span class="ff1">与<span class="_ _c"> </span></span>RNN<span class="_ _c"> </span><span class="ff1">的区别<span class="_ _c"> </span></span>.<span class="_ _b"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>46</div><div class="t m0 x6 h6 y1d ff3 fs2 fc0 sc0 ls0 ws0">7.2.3<span class="_ _a"> </span><span class="ff1">遗忘门<span class="_ _0"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>47</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">4</div><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",70.87,560.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:1177.872000px;width:112.363000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",70.87,464.27,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1144.426500px;width:122.181000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",70.87,531.57,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1110.981000px;width:89.454000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1c" data-dest-detail='[28,"XYZ",70.87,731.28,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1077.537000px;width:56.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1c" data-dest-detail='[28,"XYZ",70.87,243.23,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1044.091500px;width:165.818000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1d" data-dest-detail='[29,"XYZ",70.87,466.86,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:1010.646000px;width:83.891000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1d" data-dest-detail='[29,"XYZ",70.87,408.18,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:977.202000px;width:154.909000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1e" data-dest-detail='[30,"XYZ",70.87,473.97,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:943.756500px;width:56.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf22" data-dest-detail='[34,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:896.272500px;width:74.182000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf24" data-dest-detail='[36,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:815.268000px;width:183.751000px;height:20.662000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf24" data-dest-detail='[36,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:790.129500px;width:68.862000px;height:17.215000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf26" data-dest-detail='[38,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:741.529500px;width:85.091000px;height:10.910000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf26" data-dest-detail='[38,"XYZ",70.87,662.93,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:705.640500px;width:90.545000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:655.630500px;width:133.778000px;height:15.578000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,660.96,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:622.267500px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,391.25,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:588.822000px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf29" data-dest-detail='[41,"XYZ",70.87,664.07,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:555.376500px;width:68.727000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2a" data-dest-detail='[42,"XYZ",70.87,41.41,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:521.932500px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2b" data-dest-detail='[43,"XYZ",70.87,650.79,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:488.487000px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2c" data-dest-detail='[44,"XYZ",70.87,765.85,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:455.043000px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2c" data-dest-detail='[44,"XYZ",70.87,214.25,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:421.597500px;width:90.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2e" data-dest-detail='[46,"XYZ",70.87,568.85,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:343.464000px;width:142.426000px;height:20.663000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf30" data-dest-detail='[48,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:293.067000px;width:194.226000px;height:15.578000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf30" data-dest-detail='[48,"XYZ",70.87,682.86,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:259.704000px;width:151.691000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf30" data-dest-detail='[48,"XYZ",70.87,640.54,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:226.258500px;width:78.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf32" data-dest-detail='[50,"XYZ",70.87,260.69,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:192.813000px;width:78.545000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,665.75,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:159.369000px;width:55.854000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,626.63,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:125.923500px;width:91.123000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,531.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:92.479500px;width:144.600000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf34" data-dest-detail='[52,"XYZ",70.87,398.71,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:59.034000px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><div class="t m0 x6 h6 y1f ff3 fs2 fc0 sc0 ls0 ws0">7.2.4<span class="_ _a"> </span><span class="ff1">输入门<span class="_ _0"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>47</div><div class="t m0 x6 h6 y3c ff3 fs2 fc0 sc0 ls0 ws0">7.2.5<span class="_ _a"> </span><span class="ff1">细胞状态更新<span class="_ _b"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>48</div><div class="t m0 x6 h6 y3d ff3 fs2 fc0 sc0 ls0 ws0">7.2.6<span class="_ _a"> </span><span class="ff1">输出门<span class="_ _0"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _12"> </span>48</div><div class="t m0 x5 h6 y3e ff3 fs2 fc0 sc0 ls0 ws0">7.3<span class="_ _4"> </span><span class="ff1">带窥孔的<span class="_ _c"> </span></span>LSTM<span class="_ _1d"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>48</div><div class="t m0 x5 h4 y3f ff3 fs2 fc0 sc0 ls0 ws0">7.4<span class="_ _e"> </span>GRU<span class="_ _1c"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>48</div><div class="t m0 x3 h6 y40 ff4 fs2 fc0 sc0 ls0 ws0">第八章<span class="_ _2"> </span><span class="ff7">Seq2Seq<span class="_ _1e"> </span>51</span></div><div class="t m0 x5 h4 y41 ff3 fs2 fc0 sc0 ls0 ws0">8.1<span class="_ _e"> </span>Enco<span class="_ _1f"></span>der-Deco<span class="_ _f"></span>der<span class="_ _20"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>51</div><div class="t m0 x5 h4 y42 ff3 fs2 fc0 sc0 ls0 ws0">8.2<span class="_ _e"> </span>Seq2Seq<span class="_ _5"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>52</div><div class="t m0 x5 h6 y43 ff3 fs2 fc0 sc0 ls0 ws0">8.3<span class="_ _e"> </span>Atten<span class="_ _10"></span>tion<span class="_ _c"> </span><span class="ff1">机制<span class="_ _2"> </span></span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _6"> </span>.<span class="_ _7"> </span>.<span class="_ _6"> </span>.<span class="_ _a"> </span>53</div><a class="l" href="#pf34" data-dest-detail='[52,"XYZ",70.87,134.81,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1177.872000px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf35" data-dest-detail='[53,"XYZ",70.87,709.21,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1144.456500px;width:100.363000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf35" data-dest-detail='[53,"XYZ",70.87,559.23,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1111.042500px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf35" data-dest-detail='[53,"XYZ",70.87,381.09,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:1077.627000px;width:103.123000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf35" data-dest-detail='[53,"XYZ",70.87,238.54,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:1044.213000px;width:49.560000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf38" data-dest-detail='[56,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:994.351500px;width:86.411000px;height:15.579000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf38" data-dest-detail='[56,"XYZ",70.87,661.1,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:961.018500px;width:106.974000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,525.87,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:927.604500px;width:63.883000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,29.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:894.189000px;width:96.305000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf6" class="pf w0 h0" data-page-no="6"><div class="pc pc6 w0 h0"><div class="t m0 x8 h5 y44 ff4 fs3 fc0 sc0 ls0 ws0">第一部分</div><div class="t m0 x9 h5 y45 ff4 fs3 fc0 sc0 ls0 ws0">机器学习初步</div><div class="t m0 xa h1 y46 ff5 fs0 fc0 sc0 ls0 ws0">模型选择与评估</div><div class="t m0 x7 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">1</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf7" class="pf w0 h0" data-page-no="7"><div class="pc pc7 w0 h0"></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf8" class="pf w0 h0" data-page-no="8"><div class="pc pc8 w0 h0"><img class="bi xb y47 w1 h8" alt="" src="bg8.png"/><div class="t m0 xc h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第一章 误差与过拟合</div><div class="t m0 xd h9 y48 ff6 fs5 fc0 sc0 ls0 ws0">1.1<span class="_ _21"> </span><span class="ff9">模型的参数和超参数</span></div><div class="t m0 x3 h6 y49 ff1 fs2 fc0 sc0 ls0 ws0">参数<span class="_ _22"></span>（<span class="ff3">parameter</span>）<span class="_ _22"></span>和超参数<span class="_ _22"></span>（<span class="ff3">h<span class="_ _10"></span>yp<span class="_ _f"></span>erparameter<span class="ff1">）<span class="_ _22"></span>在文献中常被混为一谈。<span class="_ _22"></span>研究者经常提到的<span class="_ _22"></span>“调</span></span></div><div class="t m0 x3 h6 y4a ff1 fs2 fc0 sc0 ls0 ws0">参”<span class="_ _23"></span>，实际上是调整超参数。为了防止语言上的混淆，我们首先对两者进行界定。</div><div class="t m0 x3 h6 y4b ff1 fs2 fc0 sc0 ls0 ws0">参数是模型的内部变量，<span class="_ _23"></span>是模型通过学习可以确定的参数。<span class="_ _24"></span>以简单的一元线性回归模型<span class="_ _25"> </span><span class="ffa">y<span class="_ _c"> </span><span class="ffb">=<span class="_ _25"> </span></span>k<span class="_ _1f"></span>x<span class="_ _f"></span><span class="ffb">+<span class="_ _1f"></span></span>b</span></div><div class="t m0 x3 h6 y4c ff1 fs2 fc0 sc0 ls0 ws0">为例，<span class="_ _26"></span>斜率<span class="_ _27"> </span><span class="ffa">k<span class="_ _c"> </span></span>和截距<span class="_ _27"> </span><span class="ffa">b<span class="_ _27"> </span></span>是该模型的参数。<span class="_ _28"></span>支持向量机模型的支持向量，<span class="_ _26"></span>神经网络模型的神经元连</div><div class="t m0 x3 h6 y4d ff1 fs2 fc0 sc0 ls0 ws0">接权值都是模型的参数。对于决策树类的模型而言，每一步分裂的规则也属于模型参数的范畴。</div><div class="t m0 x3 h6 y4e ff1 fs2 fc0 sc0 ls0 ws0">超参数是模型的外部变量，<span class="_ _29"></span>是使用者用来确定模型的参数。<span class="_ _26"></span>假设我们希望采用回归模型对一组自</div><div class="t m0 x3 h6 y4f ff1 fs2 fc0 sc0 ls0 ws0">变量<span class="_ _27"> </span><span class="ffa">x<span class="_ _27"> </span></span>和因变量<span class="_ _25"> </span><span class="ffa">y<span class="_ _c"> </span></span>进行拟合，<span class="_ _2a"></span>究竟使用线性<span class="_ _26"></span>（一次）<span class="_ _28"></span>模型<span class="_ _27"> </span><span class="ffa">y<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span></span>k<span class="_ _f"></span>x<span class="_ _2b"> </span><span class="ffb">+<span class="_ _2b"></span></span>b</span>、<span class="_ _2a"></span>二次模型<span class="_ _27"> </span><span class="ffa">y<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span></span>k</span></div><div class="t m0 xe ha y50 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xe hb y51 ffd fs6 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf h4 y4f ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _2b"></span><span class="ffa">k</span></div><div class="t m0 x10 ha y52 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x11 h6 y4f ffa fs2 fc0 sc0 ls0 ws0">x<span class="_ _2b"> </span><span class="ffb">+<span class="_ _2b"></span></span>b<span class="ff1">、</span></div><div class="t m0 x3 h6 y53 ff1 fs2 fc0 sc0 ls0 ws0">三次模型<span class="_ _27"> </span><span class="ffa">y<span class="_ _c"> </span><span class="ffb">=<span class="_ _2c"> </span></span>k</span></div><div class="t m0 x12 ha y54 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13 hc y53 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x14 ha y55 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x15 h4 y53 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _2d"> </span><span class="ffa">k</span></div><div class="t m0 x16 ha y54 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x17 hc y53 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x18 ha y55 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x19 h4 y53 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _2d"> </span><span class="ffa">k</span></div><div class="t m0 x1a ha y54 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x1b h6 y53 ffa fs2 fc0 sc0 ls0 ws0">x<span class="_ _2d"> </span><span class="ffb">+<span class="_ _2d"> </span></span>b<span class="_ _27"> </span><span class="ff1">或者更高次的回归模型，<span class="_ _22"></span>这里的多项式次数就是模型的超参</span></div><div class="t m0 x3 h6 y56 ff1 fs2 fc0 sc0 ls0 ws0">数。下图展示了对回归模型中参数和超参数的辨析。</div><div class="t m0 x1c h6 y57 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">1.1:<span class="_ _2e"> </span></span>超参数和参数</div><div class="t m0 x3 h6 y58 ff1 fs2 fc0 sc0 ls0 ws0">支持向量机模型中核函数类型、<span class="_ _28"></span>惩罚系数等，<span class="_ _28"></span>随机森林模型的树棵数、<span class="_ _28"></span>最大特征数、<span class="_ _28"></span>剪枝参数等，</div><div class="t m0 x3 h6 y59 ff3 fs2 fc0 sc0 ls0 ws0">X<span class="_ _10"></span>GBo<span class="_ _f"></span>ost<span class="_ _c"> </span><span class="ff1">模型的学习率、<span class="_ _10"></span>最大树深度、<span class="_ _10"></span>行采样比例等、<span class="_ _10"></span>神经网络模型的网络层数、<span class="_ _10"></span>神经元个数、</span></div><div class="t m0 x3 h6 y5a ff1 fs2 fc0 sc0 ls0 ws0">激活函数类型等，这些都属于模型的超参数。</div><div class="t m0 x3 h6 y5b ff1 fs2 fc0 sc0 ls0 ws0">模型<span class="_ _f"></span>的参<span class="_ _f"></span>数<span class="_ _f"></span>可以<span class="_ _f"></span>从<span class="_ _f"></span>训练<span class="_ _f"></span>集<span class="_ _f"></span>学习<span class="_ _f"></span>到，<span class="_ _f"></span>模型<span class="_ _f"></span>的<span class="_ _f"></span>超参<span class="_ _f"></span>数<span class="_ _f"></span>无法<span class="_ _f"></span>从训<span class="_ _f"></span>练<span class="_ _f"></span>集中<span class="_ _f"></span>直<span class="_ _f"></span>接学<span class="_ _f"></span>习<span class="_ _f"></span>到。模<span class="_ _f"></span>型<span class="_ _f"></span>的超<span class="_ _f"></span>参<span class="_ _f"></span>数应</div><div class="t m0 x3 h6 y5c ff1 fs2 fc0 sc0 ls0 ws0">如何学习？<span class="_ _22"></span>在解答这一问题之前，<span class="_ _29"></span>首先要介绍模型超参数选择不当导致的问题—<span class="_ _2f"></span>—欠拟合和过拟</div><div class="t m0 x3 h6 y5d ff1 fs2 fc0 sc0 ls0 ws0">合。</div><div class="t m0 x1d h9 y5e ff6 fs5 fc0 sc0 ls0 ws0">1.2<span class="_ _21"> </span><span class="ff9">误差与过拟合</span></div><div class="t m0 x3 h6 y1d ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">1.1<span class="_ _6"> </span><span class="ff4">误差<span class="_ _11"> </span></span>(error)<span class="ff4">：<span class="ff1">样本的真实值与预测结果之间的差异。</span></span></span></div><div class="t m0 x7 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">3</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf9" class="pf w0 h0" data-page-no="9"><div class="pc pc9 w0 h0"><img class="bi x3 y5f w2 hd" alt="" src="bg9.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">1.2<span class="_ _15"> </span><span class="ff8">误差与过拟合</span></div><div class="t m0 x1e h6 y60 ff1 fs2 fc0 sc0 ls0 ws0">训练误差<span class="_ _c"> </span><span class="ff3">(training<span class="_ _c"> </span>error)</span>：在训练集上的误差，又称为经验误差（<span class="ff3">empirical<span class="_ _c"> </span>error</span>）</div><div class="t m0 x1e h6 y61 ff1 fs2 fc0 sc0 ls0 ws0">测试误差（<span class="ff3">test<span class="_ _c"> </span>error</span>）<span class="_ _23"></span>：在测试集上的误差。</div><div class="t m0 x1e h6 y62 ff1 fs2 fc0 sc0 ls0 ws0">泛化误差（<span class="ff3">generalization<span class="_ _c"> </span>error</span>）<span class="_ _23"></span>：在所有新样本上的误差，<span class="_ _10"></span>即测试误差（测试集的样本都</div><div class="t m0 x1e h6 y63 ff1 fs2 fc0 sc0 ls0 ws0">是新样本）<span class="_ _23"></span>。</div><div class="t m0 x3 h6 y64 ff1 fs2 fc0 sc0 ls0 ws0">训练误差很小是没什么用的，<span class="_ _29"></span>我们希望得到在新样本上表现得很好的学习器，<span class="_ _26"></span>即泛化误差小的学</div><div class="t m0 x3 h6 y65 ff1 fs2 fc0 sc0 ls0 ws0">习器。因此，我们应该让学习器尽可能<span class="_ _f"></span>地从训练集中学出普适性的“一般特征”<span class="_ _30"></span>，这样在遇到新</div><div class="t m0 x3 h6 y66 ff1 fs2 fc0 sc0 ls0 ws0">样本时才能做出正确的判别。<span class="_ _31"></span>然而，<span class="_ _31"></span>当学习器把训练集学得<span class="_ _31"></span>“太好”<span class="_ _2f"></span>的时候，<span class="_ _31"></span>即把一些训练样本</div><div class="t m0 x3 h6 y67 ff1 fs2 fc0 sc0 ls0 ws0">的自身特点当做了普遍特征；<span class="_ _29"></span>同时也有学习能力不足的情况，<span class="_ _26"></span>即训练集的基本特征都没有学习出</div><div class="t m0 x3 h6 y68 ff1 fs2 fc0 sc0 ls0 ws0">来。我们定义：</div><div class="t m0 x3 h6 y69 ff1 fs2 fc0 sc0 ls0 ws0">过拟合（<span class="ff3">o<span class="_ _10"></span>v<span class="_ _10"></span>ertting<span class="ff1">）<span class="_ _23"></span>：当训练误差减小，测试误差增大，则存在过拟合。</span></span></div><div class="t m0 x3 h6 y6a ff1 fs2 fc0 sc0 ls0 ws0">欠拟合（<span class="ff3">undertting</span>）<span class="_ _23"></span>：训练误差和测试误差都在减小，则存在欠拟合。</div><div class="t m0 x1f h6 y6b ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">1.2:<span class="_ _2e"> </span></span>欠拟合与过拟合</div><div class="t m0 x3 h6 y6c ff1 fs2 fc0 sc0 ls0 ws0">可以得知：<span class="_ _31"></span>在过拟合问题中，<span class="_ _31"></span>训练误差十分小，<span class="_ _31"></span>但测试误差教大；<span class="_ _31"></span>在欠拟合问题中，<span class="_ _2f"></span>训练误差和</div><div class="t m0 x3 h6 y6d ff1 fs2 fc0 sc0 ls0 ws0">测试误差都比较大。<span class="_ _31"></span>目前，<span class="_ _22"></span>欠拟合问题比较容易克服，<span class="_ _31"></span>例如增加迭代次数等，<span class="_ _22"></span>但过拟合问题还没</div><div class="t m0 x3 h6 y6e ff1 fs2 fc0 sc0 ls0 ws0">有十分好的解决方案，过拟合是机器学习面临的关键障碍。</div><div class="t m0 x3 h6 y6f ff1 fs2 fc0 sc0 ls0 ws0">对于<span class="_ _f"></span>一<span class="_ _f"></span>般的<span class="_ _f"></span>回<span class="_ _f"></span>归问<span class="_ _f"></span>题，<span class="_ _f"></span>如果<span class="_ _f"></span>我<span class="_ _f"></span>们<span class="_ _f"></span>假设</div><div class="t m0 x2 h4 y70 ff7 fs2 fc0 sc0 ls0 ws0">Y</div><div class="t m0 x20 h4 y6f ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x21 hc y70 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 x22 h4 y6f ffb fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x23 h4 y70 ff7 fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x24 h4 y6f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>+</div><div class="t m0 x25 hc y70 ffa fs2 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 x26 h6 y6f ff1 fs2 fc0 sc0 ls0 ws0">，其<span class="_ _f"></span>中</div><div class="t m0 x27 h4 y70 ff7 fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x28 h4 y6f ffb fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x29 hc y70 ffa fs2 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 x2a h4 y6f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _11"> </span>=<span class="_ _11"> </span>0</div><div class="t m0 x2b h6 y70 ff1 fs2 fc0 sc0 ls0 ws0">，并<span class="_ _f"></span>且</div><div class="t m0 x2c h4 y6f ff7 fs2 fc0 sc0 ls0 ws0">Var</div><div class="t m0 x2d h4 y70 ffb fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x2e hc y6f ffa fs2 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 x2f h4 y70 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _11"> </span>=</div><div class="t m0 x30 hc y6f ffa fs2 fc0 sc0 ls0 ws0">σ</div><div class="t m0 x31 ha y71 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x31 hb y72 ffd fs6 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 x32 h6 y6f ff1 fs2 fc0 sc0 ls0 ws0">。如</div><div class="t m0 x3 h6 y73 ff1 fs2 fc0 sc0 ls0 ws0">果使用均方误差（<span class="ff3">mean<span class="_ _27"> </span>squared<span class="_ _c"> </span>error</span>，<span class="ff3">MSE</span>）来衡量模型拟合程度的优劣的情况下，<span class="_ _10"></span>在输入点</div><div class="t m0 x3 h4 y74 ff7 fs2 fc0 sc0 ls0 ws0">X <span class="ffb">=<span class="_ _2c"> </span><span class="ffa">x</span></span></div><div class="t m0 x33 ha y75 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x34 h6 y74 ff1 fs2 fc0 sc0 ls0 ws0">处，回归拟合值</div><div class="t m0 x35 h4 y76 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x36 h6 y74 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(<span class="ff7">X</span>)<span class="_ _c"> </span><span class="ff1">的均方误差：</span></span></div><div class="t m0 x37 h4 y77 ff3 fs2 fc0 sc0 ls0 ws0">MSE<span class="_ _2d"> </span><span class="ffb">(<span class="ffa">x</span></span></div><div class="t m0 x18 ha y78 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x38 h4 y77 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff3">E</span></div><div class="t m0 x39 he y79 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3a he y7a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3b h4 y77 ffa fs2 fc0 sc0 ls0 ws0">Y<span class="_ _2e"> </span><span class="fff">−</span></div><div class="t m0 x3c h4 y7b ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x3d h4 y77 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2c"> </span><span class="ffb">(</span>x</div><div class="t m0 x3e ha y78 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x21 h4 y77 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3f he y7a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x23 ha y7c ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x40 h4 y77 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">X<span class="_ _0"> </span><span class="ffb">=<span class="_ _2c"> </span></span>x</span></div><div class="t m0 x41 ha y78 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x42 he y79 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x43 h4 y7d ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">σ</span></div><div class="t m0 x44 ha y7e ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x44 hb y7f ffd fs6 fc0 sc0 ls0 ws0">ε</div><div class="t m0 x45 h4 y7d ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x46 he y80 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x1f h4 y7d ff3 fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x47 h4 y81 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x48 h4 y7d ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2c"> </span><span class="ffb">(</span>x</div><div class="t m0 x49 ha y82 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x4a h4 y7d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _25"> </span><span class="fff">−<span class="_ _33"></span><span class="ffa">f<span class="_ _2c"> </span></span></span>(<span class="ffa">x</span></div><div class="t m0 x4b ha y82 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x4c h4 y7d ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x25 he y80 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4d ha y83 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x41 h4 y7d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff3">E</span></div><div class="t m0 x4e he y80 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4f h4 y81 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x50 h4 y7d ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2c"> </span><span class="ffb">(</span>x</div><div class="t m0 x51 ha y82 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x52 h4 y7d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">E</span></span></div><div class="t m0 x53 h4 y81 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x54 h4 y7d ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2c"> </span><span class="ffb">(</span>x</div><div class="t m0 x55 ha y82 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x56 h4 y7d ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x57 he y80 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x58 ha y83 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x43 h4 y84 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">σ</span></div><div class="t m0 x44 ha y85 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x44 hb y86 ffd fs6 fc0 sc0 ls0 ws0">ε</div><div class="t m0 x45 h4 y84 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff3">Bias</span></div><div class="t m0 x8 ha y85 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x0 he y87 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4a h4 y88 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x59 h4 y84 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2c"> </span><span class="ffb">(</span>x</div><div class="t m0 x5a ha y89 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x5b h4 y84 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x5c he y87 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5d h4 y84 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff3">Var</span></div><div class="t m0 x5e he y87 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5f h4 y88 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x60 h4 y84 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2c"> </span><span class="ffb">(</span>x</div><div class="t m0 x61 ha y89 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x28 h4 y84 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x29 he y87 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x43 h4 y8a ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _20"> </span><span class="ff3">Irreducible<span class="_ _c"> </span>Error<span class="_ _9"> </span></span>+<span class="_ _7"> </span><span class="ff3">Bias</span></div><div class="t m0 x62 ha y8b ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x63 h4 y8a ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _9"> </span><span class="ff3">V<span class="_ _31"></span>ariance</span></div><div class="t m0 x32 h4 y8c ff3 fs2 fc0 sc0 ls0 ws0">(1.1)</div><div class="t m0 x1e h6 y8d ff1 fs2 fc0 sc0 ls0 ws0">注意，<span class="_ _31"></span>输入点<span class="_ _c"> </span><span class="ff7">X <span class="ffb">=<span class="_ _2c"> </span><span class="ffa">x</span></span></span></div><div class="t m0 x64 ha y8e ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x35 h6 y8d ff1 fs2 fc0 sc0 ls0 ws0">是固定的，<span class="_ _31"></span><span class="ff7">Y <span class="ffb">=<span class="_ _2c"> </span><span class="ffa">f<span class="_ _32"> </span></span>(</span>X</span></div><div class="t m0 x23 hf y8e ff10 fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x7 h4 y8d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2d"> </span>+<span class="_ _33"> </span><span class="ffa">ϵ<span class="_ _2c"> </span></span>=<span class="_ _27"> </span><span class="ffa">Y</span></div><div class="t m0 x5e ha y8e ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x65 h6 y8d ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _34"></span>，<span class="_ _31"></span><span class="ff7">Y<span class="_ _c"> </span><span class="ff1">也是固定的，<span class="_ _31"></span>即常数。<span class="_ _2f"></span>而不固</span></span></div><div class="t m0 x1e h6 y8f ff1 fs2 fc0 sc0 ls0 ws0">定的是</div><div class="t m0 x66 h4 y90 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x67 h4 y8f ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>x</div><div class="t m0 x68 ha y91 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x69 h6 y8f ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">，显然</span></div><div class="t m0 x6a h4 y90 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x64 h4 y8f ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>x</div><div class="t m0 x43 ha y91 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xd h6 y8f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">不固定的原因是</span></div><div class="t m0 x40 h4 y90 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x5b h6 y8f ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2e"> </span><span class="ff1">是不固定的。</span></div><div class="t m0 x29 h4 y90 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x6b h6 y8f ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2e"> </span><span class="ff1">不固定的原因可能是训练集</span></div><div class="t m0 x1e h6 y92 ff1 fs2 fc0 sc0 ls0 ws0">的不同（训练集不同会导致模型参数不同）<span class="_ _23"></span>，或者模型的函数空间不同。</div><div class="t m0 x1e h6 y93 ff1 fs2 fc0 sc0 ls0 ws0">很多资料<span class="_ _f"></span>在推导均方<span class="_ _f"></span>误差分解<span class="_ _f"></span>公式时，并<span class="_ _f"></span>没有指明<span class="_ _0"> </span><span class="ff7">Y<span class="_ _0"> </span></span>是<span class="_ _f"></span>常数，或者<span class="_ _f"></span>将<span class="_ _0"> </span><span class="ff7">Y<span class="_ _c"> </span><span class="ffb">=<span class="_ _27"> </span><span class="ffa">f<span class="_ _32"> </span></span>(</span>X<span class="ffb">)<span class="_ _0"> </span></span></span>描述为</div><div class="t m0 x1e h6 y94 ff1 fs2 fc0 sc0 ls0 ws0">一个确定的函数，<span class="_ _28"></span>这是造成<span class="_ _27"> </span><span class="ff3">MSE </span>困惑的原因。<span class="_ _22"></span>实际上，<span class="_ _28"></span>确定的函数<span class="_ _22"></span>（参数确定的函数）<span class="_ _22"></span>并</div><div class="t m0 x1e h6 y95 ff1 fs2 fc0 sc0 ls0 ws0">不意味着<span class="_ _c"> </span><span class="ffa">Y<span class="_ _9"> </span></span>值是确定的，<span class="ffa">Y<span class="_ _9"> </span></span>值是否是常数，取决于<span class="_ _27"> </span><span class="ffa">x<span class="_ _c"> </span></span>值是否给定。</div><div class="t m0 x3 h6 y1d ff3 fs2 fc0 sc0 ls0 ws0">V<span class="_ _31"></span>ariance<span class="_ _c"> </span><span class="ff1">代表预测值</span></div><div class="t m0 x6c h4 y96 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x6d h4 y1d ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>x</div><div class="t m0 x6e ha y97 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x6f h6 y1d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">自身的变异性，即过拟合；<span class="ff3">Bias</span></span></div><div class="t m0 x50 ha y98 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x70 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">代表预测值</div><div class="t m0 x55 h4 y96 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x71 h4 y1d ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>x</div><div class="t m0 x58 ha y97 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x72 h6 y1d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">和真实值<span class="_ _c"> </span><span class="ffa">f<span class="_ _32"></span></span></span>(<span class="ffa">x</span></div><div class="t m0 x73 ha y97 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x74 h4 y1d ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">4</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfa" class="pf w0 h0" data-page-no="a"><div class="pc pca w0 h0"><img class="bi x75 y99 w3 h10" alt="" src="bga.png"/><div class="t m0 x76 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">1.2<span class="_ _15"> </span><span class="ff8">误差与过拟合</span></div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">的整体偏离程度，即欠拟合。</div><div class="t m0 x77 h6 y9a ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">1.3:<span class="_ _2e"> </span></span>方差和偏差（训练集不同）</div><div class="t m0 x3 h6 y9b ff1 fs2 fc0 sc0 ls0 ws0">进一<span class="_ _f"></span>步看，<span class="ff3">V<span class="_ _31"></span>ariance<span class="_ _11"> </span><span class="ff1">代<span class="_ _f"></span>表<span class="_ _f"></span>我们<span class="_ _f"></span>使用<span class="_ _f"></span>不同<span class="_ _f"></span>训练<span class="_ _f"></span>集时<span class="_ _f"></span>模型<span class="_ _f"></span>表现<span class="_ _f"></span>的<span class="_ _f"></span>差异。<span class="_ _f"></span>由于<span class="_ _f"></span>模型<span class="_ _f"></span>的构<span class="_ _f"></span>建通<span class="_ _f"></span>常和<span class="_ _f"></span>训练</span></span></div><div class="t m0 x3 h6 y9c ff1 fs2 fc0 sc0 ls0 ws0">集的统计性质有关，<span class="_ _29"></span>不同的训练集会导致模型出现差异。<span class="_ _26"></span>如果某个机器学习方法得到的模型具有</div><div class="t m0 x3 h6 y9d ff1 fs2 fc0 sc0 ls0 ws0">较大的方差，训练集只要有少许变化，模型会有很大的改变。复杂的模型一般具有更大的方差。</div><div class="t m0 x3 h6 y9e ff1 fs2 fc0 sc0 ls0 ws0">第二项偏差代表实际模型与理想模型的差别。<span class="_ _26"></span>例如线性模型是最常用的模型之一，<span class="_ _29"></span>而真实世界往</div><div class="t m0 x3 h6 y9f ff1 fs2 fc0 sc0 ls0 ws0">往是非常复杂的，<span class="_ _22"></span>当我们用线性模型这样的简单模型去解释世界时，<span class="_ _28"></span>很可能会出现问题。<span class="_ _22"></span>如果我</div><div class="t m0 x3 h6 ya0 ff1 fs2 fc0 sc0 ls0 ws0">们用复杂度为<span class="_ _2c"> </span><span class="ff3">2<span class="_ _27"> </span></span>的线性模型<span class="_ _22"></span>（包含截距和斜率两个参数）<span class="_ _26"></span>拟合一个非线性模型<span class="_ _22"></span>（模型复杂度远大</div><div class="t m0 x3 h6 ya1 ff1 fs2 fc0 sc0 ls0 ws0">于<span class="_ _25"> </span><span class="ff3">2</span>）<span class="_ _34"></span>，<span class="_ _24"></span>将产生较大的均方误差，<span class="_ _30"></span>其中很大一部分来源于偏差，<span class="_ _24"></span>这种情况称为欠拟合<span class="_ _35"></span>（<span class="ff3">undertting</span>）<span class="_ _34"></span>。</div><div class="t m0 x3 h6 ya2 ff1 fs2 fc0 sc0 ls0 ws0">当我们不<span class="_ _f"></span>断增加模<span class="_ _f"></span>型的复杂<span class="_ _f"></span>程度，模型<span class="_ _f"></span>的均方误<span class="_ _f"></span>差不断下<span class="_ _0"> </span>降，<span class="_ _f"></span>整体表<span class="_ _f"></span>现逐渐提<span class="_ _f"></span>升，主要原<span class="_ _f"></span>因是</div><div class="t m0 x3 h6 ya3 ff1 fs2 fc0 sc0 ls0 ws0">偏差逐渐下降，<span class="_ _22"></span>说明模型更加符合真实的情况。<span class="_ _22"></span>然而随着模型的复杂程度进一步增加，<span class="_ _28"></span>可以发现</div><div class="t m0 x3 h6 ya4 ff1 fs2 fc0 sc0 ls0 ws0">样本差异导致的方差急剧上升，<span class="_ _29"></span>说明复杂的模型更多地把握住了属于训练样本独有的特性，<span class="_ _26"></span>而非</div><div class="t m0 x3 h6 ya5 ff1 fs2 fc0 sc0 ls0 ws0">数据的共性，<span class="_ _22"></span>这种情况称为过拟合<span class="_ _2f"></span>（<span class="ff3">o<span class="_ _10"></span>v<span class="_ _10"></span>ertting<span class="ff1">）<span class="_ _23"></span>。<span class="_ _31"></span>均方误差、<span class="_ _22"></span>方差和偏差随模型复杂度的变化关</span></span></div><div class="t m0 x3 h6 ya6 ff1 fs2 fc0 sc0 ls0 ws0">系如下图所示。</div><div class="t m0 x78 h6 ya7 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">1.4:<span class="_ _2e"> </span></span>均方误差、方差和偏差随模型复杂度的变化关系（模型的函数空间不同）</div><div class="t m0 x79 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">5</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfb" class="pf w0 h0" data-page-no="b"><div class="pc pcb w0 h0"><img class="bi x7a ya8 w4 h11" alt="" src="bgb.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">1.3<span class="_ _15"> </span><span class="ff8">交叉验证</span></div><div class="t m0 x1c h9 ya9 ff6 fs5 fc0 sc0 ls0 ws0">1.3<span class="_ _21"> </span><span class="ff9">交叉验证</span></div><div class="t m0 x3 h6 yaa ff1 fs2 fc0 sc0 ls0 ws0">避免过拟合的重要方法之一是进行交叉验证<span class="_ _28"></span>（<span class="ff3">cross-v<span class="_ _10"></span>alidation<span class="ff1">）<span class="_ _34"></span>。<span class="_ _26"></span>英国统计学家<span class="_ _27"> </span><span class="ff3">Mervyn<span class="_ _27"> </span>Stone </span>和</span></span></div><div class="t m0 x3 h6 yab ff1 fs2 fc0 sc0 ls0 ws0">美国<span class="_ _f"></span>统计<span class="_ _f"></span>学<span class="_ _f"></span>家<span class="_ _11"> </span><span class="ff3">Seymour<span class="_ _1c"> </span>Geisser<span class="_ _11"> </span></span>是<span class="_ _f"></span>交<span class="_ _f"></span>叉验<span class="_ _f"></span>证理<span class="_ _f"></span>论<span class="_ _f"></span>的先<span class="_ _f"></span>驱。<span class="_ _f"></span>交叉<span class="_ _f"></span>验<span class="_ _f"></span>证理<span class="_ _f"></span>论<span class="_ _f"></span>并非<span class="_ _f"></span>仅针<span class="_ _f"></span>对<span class="_ _f"></span>机器<span class="_ _f"></span>学<span class="_ _f"></span>习模</div><div class="t m0 x3 h6 yac ff1 fs2 fc0 sc0 ls0 ws0">型，<span class="_ _28"></span>而是针对任何统计模型。<span class="_ _22"></span><span class="ff3 fc1">Stone <span class="ff1">和<span class="_ _27"> </span></span>Geisser<span class="_ _27"> </span><span class="ff1">在<span class="_ _c"> </span></span>1974 <span class="ff1">年分别独立地提出，<span class="_ _28"></span>在评价某个统计模型</span></span></div><div class="t m0 x3 h6 yad ff1 fs2 fc1 sc0 ls0 ws0">的表现时，应使用在估计模型环节未使用过的数据。</div><div class="t m0 x26 h6 yae ff1 fs2 fc0 sc0 ls0 ws0">随后</div><div class="t m0 x5f h4 yad ff3 fs2 fc0 sc0 ls0 ws0">Devijv<span class="_ _10"></span>er<span class="_ _c"> </span>Pierre</div><div class="t m0 x7b h6 yae ff1 fs2 fc0 sc0 ls0 ws0">（</div><div class="t m0 x7c h4 yad ff3 fs2 fc0 sc0 ls0 ws0">1982</div><div class="t m0 x7d h6 yae ff1 fs2 fc0 sc0 ls0 ws0">）<span class="_ _23"></span>、</div><div class="t m0 x7e h4 yad ff3 fs2 fc0 sc0 ls0 ws0">K<span class="_ _10"></span>oha<span class="_ _10"></span>vi<span class="_ _c"> </span>Ron</div><div class="t m0 x7f h6 yaf ff1 fs2 fc0 sc0 ls0 ws0">（<span class="ff3">1995</span>）等将交叉验<span class="_ _f"></span>证的思想引入<span class="_ _f"></span>模式识别以及<span class="_ _f"></span>机器学习，在评<span class="_ _f"></span>价机器学习模<span class="_ _f"></span>型表现时，使用<span class="_ _f"></span>不</div><div class="t m0 x3 h6 yb0 ff1 fs2 fc0 sc0 ls0 ws0">曾在训练环节出现过的样本进行验证。<span class="_ _26"></span><span class="fc1">如果模型在验证时性能和训练时大致相同，<span class="_ _29"></span>那么就可以确</span></div><div class="t m0 x3 h6 yb1 ff1 fs2 fc1 sc0 ls0 ws0">信模型真的<span class="_ _2f"></span>“学会”<span class="_ _2f"></span>了如何发现数据中的一般规律，<span class="_ _31"></span>而不是<span class="_ _31"></span>“记住”<span class="_ _2f"></span>训练样本。<span class="_ _31"></span><span class="fc0">这和学生考试的</span></div><div class="t m0 x3 h6 yb2 ff1 fs2 fc0 sc0 ls0 ws0">情形类似，要想考察学生是否掌握了<span class="_ _f"></span>某个知识点，不能使用课堂上讲过的“例<span class="_ _f"></span>题”<span class="_ _23"></span>，而应<span class="_ _f"></span>当使用</div><div class="t m0 x3 h6 yb3 ff1 fs2 fc0 sc0 ls0 ws0">相似的“习题”<span class="_ _23"></span>。</div><div class="t m0 x3 h6 yb4 ff1 fs2 fc0 sc0 ls0 ws0">交叉验证的核心思想是先将全部样本划分成两部分，<span class="_ _22"></span>一部分用来训练模型，<span class="_ _22"></span>称为训练集；<span class="_ _28"></span>另外一</div><div class="t m0 x3 h6 yb5 ff1 fs2 fc0 sc0 ls0 ws0">部分用来验证模型，<span class="_ _28"></span>称为验证集。<span class="_ _22"></span>随后考察模型在训练集和验证集的表现是否接近。<span class="_ _22"></span>如果两者接</div><div class="t m0 x3 h6 yb6 ff1 fs2 fc0 sc0 ls0 ws0">近，<span class="_ _22"></span>说明模型具备较好的预测性能；<span class="_ _22"></span>如果训练集的表现远优于验证集，<span class="_ _28"></span>说明模型存在过拟合的风</div><div class="t m0 x3 h6 yb7 ff1 fs2 fc0 sc0 ls0 ws0">险。</div><div class="t m0 x3 h6 yb8 ff1 fs2 fc0 sc0 ls0 ws0">当我<span class="_ _f"></span>们需<span class="_ _f"></span>要<span class="_ _f"></span>对不<span class="_ _f"></span>同<span class="_ _f"></span>超参<span class="_ _f"></span>数<span class="_ _f"></span>设置<span class="_ _f"></span>下<span class="_ _f"></span>的多<span class="_ _f"></span>个<span class="_ _f"></span>模型<span class="_ _f"></span>进<span class="_ _f"></span>行比<span class="_ _f"></span>较时，<span class="_ _f"></span>可<span class="_ _f"></span>以考<span class="_ _f"></span>察<span class="_ _f"></span>模型<span class="_ _f"></span>在<span class="_ _f"></span>验证<span class="_ _f"></span>集<span class="_ _f"></span>的表<span class="_ _f"></span>现，<span class="_ _f"></span>选择</div><div class="t m0 x3 h6 yb9 ff1 fs2 fc0 sc0 ls0 ws0">验证集表现最优的那组超<span class="_ _f"></span>参数作为最终模型的超参数，<span class="_ _f"></span>这一过程称为调参（<span class="ff3">parameter<span class="_ _0"> </span>tuning</span>）<span class="_ _30"></span>。</div><div class="t m0 x3 h6 yba ff1 fs2 fc0 sc0 ls0 ws0">虽然名为“调参”<span class="_ _23"></span>，本质上是“调超参”<span class="_ _23"></span>。</div><div class="t m0 x3 h6 ybb ff1 fs2 fc0 sc0 ls0 ws0">根据训练集和验证集的划分方式，<span class="_ _28"></span>交叉验证方法又可以细分为简单交叉验证、<span class="_ _28"></span><span class="ff3">K<span class="_ _c"> </span><span class="ff1">折交叉验证、<span class="_ _28"></span>留</span></span></div><div class="t m0 x3 h6 ybc ff1 fs2 fc0 sc0 ls0 ws0">一法、留<span class="_ _c"> </span><span class="ff3">P<span class="_ _c"> </span></span>法和时序交叉验证。</div><div class="t m0 x3 h12 ybd ff6 fs7 fc0 sc0 ls0 ws0">1.3.1<span class="_ _36"> </span><span class="ff9">简单交叉验证</span></div><div class="t m0 x3 h6 ybe ff1 fs2 fc0 sc0 ls0 ws0">从总样本中随机选取一定比例<span class="_ _22"></span>（如<span class="_ _27"> </span><span class="ff3">30%</span>）<span class="_ _31"></span>的样本作为验证集，<span class="_ _26"></span>其余作为训练集。<span class="_ _22"></span>这种方法称为简</div><div class="t m0 x3 h6 ybf ff1 fs2 fc0 sc0 ls0 ws0">单交叉验证，也称为留出法交叉验证（<span class="ff3">hold-out<span class="_ _c"> </span>cross-v<span class="_ _2f"></span>alidation<span class="ff1">）<span class="_ _23"></span>。</span></span></div><div class="t m0 x3 h6 yc0 ff1 fs2 fc0 sc0 ls0 ws0">优点：</div><div class="t m0 x80 h13 yc1 ff3 fs4 fc0 sc0 ls0 ws0">1</div><div class="t m0 x67 h6 yc0 ff1 fs2 fc0 sc0 ls0 ws0">只需要训练一次模型，速度较快。</div><div class="t m0 x3 h6 yc2 ff1 fs2 fc0 sc0 ls0 ws0">缺点：</div><div class="t m0 x34 h13 yc3 ff3 fs4 fc0 sc0 ls0 ws0">1</div><div class="t m0 x67 h6 yc2 ff1 fs2 fc0 sc0 ls0 ws0">一部分数据从未参与训练，可能削弱模型的准确性，<span class="_ _2f"></span>在极端情况下，当验证集中数据</div><div class="t m0 x3 h6 yc4 ff1 fs2 fc0 sc0 ls0 ws0">本身就是整体数据的“噪点”<span class="_ _10"></span>时，<span class="_ _10"></span>模型的准确度将会大大降低。</div><div class="t m0 x81 h13 yc5 ff3 fs4 fc0 sc0 ls0 ws0">2</div><div class="t m0 x82 h6 yc4 ff1 fs2 fc0 sc0 ls0 ws0">最终的模型评价结果可能受</div><div class="t m0 x3 h6 yc6 ff1 fs2 fc0 sc0 ls0 ws0">到训练集和验证集划分过程中的随机因素干扰。</div><div class="t m0 x3 h12 yc7 ff6 fs7 fc0 sc0 ls0 ws0">1.3.2<span class="_ _36"> </span>K<span class="_ _6"> </span><span class="ff9">折交叉验证</span></div><div class="t m0 x3 h6 yc8 ff1 fs2 fc0 sc0 ls0 ws0">针对简单<span class="_ _f"></span>交叉验<span class="_ _f"></span>证的缺<span class="_ _f"></span>陷，研究<span class="_ _f"></span>者提出<span class="_ _11"> </span><span class="ff3">K<span class="_ _0"> </span></span>折交<span class="_ _f"></span>互验证（<span class="_ _f"></span><span class="ff3">K-fold<span class="_ _0"> </span>cross-v<span class="_ _2f"></span>alidation<span class="ff1">）的<span class="_ _f"></span>方法，随机</span></span></div><div class="t m0 x3 h6 yc9 ff1 fs2 fc0 sc0 ls0 ws0">将全体样本分为<span class="_ _27"> </span><span class="ff3">K<span class="_ _27"> </span></span>个部分，<span class="_ _22"></span>每次用其中的一部分作为验证集，<span class="_ _28"></span>其余部分作为训练集。<span class="_ _22"></span>重复<span class="_ _27"> </span><span class="ff3">K<span class="_ _27"> </span></span>次，</div><div class="t m0 x3 h6 yca ff1 fs2 fc0 sc0 ls0 ws0">直到所有部<span class="_ _f"></span>分都被验证<span class="_ _f"></span>过。下图展示<span class="_ _f"></span>了<span class="_ _c"> </span><span class="ff3">5<span class="_ _0"> </span></span>折交<span class="_ _f"></span>互验证的过<span class="_ _f"></span>程，将全体<span class="_ _f"></span>样本随机划<span class="_ _f"></span>分成<span class="_ _0"> </span><span class="ff3">5<span class="_ _c"> </span></span>个<span class="_ _f"></span>不重</div><div class="t m0 x3 h6 ycb ff1 fs2 fc0 sc0 ls0 ws0">叠的部分，每次用<span class="_ _0"> </span><span class="ff3">4/5<span class="_ _0"> </span></span>作为训练集（粉色<span class="_ _f"></span>部分）<span class="_ _30"></span>，其余<span class="_ _0"> </span><span class="ff3">1/5<span class="_ _c"> </span></span>部分<span class="_ _f"></span>作为验证集（灰<span class="_ _f"></span>色部分）<span class="_ _30"></span>。最终</div><div class="t m0 x3 h6 ycc ff1 fs2 fc0 sc0 ls0 ws0">将得到<span class="_ _c"> </span><span class="ff3">5<span class="_ _c"> </span></span>个验证集的均方误差（或其它损失函数形式）<span class="_ _23"></span>，取均值作为验证集的平均表现。</div><div class="t m0 x83 h6 ycd ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">1.5:<span class="_ _37"> </span>K<span class="_ _c"> </span></span>折交叉验证示意图（<span class="ff3">K=5</span>）</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">6</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfc" class="pf w0 h0" data-page-no="c"><div class="pc pcc w0 h0"><img class="bi x75 yce w3 h14" alt="" src="bgc.png"/><div class="t m0 x84 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">1.3<span class="_ _15"> </span><span class="ff8">交叉验证</span></div><div class="t m0 x3 h12 ycf ff6 fs7 fc0 sc0 ls0 ws0">1.3.3<span class="_ _36"> </span><span class="ff9">留一法和留<span class="_ _6"> </span></span>P<span class="_ _7"> </span><span class="ff9">法</span></div><div class="t m0 x3 h6 yd0 ff1 fs2 fc0 sc0 ls0 ws0">除了<span class="_ _f"></span>将<span class="_ _f"></span>样本<span class="_ _f"></span>分<span class="_ _f"></span>成<span class="_ _1c"> </span><span class="ff3">K<span class="_ _11"> </span></span>个<span class="_ _f"></span>部<span class="_ _f"></span>分，还<span class="_ _f"></span>可<span class="_ _f"></span>以<span class="_ _f"></span>每次<span class="_ _f"></span>取<span class="_ _f"></span>一个<span class="_ _f"></span>固<span class="_ _f"></span>定<span class="_ _f"></span>数目<span class="_ _f"></span>的<span class="_ _f"></span>样本<span class="_ _f"></span>作<span class="_ _f"></span>为<span class="_ _f"></span>验证<span class="_ _f"></span>集。<span class="_ _f"></span>假设<span class="_ _f"></span>样<span class="_ _f"></span>本<span class="_ _f"></span>量为<span class="_ _1c"> </span><span class="ff3">N</span>，</div><div class="t m0 x3 h6 yd1 ff1 fs2 fc0 sc0 ls0 ws0">如<span class="_ _f"></span>果<span class="_ _f"></span>每<span class="_ _f"></span>次<span class="_ _f"></span>取<span class="_ _f"></span>一<span class="_ _1f"></span>个<span class="_ _f"></span>样<span class="_ _f"></span>本<span class="_ _f"></span>验<span class="_ _f"></span>证，<span class="_ _f"></span>把<span class="_ _1f"></span>其<span class="_ _f"></span>余<span class="_ _f"></span>样<span class="_ _f"></span>本<span class="_ _f"></span>用<span class="_ _f"></span>来<span class="_ _f"></span>训<span class="_ _1f"></span>练，<span class="_ _f"></span>重<span class="_ _f"></span>复<span class="_ _2e"> </span><span class="ff3">N<span class="_ _2e"> </span></span>次，<span class="_ _f"></span>这<span class="_ _f"></span>种<span class="_ _1f"></span>方<span class="_ _f"></span>法<span class="_ _f"></span>称<span class="_ _f"></span>为<span class="_ _f"></span>留<span class="_ _f"></span>一<span class="_ _f"></span>法<span class="_ _1f"></span>交<span class="_ _f"></span>叉<span class="_ _f"></span>验<span class="_ _f"></span>证</div><div class="t m0 x7f h6 yd2 ff1 fs2 fc0 sc0 ls0 ws0">（<span class="ff3">lea<span class="_ _10"></span>v<span class="_ _10"></span>e-one-out<span class="_ _c"> </span>cross-v<span class="_ _2f"></span>alidation<span class="ff1">，<span class="_ _31"></span><span class="ff3">LOOCV<span class="ff1">）<span class="_ _23"></span>。<span class="_ _2f"></span>还可以每次取<span class="_ _c"> </span><span class="ff3">P<span class="_ _c"> </span></span>个样本验证，<span class="_ _31"></span>重复<span class="_ _c"> </span><span class="ff3">C</span></span></span></span></span></div><div class="t m0 x85 hb yd3 ffd fs6 fc0 sc0 ls0 ws0">P</div><div class="t m0 x85 hb yd4 ffd fs6 fc0 sc0 ls0 ws0">N</div><div class="t m0 x86 h6 yd2 ff1 fs2 fc0 sc0 ls0 ws0">次，<span class="_ _31"></span>这种方</div><div class="t m0 x3 h6 yd5 ff1 fs2 fc0 sc0 ls0 ws0">法称为留<span class="_ _c"> </span><span class="ff3">P<span class="_ _c"> </span></span>法<span class="_ _10"></span>（<span class="ff3">leav<span class="_ _2f"></span>e-p-out<span class="_ _c"> </span>cross-v<span class="_ _2f"></span>alidation<span class="ff1">，</span>LPOCV<span class="ff1">）<span class="_ _34"></span>。留一法和留<span class="_ _c"> </span><span class="ff3">P<span class="_ _c"> </span></span>法适用于样本量较小的</span></span></div><div class="t m0 x3 h6 yd6 ff1 fs2 fc0 sc0 ls0 ws0">情形。<span class="_ _31"></span>当样本量较大时，<span class="_ _22"></span>上述两种方法所需的重复次数较大，<span class="_ _31"></span>运算速度相对较慢，<span class="_ _22"></span>因此通常不采</div><div class="t m0 x3 h6 yd7 ff1 fs2 fc0 sc0 ls0 ws0">用留一法和留<span class="_ _c"> </span><span class="ff3">P<span class="_ _c"> </span></span>法，而是使用<span class="_ _c"> </span><span class="ff3">K<span class="_ _c"> </span></span>折交叉验证。</div><div class="t m0 x3 h12 yd8 ff6 fs7 fc0 sc0 ls0 ws0">1.3.4<span class="_ _36"> </span><span class="ff9">时序交叉验证</span></div><div class="t m0 x3 h6 yd9 ff1 fs2 fc0 sc0 ls0 ws0">以上<span class="_ _f"></span>四种<span class="_ _f"></span>传<span class="_ _f"></span>统交<span class="_ _f"></span>叉<span class="_ _f"></span>验证<span class="_ _f"></span>方法<span class="_ _f"></span>成<span class="_ _f"></span>立的<span class="_ _f"></span>前<span class="_ _f"></span>提是<span class="_ _f"></span>样<span class="_ _f"></span>本服<span class="_ _f"></span>从独<span class="_ _f"></span>立<span class="_ _f"></span>同分<span class="_ _f"></span>布。<span class="_ _f"></span>独立<span class="_ _f"></span>是<span class="_ _f"></span>指样<span class="_ _f"></span>本之<span class="_ _f"></span>间<span class="_ _f"></span>不存<span class="_ _f"></span>在<span class="_ _f"></span>相关</div><div class="t m0 x3 h6 yda ff1 fs2 fc0 sc0 ls0 ws0">性，<span class="_ _29"></span>从一条样本无法推知另一条样本的取值；<span class="_ _26"></span>同分布是指包括训练集和验证集在内的全部样本需</div><div class="t m0 x3 h6 ydb ff1 fs2 fc0 sc0 ls0 ws0">取自同一分布。<span class="_ _31"></span>当样本是时间序列时，<span class="_ _22"></span>数据随时间演进的过程生成，<span class="_ _31"></span>可能包含周期性、<span class="_ _22"></span>过去和未</div><div class="t m0 x3 h6 ydc ff1 fs2 fc0 sc0 ls0 ws0">来数<span class="_ _f"></span>据间<span class="_ _f"></span>相<span class="_ _f"></span>互关<span class="_ _f"></span>系<span class="_ _f"></span>等信<span class="_ _f"></span>息，<span class="_ _f"></span>并不<span class="_ _f"></span>满<span class="_ _f"></span>足交<span class="_ _f"></span>叉<span class="_ _f"></span>验证<span class="_ _f"></span>中<span class="_ _f"></span>数据<span class="_ _f"></span>独立<span class="_ _f"></span>同<span class="_ _f"></span>分布<span class="_ _f"></span>的<span class="_ _f"></span>基本<span class="_ _f"></span>假<span class="_ _f"></span>设。此<span class="_ _f"></span>时<span class="_ _f"></span>如果<span class="_ _f"></span>依<span class="_ _f"></span>然采</div><div class="t m0 x3 h6 ydd ff1 fs2 fc0 sc0 ls0 ws0">用传统交叉验证方法，<span class="_ _22"></span>可能会将未来时刻的数据划入训练集，<span class="_ _22"></span>历史时刻的数据划入验证集，<span class="_ _28"></span>进而</div><div class="t m0 x3 h6 yde ff1 fs2 fc0 sc0 ls0 ws0">出现用未来规律预测历史结果的<span class="_ _31"></span>“作弊”<span class="_ _31"></span>行为。<span class="_ _31"></span>因此需要一种既能保证数据利用率，<span class="_ _22"></span>又能保留时</div><div class="t m0 x3 h6 ydf ff1 fs2 fc0 sc0 ls0 ws0">序数据之间相互关系的交叉验证方法，<span class="_ _22"></span>这就是时序交<span class="_ _c"> </span>叉验证方法<span class="_ _31"></span>（<span class="ff3">time-series<span class="_ _27"> </span>cross-v<span class="_ _2f"></span>alidation<span class="ff1">）<span class="_ _23"></span>，</span></span></div><div class="t m0 x3 h6 ye0 ff1 fs2 fc0 sc0 ls0 ws0">如下图所示。</div><div class="t m0 x46 h6 ye1 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">1.6:<span class="_ _2e"> </span>5<span class="_ _c"> </span></span>折时序交叉验证</div><div class="t m0 x3 h6 ye2 ff1 fs2 fc0 sc0 ls0 ws0">以上图为例说明时序交叉验证方法。<span class="_ _2f"></span>假设样本时间跨度为<span class="_ _27"> </span><span class="ff3">10<span class="_ _c"> </span></span>个月，<span class="_ _2f"></span>采用<span class="_ _27"> </span><span class="ff3">5<span class="_ _c"> </span></span>折时序交叉验证，<span class="_ _2f"></span>那</div><div class="t m0 x3 h6 ye3 ff1 fs2 fc0 sc0 ls0 ws0">么首先<span class="_ _f"></span>将样本<span class="_ _f"></span>等分<span class="_ _f"></span>成<span class="_ _0"> </span><span class="ff3">5<span class="_ _11"> </span></span>个部分。<span class="_ _f"></span>以第<span class="_ _11"> </span><span class="ff3">1<span class="_ _0"> </span>2<span class="_ _11"> </span></span>月数据<span class="_ _f"></span>作为训<span class="_ _f"></span>练集，第<span class="_ _11"> </span><span class="ff3">3<span class="_ _0"> </span>4<span class="_ _11"> </span></span>月作<span class="_ _f"></span>为验证<span class="_ _f"></span>集，进<span class="_ _f"></span>行第<span class="_ _0"> </span><span class="ff3">1</span></div><div class="t m0 x3 h6 ye4 ff1 fs2 fc0 sc0 ls0 ws0">次验证。<span class="_ _2f"></span>再以第<span class="_ _c"> </span><span class="ff3">1<span class="_ _27"> </span>4<span class="_ _c"> </span></span>月数据作为训练集，<span class="_ _2f"></span>第<span class="_ _27"> </span><span class="ff3">5<span class="_ _c"> </span>6<span class="_ _c"> </span></span>月为验证集，<span class="_ _31"></span>进行第<span class="_ _c"> </span><span class="ff3">2<span class="_ _c"> </span></span>次验证。<span class="_ _2f"></span>以此类推，<span class="_ _31"></span>第<span class="_ _c"> </span><span class="ff3">4</span></div><div class="t m0 x3 h6 ye5 ff1 fs2 fc0 sc0 ls0 ws0">次验证以第<span class="_ _c"> </span><span class="ff3">1<span class="_ _c"> </span>8<span class="_ _c"> </span></span>月数据作为训练集，<span class="_ _2f"></span>第<span class="_ _c"> </span><span class="ff3">9<span class="_ _c"> </span>10<span class="_ _c"> </span></span>月作为验证集。再将总共<span class="_ _27"> </span><span class="ff3">4<span class="_ _c"> </span></span>次验证的模型评价指标</div><div class="t m0 x3 h6 ye6 ff1 fs2 fc0 sc0 ls0 ws0">取平<span class="_ _f"></span>均数。<span class="_ _f"></span>时<span class="_ _f"></span>序交<span class="_ _f"></span>叉<span class="_ _f"></span>验证<span class="_ _f"></span>避<span class="_ _f"></span>免了<span class="_ _f"></span>使<span class="_ _f"></span>用未<span class="_ _f"></span>来<span class="_ _f"></span>信息<span class="_ _f"></span>的<span class="_ _f"></span>可能，<span class="_ _f"></span>对于<span class="_ _f"></span>时<span class="_ _f"></span>序数<span class="_ _f"></span>据<span class="_ _f"></span>的机<span class="_ _f"></span>器<span class="_ _f"></span>学习<span class="_ _f"></span>而<span class="_ _f"></span>言是<span class="_ _f"></span>较<span class="_ _f"></span>为合</div><div class="t m0 x3 h6 ye7 ff1 fs2 fc0 sc0 ls0 ws0">理的选择。</div><div class="t m0 x3 h6 ye8 ff3 fs2 fc0 sc0 ls0 ws0">T<span class="_ _31"></span>ashman<span class="ff1">（</span>2000<span class="ff1">）<span class="_ _35"></span>、<span class="ff3">V<span class="_ _31"></span>arma<span class="_ _11"> </span><span class="ff1">和<span class="_ _11"> </span></span>Simon<span class="ff1">（</span>2006<span class="ff1">）<span class="_ _f"></span>和<span class="_ _11"> </span></span>Bergmeir<span class="_ _11"> </span><span class="ff1">和<span class="_ _1c"> </span></span>Benitez<span class="ff1">（</span>2012<span class="ff1">）等<span class="_ _f"></span>研究<span class="_ _f"></span>表<span class="_ _f"></span>明，时</span></span></span></div><div class="t m0 x3 h6 ye9 ff1 fs2 fc0 sc0 ls0 ws0">序交叉验<span class="_ _f"></span>证方法<span class="_ _f"></span>在时序<span class="_ _f"></span>数据上<span class="_ _f"></span>的表现<span class="_ _f"></span>优于传<span class="_ _f"></span>统交叉<span class="_ _f"></span>验证方<span class="_ _f"></span>法。时序<span class="_ _f"></span>特性是<span class="_ _f"></span>金融数<span class="_ _f"></span>据的典<span class="_ _f"></span>型特征，</div><div class="t m0 x3 h6 yea ff1 fs2 fc0 sc0 ls0 ws0">然而时序交叉验证在投资领域的效果尚没有被系统性地测试。</div><div class="t m0 x79 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">7</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfd" class="pf w0 h0" data-page-no="d"><div class="pc pcd w0 h0"><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">1.3<span class="_ _15"> </span><span class="ff8">交叉验证</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">8</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfe" class="pf w0 h0" data-page-no="e"><div class="pc pce w0 h0"><img class="bi x43 yeb w5 h15" alt="" src="bge.png"/><div class="t m0 x69 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第二章 性能度量——模型的好坏</div><div class="t m0 x3 h6 yec ff1 fs2 fc0 sc0 ls0 ws0">好<span class="_ _f"></span>了，<span class="_ _1f"></span>经<span class="_ _f"></span>过<span class="_ _1f"></span>对<span class="_ _f"></span>原<span class="_ _1f"></span>始<span class="_ _f"></span>数<span class="_ _1f"></span>据<span class="_ _f"></span>集<span class="_ _f"></span>进<span class="_ _1f"></span>行<span class="_ _f"></span>有<span class="_ _1f"></span>效<span class="_ _f"></span>划<span class="_ _1f"></span>分，<span class="_ _f"></span>我<span class="_ _1f"></span>们<span class="_ _f"></span>得<span class="_ _1f"></span>到<span class="_ _f"></span>了<span class="_ _1f"></span>训<span class="_ _f"></span>练<span class="_ _1f"></span>集<span class="_ _f"></span>和<span class="_ _1f"></span>测<span class="_ _f"></span>试<span class="_ _1f"></span>集。<span class="_ _f"></span>那<span class="_ _1f"></span>么<span class="_ _f"></span>现<span class="_ _1f"></span>在<span class="_ _f"></span>的<span class="_ _1f"></span>问<span class="_ _f"></span>题<span class="_ _1f"></span>就<span class="_ _f"></span>是：</div><div class="t m0 x3 h6 yed ff1 fs2 fc0 sc0 ls0 ws0">如何<span class="_ _f"></span>衡量<span class="_ _f"></span>模<span class="_ _f"></span>型泛<span class="_ _f"></span>化<span class="_ _f"></span>能力<span class="_ _f"></span>呢？<span class="_ _f"></span>也就<span class="_ _f"></span>是<span class="_ _f"></span>模型<span class="_ _f"></span>的<span class="_ _f"></span>泛化<span class="_ _f"></span>能<span class="_ _f"></span>力的<span class="_ _f"></span>评价<span class="_ _f"></span>需<span class="_ _f"></span>要人<span class="_ _f"></span>为<span class="_ _f"></span>制定<span class="_ _f"></span>标<span class="_ _f"></span>准，这<span class="_ _f"></span>就<span class="_ _f"></span>是性<span class="_ _f"></span>能<span class="_ _f"></span>度量</div><div class="t m0 x3 h6 yee ff3 fs2 fc0 sc0 ls0 ws0">(p<span class="_ _f"></span>erformance<span class="_ _c"> </span>measure)<span class="ff1">。</span></div><div class="t m0 x3 h6 yef ff1 fs2 fc1 sc0 ls0 ws0">衡量模型泛化能力也就是计算模型的测试误差<span class="fc0">，性能度量也就是测试误差的具体实例。</span></div><div class="t m0 x3 h6 yf0 ff1 fs2 fc0 sc0 ls0 ws0">性能度量反映了任务需求，<span class="_ _29"></span>在对比不同模型的能力时，<span class="_ _26"></span>使用不同的性能度量往往会导致不同的评</div><div class="t m0 x3 h6 yf1 ff1 fs2 fc0 sc0 ls0 ws0">判结果。<span class="_ _22"></span>也就是模型的好坏并不是绝对的，<span class="_ _22"></span>这视不同的性能度量而定，<span class="_ _28"></span>而选取什么样的性能度量</div><div class="t m0 x3 h6 yf2 ff1 fs2 fc0 sc0 ls0 ws0">取决于任务需求。</div><div class="t m0 x3 h6 yf3 ff1 fs2 fc0 sc0 ls0 ws0">以下介绍常见的性能度量。</div><div class="t m0 x3 h6 yf4 ff1 fs2 fc0 sc0 ls0 ws0">在预测任务中，<span class="_ _28"></span>给定样本集<span class="_ _27"> </span><span class="ffa">D<span class="_ _c"> </span><span class="ffb">=<span class="_ _2c"> </span><span class="fff">{</span>(</span>x</span></div><div class="t m0 x87 hb yf5 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1c hc yf4 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>y</div><div class="t m0 x8 hb yf5 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x88 h6 yf4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="fff">} <span class="ffa">i<span class="_ _2c"> </span></span></span>=<span class="_ _2c"> </span>1<span class="ffa">,<span class="_ _2d"> </span></span>2<span class="ffa">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2d"> </span>m<span class="ff1">，<span class="_ _28"></span>其中<span class="_ _27"> </span><span class="ffa">y</span></span></span></div><div class="t m0 x89 hb yf5 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x8a h6 yf4 ff1 fs2 fc0 sc0 ls0 ws0">是实例<span class="_ _27"> </span><span class="ffa">x</span></div><div class="t m0 x58 hb yf5 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x8b h6 yf4 ff1 fs2 fc0 sc0 ls0 ws0">的真实<span class="_ _27"> </span><span class="ff3">lab<span class="_ _f"></span>el</span>。<span class="_ _22"></span>要</div><div class="t m0 x3 h6 yf6 ff1 fs2 fc0 sc0 ls0 ws0">评估学习器<span class="_ _c"> </span><span class="ffa">f<span class="_ _2e"> </span></span>的性能，就要把学习器预测结果<span class="_ _c"> </span><span class="ffa">f<span class="_ _32"></span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _c"> </span></span></span>与真实<span class="_ _c"> </span><span class="ff3">lab<span class="_ _f"></span>el<span class="_ _c"> </span><span class="ffa">y<span class="_ _0"> </span></span></span>进行比较。</div><div class="t m0 x1c h9 yf7 ff6 fs5 fc0 sc0 ls0 ws0">2.1<span class="_ _21"> </span><span class="ff9">均方误差</span></div><div class="t m0 x3 h6 yf8 ff1 fs2 fc0 sc0 ls0 ws0">在回归任务中，<span class="_ _31"></span>即预测连续值的问题，<span class="_ _2f"></span>最常用的性能度量是<span class="_ _2f"></span>“均方误差”<span class="_ _34"></span>（<span class="ff3">mean<span class="_ _c"> </span>squared<span class="_ _27"> </span>error</span>）<span class="_ _23"></span>。</div><div class="t m0 x8c h4 yf9 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _1f"></span><span class="ffb">(</span>f<span class="_ _32"></span><span class="ffb">;<span class="_ _2d"> </span></span>D<span class="_ _f"></span><span class="ffb">)<span class="_ _2c"> </span>=</span></div><div class="t m0 x8d h4 yfa ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8e hc yfb ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x7 hb yfc ffd fs6 fc0 sc0 ls0 ws0">m</div><div class="t m0 x8f he yfd ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x90 ha yfe ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x91 h4 yf9 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _2c"> </span></span>(<span class="ff11">x</span></div><div class="t m0 x92 hb yff ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x93 h4 yf9 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">y</span></span></div><div class="t m0 x94 hb yff ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x95 h4 yf9 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x96 ha y100 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x32 h4 yf9 ff3 fs2 fc0 sc0 ls0 ws0">(2.1)</div><div class="t m0 x3 h6 y101 ff1 fs2 fc0 sc0 ls0 ws0">更一般的，对于数据分布<span class="_ _c"> </span><span class="fff">D<span class="_ _0"> </span></span>和概率密度函数<span class="_ _c"> </span><span class="ffa">p<span class="ffb">(<span class="fff">·</span>)</span></span>，均方误差可描为：</div><div class="t m0 x97 h4 y102 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _1f"></span><span class="ffb">(</span>f<span class="_ _32"></span><span class="ffb">;<span class="_ _2d"> </span><span class="fff">D<span class="_ _f"></span></span>)<span class="_ _2c"> </span>=</span></div><div class="t m0 x20 he y103 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4a h16 y104 ff11 fs6 fc0 sc0 ls0 ws0">x</div><div class="t m0 x8e ha y105 ff12 fs6 fc0 sc0 ls0 ws0">∼D</div><div class="t m0 x90 h4 y102 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _32"></span></span>(<span class="ff11">x</span>)<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">y<span class="_ _f"></span></span></span>)</div><div class="t m0 x65 ha y106 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x5f h4 y102 ffa fs2 fc0 sc0 ls0 ws0">p<span class="ffb">(<span class="ff11">x</span>)<span class="ff3">d<span class="ff11">x<span class="_ _38"> </span></span>(2.2)</span></span></div><div class="t m0 x3 h6 y107 ff1 fs2 fc1 sc0 ls0 ws0">均方误差在数理统计中说过了，<span class="_ _29"></span>这里再强调一下：<span class="_ _26"></span>均方误差是反映估计量与被估计量之间差异程</div><div class="t m0 x3 h6 y108 ff1 fs2 fc1 sc0 ls0 ws0">度的一种度量。当估计量是无偏时，均方误差就是方差。</div><div class="t m0 x1c h9 y109 ff6 fs5 fc0 sc0 ls0 ws0">2.2<span class="_ _21"> </span><span class="ff9">混淆矩阵</span></div><div class="t m0 x3 h6 y10a ff1 fs2 fc0 sc0 ls0 ws0">对于二分类问题，分类结果混淆矩阵如下：</div><div class="t m0 x3c h6 y10b ff1 fs2 fc0 sc0 ls0 ws0">表<span class="_ _c"> </span><span class="ff3">2.1:<span class="_ _2e"> </span></span>混淆矩阵</div><div class="t m0 x98 h6 y10c ff1 fs2 fc0 sc0 ls0 ws0">真实情况</div><div class="t m0 x99 h6 y10d ff1 fs2 fc0 sc0 ls0 ws0">预测结果</div><div class="t m0 x8d h6 y10e ff1 fs2 fc0 sc0 ls0 ws0">正例<span class="_ _39"> </span>反例</div><div class="t m0 x44 h6 y10f ff1 fs2 fc0 sc0 ls0 ws0">正例<span class="_ _3a"> </span><span class="ff3">TP(</span>真正例<span class="ff3">)<span class="_ _a"> </span>FN(</span>假反例<span class="ff3">)</span></div><div class="t m0 x44 h6 y110 ff1 fs2 fc0 sc0 ls0 ws0">反例<span class="_ _3b"> </span><span class="ff3">FP(</span>假正例<span class="ff3">)<span class="_ _a"> </span>TN(</span>真反例<span class="ff3">)</span></div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">对于二分类问题，<span class="_ _31"></span>样本被分为了正类和负类，<span class="_ _22"></span>其预测结果也只有两种：<span class="_ _31"></span>正类或负类，<span class="_ _22"></span>因此可以将</div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">所有样本分为四类：</div><div class="t m0 x7 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">9</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pff" class="pf w0 h0" data-page-no="f"><div class="pc pcf w0 h0"><img class="bi x4 y112 w6 h17" alt="" src="bgf.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">2.3<span class="_ _15"> </span>ERR<span class="_ _10"></span>OR<span class="_ _27"> </span>RA<span class="_ _2f"></span>TE<span class="_ _27"> </span><span class="ff8">与<span class="_ _27"> </span></span>ACCURA<span class="_ _2f"></span>CY</div><div class="t m0 x9a h6 y1f ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span>T<span class="_ _31"></span>rue<span class="_ _c"> </span>Positiv<span class="_ _2f"></span>e<span class="ff1">：实际为正类，预测结果也是正类，也称真阳性或者命中<span class="_ _c"> </span></span>(Hit)<span class="ff1">。</span></div><div class="t m0 x9a h6 y113 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span>T<span class="_ _31"></span>rue<span class="_ _c"> </span>Negative<span class="ff1">：实际为负类，预测结果也是负类，也称真阴性或者正确拒绝<span class="_ _0"> </span></span>(Correct<span class="_ _c"> </span>Re-</div><div class="t m0 x9b h6 y114 ff3 fs2 fc0 sc0 ls0 ws0">jection)<span class="ff1">。</span></div><div class="t m0 x9a h6 y115 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span>F<span class="_ _31"></span>alse<span class="_ _c"> </span>P<span class="_ _10"></span>ositiv<span class="_ _10"></span>e<span class="ff1">：<span class="_ _2f"></span>实际为负类，<span class="_ _2f"></span>预测结果却是正类，<span class="_ _2f"></span>也称伪阳性或假警报<span class="_ _c"> </span><span class="ff3">(F<span class="_ _31"></span>alse<span class="_ _c"> </span>Alarm)<span class="ff1">，<span class="_ _2f"></span>指</span></span></span></div><div class="t m0 x9b h6 y116 ff1 fs2 fc0 sc0 ls0 ws0">代统计学第一型错误<span class="_ _c"> </span><span class="ff3">(T<span class="_ _10"></span>yp<span class="_ _f"></span>e<span class="_ _c"> </span>I<span class="_ _c"> </span>Error)<span class="ff1">。</span></span></div><div class="t m0 x9a h6 y117 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span>F<span class="_ _31"></span>alse<span class="_ _c"> </span>Negativ<span class="_ _10"></span>e<span class="ff1">：<span class="_ _31"></span>实际为正类，<span class="_ _31"></span>预测结果却是负类，<span class="_ _2f"></span>也称伪阴性或未命中<span class="_ _c"> </span><span class="ff3">(Miss)</span>，<span class="_ _31"></span>指代统计</span></div><div class="t m0 x9b h6 y118 ff1 fs2 fc0 sc0 ls0 ws0">学第二型错误<span class="_ _c"> </span><span class="ff3">(T<span class="_ _10"></span>yp<span class="_ _f"></span>e<span class="_ _c"> </span>I<span class="_ _f"></span>I<span class="_ _c"> </span>Error)<span class="ff1">。</span></span></div><div class="t m0 x3 h6 y119 ff1 fs2 fc0 sc0 ls0 ws0">进一步，<span class="_ _29"></span>为了更好的理解这种样本分类，<span class="_ _26"></span>我们还可以按照三种不同的方法将这四种类别归为两大</div><div class="t m0 x3 h6 y11a ff1 fs2 fc0 sc0 ls0 ws0">类：</div><div class="t m0 x3 h6 y11b ff4 fs2 fc0 sc0 ls0 ws0">按照预测结果是否正确进行归类：</div><div class="t m0 x9a h6 y11c ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _6"> </span><span class="ff1">预测正确的样本：</span>TP<span class="_ _c"> </span>+<span class="_ _c"> </span>TN</div><div class="t m0 x9a h6 y11d ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff1">预测错误的样本：</span>FN<span class="_ _c"> </span>+<span class="_ _c"> </span>FP</div><div class="t m0 x3 h6 y11e ff4 fs2 fc0 sc0 ls0 ws0">按照样本的实际类别进行归类：</div><div class="t m0 x9a h6 y11f ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _6"> </span><span class="ff1">实际类别为正类的样本：</span>TP<span class="_ _c"> </span>+<span class="_ _c"> </span>FN</div><div class="t m0 x9a h6 y120 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff1">实际类别为负类的样本：</span>TN<span class="_ _c"> </span>+<span class="_ _c"> </span>FP</div><div class="t m0 x3 h6 y121 ff4 fs2 fc0 sc0 ls0 ws0">按照样本的预测类别进行归类：</div><div class="t m0 x9a h6 y122 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _6"> </span><span class="ff1">预测为正类的样本：</span></div><div class="t m0 x6f h4 y123 ff3 fs2 fc0 sc0 ls0 ws0">TP<span class="_ _c"> </span>+<span class="_ _c"> </span>FP</div><div class="t m0 x9a h6 y124 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff1">预测为负类的样本：</span>TN<span class="_ _c"> </span>+<span class="_ _c"> </span>FN</div><div class="t m0 x3 h6 y125 ff1 fs2 fc1 sc0 ls0 ws0">下面介绍的性能度量，<span class="_ _31"></span>用于从不同的侧面对模型进行描述，<span class="_ _31"></span>其共同之处是都是由<span class="_ _c"> </span><span class="ff3">TP</span>、<span class="_ _31"></span><span class="ff3">TN<span class="ff1">、<span class="_ _2f"></span><span class="ff3">FP<span class="ff1">、</span></span></span></span></div><div class="t m0 x3 h6 y126 ff3 fs2 fc1 sc0 ls0 ws0">FN<span class="_ _c"> </span><span class="ff1">中的部分或全部所组成的表达式。</span></div><div class="t m0 x6a h9 y127 ff6 fs5 fc0 sc0 ls0 ws0">2.3<span class="_ _21"> </span>Error<span class="_ _9"> </span>Rate<span class="_ _7"> </span><span class="ff9">与<span class="_ _9"> </span></span>accuracy</div><div class="t m0 x3 h6 y128 ff1 fs2 fc0 sc0 ls0 ws0">在分类任务中，即预测离散值的问题，最常用的是错误率和精度。</div><div class="t m0 x3 h6 y129 ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">2.1<span class="_ _6"> </span>Error<span class="_ _11"> </span>Rate(<span class="ff4">错误率</span>)<span class="ff4">：<span class="ff1">分类错误的样本数占样本总数的比例。</span></span></span></div><div class="t m0 x3 h6 y12a ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">2.2<span class="_ _6"> </span>accuracy(<span class="ff4">精度，准确率</span>)<span class="ff4">：<span class="ff1">分类正确的样本数占样本总数的比例，简记为<span class="_ _c"> </span><span class="ffa">AC<span class="_ _1f"></span>C<span class="_ _32"></span></span>。</span></span></span></div><div class="t m0 x3 h6 y12b ff1 fs2 fc0 sc0 ls0 ws0">一般来说，<span class="_ _28"></span>说到<span class="_ _c"> </span><span class="ff3">accuracy</span>，<span class="_ _28"></span>指的都是总的准确率，<span class="_ _22"></span>但实际上，<span class="_ _28"></span>不仅可以计算出总分类的<span class="_ _27"> </span><span class="ff3">accuracy</span></div><div class="t m0 x3 h6 y12c ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _c"> </span><span class="ff3">Error<span class="_ _c"> </span>Rate</span>，也可以计算出各分类的<span class="_ _c"> </span><span class="ff3">accuracy<span class="_ _c"> </span></span>和<span class="_ _c"> </span><span class="ff3">Error<span class="_ _c"> </span>Rate</span>。</div><div class="t m0 x3 h6 y12d ff4 fs2 fc0 sc0 ls0 ws0">以下是总分类情形下的定义：</div><div class="t m0 x3 h6 y12e ff1 fs2 fc0 sc0 ls0 ws0">错误率定义为：</div><div class="t m0 x9c h4 y12f ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _1f"></span><span class="ffb">(</span>f<span class="_ _32"></span><span class="ffb">;<span class="_ _2d"> </span></span>D<span class="_ _f"></span><span class="ffb">)<span class="_ _2c"> </span>=</span></div><div class="t m0 x21 h4 y130 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4 hc y131 ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x5b hb y132 ffd fs6 fc0 sc0 ls0 ws0">m</div><div class="t m0 x5a he y133 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x8f ha y134 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x5d h4 y12f ff13 fs2 fc0 sc0 ls0 ws0">I<span class="_ _2d"> </span><span class="ffb">(<span class="ffa">f<span class="_ _2c"> </span></span>(<span class="ff11">x</span></span></div><div class="t m0 x5e hb y135 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x62 h4 y12f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff"≯</span>=<span class="_ _2c"> </span><span class="ffa">y</span></div><div class="t m0 x9d hb y135 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x28 h4 y12f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _3c"> </span><span class="ff3">(2.3)</span></div><div class="t m0 x3 h6 y136 ff1 fs2 fc0 sc0 ls0 ws0">正确率定义为：</div><div class="t m0 x9e h4 y137 ff3 fs2 fc0 sc0 ls0 ws0">acc<span class="ffb">(<span class="ffa">f<span class="_ _32"></span></span>;<span class="_ _2d"> </span><span class="ffa">D </span>)<span class="_ _27"> </span>=</span></div><div class="t m0 x1 h4 y138 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8d hc y139 ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x40 hb y13a ffd fs6 fc0 sc0 ls0 ws0">m</div><div class="t m0 x9f he y13b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5b ha y13c ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 xa0 h4 y137 ff13 fs2 fc0 sc0 ls0 ws0">I<span class="_ _2d"> </span><span class="ffb">(<span class="ffa">f<span class="_ _2c"> </span></span>(<span class="ff11">x</span></span></div><div class="t m0 x62 hb y13d ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x60 h4 y137 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ffa">y</span></div><div class="t m0 x28 hb y13d ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa1 h4 y137 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x49 h4 y13e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>1<span class="_ _25"> </span><span class="fff">−<span class="_ _33"></span><span class="ffa">E<span class="_ _1f"></span></span></span>(<span class="ffa">f<span class="_ _32"> </span></span>;<span class="_ _2d"> </span><span class="ffa">D<span class="_ _f"></span></span>)</div><div class="t m0 x32 h4 y13f ff3 fs2 fc0 sc0 ls0 ws0">(2.4)</div><div class="t m0 x3 h6 y140 ff1 fs2 fc0 sc0 ls0 ws0">更一般的，对于数据分布<span class="_ _c"> </span><span class="fff">D<span class="_ _0"> </span></span>和概率密度函数<span class="_ _c"> </span><span class="ffa">p<span class="ffb">(<span class="fff">·</span>)<span class="_ _c"> </span></span></span>，错误率与精度可分别描述为：</div><div class="t m0 xa2 h4 y141 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _1f"></span><span class="ffb">(</span>f<span class="_ _32"></span><span class="ffb">;<span class="_ _2d"> </span><span class="fff">D<span class="_ _f"></span></span>)<span class="_ _2c"> </span>=</span></div><div class="t m0 x88 he y142 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 ha y143 ff11 fs6 fc0 sc0 ls0 ws0">x<span class="ff12">∼D</span></div><div class="t m0 xa3 h4 y141 ff13 fs2 fc0 sc0 ls0 ws0">I<span class="ffb">(<span class="ffa">f<span class="_ _32"></span></span>(<span class="ff11">x</span>)<span class="_ _2c"> </span><span class="fff"≯</span>=<span class="_ _2c"> </span><span class="ffa">y<span class="_ _1f"></span></span>)<span class="ffa">p</span>(<span class="ff11">x</span>)<span class="ff3">d<span class="ff11">x</span></span></span></div><div class="t m0 x32 h4 y144 ff3 fs2 fc0 sc0 ls0 ws0">(2.5)</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">10</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf10" class="pf w0 h0" data-page-no="10"><div class="pc pc10 w0 h0"><img class="bi x46 y145 w7 h18" alt="" src="bg10.png"/><div class="t m0 xa4 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">2.4<span class="_ _15"> </span>PRECISION<span class="ff8">、</span>RECALL</div><div class="t m0 xa5 h4 y146 ff3 fs2 fc0 sc0 ls0 ws0">acc<span class="ffb">(<span class="ffa">f<span class="_ _32"></span></span>;<span class="_ _2d"> </span><span class="fff">D</span>)<span class="_ _27"> </span>=</span></div><div class="t m0 xa6 he y147 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3e ha y148 ff11 fs6 fc0 sc0 ls0 ws0">x<span class="ff12">∼D</span></div><div class="t m0 x7 h4 y146 ff13 fs2 fc0 sc0 ls0 ws0">I<span class="ffb">(<span class="ffa">f<span class="_ _32"></span></span>(<span class="ff11">x</span>)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ffa">y<span class="_ _1f"></span></span>)<span class="ffa">p</span>(<span class="ff11">x</span>)<span class="ff3">d<span class="ff11">x</span></span></span></div><div class="t m0 x8 h4 y149 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>1<span class="_ _25"> </span><span class="fff">−<span class="_ _33"></span><span class="ffa">E<span class="_ _1f"></span></span></span>(<span class="ffa">f<span class="_ _32"> </span></span>;<span class="_ _2d"> </span><span class="fff">D<span class="_ _f"></span></span>)</div><div class="t m0 x32 h4 y14a ff3 fs2 fc0 sc0 ls0 ws0">(2.6)</div><div class="t m0 x3 h6 y14b ff4 fs2 fc0 sc0 ls0 ws0">以下是各分类情形下的定义：</div><div class="t m0 x3 h6 y14c ff1 fs2 fc0 sc0 ls0 ws0">根据混淆矩阵<span class="_ _c"> </span><span class="ff3">(</span>表<span class="ff3">2.1)</span>，各分类的错误率和准确率定义如下：</div><div class="t m0 x64 hc y14d ffa fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x35 hb y14e ffd fs6 fc0 sc0 ls0 ws0">P</div><div class="t m0 xa7 h4 y14d ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _32"></span></span>;<span class="_ _2d"> </span><span class="ffa">D </span>)<span class="_ _27"> </span>=</div><div class="t m0 xa8 hc y14f ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>N</div><div class="t m0 xa9 h4 y150 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P<span class="_ _0"> </span><span class="ffb">+<span class="_ _25"> </span></span>F<span class="_ _2b"> </span>N</div><div class="t m0 xaa hc y14d ffa fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x4d hb y14e ffd fs6 fc0 sc0 ls0 ws0">N</div><div class="t m0 xab h4 y14d ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _32"></span></span>;<span class="_ _2d"> </span><span class="ffa">D </span>)<span class="_ _27"> </span>=</div><div class="t m0 xac hc y14f ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _2b"> </span>P</div><div class="t m0 x2a h4 y150 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>N<span class="_ _c"> </span><span class="ffb">+<span class="_ _25"> </span></span>F<span class="_ _32"> </span>P</div><div class="t m0 xad hc y151 ffa fs2 fc0 sc0 ls0 ws0">acc</div><div class="t m0 xae hb y152 ffd fs6 fc0 sc0 ls0 ws0">P</div><div class="t m0 x35 h4 y151 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _32"></span></span>;<span class="_ _2d"> </span><span class="ffa">D </span>)<span class="_ _27"> </span>=</div><div class="t m0 x2 hc y153 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P</div><div class="t m0 x46 h4 y154 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P<span class="_ _0"> </span><span class="ffb">+<span class="_ _25"> </span></span>F<span class="_ _2b"> </span>N</div><div class="t m0 x91 hc y151 ffa fs2 fc0 sc0 ls0 ws0">acc</div><div class="t m0 x4d hb y152 ffd fs6 fc0 sc0 ls0 ws0">N</div><div class="t m0 xab h4 y151 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _32"></span></span>;<span class="_ _2d"> </span><span class="ffa">D </span>)<span class="_ _27"> </span>=</div><div class="t m0 xac hc y153 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>N</div><div class="t m0 x2a h4 y154 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>N<span class="_ _c"> </span><span class="ffb">+<span class="_ _25"> </span></span>F<span class="_ _32"> </span>P</div><div class="t m0 x32 h4 y155 ff3 fs2 fc0 sc0 ls0 ws0">(2.7)</div><div class="t m0 xa5 h9 y156 ff6 fs5 fc0 sc0 ls0 ws0">2.4<span class="_ _21"> </span>Precision<span class="ff9">、</span>Recall</div><div class="t m0 x3 h6 y157 ff1 fs2 fc0 sc0 ls0 ws0">错误率和精度虽然常用，<span class="_ _31"></span>但不能满足所有的需求，<span class="_ _22"></span>例如：<span class="_ _31"></span>在推荐系统中，<span class="_ _22"></span>我们只关心推送给用户</div><div class="t m0 x3 h6 y158 ff1 fs2 fc0 sc0 ls0 ws0">的内容用户是否感兴趣（即查准率）<span class="_ _30"></span>，或者说所有用户感兴趣的内容我们推送出<span class="_ _f"></span>来了多少（即查</div><div class="t m0 x3 h6 y159 ff1 fs2 fc0 sc0 ls0 ws0">全率）<span class="_ _23"></span>。因此，使用查准<span class="ff3">/</span>查全率更适合描述这类问题。</div><div class="t m0 x3 h6 y15a ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">2.3<span class="_ _6"> </span>Recall(<span class="ff4">查全率、召<span class="_ _f"></span>回率</span>)<span class="ff4">：<span class="ff1">模型挑<span class="_ _f"></span>选出正类<span class="_ _f"></span>样本的能力。<span class="_ _f"></span>所有正例<span class="_ _f"></span>样本中，预测<span class="_ _f"></span>正确的</span></span></span></div><div class="t m0 x3 h6 y15b ff1 fs2 fc0 sc0 ls0 ws0">样本所占比例。</div><div class="t m0 x3 h6 y15c ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">2.4<span class="_ _6"> </span>Precision(<span class="ff4">查准率</span>)<span class="ff4">：<span class="ff1">在所有预测为正例的样本中，预测正确的样本所占比例。</span></span></span></div><div class="t m0 x1f h4 y15d ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span>r<span class="_ _f"></span>ecision<span class="_ _2c"> </span><span class="ffb">=</span></div><div class="t m0 xaf hc y15e ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P</div><div class="t m0 xb0 h4 y15f ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P<span class="_ _0"> </span><span class="ffb">+<span class="_ _25"> </span></span>F<span class="_ _2b"> </span>P</div><div class="t m0 x32 h4 y15d ff3 fs2 fc0 sc0 ls0 ws0">(2.8)</div><div class="t m0 xb1 h4 y160 ffa fs2 fc0 sc0 ls0 ws0">Recal<span class="_ _f"></span>l<span class="_ _27"> </span><span class="ffb">=</span></div><div class="t m0 xb2 hc y161 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P</div><div class="t m0 x40 h4 y162 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P<span class="_ _0"> </span><span class="ffb">+<span class="_ _25"> </span></span>F<span class="_ _2b"> </span>N</div><div class="t m0 x32 h4 y160 ff3 fs2 fc0 sc0 ls0 ws0">(2.9)</div><div class="t m0 x3 h6 y163 ff1 fs2 fc0 sc0 ls0 ws0">根据上式，可以看出，<span class="ff3">Recall<span class="_ _c"> </span></span>就是各分类情形下的<span class="_ _c"> </span><span class="ff3">accuracy</span>。</div><div class="t m0 x3 h6 y164 ff1 fs2 fc0 sc0 ls0 ws0">很多<span class="_ _f"></span>时候，<span class="_ _f"></span>分<span class="_ _f"></span>类模<span class="_ _f"></span>型<span class="_ _f"></span>的精<span class="_ _f"></span>度<span class="_ _f"></span>与召<span class="_ _f"></span>回<span class="_ _f"></span>率之<span class="_ _f"></span>间<span class="_ _f"></span>存在<span class="_ _f"></span>着<span class="_ _f"></span>某种<span class="_ _f"></span>此消<span class="_ _f"></span>彼<span class="_ _f"></span>长的<span class="_ _f"></span>关<span class="_ _f"></span>系。通<span class="_ _f"></span>常<span class="_ _f"></span>只有<span class="_ _f"></span>在<span class="_ _f"></span>一些<span class="_ _f"></span>简<span class="_ _f"></span>单的</div><div class="t m0 x3 h6 y165 ff1 fs2 fc0 sc0 ls0 ws0">任务中，才可能使<span class="_ _c"> </span><span class="ff3">Recall</span>、<span class="ff3">Precision<span class="_ _c"> </span></span>都很高。</div><div class="t m0 x3 h6 y166 ff1 fs2 fc0 sc0 ls0 ws0">对于某些应用来讲，我们可能希望<span class="_ _27"> </span><span class="ff3">Precision<span class="_ _c"> </span></span>越高越好，那么就需要适当牺牲一些召回率，将分</div><div class="t m0 x3 h6 y167 ff1 fs2 fc0 sc0 ls0 ws0">类阈值调高；<span class="_ _f"></span>而对于另<span class="_ _f"></span>一些应用<span class="_ _f"></span>来讲，我们<span class="_ _f"></span>可能希望<span class="_ _0"> </span><span class="ff3">Recall<span class="_ _0"> </span></span>越高<span class="_ _f"></span>越好，那么<span class="_ _f"></span>就需要适<span class="_ _f"></span>当牺牲一</div><div class="t m0 x3 h6 y168 ff1 fs2 fc0 sc0 ls0 ws0">些<span class="_ _27"> </span><span class="ff3">Precision</span>，<span class="_ _22"></span>将分类阈值调低，<span class="_ _22"></span>从而使更多的样本被分为正类。<span class="_ _22"></span>因此，<span class="_ _22"></span>对于不同的应用场景，<span class="_ _22"></span>对</div><div class="t m0 x3 h6 y169 ff3 fs2 fc0 sc0 ls0 ws0">Precision<span class="_ _c"> </span><span class="ff1">和<span class="_ _c"> </span></span>Recall<span class="_ _c"> </span><span class="ff1">的关注程度也会有所不同，需要根据实际情况进行权衡。</span></div><div class="t m0 x3 h6 y16a ff1 fs2 fc0 sc0 ls0 ws0">在很<span class="_ _f"></span>多情<span class="_ _f"></span>形<span class="_ _f"></span>下，学<span class="_ _f"></span>习<span class="_ _f"></span>器可<span class="_ _f"></span>以<span class="_ _f"></span>得到<span class="_ _f"></span>样<span class="_ _f"></span>本属<span class="_ _f"></span>于<span class="_ _f"></span>正类<span class="_ _f"></span>的<span class="_ _f"></span>概率<span class="_ _f"></span>（或者<span class="_ _f"></span>其<span class="_ _f"></span>他度<span class="_ _f"></span>量<span class="_ _f"></span>样本<span class="_ _f"></span>属<span class="_ _f"></span>于正<span class="_ _f"></span>类<span class="_ _f"></span>可能<span class="_ _f"></span>性<span class="_ _f"></span>大小</div><div class="t m0 x3 h6 y16b ff1 fs2 fc0 sc0 ls0 ws0">的量）<span class="_ _23"></span>。我们<span class="_ _f"></span>可以按概率的大小对样本进行排序，然<span class="_ _f"></span>后逐个把样本对应的概率作为分类<span class="_ _f"></span>阈值，则</div><div class="t m0 x3 h6 y16c ff1 fs2 fc0 sc0 ls0 ws0">每次可以计算出当前的<span class="_ _c"> </span><span class="ff3">Precision<span class="_ _c"> </span></span>和<span class="_ _c"> </span><span class="ff3">Recall</span>。以<span class="_ _27"> </span><span class="ff3">Precision<span class="_ _c"> </span></span>和<span class="_ _c"> </span><span class="ff3">Recall<span class="_ _c"> </span></span>分别作为纵轴、横轴，就得</div><div class="t m0 x3 h6 y16d ff1 fs2 fc0 sc0 ls0 ws0">到了“查准率<span class="ff3">-</span>查全<span class="_ _f"></span>率曲线”<span class="_ _30"></span>，简<span class="_ _f"></span>称<span class="fc1">“<span class="ff3">P-R<span class="_ _c"> </span></span>曲线<span class="_ _f"></span>（<span class="ff3">Precision<span class="_ _c"> </span>Recall<span class="_ _0"> </span>Curve</span>）<span class="_ _30"></span>”<span class="fc0">，显示该曲线的图<span class="_ _f"></span>称</span></span></div><div class="t m0 x3 h6 y16e ff1 fs2 fc0 sc0 ls0 ws0">为<span class="ff3">”P-R<span class="_ _c"> </span></span>图<span class="ff3">”</span>。</div><div class="t m0 x3 h6 y16f ff3 fs2 fc0 sc0 ls0 ws0">P-R<span class="_ _11"> </span><span class="ff1">曲线<span class="_ _f"></span>的作<span class="_ _f"></span>用：很<span class="_ _f"></span>好地<span class="_ _f"></span>表示<span class="_ _f"></span>精度<span class="_ _f"></span>与召<span class="_ _f"></span>回率<span class="_ _f"></span>之间<span class="_ _f"></span>的<span class="_ _f"></span>权衡<span class="_ _f"></span>关系，<span class="_ _f"></span>在实<span class="_ _f"></span>际应<span class="_ _f"></span>用中<span class="_ _f"></span>可以<span class="_ _f"></span>根据<span class="_ _f"></span>实际<span class="_ _f"></span>情<span class="_ _f"></span>况</span></div><div class="t m0 x3 h6 y170 ff1 fs2 fc0 sc0 ls0 ws0">选取曲线上合适的点所对于的分类阈值作为最终分类器的阈值。</div><div class="t m0 x3 h6 y171 ff1 fs2 fc0 sc0 ls0 ws0">示意图中有三个学习器的<span class="_ _c"> </span><span class="ff3">P-R<span class="_ _c"> </span></span>曲线。</div><div class="t m0 x9b h6 y172 ff7 fs2 fc1 sc0 ls0 ws0">1.<span class="_ _7"> </span><span class="ff4">显然，若一个学习器<span class="_ _11"> </span></span>C<span class="_ _11"> </span><span class="ff4">的<span class="_ _11"> </span></span>P-R<span class="_ _1c"> </span><span class="ff4">曲线被另一个学习器<span class="_ _11"> </span></span>A<span class="_ _11"> </span><span class="ff4">的<span class="_ _11"> </span></span>P-R<span class="_ _1c"> </span><span class="ff4">曲线完全包住，</span></div><div class="t m0 x9b h6 y173 ff4 fs2 fc1 sc0 ls0 ws0">则称：<span class="ff7">A<span class="_ _11"> </span></span>的性能优于<span class="_ _11"> </span><span class="ff7">C</span>。</div><div class="t m0 x3 h6 y174 ff1 fs2 fc0 sc0 ls0 ws0">如果两个学习器的<span class="_ _c"> </span><span class="ff3">P-R<span class="_ _0"> </span></span>曲线发生了交叉，例如图<span class="ff3">2.1</span>中的<span class="_ _0"> </span><span class="ff3">A<span class="_ _c"> </span></span>与<span class="_ _c"> </span><span class="ff3">B<span class="_ _c"> </span></span>，则<span class="_ _f"></span>不能一般性地断言两者孰</div><div class="t m0 x3 h6 y175 ff1 fs2 fc0 sc0 ls0 ws0">优孰劣。<span class="_ _31"></span>只能在具体的查准率或查全率条件下进行比较。<span class="_ _31"></span>然而，<span class="_ _22"></span>在很多情形下，<span class="_ _22"></span>人们往往仍希望</div><div class="t m0 x3 h6 y176 ff1 fs2 fc0 sc0 ls0 ws0">把学习器<span class="_ _c"> </span><span class="ff3">A<span class="_ _c"> </span></span>与<span class="_ _c"> </span><span class="ff3">B<span class="_ _c"> </span></span>比出个高低。存在以下比较准则：</div><div class="t m0 x9b h6 y1d ff7 fs2 fc1 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff4">若<span class="_ _11"> </span></span>A<span class="_ _11"> </span><span class="ff4">和<span class="_ _11"> </span></span>B<span class="_ _11"> </span><span class="ff4">的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。</span></div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">11</div><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,179.61,null]'><div class="d m1" style="border-style:none;position:absolute;left:232.659000px;bottom:1064.503500px;width:13.942000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",412.84,620.92,null]'><div class="d m1" style="border-style:none;position:absolute;left:457.413000px;bottom:139.624500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf11" class="pf w0 h0" data-page-no="11"><div class="pc pc11 w0 h0"><img class="bi x3 y177 w2 h19" alt="" src="bg11.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">2.5<span class="_ _15"> </span>TPR<span class="ff8">、</span>FPR</div><div class="t m0 x45 h6 y178 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">2.1:<span class="_ _2e"> </span>Precision<span class="_ _c"> </span>Recall<span class="_ _c"> </span>Curv<span class="_ _10"></span>e</span></div><div class="t m0 x3 h6 y179 ff1 fs2 fc0 sc0 ls0 ws0">但曲线下的面积难以进行估算，<span class="_ _26"></span>所以，<span class="_ _28"></span>人们设计了<span class="_ _27"> </span>一些综合考虑查准率、<span class="_ _22"></span>查全率的性能度量，<span class="_ _26"></span>例</div><div class="t m0 x3 h6 y17a ff1 fs2 fc0 sc0 ls0 ws0">如<span class="ff4">平衡点</span>（平衡点如图<span class="ff3">2.1</span>所示）<span class="_ _23"></span>。</div><div class="t m0 x9b h6 y17b ff7 fs2 fc1 sc0 ls0 ws0">3.<span class="_ _9"> </span><span class="ff4">平衡点（</span>Break-Even<span class="_ _2f"></span>t<span class="_ _1c"> </span>Poin<span class="_ _2f"></span>t<span class="ff4">，简称<span class="_ _1c"> </span></span>BEP<span class="ff4">）<span class="_ _30"></span>：即<span class="_ _f"></span>当<span class="_ _1c"> </span><span class="ff7">P=R<span class="_ _11"> </span></span>时的<span class="_ _f"></span>取值，平衡点<span class="_ _f"></span>的</span></div><div class="t m0 x9b h6 y17c ff4 fs2 fc1 sc0 ls0 ws0">取值越高，性能更优。</div><div class="t m0 x3 h6 y17d ff1 fs2 fc0 sc0 ls0 ws0">但<span class="_ _c"> </span><span class="ff3">BEP<span class="_ _c"> </span></span>还是过于简化了些，更常用的是<span class="_ _c"> </span><span class="ff7">F1<span class="_ _c"> </span></span>度量<span class="_ _c"> </span><span class="ff3">(<span class="ff7">F1<span class="_ _c"> </span></span></span>度量实际是<span class="ff4">调和平均值<span class="ff3">)</span></span>：</div><div class="t m0 x9b h6 y17e ff7 fs2 fc1 sc0 ls0 ws0">4.<span class="_ _6"> </span>F1<span class="_ _11"> </span><span class="ff4">值越大，性能越优。</span></div><div class="t m0 xb4 h4 y17f ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _2b"> </span><span class="ffb">1<span class="_ _2c"> </span>=</span></div><div class="t m0 x1b h4 y180 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x36 ha y181 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x36 ha y182 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb5 h4 y183 fff fs2 fc0 sc0 ls0 ws0">×<span class="_ _33"> </span><span class="ffb">(</span></div><div class="t m0 x97 ha y181 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x77 hb y182 ffd fs6 fc0 sc0 ls0 ws0">P</div><div class="t m0 x8c h4 y183 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xa ha y181 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9 hb y182 ffd fs6 fc0 sc0 ls0 ws0">R</div><div class="t m0 xa9 h4 y183 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x2 h4 y17f ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb6 h4 y180 ffb fs2 fc0 sc0 ls0 ws0">2<span class="_ _33"> </span><span class="fff">×<span class="_ _25"> </span><span class="ffa">P<span class="_ _0"> </span></span>×<span class="_ _33"> </span><span class="ffa">R</span></span></div><div class="t m0 x3e h4 y184 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _0"> </span><span class="ffb">+<span class="_ _33"> </span></span>R</div><div class="t m0 x25 h4 y17f ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x96 h4 y180 ffb fs2 fc0 sc0 ls0 ws0">2<span class="_ _33"> </span><span class="fff">×<span class="_ _25"> </span><span class="ffa">T<span class="_ _2b"> </span>P</span></span></div><div class="t m0 xab h6 y185 ff1 fs2 fc0 sc0 ls0 ws0">样本总数<span class="_ _33"> </span><span class="ffb">+<span class="_ _25"> </span><span class="ffa">T<span class="_ _2b"> </span>P<span class="_ _0"> </span><span class="fff">−<span class="_ _25"> </span></span>T<span class="_ _2b"> </span>N</span></span></div><div class="t m0 xb7 h4 y17f ff3 fs2 fc0 sc0 ls0 ws0">(2.10)</div><div class="t m0 x3 h6 y186 ff1 fs2 fc1 sc0 ls0 ws0">容易证明：<span class="_ _26"></span><span class="ff3">F1<span class="_ _27"> </span>Score<span class="_ _27"> </span><span class="ff1">与查准率和召回率之间存在着正向的关系，<span class="_ _26"></span>也就是查准率越高，<span class="_ _28"></span><span class="ff3">F1 Score<span class="_ _c"> </span><span class="ff1">就</span></span></span></span></div><div class="t m0 x3 h6 y187 ff1 fs2 fc1 sc0 ls0 ws0">越大，同样召回率越高，<span class="ff3">F1<span class="_ _c"> </span>Score<span class="_ _c"> </span></span>也就越大。</div><div class="t m0 x3 h6 y188 ff1 fs2 fc0 sc0 ls0 ws0">但是在<span class="_ _f"></span>一些应用<span class="_ _f"></span>中，对<span class="_ _f"></span>查准率<span class="_ _f"></span>和查全<span class="_ _f"></span>率的重<span class="_ _f"></span>视程度<span class="_ _f"></span>有所不<span class="_ _f"></span>同，这就<span class="_ _f"></span>需要对<span class="_ _f"></span>它们赋<span class="_ _f"></span>予不同<span class="_ _f"></span>的权重，</div><div class="t m0 x3 h6 y189 ff1 fs2 fc0 sc0 ls0 ws0">因此有<span class="_ _c"> </span><span class="ff3">F1<span class="_ _c"> </span></span>的更一般形式<span class="_ _c"> </span><span class="ffa">F</span></div><div class="t m0 xa7 hb y18a ffd fs6 fc0 sc0 ls0 ws0">β</div><div class="t m0 x83 h6 y189 ff3 fs2 fc0 sc0 ls0 ws0">(<span class="ff4">加权调和平均</span>)<span class="ff1">：</span></div><div class="t m0 xd hc y18b ffa fs2 fc0 sc0 ls0 ws0">F</div><div class="t m0 xb8 hb y18c ffd fs6 fc0 sc0 ls0 ws0">β</div><div class="t m0 xb9 h4 y18b ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xa8 h4 y18d ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xba ha y18e ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9 hb y18f ffd fs6 fc0 sc0 ls0 ws0">β</div><div class="t m0 x1f h1a y190 ff14 fs8 fc0 sc0 ls0 ws0">2</div><div class="t m0 x1c h4 y191 ffb fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x2 ha y18e ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x47 hb y192 ffd fs6 fc0 sc0 ls0 ws0">P</div><div class="t m0 xbb h4 y191 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x3e hb y193 ffd fs6 fc0 sc0 ls0 ws0">β</div><div class="t m0 x21 h1a y194 ff14 fs8 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbc hb y192 ffd fs6 fc0 sc0 ls0 ws0">R</div><div class="t m0 xbd h4 y191 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x9f h4 y18b ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb0 h4 y18d ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span>+<span class="_ _25"> </span><span class="ffa">β</span></div><div class="t m0 x93 ha y195 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x62 h4 y18d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">×<span class="_ _25"> </span><span class="ffa">P<span class="_ _0"> </span></span>×<span class="_ _33"> </span><span class="ffa">R</span></span></div><div class="t m0 xbe hc y196 ffa fs2 fc0 sc0 ls0 ws0">β</div><div class="t m0 xbf ha y197 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc0 h4 y196 fff fs2 fc0 sc0 ls0 ws0">×<span class="_ _33"> </span><span class="ffa">P<span class="_ _0"> </span><span class="ffb">+<span class="_ _25"> </span></span>R</span></div><div class="t m0 xb7 h4 y18b ff3 fs2 fc0 sc0 ls0 ws0">(2.11)</div><div class="t m0 x3 h6 y198 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _27"> </span><span class="ffa">β<span class="_ _c"> </span>&gt;<span class="_ _2c"> </span><span class="ffb">0<span class="_ _c"> </span></span></span>度量了查全率对查准率的相对重要性。<span class="_ _31"></span><span class="ffa">β<span class="_ _c"> </span><span class="ffb">=<span class="_ _2c"> </span>1<span class="_ _27"> </span><span class="ff1">时退化为标准的<span class="_ _c"> </span><span class="ff3">F1;<span class="_ _c"> </span></span></span></span>β<span class="_ _27"> </span>&gt;<span class="_ _27"> </span><span class="ffb">1<span class="_ _27"> </span><span class="ff1">时查全率有</span></span></span></div><div class="t m0 x3 h6 y199 ff1 fs2 fc0 sc0 ls0 ws0">更大影响<span class="ff3">;<span class="_ _c"> </span><span class="ffa">β<span class="_ _c"> </span>&lt;<span class="_ _2c"> </span><span class="ffb">1<span class="_ _c"> </span></span></span></span>时查准率有更大影响。</div><div class="t m0 x1e h6 y19a ff1 fs2 fc0 sc0 ls0 ws0">与算术平均</div><div class="t m0 x12 ha y19b ffd fs6 fc0 sc0 ls0 ws0">P<span class="_ _32"> </span><span class="ffc">+</span>R</div><div class="t m0 x37 ha y19c ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc1 h6 y19a ff1 fs2 fc0 sc0 ls0 ws0">和几何平均</div><div class="t m0 x3a h4 y19d fff fs2 fc0 sc0 ls0 ws0">√</div><div class="t m0 x9 h6 y19a ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _0"> </span><span class="fff">×<span class="_ _33"> </span></span>R<span class="_ _0"> </span><span class="ff1">相比，调和平均更重视较小值。</span></div><div class="t m0 xc2 h9 y19e ff6 fs5 fc0 sc0 ls0 ws0">2.5<span class="_ _21"> </span>TPR<span class="ff9">、</span>FPR</div><div class="t m0 x3 h6 y19f ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">2.5<span class="_ _6"> </span>TPR<span class="ff4">：<span class="_ _2e"> </span><span class="ff3">T<span class="_ _31"></span>rue<span class="_ _2e"> </span>P<span class="_ _2f"></span>ositive<span class="_ _1c"> </span>Rate<span class="ff1">，<span class="_ _f"></span>真<span class="_ _f"></span>正<span class="_ _f"></span>例<span class="_ _f"></span>率。<span class="_ _f"></span>所<span class="_ _f"></span>有<span class="_ _f"></span>正<span class="_ _f"></span>例<span class="_ _f"></span>样<span class="_ _f"></span>本<span class="_ _f"></span>中，<span class="_ _f"></span>预<span class="_ _f"></span>测<span class="_ _f"></span>正<span class="_ _f"></span>确<span class="_ _f"></span>的<span class="_ _f"></span>样<span class="_ _f"></span>本<span class="_ _f"></span>所<span class="_ _f"></span>占<span class="_ _f"></span>比<span class="_ _f"></span>例。</span></span></span></span></div><div class="t m0 x3 h6 y1a0 ff3 fs2 fc0 sc0 ls0 ws0">TPR<span class="_ _c"> </span><span class="ff1">就是<span class="_ _c"> </span></span>Recall<span class="ff1">。</span></div><div class="t m0 x3 h6 y1a1 ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">2.6<span class="_ _6"> </span>FPR<span class="ff4">：<span class="_ _11"> </span><span class="ff3">F<span class="_ _2f"></span>alse<span class="_ _11"> </span>Positiv<span class="_ _2f"></span>e<span class="_ _11"> </span>Rate<span class="ff1">，<span class="_ _f"></span>伪<span class="_ _f"></span>阳性<span class="_ _f"></span>率、假<span class="_ _f"></span>正<span class="_ _f"></span>例率、<span class="_ _f"></span>也<span class="_ _f"></span>称误<span class="_ _f"></span>报率<span class="_ _f"></span>（</span>Probability<span class="_ _0"> </span>of<span class="_ _1c"> </span>F<span class="_ _31"></span>alse</span></span></span></div><div class="t m0 x3 h6 y1a2 ff3 fs2 fc0 sc0 ls0 ws0">Alarm<span class="ff1">）<span class="_ _23"></span>、错误命中率、<span class="_ _10"></span>假警报率，简记为<span class="_ _27"> </span><span class="ff3">FPR</span>。在所有实际上为负类的样本中，误判为正类的</span></div><div class="t m0 x3 h6 y1a3 ff1 fs2 fc0 sc0 ls0 ws0">样本所占的比例。</div><div class="t m0 x2 h4 y1a4 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=</span></div><div class="t m0 x4b hc y1a5 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P</div><div class="t m0 x9f h4 y1a6 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P<span class="_ _0"> </span><span class="ffb">+<span class="_ _25"> </span></span>F<span class="_ _2b"> </span>N</div><div class="t m0 xb7 h4 y1a4 ff3 fs2 fc0 sc0 ls0 ws0">(2.12)</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">12</div><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",412.84,620.92,null]'><div class="d m1" style="border-style:none;position:absolute;left:269.935500px;bottom:802.786500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf12" class="pf w0 h0" data-page-no="12"><div class="pc pc12 w0 h0"><img class="bi xc3 y1a7 w8 h1b" alt="" src="bg12.png"/><div class="t m0 xc4 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">2.6<span class="_ _15"> </span>R<span class="_ _10"></span>OC<span class="ff8">、</span>A<span class="_ _10"></span>UC</div><div class="t m0 x2 h4 y1a8 ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=</span></div><div class="t m0 x4b hc y1a9 ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _2b"> </span>P</div><div class="t m0 x5b h4 y1aa ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>N<span class="_ _c"> </span><span class="ffb">+<span class="_ _25"> </span></span>F<span class="_ _32"> </span>P</div><div class="t m0 xb7 h4 y1a8 ff3 fs2 fc0 sc0 ls0 ws0">(2.13)</div><div class="t m0 x3 h6 y1ab ff1 fs2 fc0 sc0 ls0 ws0">除了<span class="_ _27"> </span><span class="ff3">TPR</span>、<span class="_ _31"></span><span class="ff3">FPR<span class="ff1">，<span class="_ _31"></span>还有真负例率和假负例率。<span class="_ _31"></span><span class="ff3 fc1">TPR<span class="ff1">、<span class="_ _31"></span><span class="ff3">FPR<span class="_ _c"> </span><span class="ff1">有一个很好的特性：<span class="_ _22"></span>对数据集是否均</span></span></span></span></span></span></div><div class="t m0 x3 h6 y1ac ff1 fs2 fc1 sc0 ls0 ws0">衡不敏感<span class="fc0">，<span class="_ _2a"></span>因为<span class="_ _c"> </span><span class="ff7">TPR<span class="ff4">、<span class="_ _26"></span><span class="ff7">FPR<span class="_ _c"> </span><span class="ff4">的分子和分母只涉及了单一类别的样本<span class="ff1">。<span class="_ _29"></span><span class="ff3">ROC <span class="ff1">曲线以<span class="_ _2c"> </span></span>TPR<span class="ff1">、<span class="_ _29"></span><span class="ff3">FPR</span></span></span></span></span></span></span></span></span></div><div class="t m0 x3 h6 y1ad ff1 fs2 fc0 sc0 ls0 ws0">基础的，所以这也是<span class="_ _c"> </span><span class="ff3">R<span class="_ _10"></span>OC<span class="_ _c"> </span><span class="ff1">曲线的优点。</span></span></div><div class="t m0 x1d h9 y1ae ff6 fs5 fc0 sc0 ls0 ws0">2.6<span class="_ _21"> </span>R<span class="_ _2f"></span>OC<span class="ff9">、</span>A<span class="_ _10"></span>UC</div><div class="t m0 x3 h6 y1af ff1 fs2 fc0 sc0 ls0 ws0">很多学习器是为测试样本产生一个实值或概率预测，<span class="_ _28"></span>然后将这个预测值与一个分类阈值<span class="_ _27"> </span><span class="ff3">(thresh-</span></div><div class="t m0 x3 h6 y1b0 ff3 fs2 fc0 sc0 ls0 ws0">old)<span class="_ _11"> </span><span class="ff1">进行<span class="_ _f"></span>比<span class="_ _f"></span>较，若<span class="_ _f"></span>大于<span class="_ _f"></span>阈值<span class="_ _f"></span>则<span class="_ _f"></span>分为<span class="_ _f"></span>正类，<span class="_ _f"></span>否<span class="_ _f"></span>则为<span class="_ _f"></span>反类。<span class="_ _f"></span>这个<span class="_ _f"></span>实<span class="_ _f"></span>值或<span class="_ _f"></span>概率<span class="_ _f"></span>预<span class="_ _f"></span>测结<span class="_ _f"></span>果的<span class="_ _f"></span>好坏，<span class="_ _f"></span>直<span class="_ _f"></span>接</span></div><div class="t m0 x3 h6 y1b1 ff1 fs2 fc0 sc0 ls0 ws0">决定<span class="_ _f"></span>了学<span class="_ _f"></span>习<span class="_ _f"></span>器<span class="_ _f"></span>的泛<span class="_ _f"></span>化能<span class="_ _f"></span>力。<span class="_ _f"></span>实<span class="_ _f"></span>际上，<span class="_ _f"></span>根<span class="_ _f"></span>据这<span class="_ _f"></span>个<span class="_ _f"></span>实值<span class="_ _f"></span>或<span class="_ _f"></span>概率<span class="_ _f"></span>预<span class="_ _f"></span>测结<span class="_ _f"></span>果，<span class="_ _f"></span>我们<span class="_ _f"></span>可<span class="_ _f"></span>将测<span class="_ _f"></span>试<span class="_ _f"></span>样本<span class="_ _f"></span>进<span class="_ _f"></span>行排</div><div class="t m0 x3 h6 y1b2 ff1 fs2 fc0 sc0 ls0 ws0">序，<span class="_ _3d"></span>“最可能”<span class="_ _2f"></span>是正例的排在最前面，<span class="_ _22"></span><span class="ff3">”<span class="_ _c"> </span><span class="ff1">最不可能</span>” <span class="ff1">是正例的排在最后面。<span class="_ _31"></span>这样，<span class="_ _31"></span>分类过程就相当</span></span></div><div class="t m0 x3 h6 y1b3 ff1 fs2 fc0 sc0 ls0 ws0">于在这个排序中以某个<span class="ff3">”<span class="_ _c"> </span></span>截断点<span class="ff3">”<span class="_ _27"> </span>(cut<span class="_ _c"> </span>p<span class="_ _f"></span>oint)<span class="_ _27"> </span></span>将样本分为两部分，<span class="_ _2f"></span>前一部分判作正例，<span class="_ _2f"></span>后一部分</div><div class="t m0 x3 h6 y1b4 ff1 fs2 fc0 sc0 ls0 ws0">则判作反例。</div><div class="t m0 x3 h6 y1b5 ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">2.7<span class="_ _6"> </span>R<span class="_ _10"></span>OC<span class="ff4">：<span class="_ _2b"> </span><span class="ff3">R<span class="_ _10"></span>OC<span class="_ _27"> </span><span class="ff1">曲线的全称为<span class="_ _27"> </span></span>Receiver Op<span class="_ _f"></span>erating Characteristic<span class="ff1">，<span class="_ _28"></span>其纵轴为<span class="_ _27"> </span><span class="ff3">T<span class="_ _31"></span>rue<span class="_ _27"> </span>Positiv<span class="_ _2f"></span>e</span></span></span></span></span></div><div class="t m0 x3 h6 y1b6 ff3 fs2 fc0 sc0 ls0 ws0">Rate<span class="_ _27"> </span>(TPR)<span class="ff1">，<span class="_ _31"></span>也就是召回率，<span class="_ _22"></span>横轴为伪阳性率<span class="_ _27"> </span><span class="ff3">F<span class="_ _2f"></span>alse<span class="_ _27"> </span>Positiv<span class="_ _2f"></span>e<span class="_ _c"> </span>Rate (FPR)<span class="ff1">。<span class="_ _31"></span>显示<span class="_ _c"> </span><span class="ff3">R<span class="_ _2f"></span>OC<span class="_ _c"> </span><span class="ff1">曲线的图</span></span></span></span></span></div><div class="t m0 x3 h6 y1b7 ff1 fs2 fc0 sc0 ls0 ws0">称为<span class="ff3">”R<span class="_ _10"></span>OC<span class="_ _c"> </span><span class="ff1">图。</span></span></div><div class="t m0 x3 h6 y1b8 ff1 fs2 fc0 sc0 ls0 ws0">下图给出了一个示意图：</div><div class="t m0 xc5 h6 y1b9 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">2.2:<span class="_ _2e"> </span>ro<span class="_ _f"></span>c<span class="_ _c"> </span></span>与<span class="_ _c"> </span><span class="ff3">auc<span class="_ _c"> </span></span>曲线</div><div class="t m0 x3 h6 y1ba ff1 fs2 fc0 sc0 ls0 ws0">看几个特殊点或特殊曲线：</div><div class="t m0 x9a h6 y1bb ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">第一个点：<span class="ffb">(0<span class="ffa">,<span class="_ _2d"> </span></span>1)</span>，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span>0</span>T<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span>1<span class="_ _c"> </span></span></span>，这意味着所有的样本都分类正确。</span></div><div class="t m0 x9a h6 y1bc ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">第二个点：<span class="ffb">(1<span class="ffa">,<span class="_ _2d"> </span></span>0)</span>，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _2d"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _c"> </span>1</span>T<span class="_ _32"> </span>P<span class="_ _2d"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span>0<span class="_ _0"> </span></span></span>，和<span class="_ _f"></span>第一个点比<span class="_ _f"></span>较，这是第一<span class="_ _f"></span>个点的完全<span class="_ _f"></span>反面，意</span></div><div class="t m0 x9b h6 y1bd ff1 fs2 fc0 sc0 ls0 ws0">味着是个最糟糕的分类器，<span class="_ _31"></span>将所有的样本都分类错误了<span class="_ _2f"></span>（但其实可以直接取反，<span class="_ _31"></span>就<span class="_ _27"> </span>是最好</div><div class="t m0 x9b h6 y1be ff1 fs2 fc0 sc0 ls0 ws0">的模型，因为是二分类问题）<span class="_ _23"></span>。</div><div class="t m0 x9a h6 y1bf ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">第三个点：<span class="ffb">(0<span class="ffa">,<span class="_ _2d"> </span></span>0)</span>，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _2d"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _c"> </span>0</span>T<span class="_ _32"> </span>P<span class="_ _2d"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span>0<span class="_ _0"> </span></span></span>也就<span class="_ _f"></span>是原点，这个<span class="_ _f"></span>点表示的意<span class="_ _f"></span>思是，分类器<span class="_ _f"></span>预测所</span></div><div class="t m0 x9b h6 y1c0 ff1 fs2 fc0 sc0 ls0 ws0">有的样本都为负类。</div><div class="t m0 x9a h6 y1c1 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">第四个点：<span class="_ _31"></span><span class="ffb">(1<span class="ffa">,<span class="_ _2b"> </span></span>1)<span class="ff1">，<span class="_ _31"></span><span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span>1</span>T<span class="_ _2d"> </span>P<span class="_ _32"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span>1<span class="ff1">，<span class="_ _31"></span>和第三个点对应，<span class="_ _31"></span>表示分类器预测所有的样本都为</span></span></span></span></span></span></div><div class="t m0 x9b h6 y1c2 ff1 fs2 fc0 sc0 ls0 ws0">正类。</div><div class="t m0 x9a h6 y1c3 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">一条线：<span class="ffa">y<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span></span>x</span>，对角线对应于“随机猜测”模型。</span></div><div class="t m0 x3 h6 y1c4 ff1 fs2 fc0 sc0 ls0 ws0">于是，对<span class="_ _f"></span>于特<span class="_ _f"></span>定的<span class="_ _f"></span>分类模<span class="_ _f"></span>型，如<span class="_ _f"></span>果<span class="_ _11"> </span><span class="ff3">R<span class="_ _10"></span>OC<span class="_ _0"> </span><span class="ff1">曲<span class="_ _f"></span>线位<span class="_ _f"></span>于对<span class="_ _f"></span>角线左<span class="_ _f"></span>上方，<span class="_ _f"></span>说明<span class="_ _f"></span>模型<span class="_ _f"></span>性能好<span class="_ _f"></span>于随<span class="_ _f"></span>机猜<span class="_ _f"></span>测，</span></span></div><div class="t m0 x3 h6 y1c5 ff1 fs2 fc0 sc0 ls0 ws0">如果<span class="_ _c"> </span><span class="ff3">R<span class="_ _10"></span>OC<span class="_ _c"> </span><span class="ff1">曲线位于对角线右下方，说明模型性能劣于随机猜测。</span></span></div><div class="t m0 x3 h6 y1c6 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="ff3">2.2(a) </span>是理想化的<span class="_ _2c"> </span><span class="ff3">ROC </span>曲线图，<span class="_ _2a"></span>但在现实任务中，<span class="_ _2a"></span>通常只能利用有限个测试样本来绘制<span class="_ _2c"> </span><span class="ff3">R<span class="_ _10"></span>OC</span></div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">图，此时只<span class="_ _f"></span>有有限<span class="_ _f"></span>个<span class="_ _0"> </span><span class="ffb">(<span class="ffa">T<span class="_ _2b"> </span>P<span class="_ _2d"> </span>R,<span class="_ _2d"> </span>F<span class="_ _32"> </span>P<span class="_ _2d"> </span>R</span>)<span class="_ _0"> </span></span>坐标对，<span class="_ _f"></span>无法产<span class="_ _f"></span>生图<span class="ff3">2.2(a)<span class="_ _0"> </span></span>中<span class="_ _f"></span>的光滑<span class="_ _11"> </span><span class="ff3">R<span class="_ _10"></span>OC<span class="_ _0"> </span><span class="ff1">曲线，<span class="_ _f"></span>只能绘<span class="_ _f"></span>制</span></span></div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">出图<span class="ff3">2.2(b)<span class="_ _c"> </span></span>中的近似<span class="_ _c"> </span><span class="ff3">R<span class="_ _10"></span>OC<span class="_ _c"> </span><span class="ff1">曲线。<span class="ff4">绘制<span class="_ _11"> </span><span class="ff7">R<span class="_ _10"></span>OC<span class="_ _11"> </span><span class="ff4">曲线的过程如下：</span></span></span></span></span></div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">13</div><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",458.19,345.2,null]'><div class="d m1" style="border-style:none;position:absolute;left:122.662500px;bottom:99.681000px;width:13.942000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",458.19,345.2,null]'><div class="d m1" style="border-style:none;position:absolute;left:509.788500px;bottom:79.357500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",458.19,345.2,null]'><div class="d m1" style="border-style:none;position:absolute;left:139.026000px;bottom:59.034000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf13" class="pf w0 h0" data-page-no="13"><div class="pc pc13 w0 h0"><img class="bi x75 y1c7 w3 h1c" alt="" src="bg13.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">2.6<span class="_ _15"> </span>R<span class="_ _10"></span>OC<span class="ff8">、</span>A<span class="_ _10"></span>UC</div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">设数据集共有<span class="_ _c"> </span><span class="ffa">m</span></div><div class="t m0 xc6 ha y1c8 ffc fs6 fc0 sc0 ls0 ws0">+</div><div class="t m0 xc7 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">个正例，<span class="ffa">m</span></div><div class="t m0 xb8 ha y1c8 ff12 fs6 fc0 sc0 ls0 ws0">−</div><div class="t m0 x8c h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">个反例</div><div class="t m0 x9a h6 y3c ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _6"> </span><span class="ff1">将所有的样本按模型的预测打分<span class="_ _c"> </span></span>(score)<span class="_ _c"> </span><span class="ff1">由大到小排序；</span></div><div class="t m0 x9a h6 y1c9 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff1">将分类阈<span class="_ _f"></span>值设为<span class="_ _f"></span>最大，即<span class="_ _f"></span>把所有样<span class="_ _f"></span>本都归<span class="_ _f"></span>类为反<span class="_ _f"></span>例，此时<span class="_ _0"> </span><span class="ffa">T<span class="_ _2d"> </span>P<span class="_ _32"> </span>R<span class="_ _c"> </span><span class="ffb">=<span class="_ _c"> </span></span>F<span class="_ _2b"> </span>P<span class="_ _2d"> </span>R<span class="_ _c"> </span><span class="ffb">=<span class="_ _27"> </span>0</span></span>，<span class="_ _f"></span>得到<span class="_ _0"> </span><span class="ffb">(0<span class="ffa">,<span class="_ _2d"> </span></span>0)</span></span></div><div class="t m0 x9b h6 y1ca ff1 fs2 fc0 sc0 ls0 ws0">坐标点；</div><div class="t m0 x9a h6 y1cb ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _6"> </span><span class="ff1">将分类阈值依次设为每个<span class="_ _f"></span>样本的打分，即依次把每个样<span class="_ _f"></span>本划分为正例。设前一个标<span class="_ _f"></span>记点的</span></div><div class="t m0 x9b h6 y1cc ff1 fs2 fc0 sc0 ls0 ws0">坐标为<span class="_ _27"> </span><span class="ffb">(<span class="ffa">x,<span class="_ _2d"> </span>y<span class="_ _f"></span></span>)</span>，<span class="_ _28"></span>若当前为真正例，<span class="_ _28"></span>则当前标记点的坐标为<span class="_ _27"> </span><span class="ffb">(<span class="ffa">x,<span class="_ _2d"> </span>y<span class="_ _33"> </span></span>+</span></div><div class="t m0 x54 ha y1cd ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xc8 hb y1ce ffd fs6 fc0 sc0 ls0 ws0">m</div><div class="t m0 x53 h1a y1cf ff14 fs8 fc0 sc0 ls0 ws0">+</div><div class="t m0 xc9 h6 y1cc ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">，<span class="_ _28"></span>若当前为假正例，<span class="_ _28"></span>则</span></div><div class="t m0 x9b h6 y1d0 ff1 fs2 fc0 sc0 ls0 ws0">当前标记点的坐标为<span class="_ _c"> </span><span class="ffb">(<span class="ffa">x<span class="_ _33"> </span></span>+</span></div><div class="t m0 x1d ha y1d1 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8c hb y1d2 ffd fs6 fc0 sc0 ls0 ws0">m</div><div class="t m0 xc2 h1d y1d3 ff15 fs8 fc0 sc0 ls0 ws0">−</div><div class="t m0 xca h6 y1d0 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>y<span class="_ _f"></span><span class="ffb">)<span class="ff1">。</span></span></div><div class="t m0 x3 h6 y1d4 ff1 fs2 fc0 sc0 ls0 ws0">现设数<span class="_ _f"></span>据集共<span class="_ _f"></span>有<span class="_ _0"> </span><span class="ffb">10<span class="_ _11"> </span></span>个正<span class="_ _f"></span>例，<span class="ffb">10<span class="_ _0"> </span></span>个反<span class="_ _f"></span>例，如<span class="_ _f"></span>下表。<span class="ff3">Class<span class="_ _11"> </span></span>一栏表<span class="_ _f"></span>示每个<span class="_ _f"></span>测试<span class="_ _f"></span>样本真<span class="_ _f"></span>正的标<span class="_ _f"></span>签（<span class="ff3">p</span></div><div class="t m0 x3 h6 y1d5 ff1 fs2 fc0 sc0 ls0 ws0">表示正样本，<span class="_ _22"></span><span class="ff3">n <span class="ff1">表示负样本）<span class="_ _23"></span>，<span class="_ _22"></span><span class="ff3">Score <span class="ff1">表示每个测试样本属于正样本的概率。<span class="_ _22"></span>我们根据每个测试样</span></span></span></span></div><div class="t m0 x3 h6 y1d6 ff1 fs2 fc0 sc0 ls0 ws0">本属于正样本的概率值从大到小排序。</div><div class="t m0 xae h4 y1d7 ff7 fs2 fc0 sc0 ls0 ws0">n<span class="_ _10"></span>um<span class="_ _3e"> </span>Class<span class="_ _3e"> </span>Score<span class="_ _3e"> </span>n<span class="_ _10"></span>um<span class="_ _3e"> </span>Class<span class="_ _3e"> </span>Score</div><div class="t m0 xcb h4 y1d8 ff3 fs2 fc0 sc0 ls0 ws0">1<span class="_ _3e"> </span><span class="ff7">p<span class="_ _3f"> </span></span>0.9<span class="_ _40"> </span>11<span class="_ _3e"> </span><span class="ff7">p<span class="_ _3f"> </span></span>0.4</div><div class="t m0 xcb h4 y1d9 ff3 fs2 fc0 sc0 ls0 ws0">2<span class="_ _3e"> </span><span class="ff7">p<span class="_ _3f"> </span></span>0.8<span class="_ _40"> </span>12<span class="_ _3e"> </span><span class="ff7">n<span class="_ _41"> </span></span>0.39</div><div class="t m0 xcb h4 y1da ff3 fs2 fc0 sc0 ls0 ws0">3<span class="_ _3e"> </span><span class="ff7">n<span class="_ _3f"> </span></span>0.7<span class="_ _40"> </span>13<span class="_ _3e"> </span><span class="ff7">p<span class="_ _41"> </span></span>0.38</div><div class="t m0 xcb h4 y1db ff3 fs2 fc0 sc0 ls0 ws0">4</div><div class="t m0 x39 h4 y1dc ff7 fs2 fc0 sc0 ls0 ws0">p</div><div class="t m0 x8e h4 y1db ff3 fs2 fc0 sc0 ls0 ws0">0.6<span class="_ _40"> </span>14</div><div class="t m0 xcc h4 y1dc ff7 fs2 fc0 sc0 ls0 ws0">n</div><div class="t m0 x89 h4 y1db ff3 fs2 fc0 sc0 ls0 ws0">0.37</div><div class="t m0 xcb h4 y1dd ff3 fs2 fc0 sc0 ls0 ws0">5<span class="_ _3e"> </span><span class="ff7">p<span class="_ _41"> </span></span>0.55<span class="_ _40"> </span>15<span class="_ _3e"> </span><span class="ff7">n<span class="_ _41"> </span></span>0.36</div><div class="t m0 xcb h4 y1de ff3 fs2 fc0 sc0 ls0 ws0">6<span class="_ _3e"> </span><span class="ff7">p<span class="_ _41"> </span></span>0.54<span class="_ _40"> </span>16<span class="_ _3e"> </span><span class="ff7">n<span class="_ _41"> </span></span>0.35</div><div class="t m0 xcb h4 y1df ff3 fs2 fc0 sc0 ls0 ws0">7<span class="_ _3e"> </span><span class="ff7">n<span class="_ _41"> </span></span>0.53<span class="_ _40"> </span>17<span class="_ _3e"> </span><span class="ff7">p<span class="_ _41"> </span></span>0.34</div><div class="t m0 xcb h4 y1e0 ff3 fs2 fc0 sc0 ls0 ws0">8<span class="_ _3e"> </span><span class="ff7">n<span class="_ _41"> </span></span>0.52<span class="_ _40"> </span>18<span class="_ _3e"> </span><span class="ff7">n<span class="_ _41"> </span></span>0.33</div><div class="t m0 xcb h4 y1e1 ff3 fs2 fc0 sc0 ls0 ws0">9<span class="_ _3e"> </span><span class="ff7">p<span class="_ _41"> </span></span>0.51<span class="_ _40"> </span>19<span class="_ _3e"> </span><span class="ff7">p<span class="_ _3f"> </span></span>0.3</div><div class="t m0 xa7 h4 y1e2 ff3 fs2 fc0 sc0 ls0 ws0">10<span class="_ _3e"> </span><span class="ff7">n<span class="_ _42"> </span></span>0.505<span class="_ _40"> </span>20<span class="_ _3e"> </span><span class="ff7">n<span class="_ _3f"> </span></span>0.1</div><div class="t m0 x9a h6 y1e3 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _6"> </span><span class="ff1">阈值</span></div><div class="t m0 x66 hc y1e4 ffa fs2 fc0 sc0 ls0 ws0">t<span class="_ _2c"> </span>&gt;</div><div class="t m0 xcd h4 y1e3 ffb fs2 fc0 sc0 ls0 ws0">0</div><div class="t m0 xce hc y1e4 ffa fs2 fc0 sc0 ls0 ws0">.</div><div class="t m0 xcf h4 y1e3 ffb fs2 fc0 sc0 ls0 ws0">9</div><div class="t m0 xd0 h6 y1e4 ff1 fs2 fc0 sc0 ls0 ws0">，则</div><div class="t m0 xd1 hc y1e3 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P</div><div class="t m0 xd2 h4 y1e4 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xd3 hc y1e3 ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _2b"> </span>P</div><div class="t m0 xc2 h4 y1e4 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>0</div><div class="t m0 x48 h6 y1e3 ff1 fs2 fc0 sc0 ls0 ws0">，</div><div class="t m0 x88 hc y1e4 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R</div><div class="t m0 x5a h4 y1e3 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>0</div><div class="t m0 xb0 h6 y1e4 ff1 fs2 fc0 sc0 ls0 ws0">，</div><div class="t m0 xd4 hc y1e3 ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R</div><div class="t m0 xd5 h4 y1e4 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>0</div><div class="t m0 x95 h6 y1e3 ff1 fs2 fc0 sc0 ls0 ws0">；</div><div class="t m0 x9a h6 y1e5 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff1">阈值<span class="_ _c"> </span><span class="ffa">t<span class="_ _2c"> </span><span class="fff">≥<span class="_ _2c"> </span><span class="ffb">0</span></span>.<span class="ffb">9</span></span>，则<span class="_ _c"> </span><span class="ffa">T<span class="_ _2b"> </span>P<span class="_ _2e"> </span><span class="ffb">=<span class="_ _2c"> </span>1</span></span>，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _27"> </span>0</span></span>，<span class="ffa">T<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=</span></span></span></div><div class="t m0 xbe ha y1e6 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x25 ha y1e7 ffc fs6 fc0 sc0 ls0 ws0">10</div><div class="t m0 xd6 h6 y1e5 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span>0</span></span>；</div><div class="t m0 x9a h6 y1e8 ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _6"> </span><span class="ff1">阈值<span class="_ _c"> </span><span class="ffa">t<span class="_ _2c"> </span><span class="fff">≥<span class="_ _2c"> </span><span class="ffb">0</span></span>.<span class="ffb">9</span></span>，则<span class="_ _c"> </span><span class="ffa">T<span class="_ _2b"> </span>P<span class="_ _2e"> </span><span class="ffb">=<span class="_ _2c"> </span>1</span></span>，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _27"> </span>0</span></span>，<span class="ffa">T<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=</span></span></span></div><div class="t m0 xbe ha y1e9 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x25 ha y1ea ffc fs6 fc0 sc0 ls0 ws0">10</div><div class="t m0 xd6 h6 y1e8 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span>0</span></span>；</div><div class="t m0 x9a h4 y1eb ff3 fs2 fc0 sc0 ls0 ws0">4.<span class="_ _6"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·</span></div><div class="t m0 x9a h6 y1ec ff3 fs2 fc0 sc0 ls0 ws0">5.<span class="_ _6"> </span><span class="ff1">阈值<span class="_ _c"> </span><span class="ffa">t<span class="_ _2c"> </span><span class="fff">≥<span class="_ _2c"> </span><span class="ffb">0</span></span>.<span class="ffb">1</span></span>，则<span class="_ _c"> </span><span class="ffa">T<span class="_ _2b"> </span>P<span class="_ _2e"> </span><span class="ffb">=<span class="_ _2c"> </span>10</span></span>，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _27"> </span>10</span></span>，<span class="ffa">T<span class="_ _2b"> </span>P<span class="_ _2b"> </span>R<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span>1</span></span>，<span class="ffa">F<span class="_ _2b"> </span>P<span class="_ _2d"> </span>R<span class="_ _2c"> </span><span class="ffb">=<span class="_ _2c"> </span>1</span></span>。</span></div><div class="t m0 x3 h6 y1ed ff1 fs2 fc0 sc0 ls0 ws0">最后绘制出来的<span class="_ _c"> </span><span class="ff3">R<span class="_ _10"></span>OC<span class="_ _c"> </span><span class="ff1">图如下所示：</span></span></div><div class="t m0 x3 h6 y1c6 ff3 fs2 fc0 sc0 ls0 ws0">R<span class="_ _10"></span>OC<span class="_ _c"> </span><span class="ff1">曲线<span class="_ _f"></span>可以很直观的<span class="_ _f"></span>展示模型的好坏，<span class="_ _f"></span>但是如果不同<span class="_ _f"></span>模型的<span class="_ _0"> </span></span>R<span class="_ _10"></span>OC<span class="_ _c"> </span><span class="ff1">曲线<span class="_ _f"></span>存在交叉，则很难<span class="_ _f"></span>依</span></div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">靠视觉来对<span class="_ _f"></span>模型的优<span class="_ _f"></span>劣进行比<span class="_ _f"></span>较，此时可<span class="_ _f"></span>以使用曲线<span class="_ _f"></span>下面积<span class="_ _0"> </span><span class="ff3">(Area<span class="_ _0"> </span>Under<span class="_ _0"> </span>Curve,<span class="_ _c"> </span>AUC)<span class="_ _c"> </span></span>这个指</div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">标来进行评价。</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">14</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf14" class="pf w0 h0" data-page-no="14"><div class="pc pc14 w0 h0"><img class="bi x3 y1ee w2 h1e" alt="" src="bg14.png"/><div class="t m0 xd7 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">2.7<span class="_ _15"> </span><span class="ff8">代价敏感错误率</span></div><div class="t m0 x3 h6 y1f ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">2.8<span class="_ _6"> </span>A<span class="_ _10"></span>UC<span class="ff4">：<span class="ff1">指<span class="_ _f"></span>的是<span class="_ _11"> </span><span class="ff3">ROC<span class="_ _0"> </span></span>曲<span class="_ _f"></span>线右<span class="_ _f"></span>下方<span class="_ _f"></span>的面<span class="_ _f"></span>积，该<span class="_ _f"></span>面积<span class="_ _f"></span>越大，<span class="_ _f"></span>一般<span class="_ _f"></span>表示<span class="_ _f"></span>模型<span class="_ _f"></span>的预<span class="_ _f"></span>测<span class="_ _f"></span>能力<span class="_ _f"></span>越好，</span></span></span></div><div class="t m0 x3 h6 y1ef ff1 fs2 fc0 sc0 ls0 ws0">此时可以将<span class="_ _c"> </span><span class="ff3">R<span class="_ _10"></span>OC<span class="_ _c"> </span><span class="ff1">曲线上离左上角最近的点所对于的分类阈值作为最终分类器的阈值。</span></span></div><div class="t m0 x3 h6 y1f0 ff1 fs2 fc0 sc0 ls0 ws0">由定义可<span class="_ _f"></span>知，<span class="ff3">A<span class="_ _10"></span>UC<span class="_ _0"> </span><span class="ff1">可通过<span class="_ _f"></span>对<span class="_ _0"> </span></span>ROC<span class="_ _c"> </span><span class="ff1">曲线下各<span class="_ _f"></span>部分的<span class="_ _f"></span>面积求和<span class="_ _f"></span>而得。假定<span class="_ _0"> </span></span>ROC<span class="_ _c"> </span><span class="ff1">曲<span class="_ _f"></span>线是由坐<span class="_ _f"></span>标为</span></span></div><div class="t m0 x3 h4 y1f1 fff fs2 fc0 sc0 ls0 ws0">{<span class="ffb">(<span class="ffa">x</span></span></div><div class="t m0 x5 ha y1f2 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd8 hc y1f1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>y</div><div class="t m0 x33 ha y1f2 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x7a h4 y1f1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ffa">,<span class="_ _2d"> </span></span>(<span class="ffa">x</span></div><div class="t m0 xd9 ha y1f2 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xda hc y1f1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>y</div><div class="t m0 xdb ha y1f2 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xdc h4 y1f1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ffa">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span></span>(<span class="ffa">x</span></div><div class="t m0 x6a hb y1f2 ffd fs6 fc0 sc0 ls0 ws0">m</div><div class="t m0 xc hc y1f1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>y</div><div class="t m0 xcb hb y1f2 ffd fs6 fc0 sc0 ls0 ws0">m</div><div class="t m0 xd3 h6 y1f1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="fff">}<span class="_ _27"> </span><span class="ff1">的点按序连接而形成<span class="_ _c"> </span></span></span>(<span class="ffa">x</span></div><div class="t m0 x5e ha y1f2 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5f h4 y1f1 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>0<span class="ffa">,<span class="_ _2d"> </span>x</span></div><div class="t m0 xdd hb y1f2 ffd fs6 fc0 sc0 ls0 ws0">m</div><div class="t m0 xde h6 y1f1 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>1)<span class="ff1">，<span class="_ _22"></span>参见图<span class="ff3">2.2(b)</span>，<span class="_ _31"></span>则<span class="_ _27"> </span><span class="ff3">A<span class="_ _10"></span>UC</span></span></div><div class="t m0 x3 h6 y1f3 ff1 fs2 fc0 sc0 ls0 ws0">可估算为：</div><div class="t m0 xa2 h4 y1f4 ff3 fs2 fc0 sc0 ls0 ws0">AUC <span class="ffb">=</span></div><div class="t m0 x48 h4 y1f5 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x48 h4 y1f6 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8 ha y1f7 ffd fs6 fc0 sc0 ls0 ws0">m<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x3c he y1f8 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa8 ha y1f9 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x4 h4 y1f4 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span></div><div class="t m0 xa3 ha y1fa ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">+1</span></div><div class="t m0 x99 h4 y1f4 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">x</span></div><div class="t m0 xaf hb y1fa ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xdf h4 y1f4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">·<span class="_ _25"> </span></span>(<span class="ffa">y</span></div><div class="t m0 x5f hb y1fa ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xe0 h4 y1f4 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 xe1 ha y1fa ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">+1</span></div><div class="t m0 xe2 h4 y1f4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _43"> </span><span class="ff3">(2.14)</span></div><div class="t m0 x1e h6 y1fb ff1 fs2 fc0 sc0 ls0 ws0">这是梯形面积的计算公式，因为当存在正例和反例的打分相等时，则会出现梯形；<span class="_ _10"></span>若不存</div><div class="t m0 x1e h6 y1fc ff1 fs2 fc0 sc0 ls0 ws0">在这种情况，则只会出现长方形，而长方形的面积亦可使用梯形面积公式计算。</div><div class="t m0 x3 h6 y1fd ff1 fs2 fc0 sc0 ls0 ws0">形式化地看，<span class="_ _2f"></span><span class="ff3">AUC<span class="_ _27"> </span><span class="ff1">考虑的是样本预测的排序质量，因此它与排序误差有紧密联系，<span class="_ _2f"></span>给定<span class="_ _c"> </span><span class="ffa">m</span></span></span></div><div class="t m0 x32 ha y1fe ffc fs6 fc0 sc0 ls0 ws0">+</div><div class="t m0 xb3 h6 y1fd ff1 fs2 fc0 sc0 ls0 ws0">个</div><div class="t m0 x3 h6 y1ff ff1 fs2 fc0 sc0 ls0 ws0">正例和<span class="_ _c"> </span><span class="ffa">m</span></div><div class="t m0 xe3 ha y200 ff12 fs6 fc0 sc0 ls0 ws0">−</div><div class="t m0 xe4 h6 y1ff ff1 fs2 fc0 sc0 ls0 ws0">个反例，另<span class="_ _c"> </span><span class="ffa">D</span></div><div class="t m0 x19 ha y200 ffc fs6 fc0 sc0 ls0 ws0">+</div><div class="t m0 x83 h6 y1ff ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _c"> </span><span class="ffa">D</span></div><div class="t m0 x1d ha y200 ff12 fs6 fc0 sc0 ls0 ws0">−</div><div class="t m0 xca h6 y1ff ff1 fs2 fc0 sc0 ls0 ws0">分别表示正、反例集合，则排序“损失”<span class="ff3">(loss)<span class="_ _c"> </span></span>定义为</div><div class="t m0 x78 hc y201 ffa fs2 fc0 sc0 ls0 ws0">ℓ</div><div class="t m0 x34 h1f y202 ff16 fs6 fc0 sc0 ls0 ws0">rank</div><div class="t m0 xe5 h4 y201 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xd0 h4 y203 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xcd hc y204 ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x37 ha y205 ffc fs6 fc0 sc0 ls0 ws0">+</div><div class="t m0 xb4 hc y204 ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 xc1 ha y205 ff12 fs6 fc0 sc0 ls0 ws0">−</div><div class="t m0 xb5 he y206 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe6 h16 y207 ff11 fs6 fc0 sc0 ls0 ws0">x</div><div class="t m0 xe7 h1a y208 ff14 fs8 fc0 sc0 ls0 ws0">+</div><div class="t m0 xe8 ha y207 ff12 fs6 fc0 sc0 ls0 ws0">∈<span class="ffd">D</span></div><div class="t m0 xe9 h1a y208 ff14 fs8 fc0 sc0 ls0 ws0">+</div><div class="t m0 xa2 h16 y207 ff11 fs6 fc0 sc0 ls0 ws0">x</div><div class="t m0 x77 h1d y208 ff15 fs8 fc0 sc0 ls0 ws0">−</div><div class="t m0 x39 h16 y207 ff11 fs6 fc0 sc0 ls0 ws0">p</div><div class="t m0 x45 h1d y208 ff15 fs8 fc0 sc0 ls0 ws0">−</div><div class="t m0 x3b he y209 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x1f h20 y201 ff13 fs2 fc0 sc0 ls0 ws0">I</div><div class="t m0 xea he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x2 hc y201 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 xeb he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 h21 y201 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x4a ha y20b ffc fs6 fc0 sc0 ls0 ws0">+</div><div class="t m0 x8d he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a hc y201 ffa fs2 fc0 sc0 ls0 ws0">&lt;<span class="_ _2c"> </span>f</div><div class="t m0 x91 he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4c h21 y201 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xaf ha y20b ff12 fs6 fc0 sc0 ls0 ws0">−</div><div class="t m0 xd6 he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xcc h4 y201 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xe0 h4 y203 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe0 h4 y204 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x94 h20 y201 ff13 fs2 fc0 sc0 ls0 ws0">I</div><div class="t m0 x9d he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x6b hc y201 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 xec he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe2 h21 y201 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x89 ha y20b ffc fs6 fc0 sc0 ls0 ws0">+</div><div class="t m0 xed he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x54 h4 y201 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 xee he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h21 y201 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xef ha y20b ff12 fs6 fc0 sc0 ls0 ws0">−</div><div class="t m0 xf0 he y20a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf1 he y209 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xb7 h4 y201 ff3 fs2 fc0 sc0 ls0 ws0">(2.15)</div><div class="t m0 x3 h6 y20c ff1 fs2 fc0 sc0 ls0 ws0">即考虑每一对正、<span class="_ _2f"></span>反例，<span class="_ _2f"></span>若正例的预测值小于反例，<span class="_ _2f"></span>则记一个罚分，<span class="_ _2f"></span>若相等，<span class="_ _2f"></span>记<span class="_ _27"> </span><span class="ff3">0.5<span class="_ _c"> </span></span>个罚分。<span class="_ _2f"></span>容</div><div class="t m0 x3 h6 y20d ff1 fs2 fc0 sc0 ls0 ws0">易看出，<span class="_ _28"></span><span class="ffa">ℓ</span></div><div class="t m0 xe3 h1f y20e ff16 fs6 fc0 sc0 ls0 ws0">rank</div><div class="t m0 xf2 h6 y20d ff1 fs2 fc0 sc0 ls0 ws0">对应的是<span class="_ _27"> </span><span class="ff3">ROC </span>曲线之上的面积：<span class="_ _28"></span>若一个正例在<span class="_ _27"> </span><span class="ff3">ROC </span>曲线上对应标记点的坐标为</div><div class="t m0 x3 h6 y20f ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x,<span class="_ _2d"> </span>y<span class="_ _f"></span></span>)<span class="ff1">，则<span class="_ _c"> </span><span class="ffa">x<span class="_ _c"> </span></span>恰是排序在其之前的反例所占的比例，即假正率。因此有</span></div><div class="t m0 x3c h4 y210 ff3 fs2 fc0 sc0 ls0 ws0">AUC <span class="ffb">=<span class="_ _2c"> </span>1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">ℓ</span></span></span></div><div class="t m0 xaf h1f y211 ff16 fs6 fc0 sc0 ls0 ws0">rank</div><div class="t m0 xb7 h4 y210 ff3 fs2 fc0 sc0 ls0 ws0">(2.16)</div><div class="t m0 xb9 h9 y212 ff6 fs5 fc0 sc0 ls0 ws0">2.7<span class="_ _21"> </span><span class="ff9">代价敏感错误率</span></div><div class="t m0 x3 h6 y213 ff1 fs2 fc0 sc0 ls0 ws0">有时候，<span class="_ _22"></span>不同类型的错误所造成的后果不同。<span class="_ _22"></span>为权衡不同类型错误所造成的不同损失，<span class="_ _28"></span>可为错误</div><div class="t m0 x3 h6 y214 ff1 fs2 fc0 sc0 ls0 ws0">赋予“非均等代价”<span class="ff3">(unequa1<span class="_ _c"> </span>cost)</span>。</div><div class="t m0 x3 h6 y215 ff1 fs2 fc0 sc0 ls0 ws0">以二分类任务为例，<span class="_ _2f"></span>我们可以根据任务的领域知识设定一个<span class="_ _10"></span>“代价矩阵”<span class="_ _10"></span><span class="ff3">(cost<span class="_ _c"> </span>matrix)<span class="ff1">，<span class="_ _2f"></span>如下表</span></span></div><div class="t m0 x3 h6 y216 ff1 fs2 fc0 sc0 ls0 ws0">所示。其中，<span class="ffa">cost</span></div><div class="t m0 x14 hb y217 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xf3 h6 y216 ff1 fs2 fc0 sc0 ls0 ws0">表示将第<span class="_ _c"> </span><span class="ffa">i<span class="_ _c"> </span></span>类样本预测为第<span class="_ _c"> </span><span class="ffa">j<span class="_ _11"> </span></span>类样本的代价。一般来说，<span class="ffa">cost</span></div><div class="t m0 x85 hb y217 ffd fs6 fc0 sc0 ls0 ws0">ii</div><div class="t m0 xf4 h6 y216 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>0<span class="ff1">。</span></div><div class="t m0 xf5 h6 y218 ff1 fs2 fc0 sc0 ls0 ws0">真实情况</div><div class="t m0 x99 h6 y219 ff1 fs2 fc0 sc0 ls0 ws0">预测结果</div><div class="t m0 xbd h6 y21a ff1 fs2 fc0 sc0 ls0 ws0">第<span class="_ _c"> </span><span class="ff3">0<span class="_ _c"> </span></span>类<span class="_ _3e"> </span>第<span class="_ _c"> </span><span class="ff3">1<span class="_ _c"> </span></span>类</div><div class="t m0 xf6 h6 y21b ff1 fs2 fc0 sc0 ls0 ws0">第<span class="_ _c"> </span><span class="ff3">0<span class="_ _c"> </span></span>类<span class="_ _44"> </span><span class="ff3">0<span class="_ _45"> </span><span class="ffa">cost</span></span></div><div class="t m0 xf7 ha y21c ffc fs6 fc0 sc0 ls0 ws0">01</div><div class="t m0 xf6 h6 y21d ff1 fs2 fc0 sc0 ls0 ws0">第<span class="_ _c"> </span><span class="ff3">1<span class="_ _c"> </span></span>类<span class="_ _46"> </span><span class="ffa">cost</span></div><div class="t m0 x5d ha y21e ffc fs6 fc0 sc0 ls0 ws0">10</div><div class="t m0 x5f h4 y21d ff3 fs2 fc0 sc0 ls0 ws0">0</div><div class="t m0 x1e h6 y21f ff1 fs2 fc0 sc0 ls0 ws0">重要的是代价比值而非绝对值，例如<span class="_ _c"> </span><span class="ffa">cost</span></div><div class="t m0 x1 ha y220 ffc fs6 fc0 sc0 ls0 ws0">01</div><div class="t m0 x7 h4 y21f ffb fs2 fc0 sc0 ls0 ws0">:<span class="_ _2c"> </span><span class="ffa">cost</span></div><div class="t m0 xbe ha y220 ffc fs6 fc0 sc0 ls0 ws0">01</div><div class="t m0 xab h6 y21f ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>5<span class="_ _2c"> </span>:<span class="_ _2c"> </span>1<span class="_ _c"> </span><span class="ff1">与<span class="_ _c"> </span></span>50<span class="_ _27"> </span>:<span class="_ _2c"> </span>10<span class="_ _c"> </span><span class="ff1">的效果是一样的。</span></div><div class="t m0 x3 h6 y221 ff1 fs2 fc0 sc0 ls0 ws0">前面介绍的性能度量都是假设均等代价，<span class="_ _22"></span>也就是犯错误次数越少越好。<span class="_ _22"></span>在非均等错误代价下，<span class="_ _28"></span>我</div><div class="t m0 x3 h6 y222 ff1 fs2 fc0 sc0 ls0 ws0">们希望的是最小化“总体代价”<span class="_ _23"></span>，则“代价敏感”错误率为：</div><div class="t m0 xf8 h4 y223 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _1f"></span><span class="ffb">(</span>f<span class="_ _32"></span><span class="ffb">;<span class="_ _2d"> </span></span>D<span class="_ _f"></span><span class="ffb">;<span class="_ _2d"> </span><span class="ff3">cos<span class="_ _2d"> </span></span></span>t<span class="ffb">)<span class="_ _2c"> </span>=</span></div><div class="t m0 x3c h4 y224 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3d hc y225 ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x49 he y226 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x49 he y227 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3f he y228 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4 h16 y229 ff11 fs6 fc0 sc0 ls0 ws0">x</div><div class="t m0 x3f h22 y22a ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 xf9 ha y229 ff12 fs6 fc0 sc0 ls0 ws0">∈<span class="ffd">D</span></div><div class="t m0 x24 h1a y22b ff14 fs8 fc0 sc0 ls0 ws0">+</div><div class="t m0 x5d h4 y223 ff13 fs2 fc0 sc0 ls0 ws0">I<span class="_ _2d"> </span><span class="ffb">(<span class="ffa">f<span class="_ _2c"> </span></span>(<span class="ff11">x</span></span></div><div class="t m0 x5e hb y22c ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xcc h4 y223 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff"≯</span>=<span class="_ _2c"> </span><span class="ffa">y</span></div><div class="t m0 x9d hb y22c ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x28 h4 y223 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">×<span class="_ _25"> </span><span class="ff3">cos<span class="_ _2d"> </span><span class="ffa">t</span></span></span></div><div class="t m0 x54 ha y22c ffc fs6 fc0 sc0 ls0 ws0">01</div><div class="t m0 x3c h4 y22d ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xfa he y22e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x49 h16 y22f ff11 fs6 fc0 sc0 ls0 ws0">x</div><div class="t m0 x4a h22 y230 ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 xbc ha y22f ff12 fs6 fc0 sc0 ls0 ws0">∈<span class="ffd">D</span></div><div class="t m0 x5a h1d y231 ff15 fs8 fc0 sc0 ls0 ws0">−</div><div class="t m0 x40 h4 y22d ff13 fs2 fc0 sc0 ls0 ws0">I<span class="_ _2d"> </span><span class="ffb">(<span class="ffa">f<span class="_ _2c"> </span></span>(<span class="ff11">x</span></span></div><div class="t m0 xd6 hb y232 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x41 h4 y22d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff"≯</span>=<span class="_ _2c"> </span><span class="ffa">y</span></div><div class="t m0 xf7 hb y232 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4f h4 y22d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">×<span class="_ _25"> </span><span class="ff3">cos<span class="_ _2d"> </span><span class="ffa">t</span></span></span></div><div class="t m0 xfb ha y232 ffc fs6 fc0 sc0 ls0 ws0">10</div><div class="t m0 x54 he y233 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x54 he y234 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xb7 h4 y235 ff3 fs2 fc0 sc0 ls0 ws0">(2.17)</div><div class="t m0 x3 h6 y236 ff1 fs2 fc0 sc0 ls0 ws0">其中，第<span class="_ _c"> </span><span class="ff3">0<span class="_ _c"> </span></span>类作为正类、第<span class="_ _c"> </span><span class="ff3">1<span class="_ _c"> </span></span>类作为反类，<span class="ffa">D</span></div><div class="t m0 x8f ha y237 ffc fs6 fc0 sc0 ls0 ws0">+</div><div class="t m0 xfc h6 y236 ff1 fs2 fc0 sc0 ls0 ws0">与<span class="_ _c"> </span><span class="ffa">D</span></div><div class="t m0 xbf ha y237 ff12 fs6 fc0 sc0 ls0 ws0">−</div><div class="t m0 xfd h6 y236 ff1 fs2 fc0 sc0 ls0 ws0">分别代表样本集<span class="_ _c"> </span><span class="ffa">D<span class="_ _0"> </span></span>的正例集和反例集。</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">15</div><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",458.19,345.2,null]'><div class="d m1" style="border-style:none;position:absolute;left:672.174000px;bottom:1103.809500px;width:13.941000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf15" class="pf w0 h0" data-page-no="15"><div class="pc pc15 w0 h0"><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">2.7<span class="_ _15"> </span><span class="ff8">代价敏感错误率</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">16</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf16" class="pf w0 h0" data-page-no="16"><div class="pc pc16 w0 h0"><div class="t m0 x8 h5 y44 ff4 fs3 fc0 sc0 ls0 ws0">第二部分</div><div class="t m0 x9 h5 y45 ff4 fs3 fc0 sc0 ls0 ws0">机器学习中阶</div><div class="t m0 x0 h1 y46 ff5 fs0 fc0 sc0 ls0 ws0">传统模型</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">17</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf17" class="pf w0 h0" data-page-no="17"><div class="pc pc17 w0 h0"></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf18" class="pf w0 h0" data-page-no="18"><div class="pc pc18 w0 h0"><img class="bi x3 y238 w2 h23" alt="" src="bg18.png"/><div class="t m0 xc h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第三章 贝叶斯分类器</div><div class="t m0 x1c h9 y48 ff6 fs5 fc0 sc0 ls0 ws0">3.1<span class="_ _21"> </span><span class="ff9">判别规则</span></div><div class="t m0 x3 h6 y239 ff4 fs6 fc0 sc0 ls0 ws0">定义<span class="ff7 fs2">3.1<span class="_ _6"> </span>Ba<span class="_ _10"></span>y<span class="_ _10"></span>esian<span class="_ _c"> </span>decision<span class="_ _c"> </span>theory(<span class="ff4">叶斯决策论</span>)<span class="ff4">：<span class="_ _28"></span><span class="ff1">基于概率实施决策的方法。<span class="_ _28"></span>对分类任务来说，</span></span></span></div><div class="t m0 x3 h6 y23a ff4 fs2 fc0 sc0 ls0 ws0">在所<span class="_ _f"></span>有相<span class="_ _f"></span>关<span class="_ _f"></span>概率<span class="_ _f"></span>都<span class="_ _f"></span>己知<span class="_ _f"></span>的理<span class="_ _f"></span>想<span class="_ _f"></span>情形<span class="_ _f"></span>下<span class="ff1">，<span class="_ _f"></span>贝叶<span class="_ _f"></span>斯<span class="_ _f"></span>决策<span class="_ _f"></span>论根<span class="_ _f"></span>据<span class="_ _f"></span>误判<span class="_ _f"></span>代<span class="_ _f"></span>价最<span class="_ _f"></span>小<span class="_ _f"></span>的原<span class="_ _f"></span>则来<span class="_ _f"></span>选<span class="_ _f"></span>择最<span class="_ _f"></span>优<span class="_ _f"></span>的分</span></div><div class="t m0 x3 h6 y23b ff1 fs2 fc0 sc0 ls0 ws0">类标记。</div><div class="t m0 x3 h6 y23c ff1 fs2 fc0 sc0 ls0 ws0">以多分类任<span class="_ _f"></span>务为例来解<span class="_ _f"></span>释其基本原<span class="_ _f"></span>理：假设有<span class="_ _0"> </span><span class="ff3">N<span class="_ _0"> </span></span>种可能的<span class="_ _f"></span>类别<span class="_ _1c"> </span><span class="ff7">lab<span class="_ _f"></span>el</span>，即<span class="_ _0"> </span><span class="ffa">y<span class="_ _0"> </span><span class="ffb">=<span class="_ _27"> </span><span class="fff">{</span></span>c</span></div><div class="t m0 x85 ha y23d ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xfe hc y23c ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>c</div><div class="t m0 xff ha y23d ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xf h4 y23c ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>c</div><div class="t m0 x100 hb y23e ffd fs6 fc0 sc0 ls0 ws0">N</div><div class="t m0 x101 h6 y23c fff fs2 fc0 sc0 ls0 ws0">}<span class="ff1">，</span></div><div class="t m0 x3 hc y23f ffa fs2 fc0 sc0 ls0 ws0">λ</div><div class="t m0 x102 hb y240 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x103 h6 y23f ff1 fs2 fc0 sc0 ls0 ws0">是将一个<span class="_ _f"></span>真实标<span class="_ _f"></span>记为<span class="_ _0"> </span><span class="ffa">c</span></div><div class="t m0 x6f hb y240 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xcb h6 y23f ff1 fs2 fc0 sc0 ls0 ws0">的样本误<span class="_ _f"></span>分类为<span class="_ _0"> </span><span class="ffa">c</span></div><div class="t m0 x23 hb y240 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x104 h6 y23f ff1 fs2 fc0 sc0 ls0 ws0">所产生的<span class="_ _f"></span>损失。则<span class="_ _f"></span>当样本为<span class="_ _11"> </span><span class="ffa">x<span class="_ _0"> </span></span>时，分类<span class="_ _f"></span>为<span class="_ _0"> </span><span class="ffa">c</span></div><div class="t m0 x105 hb y240 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb3 h6 y23f ff1 fs2 fc0 sc0 ls0 ws0">所</div><div class="t m0 x3 h6 y241 ff1 fs2 fc0 sc0 ls0 ws0">产生的期望损失<span class="_ _c"> </span><span class="ff3">(exp<span class="_ _f"></span>ected<span class="_ _c"> </span>loss)<span class="_ _c"> </span></span>为：</div><div class="t m0 xca h4 y242 ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>c</div><div class="t m0 x3c hb y243 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xeb h4 y242 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _2c"> </span>=</span></span></div><div class="t m0 x9f hb y244 ffd fs6 fc0 sc0 ls0 ws0">N</div><div class="t m0 x5a he y245 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a ha y246 ffd fs6 fc0 sc0 ls0 ws0">j<span class="_ _f"></span><span class="ffc">=1</span></div><div class="t m0 x5d hc y242 ffa fs2 fc0 sc0 ls0 ws0">λ</div><div class="t m0 xb2 hb y243 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xbe h4 y242 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c</div><div class="t m0 x5e hb y243 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x65 h4 y242 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)</span></span></div><div class="t m0 x1e h6 y247 ff1 fs2 fc0 sc0 ls0 ws0">这又称为<span class="ff4">在样本<span class="_ _11"> </span><span class="ffa">x<span class="_ _11"> </span></span>上的条件风险</span>（<span class="ff3">conditional<span class="_ _c"> </span>risk</span>）</div><div class="t m0 x1e h6 y248 ff1 fs2 fc0 sc0 ls0 ws0">注意：<span class="_ _29"></span>这里求的是期望损失，<span class="_ _29"></span>所谓期望，<span class="_ _29"></span>就是所有分类情况的平均<span class="_ _28"></span>（但真实情况只有一个）<span class="_ _34"></span>。</div><div class="t m0 x3 h6 y249 ff1 fs2 fc0 sc0 ls0 ws0">那么，现在要找到一个判定准则：<span class="ffa">x<span class="_ _2c"> </span><span class="fff">→<span class="_ _2c"> </span></span>y<span class="_ _1f"></span></span>，它可以使得总体风险最小：</div><div class="t m0 x106 h4 y24a ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span></span>E</div><div class="t m0 x90 hb y24b ffd fs6 fc0 sc0 ls0 ws0">x</div><div class="t m0 x40 h4 y24a ffb fs2 fc0 sc0 ls0 ws0">[<span class="ffa">R</span>(<span class="ffa">h</span>(<span class="ffa">x</span>)<span class="fff">|<span class="ffa">x</span></span>)]</div><div class="t m0 x1e h6 y24c ff1 fs2 fc0 sc0 ls0 ws0">注意：<span class="_ _22"></span><span class="ffa">R<span class="ffb">(</span>c</span></div><div class="t m0 x107 hb y24d ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc3 h6 y24c fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _27"> </span><span class="ff1">是一个期望，<span class="_ _22"></span>针对所有<span class="_ _27"> </span><span class="ffa">x<span class="_ _27"> </span></span>的所有分类情况<span class="_ _31"></span>（包括正确的分类情况）<span class="_ _34"></span>；<span class="_ _22"></span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _27"> </span><span class="ff1">是</span></span></span></span></span></span></div><div class="t m0 x1e h4 y24e ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>c</div><div class="t m0 x108 hb y24f ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x109 h6 y24e fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _c"> </span><span class="ff1">的期望，针对所有<span class="_ _c"> </span></span></span>x<span class="_ _c"> </span><span class="ff1">的期望损失。</span></span></div><div class="t m0 x3 h6 y250 ff1 fs2 fc0 sc0 ls0 ws0">那<span class="_ _f"></span>么，<span class="_ _1f"></span>如<span class="_ _f"></span>何<span class="_ _1f"></span>使<span class="_ _f"></span>得<span class="_ _6"> </span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _6"> </span></span></span>最<span class="_ _f"></span>小<span class="_ _1f"></span>呢？<span class="_ _f"></span>最<span class="_ _1f"></span>直<span class="_ _f"></span>接<span class="_ _1f"></span>的<span class="_ _f"></span>想<span class="_ _1f"></span>法<span class="_ _f"></span>时，<span class="_ _1f"></span>如<span class="_ _f"></span>果<span class="_ _1f"></span>对<span class="_ _f"></span>于<span class="_ _1f"></span>每<span class="_ _1f"></span>个<span class="_ _b"> </span><span class="ffa">x</span></div><div class="t m0 x8a hb y251 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc8 h6 y250 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="ffa">h<span class="_ _b"> </span></span>都<span class="_ _1f"></span>能<span class="_ _f"></span>最<span class="_ _1f"></span>小<span class="_ _f"></span>化<span class="_ _1f"></span>条<span class="_ _f"></span>件<span class="_ _1f"></span>风<span class="_ _f"></span>险</div><div class="t m0 x3 h6 y252 ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>h<span class="ffb">(</span>x<span class="ffb">)<span class="fff">|</span></span>x<span class="ffb">)<span class="ff1">，<span class="_ _22"></span>那么总体风险<span class="_ _c"> </span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _27"> </span></span></span>必定也是最小的，<span class="_ _22"></span>这就是<span class="ff4">贝叶斯判别准则</span>。<span class="_ _31"></span>因此，<span class="_ _22"></span>在贝叶斯判定</span></span></div><div class="t m0 x3 h6 y253 ff1 fs2 fc0 sc0 ls0 ws0">准则下，对每个样本都选择能使条件风险<span class="_ _c"> </span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">(</span>x<span class="ffb">)<span class="fff">|</span></span>x<span class="ffb">)<span class="_ _c"> </span></span></span>最小的<span class="_ _c"> </span><span class="ff3">lab<span class="_ _f"></span>el</span>，即：</div><div class="t m0 x87 hc y254 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xb1 ha y255 ff12 fs6 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x10a h4 y254 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span>)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff3">arg<span class="_ _2d"> </span>min</span></div><div class="t m0 x99 ha y256 ffd fs6 fc0 sc0 ls0 ws0">c<span class="ff12">∈</span>y</div><div class="t m0 xaf h4 y254 ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></div><div class="t m0 x1e h6 y257 ff3 fs2 fc0 sc0 ls0 ws0">arg<span class="_ _2d"> </span>min<span class="_ _2d"> </span><span class="ffa">f<span class="_ _32"></span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _c"> </span><span class="ff1">的含义时，当<span class="_ _c"> </span></span></span>f<span class="_ _32"></span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _c"> </span><span class="ff1">取最小值时，</span></span>x<span class="_ _c"> </span><span class="ff1">的取值。上述公式的意义就是：当<span class="_ _c"> </span></span>R<span class="ffb">(</span>c<span class="fff">|</span>x</span></div><div class="t m0 x1e h6 y258 ff1 fs2 fc0 sc0 ls0 ws0">取最小值时，<span class="ffa">c<span class="_ _c"> </span></span>的取值。</div><div class="t m0 x3 h6 y259 ff1 fs2 fc0 sc0 ls0 ws0">此时，<span class="_ _22"></span><span class="ffa">h</span></div><div class="t m0 x10b ha y25a ff12 fs6 fc0 sc0 ls0 ws0">∗</div><div class="t m0 xb h6 y259 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span>)<span class="_ _27"> </span><span class="ff1">称为<span class="ff4">贝叶斯最优分类器<span class="_ _0"> </span><span class="ff7">(Bay<span class="_ _2f"></span>es<span class="_ _0"> </span>optimal<span class="_ _0"> </span>classier)<span class="_ _c"> </span><span class="ff1">，<span class="_ _22"></span>与之对应的总体风险<span class="_ _c"> </span><span class="ffa">R<span class="ffb">(</span>h</span></span></span></span></span></div><div class="t m0 x73 ha y25a ff12 fs6 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x74 h4 y259 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y25b ff1 fs2 fc0 sc0 ls0 ws0">称为贝<span class="_ _f"></span>叶斯风<span class="_ _f"></span>险<span class="_ _0"> </span><span class="ff3">(Bay<span class="_ _10"></span>es<span class="_ _0"> </span>risk)<span class="ff1">。<span class="ffb">1<span class="_ _25"> </span><span class="fff">−<span class="_ _2c"> </span><span class="ffa">R</span></span>(<span class="ffa">h</span></span></span></span></div><div class="t m0 x10c ha y25c ff12 fs6 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x0 h6 y25b ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _0"> </span><span class="ff1">反映<span class="_ _f"></span>了分<span class="_ _f"></span>类器所<span class="_ _f"></span>能达<span class="_ _f"></span>到的最<span class="_ _f"></span>好性<span class="_ _f"></span>能，即通<span class="_ _f"></span>过机<span class="_ _f"></span>器学习</span></div><div class="t m0 x3 h6 y25d ff1 fs2 fc0 sc0 ls0 ws0">所能产生的模型精度的理论上限。</div><div class="t m0 x1e h6 y25e ff1 fs2 fc0 sc0 ls0 ws0">换而言之，使得<span class="_ _c"> </span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _c"> </span></span></span>达到理论最小值的贝叶斯分类器才是贝叶斯最优分类器。</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">19</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf19" class="pf w0 h0" data-page-no="19"><div class="pc pc19 w0 h0"><img class="bi x5b y25f w9 h24" alt="" src="bg19.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.2<span class="_ _15"> </span><span class="ff8">参数估计</span></div><div class="t m0 x3 h12 ycf ff6 fs7 fc0 sc0 ls0 ws0">3.1.1<span class="_ _36"> </span><span class="ff9">特殊情形</span></div><div class="t m0 x3 h6 y260 ff1 fs2 fc0 sc0 ls0 ws0">如果在各类上犯错的损失（风险权重）是一样的，同时不犯错就不会有损失，那么：</div><div class="t m0 xc5 hc y261 ffa fs2 fc0 sc0 ls0 ws0">λ</div><div class="t m0 x48 hb y262 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x10c h4 y261 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x59 he y263 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x21 h4 y264 ffb fs2 fc0 sc0 ls0 ws0">0<span class="ffa">,<span class="_ _6"> </span>if<span class="_ _2e"> </span>i<span class="_ _2c"> </span></span>=<span class="_ _2c"> </span><span class="ffa">j</span></div><div class="t m0 x21 h4 y265 ffb fs2 fc0 sc0 ls0 ws0">1<span class="ffa">,<span class="_ _6"> </span>other<span class="_ _f"></span>w<span class="_ _f"></span>ise</span></div><div class="t m0 x32 h4 y261 ff3 fs2 fc0 sc0 ls0 ws0">(3.1)</div><div class="t m0 x3 h6 y266 ff1 fs2 fc0 sc0 ls0 ws0">此时，<span class="_ _2f"></span>条件风险为<span class="_ _c"> </span><span class="ffa">R<span class="ffb">(</span>c</span></div><div class="t m0 xe6 hb y267 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd1 h4 y266 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _2c"> </span>=</span></span></div><div class="t m0 xa5 he y268 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x39 hb y269 ffd fs6 fc0 sc0 ls0 ws0">N</div><div class="t m0 x39 ha y26a ffd fs6 fc0 sc0 ls0 ws0">j<span class="_ _f"></span><span class="ff12"≯<span class="ffc">=</span></span>i</div><div class="t m0 xa h4 y266 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c</div><div class="t m0 x10a hb y267 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x10c h4 y266 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span>1<span class="_ _33"> </span></span></span>−<span class="_ _33"> </span><span class="ffa">P<span class="_ _2d"> </span><span class="ffb">(</span>c</span></div><div class="t m0 x4d hb y267 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xbf h6 y266 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="ff1">。<span class="_ _2f"></span>于是，<span class="_ _10"></span>最优的贝叶斯分类器就是使得</span></span></span></div><div class="t m0 x3 hc y26b ffa fs2 fc0 sc0 ls0 ws0">c</div><div class="t m0 x10d hb y26c ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x10e h6 y26b ff1 fs2 fc0 sc0 ls0 ws0">的后验概率最大的分类器：</div><div class="t m0 xc5 hc y26d ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x48 ha y26e ff12 fs6 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x10f h4 y26d ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span>)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff3">arg<span class="_ _2d"> </span>max</span></div><div class="t m0 x99 ha y26f ffd fs6 fc0 sc0 ls0 ws0">c<span class="ff12">∈</span>y</div><div class="t m0 x26 h4 y26d ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _47"> </span><span class="ff3">(3.2)</span></span></div><div class="t m0 x106 h9 y270 ff6 fs5 fc0 sc0 ls0 ws0">3.2<span class="_ _21"> </span><span class="ff9">参数估计</span></div><div class="t m0 x3 h6 y271 ff1 fs2 fc0 sc0 ls0 ws0">很显然，在<span class="_ _f"></span>判定准则<span class="_ _f"></span>中只有两<span class="_ _f"></span>个未知量：<span class="ffa">λ</span></div><div class="t m0 x3e hb y272 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x22 h6 y271 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _0"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>，<span class="ffa">λ</span></div><div class="t m0 x110 hb y272 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x27 h6 y271 ff1 fs2 fc0 sc0 ls0 ws0">相对来说<span class="_ _f"></span>很容易得<span class="_ _f"></span>出。因此，使<span class="_ _f"></span>用</div><div class="t m0 x3 h6 y273 ff1 fs2 fc0 sc0 ls0 ws0">贝叶斯<span class="_ _f"></span>分类<span class="_ _f"></span>最关<span class="_ _f"></span>键的<span class="_ _f"></span>就是获<span class="_ _f"></span>得后<span class="_ _f"></span>验概<span class="_ _f"></span>率<span class="_ _11"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>。然<span class="_ _f"></span>而，在<span class="_ _f"></span>现实<span class="_ _f"></span>任务中<span class="_ _f"></span>这通<span class="_ _f"></span>常难<span class="_ _f"></span>以直<span class="_ _f"></span>接获得。<span class="_ _f"></span>我</div><div class="t m0 x3 h6 y274 ff1 fs2 fc0 sc0 ls0 ws0">们要解决的问题是基于有限的训练样本集尽可能准确地估计出后验概率<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>。</div><div class="t m0 x3 h6 y275 ff4 fs2 fc0 sc0 ls0 ws0">主要有两种策略：</div><div class="t m0 x9a h6 y276 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _6"> </span><span class="ff1">给定<span class="_ _1c"> </span><span class="ffa">x</span>，<span class="_ _f"></span>可<span class="_ _f"></span>通过<span class="_ _f"></span>直<span class="_ _f"></span>接<span class="_ _f"></span>建模<span class="_ _1c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _1c"> </span></span></span>来<span class="_ _f"></span>预<span class="_ _f"></span>测<span class="_ _1c"> </span></span>c<span class="ff1">，这<span class="_ _f"></span>样<span class="_ _f"></span>得<span class="_ _f"></span>到的<span class="_ _f"></span>是</span>”<span class="_ _1c"> </span><span class="ff1">判<span class="_ _f"></span>别式<span class="_ _f"></span>模<span class="_ _f"></span>型</span>”<span class="_ _1c"> </span>(discriminativ<span class="_ _10"></span>e</div><div class="t m0 x9b h4 y277 ff3 fs2 fc0 sc0 ls0 ws0">mo<span class="_ _f"></span>dels)</div><div class="t m0 x9a h6 y278 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff1">也可先<span class="_ _f"></span>对联<span class="_ _f"></span>合概<span class="_ _f"></span>率分布<span class="_ _11"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x,<span class="_ _2d"> </span>c<span class="ffb">)<span class="_ _11"> </span></span></span>建模，<span class="_ _f"></span>然后再<span class="_ _f"></span>由此<span class="_ _f"></span>获得<span class="_ _11"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>，<span class="_ _f"></span>这样得<span class="_ _f"></span>到的<span class="_ _f"></span>是</span>”<span class="_ _0"> </span><span class="ff1">生<span class="_ _f"></span>成式<span class="_ _f"></span>模</span></div><div class="t m0 x9b h6 y279 ff1 fs2 fc0 sc0 ls0 ws0">型<span class="ff3">”<span class="_ _c"> </span>(generativ<span class="_ _10"></span>e<span class="_ _c"> </span>mo<span class="_ _f"></span>dels)</span></div><div class="t m0 x3 h6 y27a ff1 fs2 fc0 sc0 ls0 ws0">对生成式模型来说，必然考虑：</div><div class="t m0 x3c h4 y27b ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _2c"> </span>=</span></div><div class="t m0 x99 h4 y27c ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c,<span class="_ _2d"> </span>x<span class="ffb">)</span></div><div class="t m0 x91 h4 y27d ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)</span></div><div class="t m0 x3 h6 y27e ff1 fs2 fc0 sc0 ls0 ws0">使用贝叶斯公式，得到：</div><div class="t m0 x1c h4 y27f ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _2c"> </span>=</span></div><div class="t m0 x5b h4 y280 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="ffb">)</span>P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)</span></div><div class="t m0 x91 h4 y281 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)</span></div><div class="t m0 x3 h6 y282 ff1 fs2 fc0 sc0 ls0 ws0">此时，我们把要估计的<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _c"> </span></span></span>分解为三个概率，也就是要估计以下三个概率：</div><div class="t m0 x3 h6 y283 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _c"> </span><span class="ff4">类先验概率<span class="_ _1c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="ffb">)</span></span>：<span class="ff1">代表了样本空<span class="_ _f"></span>间中各类样本所占的比例，<span class="_ _f"></span>根据大数定律，当训练集包<span class="_ _f"></span>含充</span></span></div><div class="t m0 x3 h6 y284 ff1 fs2 fc0 sc0 ls0 ws0">足的独立同分布样本时，<span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="ffb">)<span class="_ _c"> </span></span></span>可通过各类样本出现的频率来进行估计。</div><div class="t m0 x3 h6 y285 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _c"> </span><span class="ff4">样本值概率<span class="_ _0"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)</span></span>：<span class="_ _2f"></span><span class="ff1">理论上<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _c"> </span></span></span>也可以通过大数定律，<span class="_ _2f"></span>以频率来估计概率，<span class="_ _2f"></span>但是这很难实现。</span></span></div><div class="t m0 x3 h6 y286 ff1 fs2 fc0 sc0 ls0 ws0">因此，可以尽量避免估计<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _c"> </span></span></span>的值。</div><div class="t m0 x3 h6 y1c3 ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _c"> </span><span class="ff4">类条件概率<span class="_ _11"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)</span></span>：<span class="ff1">由于涉及关于样本<span class="_ _c"> </span><span class="ffa">x<span class="_ _c"> </span></span>所有属性的联合概率，直接根据样本出现的频率来</span></span></div><div class="t m0 x3 h6 y287 ff1 fs2 fc0 sc0 ls0 ws0">估计将会遇到严重的困难。估计这个概率是贝叶斯分类方法最重要的任务。</div><div class="t m0 x3 h6 y1c5 ff1 fs2 fc0 sc0 ls0 ws0">例如，<span class="_ _2f"></span>假设样本的<span class="_ _c"> </span><span class="ffa">d<span class="_ _c"> </span></span>个属性都是二值的，<span class="_ _2f"></span>则样本空间将有<span class="_ _c"> </span><span class="ffb">2</span></div><div class="t m0 xf7 hb y288 ffd fs6 fc0 sc0 ls0 ws0">d</div><div class="t m0 x95 h6 y1c5 ff1 fs2 fc0 sc0 ls0 ws0">种可能的取值，<span class="_ _2f"></span>在现实应用中，<span class="_ _2f"></span>这</div><div class="t m0 x3 h6 y289 ff1 fs2 fc0 sc0 ls0 ws0">个值往<span class="_ _f"></span>往远大<span class="_ _f"></span>于训<span class="_ _f"></span>练样本<span class="_ _f"></span>数<span class="_ _0"> </span><span class="ffa">m</span>，<span class="_ _f"></span>也就<span class="_ _f"></span>是说，很<span class="_ _f"></span>多样本<span class="_ _f"></span>取值<span class="_ _f"></span>在训练<span class="_ _f"></span>集中<span class="_ _f"></span>根本没<span class="_ _f"></span>有出<span class="_ _f"></span>现，直接<span class="_ _f"></span>使用</div><div class="t m0 x3 h6 y28a ff1 fs2 fc0 sc0 ls0 ws0">频率来估计<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)<span class="_ _c"> </span></span></span>显然不可行，因为<span class="ff3">”<span class="_ _c"> </span></span>未被观测到<span class="ff3">”<span class="_ _c"> </span></span>与<span class="ff3">”<span class="_ _c"> </span></span>出现概率为零<span class="ff3">”<span class="_ _c"> </span></span>通常是不同的。</div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">那怎么估计<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _c"> </span></span></span>的值呢？这就需要极大似然估计。</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">20</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1a" class="pf w0 h0" data-page-no="1a"><div class="pc pc1a w0 h0"><img class="bi x3 y28b wa h25" alt="" src="bg1a.png"/><div class="t m0 x71 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.3<span class="_ _15"> </span><span class="ff8">朴素贝叶斯分类器</span></div><div class="t m0 x3 h12 ycf ff6 fs7 fc0 sc0 ls0 ws0">3.2.1<span class="_ _36"> </span><span class="ff9">极大似然估计</span></div><div class="t m0 x3 h6 y28c ff1 fs2 fc0 sc0 ls0 ws0">估计类条<span class="_ _f"></span>件概率的<span class="_ _f"></span>一种常用<span class="_ _f"></span>策略是先<span class="_ _f"></span>假定其具<span class="_ _f"></span>有某种确<span class="_ _f"></span>定的概率<span class="_ _f"></span>分布形<span class="_ _0"> </span>式（例<span class="_ _f"></span>如：变量有<span class="_ _f"></span>两个</div><div class="t m0 x3 h6 y28d ff1 fs2 fc0 sc0 ls0 ws0">取值，假定为二项分布；变量有多个取<span class="_ _f"></span>值，假定为多项分布）<span class="_ _30"></span>，再使用极大似然估计（或者其它</div><div class="t m0 x3 h6 y28e ff1 fs2 fc0 sc0 ls0 ws0">参数<span class="_ _f"></span>估计<span class="_ _f"></span>方<span class="_ _f"></span>法）估<span class="_ _f"></span>计<span class="_ _f"></span>出这<span class="_ _f"></span>种<span class="_ _f"></span>概率<span class="_ _f"></span>分<span class="_ _f"></span>布形<span class="_ _f"></span>式<span class="_ _f"></span>下的<span class="_ _f"></span><span class="ff4">理<span class="_ _f"></span>论概<span class="_ _f"></span>率估<span class="_ _f"></span>计<span class="_ _f"></span>值</span>（这<span class="_ _f"></span>个<span class="_ _f"></span>估计<span class="_ _f"></span>值<span class="_ _f"></span>就是<span class="_ _f"></span>分<span class="_ _f"></span>布参<span class="_ _f"></span>数<span class="_ _f"></span>的估</div><div class="t m0 x3 h6 y28f ff1 fs2 fc0 sc0 ls0 ws0">计值）<span class="_ _23"></span>。最后，基于训练样本求出</div><div class="t m0 xf5 h6 y290 ff4 fs2 fc0 sc0 ls0 ws0">理论概率估计值</div><div class="t m0 xb0 h6 y28f ff1 fs2 fc0 sc0 ls0 ws0">。</div><div class="t m0 x3 h6 y291 ff1 fs2 fc0 sc0 ls0 ws0">事实上，<span class="_ _22"></span>概率模型的训练过程就是参数估计<span class="_ _31"></span>〔<span class="ff3">parameter<span class="_ _27"> </span>estimation)<span class="_ _c"> </span></span>过程。<span class="_ _31"></span>对于参数估计，<span class="_ _22"></span>统计</div><div class="t m0 x3 h6 y292 ff1 fs2 fc0 sc0 ls0 ws0">学界的两个学派分别提供了不同的解决方案：<span class="_ _22"></span>频率学派认为参数未知，<span class="_ _22"></span>但存在客观的固定值，<span class="_ _28"></span>因</div><div class="t m0 x3 h6 y293 ff1 fs2 fc0 sc0 ls0 ws0">此，<span class="_ _22"></span>可通过优化似然函数等准则来确定参数值；<span class="_ _22"></span>贝叶斯学派认为参数是未观察到的随机变量，<span class="_ _28"></span>其</div><div class="t m0 x3 h6 y294 ff1 fs2 fc0 sc0 ls0 ws0">本身也可有分布，<span class="_ _22"></span>因此，<span class="_ _22"></span>可假定参数服从一个先验分布，<span class="_ _28"></span>然后基于观测到的数据来计算参数的后</div><div class="t m0 x3 h6 y295 ff1 fs2 fc0 sc0 ls0 ws0">验分布。</div><div class="t m0 x3 h6 y296 ff1 fs2 fc1 sc0 ls0 ws0">极大<span class="_ _f"></span>似然<span class="_ _f"></span>估<span class="_ _f"></span>计虽<span class="_ _f"></span>然<span class="_ _f"></span>能使<span class="_ _f"></span>条件<span class="_ _f"></span>概<span class="_ _f"></span>率估<span class="_ _f"></span>计<span class="_ _f"></span>变得<span class="_ _f"></span>相<span class="_ _f"></span>对简<span class="_ _f"></span>单，但<span class="_ _f"></span>估<span class="_ _f"></span>计结<span class="_ _f"></span>果<span class="_ _f"></span>的准<span class="_ _f"></span>确<span class="_ _f"></span>性严<span class="_ _f"></span>重依<span class="_ _f"></span>赖<span class="_ _f"></span>于所<span class="_ _f"></span>假<span class="_ _f"></span>设的</div><div class="t m0 x3 h6 y297 ff1 fs2 fc1 sc0 ls0 ws0">概率<span class="_ _f"></span>分布<span class="_ _f"></span>形<span class="_ _f"></span>式是<span class="_ _f"></span>否<span class="_ _f"></span>符合<span class="_ _f"></span>潜在<span class="_ _f"></span>的<span class="_ _f"></span>真实<span class="_ _f"></span>数<span class="_ _f"></span>据分<span class="_ _f"></span>布<span class="_ _f"></span>（而贝<span class="_ _f"></span>叶斯<span class="_ _f"></span>估<span class="_ _f"></span>计则<span class="_ _f"></span>会<span class="_ _f"></span>利用<span class="_ _f"></span>样<span class="_ _f"></span>本信<span class="_ _f"></span>息对<span class="_ _f"></span>假<span class="_ _f"></span>设的<span class="_ _f"></span>先<span class="_ _f"></span>验分</div><div class="t m0 x3 h6 y298 ff1 fs2 fc1 sc0 ls0 ws0">布进行修正）<span class="_ _30"></span>。<span class="fc0">在现实应用中，欲做出能较好地接近潜在真实分布的假设，往往需<span class="_ _f"></span>在一定程度上</span></div><div class="t m0 x3 h6 y299 ff1 fs2 fc0 sc0 ls0 ws0">利用关于应用任务本身的经验知讽，否则若仅凭<span class="ff3">”<span class="_ _27"> </span></span>猜测<span class="ff3">”<span class="_ _c"> </span></span>来假设概率分布形式，很可能产生误导</div><div class="t m0 x3 h6 y29a ff1 fs2 fc0 sc0 ls0 ws0">性的结果。</div><div class="t m0 x77 h9 y29b ff6 fs5 fc0 sc0 ls0 ws0">3.3<span class="_ _21"> </span><span class="ff9">朴素贝叶斯分类器</span></div><div class="t m0 x3 h6 y29c ff1 fs2 fc0 sc0 ls0 ws0">以下<span class="_ _f"></span>用文<span class="_ _f"></span>本<span class="_ _f"></span>信息<span class="_ _f"></span>分<span class="_ _f"></span>类作<span class="_ _f"></span>为例<span class="_ _f"></span>子<span class="_ _f"></span>来解<span class="_ _f"></span>释<span class="_ _f"></span>朴素<span class="_ _f"></span>贝<span class="_ _f"></span>叶斯<span class="_ _f"></span>分类<span class="_ _f"></span>器。<span class="_ _f"></span>先来<span class="_ _f"></span>看<span class="_ _f"></span>用数<span class="_ _f"></span>学<span class="_ _f"></span>描述<span class="_ _f"></span>语言<span class="_ _f"></span>规<span class="_ _f"></span>律的<span class="_ _f"></span>普<span class="_ _f"></span>遍方</div><div class="t m0 x3 h6 y29d ff1 fs2 fc0 sc0 ls0 ws0">法。</div><div class="t m0 x3 h12 y29e ff6 fs7 fc0 sc0 ls0 ws0">3.3.1<span class="_ _36"> </span><span class="ff9">统计语言模型简述</span></div><div class="t m0 x3 h6 y29f ff1 fs2 fc0 sc0 ls0 ws0">假设一个句子的模型为：<span class="ffa">S<span class="_ _c"> </span><span class="ffb">=<span class="_ _2c"> </span></span>w</span></div><div class="t m0 x9e ha y2a0 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x45 hc y29f ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xa ha y2a0 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc5 h4 y29f ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>w</div><div class="t m0 x4 hb y2a0 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x1 h6 y29f ff1 fs2 fc0 sc0 ls0 ws0">（句子<span class="_ _c"> </span><span class="ffa">S<span class="_ _11"> </span></span>由<span class="_ _c"> </span><span class="ff3">n<span class="_ _c"> </span></span>个词组成）</div><div class="t m0 x3 h6 y2a1 ff1 fs2 fc0 sc0 ls0 ws0">那么<span class="_ _11"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>S<span class="_ _1f"></span><span class="ffb">)<span class="_ _0"> </span>=<span class="_ _0"> </span></span>P<span class="_ _2b"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x111 ha y2a2 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x112 hc y2a1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x113 ha y2a2 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xf8 h4 y2a1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>w</div><div class="t m0 x77 hb y2a2 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x9e h6 y2a1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">。显然<span class="_ _11"> </span><span class="ffa">P<span class="_ _2d"> </span></span></span>(<span class="ffa">S<span class="_ _f"></span></span>)<span class="_ _11"> </span><span class="ff1">使句<span class="_ _f"></span>子<span class="_ _11"> </span><span class="ffa">S<span class="_ _2e"> </span></span>出现的<span class="_ _f"></span>概率，<span class="_ _f"></span>在语言<span class="_ _f"></span>研究<span class="_ _f"></span>中<span class="_ _11"> </span><span class="ffa">P<span class="_ _2b"> </span></span></span>(<span class="ffa">S<span class="_ _1f"></span></span>)<span class="_ _11"> </span><span class="ff1">越大</span></div><div class="t m0 x3 h6 y2a3 ff1 fs2 fc0 sc0 ls0 ws0">说明<span class="_ _f"></span>此时<span class="_ _1c"> </span><span class="ffa">S<span class="_ _2e"> </span></span>越<span class="_ _f"></span>可能<span class="_ _f"></span>是正<span class="_ _f"></span>确<span class="_ _f"></span>的句<span class="_ _f"></span>子，<span class="_ _f"></span>反之<span class="_ _1c"> </span><span class="ffa">S<span class="_ _2e"> </span></span>越不<span class="_ _f"></span>可<span class="_ _f"></span>能当<span class="_ _f"></span>前<span class="_ _f"></span>应该<span class="_ _f"></span>出现<span class="_ _f"></span>的<span class="_ _f"></span>句子。<span class="_ _f"></span>利<span class="_ _f"></span>用条<span class="_ _f"></span>件概<span class="_ _f"></span>率<span class="_ _f"></span>公式，</div><div class="t m0 x3 h4 y2a4 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 xd8 ha y2a5 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x114 hc y2a4 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x10b ha y2a5 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb h4 y2a4 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>w</div><div class="t m0 xce hb y2a5 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x115 h6 y2a4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">可以写为：</span></div><div class="t m0 x116 h4 y2a6 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 xb ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x117 hc y2a6 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x118 ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc3 h4 y2a6 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>w</div><div class="t m0 x119 hb y2a7 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x113 h4 y2a6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ffa">P<span class="_ _2b"> </span></span>(<span class="ffa">w</span></div><div class="t m0 x97 ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9e h4 y2a6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff3">·<span class="ffa">P<span class="_ _2b"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x10f ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x3c h4 y2a6 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xa6 ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xfa h4 y2a6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff3">·<span class="ffa">P<span class="_ _2b"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x5d ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 xb2 h4 y2a6 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x26 ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd6 hc y2a6 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xcc ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xd5 h4 y2a6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _2b"></span><span class="ffa">P<span class="_ _2d"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x11a hb y2a7 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 xac h4 y2a6 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x2b ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x53 hc y2a6 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x11b ha y2a7 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x55 h4 y2a6 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>w</div><div class="t m0 x11c ha y2a7 ffd fs6 fc0 sc0 ls0 ws0">n<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x11d h4 y2a6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _3a"> </span><span class="ff3">(3.3)</span></div><div class="t m0 x3 h6 y2a8 ff1 fs2 fc0 sc0 ls0 ws0">显<span class="_ _f"></span>然，<span class="_ _1f"></span>词<span class="_ _b"> </span><span class="ffa">w</span></div><div class="t m0 x11e hb y2a9 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x11f h6 y2a8 ff1 fs2 fc0 sc0 ls0 ws0">出<span class="_ _f"></span>现<span class="_ _1f"></span>的<span class="_ _f"></span>概<span class="_ _1f"></span>率<span class="_ _f"></span>取<span class="_ _1f"></span>决<span class="_ _f"></span>于<span class="_ _1f"></span>它<span class="_ _f"></span>前<span class="_ _1f"></span>面<span class="_ _1f"></span>的<span class="_ _f"></span>所<span class="_ _1f"></span>有<span class="_ _f"></span>词。<span class="_ _1f"></span>从<span class="_ _f"></span>计<span class="_ _1f"></span>算<span class="_ _f"></span>的<span class="_ _1f"></span>角<span class="_ _f"></span>度<span class="_ _1f"></span>来<span class="_ _f"></span>看，<span class="ffa">P<span class="_ _2d"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x76 ha y2a9 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x120 h4 y2a8 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x121 h1f y2aa ff16 fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x122 h6 y2a8 ff1 fs2 fc0 sc0 ls0 ws0">很<span class="_ _f"></span>容<span class="_ _1f"></span>易<span class="_ _f"></span>计<span class="_ _1f"></span>算，</div><div class="t m0 x3 h4 y2ab ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 xd8 ha y2ac ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x114 h4 y2ab fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x7a ha y2ac ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x6 h6 y2ab ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">也不算太难，<span class="_ _31"></span>但<span class="_ _27"> </span><span class="ffa">P<span class="_ _2d"> </span><span class="ffb">(</span>w</span></span></div><div class="t m0 x123 ha y2ac ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x9c h4 y2ab fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xf6 ha y2ac ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xca hc y2ab ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x47 ha y2ac ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8 h6 y2ab ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">就已经相当有难度，<span class="_ _31"></span>因为它涉及到三个变量，<span class="_ _31"></span>每个变量</span></div><div class="t m0 x3 h6 y2ad ff1 fs2 fc0 sc0 ls0 ws0">的可<span class="_ _f"></span>能性<span class="_ _f"></span>都<span class="_ _f"></span>是一<span class="_ _f"></span>种语<span class="_ _f"></span>言<span class="_ _f"></span>字典<span class="_ _f"></span>的大<span class="_ _f"></span>小。<span class="_ _f"></span>到了<span class="_ _f"></span>最后<span class="_ _f"></span>一<span class="_ _f"></span>个词，<span class="_ _f"></span>条件<span class="_ _f"></span>概<span class="_ _f"></span>率<span class="_ _11"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x54 hb y2ae ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x124 h4 y2ad fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x71 ha y2ae ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x125 hc y2ad ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x126 ha y2ae ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x72 h4 y2ad ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>w</div><div class="t m0 x127 ha y2ae ffd fs6 fc0 sc0 ls0 ws0">n<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x10 h6 y2ad ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _11"> </span><span class="ff1">的可</span></div><div class="t m0 x3 h6 y2af ff1 fs2 fc0 sc0 ls0 ws0">能性太多，无法估计。那怎么办？</div><div class="t m0 x3 h6 y2b0 ff3 fs2 fc0 sc0 ls0 ws0">19<span class="_ _c"> </span><span class="ff1">世纪到<span class="_ _0"> </span></span>20<span class="_ _0"> </span><span class="ff1">世纪初，俄罗斯<span class="_ _f"></span>有个数学家叫<span class="_ _f"></span>马尔可夫（</span>Andrey<span class="_ _0"> </span>Marko<span class="_ _2f"></span>v<span class="ff1">）<span class="_ _30"></span>，他给<span class="_ _f"></span>了个偷懒但还<span class="_ _f"></span>颇</span></div><div class="t m0 x3 h6 y2b1 ff1 fs2 fc0 sc0 ls0 ws0">为有效的方法，<span class="_ _2f"></span>也就是每当遇到这种情况时，<span class="_ _2f"></span>就假设任意一个词<span class="_ _c"> </span><span class="ffa">w</span></div><div class="t m0 x128 hb y2b2 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x82 h6 y2b1 ff1 fs2 fc0 sc0 ls0 ws0">出现的概率只同它前面的词</div><div class="t m0 x3 hc y2b3 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x129 ha y2b4 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x114 h6 y2b3 ff1 fs2 fc0 sc0 ls0 ws0">有关，<span class="_ _2f"></span>于是问题就变得很简单了。<span class="_ _2f"></span>这种假设在数学上称为马尔可夫假设</div><div class="t m0 x57 h1f y2b5 ff16 fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x58 h6 y2b3 ff1 fs2 fc0 sc0 ls0 ws0">。<span class="_ _2f"></span>现在，<span class="_ _2f"></span><span class="ffa">S<span class="_ _11"> </span><span class="ff1">出现的</span></span></div><div class="t m0 x3 h6 y2b6 ff1 fs2 fc0 sc0 ls0 ws0">概率就变得简单了：</div><div class="t m0 xcd h4 y2b7 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 x112 ha y2b8 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x12a hc y2b7 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xf8 ha y2b8 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xe7 h4 y2b7 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>w</div><div class="t m0 x44 hb y2b8 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x8c h4 y2b7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ffa">P<span class="_ _2b"> </span></span>(<span class="ffa">w</span></div><div class="t m0 x0 ha y2b8 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x49 h4 y2b7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff3">·<span class="ffa">P<span class="_ _2b"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 xfc ha y2b8 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb0 h4 y2b7 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x25 ha y2b8 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x26 h4 y2b7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff3">·<span class="ffa">P<span class="_ _2b"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x50 ha y2b8 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x27 h4 y2b7 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xa1 ha y2b8 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x12b h4 y2b7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _2b"></span><span class="ffa">P<span class="_ _2d"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x12c hb y2b8 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x71 h4 y2b7 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x57 ha y2b8 ffd fs6 fc0 sc0 ls0 ws0">n<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x12d h4 y2b7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _48"> </span><span class="ff3">(3.4)</span></div><div class="t m0 x3 h6 y2b9 ff1 fs2 fc0 sc0 ls0 ws0">公式<span class="_ _11"> </span><span class="ff3">3.4<span class="_ _0"> </span></span>对<span class="_ _f"></span>应的<span class="_ _f"></span>统计<span class="_ _f"></span>语言<span class="_ _f"></span>模型是<span class="_ _f"></span>二元<span class="_ _f"></span>模型<span class="_ _f"></span>（<span class="ff3">bigram<span class="_ _0"> </span>mo<span class="_ _1f"></span>dule</span>）<span class="_ _49"></span>。当然，<span class="_ _f"></span>也可<span class="_ _f"></span>以假<span class="_ _f"></span>设一个<span class="_ _f"></span>词由<span class="_ _f"></span>前面</div><div class="t m0 x3 h6 y2ba ffa fs2 fc0 sc0 ls0 ws0">N<span class="_ _c"> </span><span class="fff">−<span class="_ _33"> </span><span class="ffb">1<span class="_ _c"> </span><span class="ff1">个词决定，对应的模型稍微复杂些，被称为<span class="_ _c"> </span></span></span></span>N<span class="_ _2e"> </span><span class="ff1">元模型。</span></div><div class="t m0 x3 h26 y2bb ff8 fs2 fc0 sc0 ls0 ws0">接下来的内容在这里可以略过。</div><div class="t m0 x10e h27 y2bc ff18 fs8 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5 h28 y2bd ff19 fs9 fc0 sc0 ls0 ws0">P<span class="_ _32"> </span><span class="ff1a">(</span>w</div><div class="t m0 x78 h1a y2be ff14 fs8 fc0 sc0 ls0 ws0">1</div><div class="t m0 x10b h29 y2bd ff1a fs9 fc0 sc0 ls0 ws0">)<span class="_ _27"> </span><span class="ff1">是第一<span class="_ _f"></span>个词的条件<span class="_ _f"></span>概率，实际上<span class="_ _f"></span>更准确的描<span class="_ _f"></span>述是<span class="_ _27"> </span><span class="ff19">P<span class="_ _2b"> </span></span></span>(<span class="ff19">w</span></div><div class="t m0 xbf h1a y2be ff14 fs8 fc0 sc0 ls0 ws0">1</div><div class="t m0 x41 h29 y2bd ff1b fs9 fc0 sc0 ls0 ws0">|<span class="_ _2c"> </span><span class="ff19">&lt;<span class="_ _2c"> </span>S<span class="_ _c"> </span>&gt;<span class="ff1a">)<span class="ff1">，即这个词在句<span class="_ _f"></span>子开头<span class="_ _c"> </span></span></span>&lt;<span class="_ _25"> </span>S<span class="_ _c"> </span>&gt;<span class="_ _27"> </span><span class="ff1">条<span class="_ _f"></span>件下的</span></span></div><div class="t m0 x3 h29 y2bf ff1 fs9 fc0 sc0 ls0 ws0">概率</div><div class="t m0 x10e h27 y2c0 ff18 fs8 fc0 sc0 ls0 ws0">2</div><div class="t m0 x5 h29 y2c1 ff1 fs9 fc0 sc0 ls0 ws0">马尔可夫在<span class="_ _c"> </span><span class="ff1c">1906<span class="_ _2c"> </span></span>年首<span class="_ _f"></span>先做出了这<span class="_ _f"></span>类过程。而将此<span class="_ _f"></span>一般化到可数<span class="_ _f"></span>无限状态空<span class="_ _f"></span>间是由柯尔莫<span class="_ _f"></span>果洛夫在<span class="_ _c"> </span><span class="ff1c">1936<span class="_ _2c"> </span></span>年给<span class="_ _f"></span>出</div><div class="t m0 x3 h29 y1d ff1 fs9 fc0 sc0 ls0 ws0">的。</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">21</div><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",87.01,88.66,null]'><div class="d m1" style="border-style:none;position:absolute;left:684.177000px;bottom:437.341500px;width:4.232000px;height:11.293000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",87.01,64.44,null]'><div class="d m1" style="border-style:none;position:absolute;left:650.293500px;bottom:302.307000px;width:4.232000px;height:11.294000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1b" class="pf w0 h0" data-page-no="1b"><div class="pc pc1b w0 h0"><img class="bi x3 y2c2 wb h2a" alt="" src="bg1b.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.3<span class="_ _15"> </span><span class="ff8">朴素贝叶斯分类器</span></div><div class="t m0 x3 h26 y1f ff8 fs2 fc0 sc0 ls0 ws0">现在的问题就是如何估计<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x97 hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x44 h4 y1f fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xf5 ha y2c3 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x87 h26 y1f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff8">的概率，根据它的定义：</span></div><div class="t m0 x9 h4 y2c4 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 x3d hb y2c5 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x10c h4 y2c4 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x59 ha y2c5 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xbd h4 y2c4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=</div><div class="t m0 x99 h4 y2c6 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 xdf hb y2c7 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x12e hc y2c6 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x62 ha y2c7 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x50 h4 y2c6 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xb2 h4 y2c8 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 x92 ha y2c9 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x5f h4 y2c8 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h26 y2ca ff8 fs2 fc0 sc0 ls0 ws0">而估计联合概率<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x12f hb y2cb ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x113 hc y2ca ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x130 ha y2cb ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x131 h26 y2ca ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff8">和边缘概率<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x5a ha y2cb ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x132 h26 y2ca ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff8">现在变得非常简单。因为<span class="_ _c"> </span>有了大量机读文本，</span></div><div class="t m0 x3 h26 y2cc ff8 fs2 fc0 sc0 ls0 ws0">也就<span class="_ _f"></span>是<span class="_ _f"></span>语料<span class="_ _f"></span>库<span class="_ _f"></span>（<span class="ff3">Corpus</span>）<span class="_ _35"></span>，只<span class="_ _f"></span>要<span class="_ _f"></span>数一<span class="_ _f"></span>数<span class="_ _1c"> </span><span class="ffa">w</span></div><div class="t m0 x49 hb y2cd ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x133 hc y2cc ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xbd ha y2cd ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x132 h26 y2cc ff8 fs2 fc0 sc0 ls0 ws0">这对<span class="_ _f"></span>词<span class="_ _f"></span>在统<span class="_ _f"></span>计<span class="_ _f"></span>的文<span class="_ _f"></span>本<span class="_ _f"></span>中前<span class="_ _f"></span>后<span class="_ _f"></span>相邻<span class="_ _f"></span>出<span class="_ _f"></span>现了<span class="_ _f"></span>多<span class="_ _f"></span>少次</div><div class="t m0 x3 h4 y2ce ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 x5 hb y2cf ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd8 hc y2ce ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x134 ha y2cf ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x135 h26 y2ce ff8 fs2 fc0 sc0 ls0 ws0">，以及<span class="_ _11"> </span><span class="ffa">w</span></div><div class="t m0 x112 ha y2cf ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xd1 h26 y2ce ff8 fs2 fc0 sc0 ls0 ws0">本身在<span class="_ _f"></span>同样<span class="_ _f"></span>的文本<span class="_ _f"></span>中出<span class="_ _f"></span>现了多<span class="_ _f"></span>少次<span class="_ _11"> </span><span class="ff3">#<span class="ffa">w</span></span></div><div class="t m0 x28 ha y2cf ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x81 h26 y2ce ff8 fs2 fc0 sc0 ls0 ws0">，然后<span class="_ _f"></span>用两<span class="_ _f"></span>个数分<span class="_ _f"></span>别除<span class="_ _f"></span>以语料</div><div class="t m0 x3 h26 y2d0 ff8 fs2 fc0 sc0 ls0 ws0">库的大小<span class="_ _c"> </span><span class="ff3">#</span>，即可得到这些词或者二元组的相对频度：</div><div class="t m0 x136 h4 y2d1 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>w</div><div class="t m0 x3c ha y2d2 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x133 hc y2d1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xbd hb y2d2 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa3 h4 y2d1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=</div><div class="t m0 x91 h4 y2d3 ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 xdf hb y2d4 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x12e hc y2d3 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x62 ha y2d4 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xd6 h4 y2d5 ff3 fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x10a h4 y2d6 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>w</div><div class="t m0 xfa ha y2d7 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xa3 h4 y2d6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=</div><div class="t m0 x91 h4 y2d8 ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 xdf ha y2d9 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xbe h4 y2da ff3 fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x3 h26 y2db ff8 fs2 fc0 sc0 ls0 ws0">根据大数定理，只要统计量足够大，相对频率就等于概率，即：</div><div class="t m0 xba h4 y2dc ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 x10c ha y2dd ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x4a hc y2dc ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x22 hb y2dd ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x5a h4 y2dc ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=</div><div class="t m0 x4b h4 y2de ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 xbf hb y2df ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x137 hc y2de ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x65 ha y2df ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x12e h4 y2e0 ff3 fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x10f h4 y2e1 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>w</div><div class="t m0 x3e ha y2e2 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x5a h4 y2e1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=</div><div class="t m0 x4b h4 y2e3 ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 xbf ha y2e4 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xbe h4 y2e5 ff3 fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x3 h26 y2e6 ff8 fs2 fc0 sc0 ls0 ws0">最后得到：<span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>w</span></div><div class="t m0 xdc hb y2e7 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc6 h4 y2e6 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xc7 ha y2e7 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x6d h4 y2e6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff">≈</span></div><div class="t m0 xc hb y2e8 ff16 fs6 fc0 sc0 ls0 ws0">#<span class="ffd">w</span></div><div class="t m0 x98 h22 y2e9 ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa5 hb y2e8 ffd fs6 fc0 sc0 ls0 ws0">,w</div><div class="t m0 x123 h1a y2e9 ff17 fs8 fc0 sc0 ls0 ws0">i<span class="ff15">−<span class="ff14">1</span></span></div><div class="t m0 x43 hb y2ea ff16 fs6 fc0 sc0 ls0 ws0">#<span class="ffd">w</span></div><div class="t m0 xb8 h1a y2eb ff17 fs8 fc0 sc0 ls0 ws0">i<span class="ff15">−<span class="ff14">1</span></span></div><div class="t m0 x3 h12 y2ec ff6 fs7 fc0 sc0 ls0 ws0">3.3.2<span class="_ _36"> </span><span class="ff9">朴素贝叶斯</span></div><div class="t m0 x3 h6 y2ed ff1 fs2 fc0 sc0 ls0 ws0">通过上一节的叙述，<span class="_ _f"></span>可以知道如果直<span class="_ _f"></span>接估计联合概率<span class="_ _0"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>，在计<span class="_ _f"></span>算上中会遭遇组<span class="_ _f"></span>合爆炸问题，</div><div class="t m0 x3 h6 y2ee ff1 fs2 fc0 sc0 ls0 ws0">在数据上将会遭遇样本稀疏问题（下面会说到）<span class="_ _23"></span>，属性数越多，问题越严重。</div><div class="t m0 x3 h6 y2ef ff1 fs2 fc0 sc0 ls0 ws0">而我们可以看出如果采用二元模型，<span class="_ _22"></span>计算显然方便很多。<span class="_ _22"></span>但是这还不是最方便的，<span class="_ _28"></span>最方便的就是</div><div class="t m0 x3 h6 y2f0 ff1 fs2 fc0 sc0 ls0 ws0">一元模型（<span class="ff3">uni-gram<span class="_ _c"> </span></span>或<span class="_ _c"> </span><span class="ff3">monogram</span>）<span class="_ _23"></span>，也就是<span class="_ _c"> </span><span class="ffa">w</span></div><div class="t m0 x104 hb y2f1 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x138 h6 y2f0 ff1 fs2 fc0 sc0 ls0 ws0">独立于历史。</div><div class="t m0 x3 h6 y2f2 ff1 fs2 fc0 sc0 ls0 ws0">而朴素贝叶<span class="_ _f"></span>斯正是相当<span class="_ _f"></span>于使用了一<span class="_ _f"></span>元模型，它<span class="_ _f"></span>的<span class="_ _c"> </span><span class="ff3">naive<span class="_ _c"> </span></span>假设</div><div class="t m0 x50 h1f y2f3 ff16 fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x139 h6 y2f2 ff1 fs2 fc0 sc0 ls0 ws0">为：对已知类<span class="_ _f"></span>别，所有属性<span class="_ _f"></span>相互独</div><div class="t m0 x3 h6 y2f4 ff1 fs2 fc0 sc0 ls0 ws0">立。于是：</div><div class="t m0 xd2 h4 y2f5 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _2c"> </span>=</span></div><div class="t m0 xea h4 y2f6 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="ffb">)</span>P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)</span></div><div class="t m0 x0 h4 y2f7 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)</span></div><div class="t m0 x138 h4 y2f5 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x13a h4 y2f6 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="ffb">)</span></div><div class="t m0 x25 h4 y2f7 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)</span></div><div class="t m0 x110 hb y2f8 ffd fs6 fc0 sc0 ls0 ws0">d</div><div class="t m0 x60 he y2f9 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x60 ha y2fa ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x27 h4 y2f5 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>x</div><div class="t m0 x52 hb y2fb ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x81 h4 y2f5 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)</span></span></div><div class="t m0 x3 h6 y2fc ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _c"> </span><span class="ffa">d<span class="_ _0"> </span></span>为属性数目，<span class="ffa">x</span></div><div class="t m0 x16 hb y2fd ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xae h6 y2fc ff1 fs2 fc0 sc0 ls0 ws0">为<span class="_ _c"> </span><span class="ffa">x<span class="_ _0"> </span></span>在第<span class="_ _c"> </span><span class="ffa">i<span class="_ _0"> </span></span>个属性上的取<span class="_ _f"></span>值。由于对于所有<span class="_ _f"></span>类别来说，<span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _0"> </span></span></span>的值相同，</div><div class="t m0 x3 h6 y2fe ff1 fs2 fc0 sc0 ls0 ws0">因此没有必要计算，它可以被约去。因此，朴素贝叶斯判定准则为：</div><div class="t m0 x44 hc y2ff ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x45 hb y300 ffd fs6 fc0 sc0 ls0 ws0">nb</div><div class="t m0 xf6 h4 y2ff ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span>)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff3">arg<span class="_ _2d"> </span>max</span></div><div class="t m0 xbd ha y301 ffd fs6 fc0 sc0 ls0 ws0">c<span class="ff12">∈</span>y</div><div class="t m0 x132 h4 y2ff ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="ffb">)</span></div><div class="t m0 xab hb y302 ffd fs6 fc0 sc0 ls0 ws0">d</div><div class="t m0 xbf he y303 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xbf ha y304 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x65 h4 y2ff ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>x</div><div class="t m0 x13b hb y305 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x9d h4 y2ff fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _4a"> </span><span class="ff3">(3.5)</span></span></span></div><div class="t m0 x3 h6 y306 ff1 fs2 fc0 sc0 ls0 ws0">这就是朴素贝叶斯分类器的表达式。</div><div class="t m0 x3 h6 y307 ff1 fs2 fc0 sc0 ls0 ws0">如果假设<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)<span class="_ _c"> </span></span></span>是多项分布，那么根据极大似然估计可以得到，它的概率估计就是频率。</div><div class="t m0 x3 h6 y308 ff1 fs2 fc0 sc0 ls0 ws0">令<span class="_ _c"> </span><span class="ffa">D</span></div><div class="t m0 x13c hb y309 ffd fs6 fc0 sc0 ls0 ws0">c</div><div class="t m0 x108 h6 y308 ff1 fs2 fc0 sc0 ls0 ws0">表示训练集<span class="_ _c"> </span><span class="ffa">D<span class="_ _0"> </span></span>中第<span class="_ _0"> </span><span class="ffa">c<span class="_ _c"> </span></span>类样本组成的集合，若有<span class="_ _f"></span>充是的独立同分布样本，则可容易地估计</div><div class="t m0 x3 h6 y30a ff1 fs2 fc0 sc0 ls0 ws0">出类先验概率：</div><div class="t m0 xa6 h4 y30b ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="ffb">)<span class="_ _2c"> </span>=</span></div><div class="t m0 xb0 h4 y30c fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D</span></div><div class="t m0 x13a hb y30d ffd fs6 fc0 sc0 ls0 ws0">c</div><div class="t m0 x26 h4 y30c fff fs2 fc0 sc0 ls0 ws0">|</div><div class="t m0 x91 h4 y30e fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D<span class="_ _f"></span></span>|</div><div class="t m0 x32 h4 y30b ff3 fs2 fc0 sc0 ls0 ws0">(3.6)</div><div class="t m0 x3 h6 y30f ff1 fs2 fc0 sc0 ls0 ws0">对离散属<span class="_ _f"></span>性而言，令<span class="_ _11"> </span><span class="ffa">D</span></div><div class="t m0 x17 hb y310 ffd fs6 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x38 h22 y311 ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd2 h6 y30f ff1 fs2 fc0 sc0 ls0 ws0">表示<span class="_ _0"> </span><span class="ffa">D</span></div><div class="t m0 x9 hb y310 ffd fs6 fc0 sc0 ls0 ws0">c</div><div class="t m0 xa9 h6 y30f ff1 fs2 fc0 sc0 ls0 ws0">中在第<span class="_ _0"> </span><span class="ff3">i<span class="_ _0"> </span></span>个<span class="_ _f"></span>属性上取<span class="_ _f"></span>值为<span class="_ _0"> </span><span class="ffa">x</span></div><div class="t m0 x51 hb y310 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x81 h6 y30f ff1 fs2 fc0 sc0 ls0 ws0">的样本组<span class="_ _f"></span>成的集合，<span class="_ _f"></span>则条件<span class="_ _f"></span>概</div><div class="t m0 x3 h6 y312 ff1 fs2 fc0 sc0 ls0 ws0">率<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x134 hb y313 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13d h6 y312 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _c"> </span><span class="ff1">可估计为</span></span></span></div><div class="t m0 x88 h4 y314 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>x</div><div class="t m0 x21 hb y315 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x3f h4 y314 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _2c"> </span>=</span></span></div><div class="t m0 xa0 hc y316 ffa fs2 fc0 sc0 ls0 ws0">D</div><div class="t m0 xbe hb y317 ffd fs6 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x41 h22 y318 ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13e h4 y319 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D<span class="_ _f"></span></span>|</div><div class="t m0 x32 h4 y314 ff3 fs2 fc0 sc0 ls0 ws0">(3.7)</div><div class="t m0 x10e h27 y31a ff18 fs8 fc0 sc0 ls0 ws0">3</div><div class="t m0 x5 h29 y1d ff1 fs9 fc0 sc0 ls0 ws0">属性条件独立性假设<span class="_ _2c"> </span><span class="ff1c">attribute<span class="_ _2c"> </span>conditional<span class="_ _27"> </span>indep<span class="_ _f"></span>endence<span class="_ _2c"> </span>assumption</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">22</div><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",87.01,53.48,null]'><div class="d m1" style="border-style:none;position:absolute;left:533.101500px;bottom:573.742500px;width:4.233000px;height:11.293000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1c" class="pf w0 h0" data-page-no="1c"><div class="pc pc1c w0 h0"><img class="bi x3 y238 w2 h2b" alt="" src="bg1c.png"/><div class="t m0 x71 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.3<span class="_ _15"> </span><span class="ff8">朴素贝叶斯分类器</span></div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">对连续属性可考虑概率密度函数，假定<span class="_ _c"> </span><span class="ffa">P<span class="_ _32"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x21 hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1 h4 y1f fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _2c"> </span></span></span>∼<span class="_ _2c"> </span><span class="ffa">N<span class="_ _32"> </span><span class="ffb">(</span>µ</span></div><div class="t m0 x137 hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x62 h22 y31b ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x60 hc y1f ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>σ</div><div class="t m0 x50 ha y1c8 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x50 hb y31c ffd fs6 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x96 h22 y31d ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6b h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">，其中<span class="_ _c"> </span><span class="ffa">µ</span></div><div class="t m0 x13f hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x140 h22 y31b ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x125 h4 y1f ff3 fs2 fc0 sc0 ls0 ws0">�<span class="ffa">σ</span></div><div class="t m0 x141 ha y1c8 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x141 hb y31c ffd fs6 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x120 h22 y31d ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 xf1 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">分别是<span class="_ _c"> </span>第<span class="_ _c"> </span><span class="ff3">c<span class="_ _c"> </span></span>类</div><div class="t m0 x3 h6 y1ef ff1 fs2 fc0 sc0 ls0 ws0">样本在第<span class="_ _c"> </span><span class="ff3">i<span class="_ _c"> </span></span>个属性上取值的均值和方差，则有</div><div class="t m0 xa5 h4 y31e ffa fs2 fc0 sc0 ls0 ws0">p<span class="ffb">(</span>x</div><div class="t m0 x45 hb y31f ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xf5 h4 y31e fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _2c"> </span>=</span></span></div><div class="t m0 x4a h4 y320 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3c h4 y321 fff fs2 fc0 sc0 ls0 ws0">√</div><div class="t m0 x20 h4 y322 ffb fs2 fc0 sc0 ls0 ws0">2<span class="ffa">π<span class="_ _f"></span>σ</span></div><div class="t m0 xbd hb y323 ffd fs6 fc0 sc0 ls0 ws0">c,i</div><div class="t m0 x104 h4 y31e ff3 fs2 fc0 sc0 ls0 ws0">exp<span class="ffb">(<span class="fff">−</span></span></div><div class="t m0 xd6 h4 y324 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span></div><div class="t m0 x142 hb y325 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x60 h4 y324 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">µ</span></div><div class="t m0 x13b hb y325 ffd fs6 fc0 sc0 ls0 ws0">c,i</div><div class="t m0 xa1 h4 y324 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x12b ha y326 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x143 h4 y327 ffb fs2 fc0 sc0 ls0 ws0">2<span class="ffa">σ</span></div><div class="t m0 x50 ha y328 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x50 hb y329 ffd fs6 fc0 sc0 ls0 ws0">c,i</div><div class="t m0 x144 h4 y31e ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _4b"> </span><span class="ff3">(3.8)</span></div><div class="t m0 x3 h12 y32a ff6 fs7 fc0 sc0 ls0 ws0">3.3.3<span class="_ _36"> </span><span class="ff9">修正</span></div><div class="t m0 x3 h6 y32b ff1 fs2 fc0 sc0 ls0 ws0">需注意，<span class="_ _22"></span>若某个属性值在训练集中没有与某个类同时出现过，<span class="_ _22"></span>则直接基于公式<span class="ff3">3.7 </span>进行概率估计，</div><div class="t m0 x3 h6 y32c ff1 fs2 fc0 sc0 ls0 ws0">再根据<span class="_ _f"></span>公式<span class="ff3">3.5</span>进行<span class="_ _f"></span>判别将<span class="_ _f"></span>出现问<span class="_ _f"></span>题。这个<span class="_ _f"></span>问题就<span class="_ _f"></span>是该属<span class="_ _f"></span>性值在<span class="_ _f"></span>没有出<span class="_ _f"></span>现的那<span class="_ _f"></span>个类<span class="_ _f"></span>的概率<span class="_ _f"></span>估计为</div><div class="t m0 x3 h6 y32d ff3 fs2 fc0 sc0 ls0 ws0">0<span class="ff1">，因为连乘的原因，概率估计值最终为<span class="_ _c"> </span></span>0<span class="ff1">。这显然不合理。</span></div><div class="t m0 x3 h6 y32e ff1 fs2 fc0 sc0 ls0 ws0">为了避免其他属性携带的信息被训练<span class="_ _f"></span>集中未出现的属性值“抹去”<span class="_ _30"></span>，在估计概率值时通常要进行</div><div class="t m0 x145 h6 y32f ff1 fs2 fc0 sc0 ls0 ws0">“平滑”<span class="_ _10"></span><span class="ff3">(smo<span class="_ _f"></span>othing)<span class="ff1">，<span class="_ _10"></span>常用“拉普拉斯修正”<span class="_ _2f"></span><span class="ff3">(Laplaciancorrection)<span class="ff1">。具体来说，<span class="_ _2f"></span>令<span class="_ _c"> </span><span class="ffa">N<span class="_ _1c"> </span></span>表示训练</span></span></span></span></div><div class="t m0 x3 h6 y330 ff1 fs2 fc0 sc0 ls0 ws0">集中可能的类别数，<span class="ffa">N</span></div><div class="t m0 x16 hb y331 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xae h6 y330 ff1 fs2 fc0 sc0 ls0 ws0">表示第<span class="_ _c"> </span><span class="ff3">i<span class="_ _c"> </span></span>个属性可能的取值数，则上式分别修正为</div><div class="t m0 xeb h4 y332 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x10c h4 y333 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>c<span class="ffb">)<span class="_ _2c"> </span>=</span></div><div class="t m0 x40 h4 y334 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D</span></div><div class="t m0 x91 hb y335 ffd fs6 fc0 sc0 ls0 ws0">c</div><div class="t m0 x4c h4 y334 fff fs2 fc0 sc0 ls0 ws0">|<span class="_ _33"> </span><span class="ffb">+<span class="_ _25"> </span>1</span></div><div class="t m0 x40 h4 y336 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D<span class="_ _f"></span></span>|<span class="_ _33"> </span><span class="ffb">+<span class="_ _25"> </span><span class="ffa">N</span></span></div><div class="t m0 x32 h4 y333 ff3 fs2 fc0 sc0 ls0 ws0">(3.9)</div><div class="t m0 xb1 h4 y337 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 xea h4 y338 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffb">(</span>x</div><div class="t m0 x146 hb y339 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x59 h4 y338 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _2c"> </span>=</span></span></div><div class="t m0 x5c h4 y33a fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D</span></div><div class="t m0 xa0 hb y33b ffd fs6 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 xaf h22 y33c ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 xdf h4 y33a fff fs2 fc0 sc0 ls0 ws0">|<span class="_ _33"> </span><span class="ffb">+<span class="_ _25"> </span>1</span></div><div class="t m0 x147 h4 y33d fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D</span></div><div class="t m0 xb2 hb y33e ffd fs6 fc0 sc0 ls0 ws0">c</div><div class="t m0 xd4 h4 y33d fff fs2 fc0 sc0 ls0 ws0">|<span class="_ _33"> </span><span class="ffb">+<span class="_ _25"> </span><span class="ffa">N</span></span></div><div class="t m0 x62 hb y33e ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb7 h4 y338 ff3 fs2 fc0 sc0 ls0 ws0">(3.10)</div><div class="t m0 x3 h6 y33f ff1 fs2 fc0 sc0 ls0 ws0">显然，<span class="_ _29"></span>拉普拉斯修正避免了因训练集样本不充分而导致概率估值为零的问题，<span class="_ _26"></span>并且在训练集变大</div><div class="t m0 x3 h6 y340 ff1 fs2 fc0 sc0 ls0 ws0">时，<span class="_ _22"></span>修正过程所引入的先验<span class="_ _27"> </span><span class="ff3">(prior)<span class="_ _27"> </span></span>的影响也会逐渐变得可忽略，<span class="_ _22"></span>使得估值渐趋向于实际概率值。</div><div class="t m0 x3 h6 y341 ff1 fs2 fc0 sc0 ls0 ws0">在现实任务中朴素贝叶斯分类器有多种使用方式。<span class="_ _22"></span>例如，<span class="_ _22"></span>若任务对预测速度要求较高，<span class="_ _28"></span>则对给定</div><div class="t m0 x3 h6 y342 ff1 fs2 fc0 sc0 ls0 ws0">训练集，<span class="_ _29"></span>可将朴素贝叶斯分类器涉及的所有概率估值事先计算好存储起来，<span class="_ _26"></span>这样在进行预测时只</div><div class="t m0 x3 h6 y343 ff1 fs2 fc0 sc0 ls0 ws0">需<span class="ff3">”<span class="_ _c"> </span></span>查表<span class="ff3">”<span class="_ _c"> </span></span>即可进行判别；若任务数据更替频繁，则可采用<span class="ff3">”<span class="_ _c"> </span></span>懒惰学习<span class="ff3">”(lazy<span class="_ _c"> </span>learning)<span class="_ _c"> </span></span>方式，先</div><div class="t m0 x3 h6 y344 ff1 fs2 fc0 sc0 ls0 ws0">不进行任何训练，<span class="_ _22"></span>待收到预测请求时再根据当前数据集进行概率估值；<span class="_ _22"></span>若数据不断增加，<span class="_ _28"></span>则可在</div><div class="t m0 x3 h6 y345 ff1 fs2 fc0 sc0 ls0 ws0">现有估值基础上，仅对新增样本的属性值所涉及的概率估值进行计数修正即可实现增量学习。</div><div class="t m0 x3 h6 y346 ff1 fs2 fc0 sc0 ls0 ws0">尽管朴<span class="_ _f"></span>素贝叶<span class="_ _f"></span>斯被<span class="_ _f"></span>认为是<span class="_ _f"></span>一种<span class="_ _f"></span>相当不<span class="_ _f"></span>错的<span class="_ _f"></span>分类器，<span class="_ _f"></span>但却<span class="_ _f"></span>不是好<span class="_ _f"></span>的估<span class="_ _f"></span>计器<span class="_ _11"> </span><span class="ff3">(estimator)</span>，所以<span class="_ _f"></span>不能</div><div class="t m0 x3 h6 y347 ff1 fs2 fc0 sc0 ls0 ws0">太过于重视从<span class="_ _c"> </span><span class="ff3">predict_proba<span class="_ _c"> </span></span>输出的概率。</div><div class="t m0 x1e h6 y348 ff4 fs2 fc0 sc0 ls0 ws0">为什么朴素贝叶斯是较好的分类器，但却是糟糕的估计器？</div><div class="t m0 x1e h6 y349 ff1 fs2 fc0 sc0 ls0 ws0">很显然，其中一个原因是因为它的朴素假设。实际上，只要使用贝叶斯方法，<span class="_ _10"></span>就会带来这</div><div class="t m0 x1e h6 y34a ff1 fs2 fc0 sc0 ls0 ws0">个问题。因为贝叶斯方法验证依赖于先验分布的假设，<span class="_ _10"></span>一旦先验分布假设和真实分布有偏</div><div class="t m0 x1e h6 y34b ff1 fs2 fc0 sc0 ls0 ws0">离，估计出来的概率与真实概率可能就会差距甚大。但是，<span class="_ _10"></span>如果样本真的能反应总体的特</div><div class="t m0 x1e h6 y34c ff1 fs2 fc0 sc0 ls0 ws0">征，那么后验概率一定会对先验概率进行纠正，因此能较好地分类。</div><div class="t m0 x3 h6 y34d ff1 fs2 fc1 sc0 ls0 ws0">还有一点要注意的是：<span class="_ _22"></span>从上面的概率修正的描述中，<span class="_ _22"></span>我们就可以看出来，<span class="_ _28"></span>贝叶斯分类器只能适用</div><div class="t m0 x3 h6 y34e ff1 fs2 fc1 sc0 ls0 ws0">于所有分类估计概率已知的情况下，如果新的样本值在训练样本中没有出现过，则无法分类。</div><div class="t m0 x3 h12 y34f ff6 fs7 fc0 sc0 ls0 ws0">3.3.4<span class="_ _36"> </span><span class="ff9">朴素贝叶斯算法的不同方法</span></div><div class="t m0 x3 h6 y350 ff1 fs2 fc0 sc0 ls0 ws0">在<span class="ff3">3.3.2</span>节中，说了后验概率<span class="_ _0"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x45 hb y351 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x148 h6 y350 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _c"> </span><span class="ff1">的估计。<span class="_ _30"></span>（朴素）贝叶斯分类器的核心就是<span class="_ _0"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x</span></span></span></span></div><div class="t m0 xf4 hb y351 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xff h6 y350 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _c"> </span><span class="ff1">的估计，</span></span></span></div><div class="t m0 x3 h6 y352 ff1 fs2 fc0 sc0 ls0 ws0">根据对<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x</span></div><div class="t m0 xd9 hb y353 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xe5 h6 y352 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _c"> </span><span class="ff1">假定的概率分布的不同，朴素贝叶斯会分为三种情况：</span></span></span></div><div class="t m0 x9a h6 y354 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _6"> </span><span class="ff1">二分类任务，<span class="ffa">x<span class="_ _c"> </span></span>取值离散且有限：假定<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x</span></span></div><div class="t m0 x138 hb y355 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x91 h6 y354 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _c"> </span><span class="ff1">服从二项分布</span></span></span></div><div class="t m0 x9a h6 y356 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff1">多分类任务，<span class="ffa">x<span class="_ _c"> </span></span>取值离散且有限：假定<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x</span></span></div><div class="t m0 x138 hb y357 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x91 h6 y356 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _c"> </span><span class="ff1">服从多项分布</span></span></span></div><div class="t m0 x9a h6 y358 ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _6"> </span><span class="ff1">当<span class="_ _c"> </span><span class="ffa">x<span class="_ _c"> </span></span>的取值是连续时</span>:<span class="_ _c"> </span><span class="ff1">假定<span class="_ _c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x</span></span></div><div class="t m0 xb1 hb y359 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x10f h6 y358 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _c"> </span><span class="ff1">服从正态分布</span></span></span></div><div class="t m0 x1e h6 y35a ff1 fs2 fc0 sc0 ls0 ws0">注意，<span class="_ _31"></span>分类的数目永远是有限的，<span class="_ _22"></span><span class="ffa">x<span class="_ _c"> </span><span class="ff1">的分布是<span class="_ _27"> </span></span>x<span class="_ _c"> </span><span class="ff1">取值的概率分布，<span class="_ _31"></span>并不是<span class="_ _27"> </span><span class="ffa">x<span class="_ _c"> </span></span>分类的概率分</span></span></div><div class="t m0 x1e h6 y35b ff1 fs2 fc0 sc0 ls0 ws0">布。<span class="_ _31"></span>例如：<span class="_ _31"></span>在文本分类中，<span class="_ _31"></span><span class="ffa">x</span></div><div class="t m0 x123 hb y35c ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x45 h6 y35b ff1 fs2 fc0 sc0 ls0 ws0">一般是<span class="ff4">词的出现次数</span>，<span class="_ _31"></span>如果是二分类，<span class="_ _31"></span><span class="ffa">x</span></div><div class="t m0 x12c hb y35c ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x140 h6 y35b ff1 fs2 fc0 sc0 ls0 ws0">的取值集合为<span class="_ _27"> </span><span class="ffb">0<span class="ffa">,<span class="_ _2d"> </span></span>1</span>，</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">23</div><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",260.24,93.48,null]'><div class="d m1" style="border-style:none;position:absolute;left:657.966000px;bottom:991.123500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",218.84,266.99,null]'><div class="d m1" style="border-style:none;position:absolute;left:188.643000px;bottom:970.800000px;width:13.941000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",70.87,531.57,null]'><div class="d m1" style="border-style:none;position:absolute;left:122.662500px;bottom:250.965000px;width:22.429000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1d" class="pf w0 h0" data-page-no="1d"><div class="pc pc1d w0 h0"><img class="bi x3 y35d w2 h2c" alt="" src="bg1d.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.4<span class="_ _15"> </span>PYTHON<span class="_ _27"> </span><span class="ff8">示例</span></div><div class="t m0 x1e h6 y35e ff1 fs2 fc0 sc0 ls0 ws0">也就是<span class="ff4">词的出现次数</span>服从二项分布。</div><div class="t m0 x1e h6 y35f ff1 fs2 fc0 sc0 ls0 ws0">伯努<span class="_ _f"></span>利朴<span class="_ _f"></span>素贝<span class="_ _f"></span>叶<span class="_ _f"></span>斯不<span class="_ _f"></span>是只<span class="_ _f"></span>能<span class="_ _f"></span>用在<span class="_ _f"></span>二分<span class="_ _f"></span>类的<span class="_ _f"></span>任<span class="_ _f"></span>务，多<span class="_ _f"></span>分类<span class="_ _f"></span>的<span class="_ _f"></span>任务<span class="_ _f"></span>也可<span class="_ _f"></span>以，<span class="_ _f"></span>因为<span class="_ _f"></span>根据<span class="_ _1c"> </span><span class="ffa">P<span class="_ _2b"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x149 hb y360 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x31 h4 y35f fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)</span></span></div><div class="t m0 x1e h6 y361 ff1 fs2 fc0 sc0 ls0 ws0">服从二项分布假定得到的只是一类的后验概率估计。<span class="_ _10"></span>预测分类需要比较各类的后验概率大</div><div class="t m0 x1e h6 y362 ff1 fs2 fc0 sc0 ls0 ws0">小。</div><div class="t m0 x1e h6 y363 ff1 fs2 fc0 sc0 ls0 ws0">多项<span class="_ _f"></span>式<span class="_ _f"></span>朴素<span class="_ _f"></span>贝<span class="_ _f"></span>叶斯<span class="_ _f"></span>只<span class="_ _f"></span>适<span class="_ _f"></span>合用<span class="_ _f"></span>来<span class="_ _f"></span>对非<span class="_ _f"></span>负<span class="_ _f"></span>离<span class="_ _f"></span>散数<span class="_ _f"></span>值<span class="_ _f"></span>特征<span class="_ _f"></span>进<span class="_ _f"></span>行分<span class="_ _f"></span>类，<span class="_ _f"></span>典<span class="_ _f"></span>型的<span class="_ _f"></span>例<span class="_ _1c"> </span>子就<span class="_ _f"></span>是<span class="_ _f"></span>对<span class="_ _f"></span>转化<span class="_ _f"></span>为</div><div class="t m0 x1e h6 y364 ff1 fs2 fc0 sc0 ls0 ws0">向量后的文本数据进行分类。</div><div class="t m0 x9 h6 y365 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">3.1:<span class="_ _2e"> </span></span>伯努利朴素贝叶斯</div><div class="t m0 x3 h26 y366 ff8 fs2 fc0 sc0 ls0 ws0">如图：二项分布的概率密度，横轴可以是一个单词的出现次数。</div><div class="t m0 x14a h9 y367 ff6 fs5 fc0 sc0 ls0 ws0">3.4<span class="_ _21"> </span>p<span class="_ _2f"></span>ython<span class="_ _9"> </span><span class="ff9">示例</span></div><div class="t m0 x3 h12 y368 ff6 fs7 fc0 sc0 ls0 ws0">3.4.1<span class="_ _36"> </span><span class="ff9">伯努利朴素贝叶斯的示例</span></div><div class="t m0 x14b h2d y369 ff1d fs8 fc0 sc0 ls0 ws0">1<span class="_ _b"> </span><span class="fs2 fc2">X<span class="_ _5"> </span>=<span class="_ _20"> </span>n<span class="_ _1f"></span>p<span class="_ _1f"></span>.<span class="_ _4c"></span>a<span class="_ _f"></span>r<span class="_ _1f"></span>r<span class="_ _1f"></span>a<span class="_ _f"></span>y<span class="_ _4c"></span>(<span class="_ _1f"></span>[<span class="_ _f"></span>[<span class="_ _1f"></span>0<span class="_ _4c"></span>,<span class="_ _f"></span>1<span class="_ _4c"></span>,<span class="_ _f"></span>0<span class="_ _4c"></span>,<span class="_ _f"></span>1<span class="_ _1f"></span>]<span class="_ _4c"></span>,</span></div><div class="t m0 x14b h2d y36a ff1d fs8 fc0 sc0 ls0 ws0">2<span class="_ _b"> </span><span class="fs2 fc2">[<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>0<span class="_ _f"></span>]<span class="_ _4c"></span>,</span></div><div class="t m0 x14b h2d y36b ff1d fs8 fc0 sc0 ls0 ws0">3<span class="_ _b"> </span><span class="fs2 fc2">[<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>0<span class="_ _f"></span>]<span class="_ _4c"></span>,</span></div><div class="t m0 x14b h2d y36c ff1d fs8 fc0 sc0 ls0 ws0">4<span class="_ _b"> </span><span class="fs2 fc2">[<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _f"></span>]<span class="_ _4c"></span>,</span></div><div class="t m0 x14b h2d y36d ff1d fs8 fc0 sc0 ls0 ws0">5<span class="_ _b"> </span><span class="fs2 fc2">[<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>0<span class="_ _f"></span>]<span class="_ _4c"></span>,</span></div><div class="t m0 x14b h2d y36e ff1d fs8 fc0 sc0 ls0 ws0">6<span class="_ _b"> </span><span class="fs2 fc2">[<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _f"></span>]<span class="_ _4c"></span>,</span></div><div class="t m0 x14b h2d y36f ff1d fs8 fc0 sc0 ls0 ws0">7<span class="_ _b"> </span><span class="fs2 fc2">[<span class="_ _1f"></span>1<span class="_ _4c"></span>,<span class="_ _f"></span>0<span class="_ _4c"></span>,<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _f"></span>]<span class="_ _1f"></span>]<span class="_ _f"></span>)</span></div><div class="t m0 x14b h6 y370 ff1d fs8 fc0 sc0 ls0 ws0">8<span class="_ _b"> </span><span class="fs2 fc3">#<span class="_ _5"> </span>y<span class="_ _32"></span><span class="ff5">是<span class="_ _32"> </span></span>X<span class="_ _2b"> </span><span class="ff5">的<span class="_ _33"> </span>标<span class="_ _33"> </span>签</span></span></div><div class="t m0 x14b h2d y371 ff1d fs8 fc0 sc0 ls0 ws0">9<span class="_ _b"> </span><span class="fs2 fc2">y<span class="_ _5"> </span>=<span class="_ _20"> </span>n<span class="_ _1f"></span>p<span class="_ _1f"></span>.<span class="_ _4c"></span>a<span class="_ _f"></span>r<span class="_ _1f"></span>r<span class="_ _1f"></span>a<span class="_ _f"></span>y<span class="_ _4c"></span>(<span class="_ _1f"></span>[<span class="_ _f"></span>0<span class="_ _4c"></span>,<span class="_ _1f"></span>1<span class="_ _1f"></span>,<span class="_ _1f"></span>1<span class="_ _4c"></span>,<span class="_ _f"></span>0<span class="_ _4c"></span>,<span class="_ _f"></span>1<span class="_ _4c"></span>,<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>0<span class="_ _f"></span>]<span class="_ _1f"></span>)</span></div><div class="t m0 x14c h2e y372 ff1d fs8 fc0 sc0 ls0 ws0">10</div><div class="t m0 x14c h2d y373 ff1d fs8 fc0 sc0 ls0 ws0">11<span class="_ _6"> </span><span class="fs2 fc2">c<span class="_ _f"></span>o<span class="_ _1f"></span>u<span class="_ _1f"></span>n<span class="_ _1f"></span>t<span class="_ _f"></span>s<span class="_ _4c"></span>=<span class="_ _1f"></span>{<span class="_ _1f"></span>}</span></div><div class="t m0 x14c h2d y374 ff1d fs8 fc0 sc0 ls0 ws0">12<span class="_ _b"> </span><span class="fs2 fc4">f<span class="_ _1f"></span>o<span class="_ _f"></span>r<span class="_ _16"> </span><span class="fc2">l<span class="_ _f"></span>a<span class="_ _1f"></span>b<span class="_ _1f"></span>e<span class="_ _f"></span>l<span class="_ _5"> </span></span>i<span class="_ _1f"></span>n<span class="_ _5"> </span><span class="fc2">n<span class="_ _f"></span>p<span class="_ _1f"></span>.<span class="_ _4c"></span>u<span class="_ _f"></span>n<span class="_ _1f"></span>i<span class="_ _1f"></span>q<span class="_ _1f"></span>u<span class="_ _f"></span>e<span class="_ _4c"></span>(<span class="_ _1f"></span>y<span class="_ _1f"></span>)<span class="_ _1f"></span>:</span></span></div><div class="t m0 x14c h2d y375 ff1d fs8 fc0 sc0 ls0 ws0">13<span class="_ _6"> </span><span class="fs2 fc2">c<span class="_ _f"></span>o<span class="_ _1f"></span>u<span class="_ _1f"></span>n<span class="_ _1f"></span>t<span class="_ _f"></span>s<span class="_ _4c"></span>[<span class="_ _4c"></span>l<span class="_ _f"></span>a<span class="_ _1f"></span>b<span class="_ _1f"></span>e<span class="_ _f"></span>l<span class="_ _4c"></span>]<span class="_ _1f"></span>=<span class="_ _1f"></span>X<span class="_ _1f"></span>[<span class="_ _1f"></span>y<span class="_ _1f"></span>=<span class="_ _1f"></span>=<span class="_ _4c"></span>l<span class="_ _f"></span>a<span class="_ _1f"></span>b<span class="_ _1f"></span>e<span class="_ _f"></span>l<span class="_ _4c"></span>]<span class="_ _1f"></span>.<span class="_ _1f"></span><span class="fc4">s<span class="_ _1f"></span>u<span class="_ _f"></span>m<span class="_ _4c"></span></span>(<span class="_ _1f"></span>a<span class="_ _1f"></span>x<span class="_ _1f"></span>i<span class="_ _f"></span>s<span class="_ _4c"></span>=<span class="_ _1f"></span>0<span class="_ _f"></span>)</span></div><div class="t m0 x14c h2e y376 ff1d fs8 fc0 sc0 ls0 ws0">14</div><div class="t m0 x14c h2d y377 ff1d fs8 fc0 sc0 ls0 ws0">15<span class="_ _b"> </span><span class="fs2 fc4">p<span class="_ _1f"></span>r<span class="_ _1f"></span>i<span class="_ _1f"></span>n<span class="_ _f"></span>t<span class="_ _4c"></span><span class="fc2">(<span class="_ _1f"></span><span class="fc5">&quot;<span class="_ _4c"></span>f<span class="_ _f"></span>e<span class="_ _1f"></span>a<span class="_ _1f"></span>t<span class="_ _1f"></span>u<span class="_ _f"></span>r<span class="_ _1f"></span>e<span class="_ _5"> </span>c<span class="_ _1f"></span>o<span class="_ _1f"></span>u<span class="_ _1f"></span>n<span class="_ _f"></span>t<span class="_ _1f"></span>s<span class="_ _4c"></span>:<span class="_ _f"></span>\<span class="_ _4c"></span>n<span class="_ _1f"></span>{<span class="_ _f"></span>}<span class="_ _4c"></span>&quot;<span class="_ _1f"></span></span>.<span class="_ _1f"></span></span>f<span class="_ _1f"></span>o<span class="_ _1f"></span>r<span class="_ _1f"></span>m<span class="_ _f"></span>a<span class="_ _1f"></span>t<span class="_ _4c"></span><span class="fc2">(<span class="_ _1f"></span>c<span class="_ _1f"></span>o<span class="_ _1f"></span>u<span class="_ _1f"></span>n<span class="_ _f"></span>t<span class="_ _1f"></span>s<span class="_ _4c"></span>)<span class="_ _1f"></span>)</span></span></div><div class="t m0 x14c h2e y378 ff1d fs8 fc0 sc0 ls0 ws0">16</div><div class="t m0 x14c h2d y379 ff1d fs8 fc0 sc0 ls0 ws0">17<span class="_ _b"> </span><span class="fs2 fc4">f<span class="_ _1f"></span>r<span class="_ _1f"></span>o<span class="_ _f"></span>m<span class="_ _16"> </span><span class="fc2">s<span class="_ _f"></span>k<span class="_ _1f"></span>l<span class="_ _1f"></span>e<span class="_ _1f"></span>a<span class="_ _f"></span>r<span class="_ _1f"></span>n<span class="_ _4c"></span>.<span class="_ _4c"></span>n<span class="_ _1f"></span>a<span class="_ _f"></span>i<span class="_ _1f"></span>v<span class="_ _1f"></span>e<span class="_ _1f"></span>_<span class="_ _1f"></span>b<span class="_ _1f"></span>a<span class="_ _f"></span>y<span class="_ _1f"></span>e<span class="_ _1f"></span>s<span class="_ _16"> </span></span>i<span class="_ _f"></span>m<span class="_ _1f"></span>p<span class="_ _1f"></span>o<span class="_ _1f"></span>r<span class="_ _f"></span>t<span class="_ _16"> </span><span class="fc2">B<span class="_ _1f"></span>e<span class="_ _1f"></span>r<span class="_ _f"></span>n<span class="_ _1f"></span>o<span class="_ _1f"></span>u<span class="_ _1f"></span>l<span class="_ _1f"></span>l<span class="_ _1f"></span>i<span class="_ _f"></span>N<span class="_ _1f"></span>B</span></span></div><div class="t m0 x14c h2e y37a ff1d fs8 fc0 sc0 ls0 ws0">18</div><div class="t m0 x14c h2d y37b ff1d fs8 fc0 sc0 ls0 ws0">19<span class="_ _b"> </span><span class="fs2 fc2">c<span class="_ _1f"></span>l<span class="_ _f"></span>f<span class="_ _5"> </span>=<span class="_ _5"> </span>B<span class="_ _1f"></span>e<span class="_ _f"></span>r<span class="_ _1f"></span>n<span class="_ _1f"></span>o<span class="_ _1f"></span>u<span class="_ _1f"></span>l<span class="_ _1f"></span>l<span class="_ _f"></span>i<span class="_ _1f"></span>N<span class="_ _1f"></span>B<span class="_ _4c"></span>(<span class="_ _1f"></span>)</span></div><div class="t m0 x14c h2d y37c ff1d fs8 fc0 sc0 ls0 ws0">20<span class="_ _b"> </span><span class="fs2 fc2">c<span class="_ _1f"></span>l<span class="_ _f"></span>f<span class="_ _4c"></span>.<span class="_ _1f"></span>f<span class="_ _1f"></span>i<span class="_ _f"></span>t<span class="_ _4c"></span>(<span class="_ _1f"></span>X<span class="_ _1f"></span>,<span class="_ _1f"></span>y<span class="_ _1f"></span>)</span></div><div class="t m0 x14c h2d y37d ff1d fs8 fc0 sc0 ls0 ws0">21<span class="_ _6"> </span><span class="fs2 fc2">N<span class="_ _f"></span>e<span class="_ _1f"></span>x<span class="_ _1f"></span>t<span class="_ _1f"></span>_<span class="_ _1f"></span>d<span class="_ _f"></span>a<span class="_ _1f"></span>y<span class="_ _5"> </span>=<span class="_ _5"> </span>[<span class="_ _f"></span>[<span class="_ _1f"></span>0<span class="_ _1f"></span>,<span class="_ _1f"></span>0<span class="_ _4c"></span>,<span class="_ _f"></span>1<span class="_ _4c"></span>,<span class="_ _1f"></span>0<span class="_ _f"></span>]<span class="_ _1f"></span>]</span></div><div class="t m0 x14c h2d y37e ff1d fs8 fc0 sc0 ls0 ws0">22<span class="_ _b"> </span><span class="fs2 fc2">p<span class="_ _1f"></span>r<span class="_ _f"></span>e<span class="_ _5"> </span>=<span class="_ _5"> </span>c<span class="_ _f"></span>l<span class="_ _f"></span>f<span class="_ _4c"></span>.<span class="_ _4c"></span>p<span class="_ _f"></span>r<span class="_ _1f"></span>e<span class="_ _1f"></span>d<span class="_ _1f"></span>i<span class="_ _f"></span>c<span class="_ _1f"></span>t<span class="_ _4c"></span>(<span class="_ _4c"></span>N<span class="_ _f"></span>e<span class="_ _1f"></span>x<span class="_ _1f"></span>t<span class="_ _1f"></span>_<span class="_ _1f"></span>d<span class="_ _f"></span>a<span class="_ _1f"></span>y<span class="_ _4c"></span>)</span></div><div class="t m0 x14c h2d y37f ff1d fs8 fc0 sc0 ls0 ws0">23<span class="_ _b"> </span><span class="fs2 fc2">c<span class="_ _1f"></span>l<span class="_ _f"></span>f<span class="_ _4c"></span>.<span class="_ _4c"></span>p<span class="_ _1f"></span>r<span class="_ _f"></span>e<span class="_ _1f"></span>d<span class="_ _1f"></span>i<span class="_ _1f"></span>c<span class="_ _1f"></span>t<span class="_ _1f"></span>_<span class="_ _1f"></span>p<span class="_ _f"></span>r<span class="_ _1f"></span>o<span class="_ _1f"></span>b<span class="_ _1f"></span>a<span class="_ _4c"></span>(<span class="_ _4c"></span>N<span class="_ _f"></span>e<span class="_ _1f"></span>x<span class="_ _1f"></span>t<span class="_ _1f"></span>_<span class="_ _1f"></span>d<span class="_ _f"></span>a<span class="_ _1f"></span>y<span class="_ _4c"></span>)</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">24</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1e" class="pf w0 h0" data-page-no="1e"><div class="pc pc1e w0 h0"><div class="t m0 x14d h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.4<span class="_ _15"> </span>PYTHON<span class="_ _27"> </span><span class="ff8">示例</span></div><div class="t m0 x3 h2d y1f ff1d fs2 fc0 sc0 ls0 ws0">X = np.array([[0,1,0,1],</div><div class="t m0 x3 h2d y1ef ff1d fs2 fc0 sc0 ls0 ws0">[1,1,1,0],</div><div class="t m0 x3 h2d y380 ff1d fs2 fc0 sc0 ls0 ws0">[0,1,1,0],</div><div class="t m0 x3 h2d y381 ff1d fs2 fc0 sc0 ls0 ws0">[0,0,0,1],</div><div class="t m0 x3 h2d y382 ff1d fs2 fc0 sc0 ls0 ws0">[0,1,1,0],</div><div class="t m0 x3 h2d y383 ff1d fs2 fc0 sc0 ls0 ws0">[0,1,0,1],</div><div class="t m0 x3 h2d y384 ff1d fs2 fc0 sc0 ls0 ws0">[1,0,0,1]])</div><div class="t m0 x3 h6 y385 ff1d fs2 fc0 sc0 ls0 ws0"># y<span class="_ _1f"></span><span class="ff5">是<span class="_ _1f"></span></span>X<span class="_ _1f"></span><span class="ff5">的<span class="_ _4c"></span>标<span class="_ _32"> </span>签</span></div><div class="t m0 x3 h2d y386 ff1d fs2 fc0 sc0 ls0 ws0">y = np.array([0,1,1,0,1,0,0])</div><div class="t m0 x3 h2d y387 ff1d fs2 fc0 sc0 ls0 ws0">counts={}</div><div class="t m0 x3 h2d y388 ff1d fs2 fc0 sc0 ls0 ws0">for label in np.unique(y):</div><div class="t m0 x3 h2d y389 ff1d fs2 fc0 sc0 ls0 ws0">counts[label]=X[y==label].sum(axis=0)</div><div class="t m0 x3 h2d y38a ff1d fs2 fc0 sc0 ls0 ws0">print(&quot;feature counts:\n{}&quot;.format(counts))</div><div class="t m0 x3 h2d y38b ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.naive_bayes import BernoulliNB</div><div class="t m0 x3 h2d y38c ff1d fs2 fc0 sc0 ls0 ws0">clf = BernoulliNB()</div><div class="t m0 x3 h2d y38d ff1d fs2 fc0 sc0 ls0 ws0">clf.fit(X,y)</div><div class="t m0 x3 h2d y38e ff1d fs2 fc0 sc0 ls0 ws0">Next_day = [[0,0,1,0]]</div><div class="t m0 x3 h2d y38f ff1d fs2 fc0 sc0 ls0 ws0">pre = clf.predict(Next_day)</div><div class="t m0 x3 h2d y390 ff1d fs2 fc0 sc0 ls0 ws0">clf.predict_proba(Next_day)</div><div class="t m0 x3 h12 y391 ff6 fs7 fc0 sc0 ls0 ws0">3.4.2<span class="_ _36"> </span><span class="ff9">对比</span></div><div class="t m0 x3 h6 y392 ff1 fs2 fc0 sc0 ls0 ws0">先尝试用伯努利贝叶斯进行分类，看看效果。</div><div class="t m0 x3 h2d y393 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.datasets import make_blobs</div><div class="t m0 x3 h2d y394 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.model_selection import train_test_split</div><div class="t m0 x3 h2d y395 ff1d fs2 fc0 sc0 ls0 ws0">X,y = make_blobs(n_samples=500,centers = 5, random_state = 2)</div><div class="t m0 x3 h6 y396 ff1d fs2 fc0 sc0 ls0 ws0"># centers=5<span class="_ _20"> </span><span class="ff5">分<span class="_ _f"></span></span>5<span class="_ _1f"></span><span class="ff5">类</span></div><div class="t m0 x3 h6 y397 ff1d fs2 fc0 sc0 ls0 ws0"># random_state<span class="_ _20"> </span><span class="ff5">随<span class="_ _4c"></span>机<span class="_ _4c"></span>数<span class="_ _32"> </span>种<span class="_ _32"></span>子</span></div><div class="t m0 x3 h2d y398 ff1d fs2 fc0 sc0 ls0 ws0">nb = BernoulliNB()</div><div class="t m0 x3 h6 y399 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _20"> </span><span class="ff5">把<span class="_ _4c"></span>样<span class="_ _32"></span>本<span class="_ _4c"></span>拆<span class="_ _32"></span>分<span class="_ _32"></span>为<span class="_ _32"></span>训<span class="_ _4c"></span>练<span class="_ _32"></span>集<span class="_ _32"></span>和<span class="_ _4c"></span>测<span class="_ _32"> </span>试<span class="_ _32"></span>集</span></div><div class="t m0 x3 h2d y39a ff1d fs2 fc0 sc0 ls0 ws0">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=2)</div><div class="t m0 x3 h2d y39b ff1d fs2 fc0 sc0 ls0 ws0">nb.fit(X_train,y_train)</div><div class="t m0 x3 h6 y39c ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _20"> </span><span class="ff5">模<span class="_ _4c"></span>型<span class="_ _32"></span>得<span class="_ _4c"></span>分</span></div><div class="t m0 x3 h2d y39d ff1d fs2 fc0 sc0 ls0 ws0">nb.score(X_test,y_test)</div><div class="t m0 x3 h2d y39e ff1d fs2 fc0 sc0 ls0 ws0">nb.predict(X_test)</div><div class="t m0 x3 h6 y39f ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">导<span class="_ _4c"></span>入<span class="_ _32"> </span>画<span class="_ _32"></span>图<span class="_ _32"></span>工<span class="_ _4c"></span>具</span></div><div class="t m0 x3 h2d y3a0 ff1d fs2 fc0 sc0 ls0 ws0">import matplotlib.pyplot as plt</div><div class="t m0 x3 h6 y3a1 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">限<span class="_ _4c"></span>定<span class="_ _32"> </span>横<span class="_ _32"></span>轴<span class="_ _32"></span>与<span class="_ _4c"></span>纵<span class="_ _32"> </span>轴<span class="_ _32"></span>的<span class="_ _32"></span>最<span class="_ _4c"></span>大<span class="_ _32"> </span>值</span></div><div class="t m0 x3 h2d y3a2 ff1d fs2 fc0 sc0 ls0 ws0">x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5</div><div class="t m0 x3 h2d y3a3 ff1d fs2 fc0 sc0 ls0 ws0">y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5</div><div class="t m0 x3 h6 y1c6 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">用<span class="_ _4c"></span>不<span class="_ _32"> </span>同<span class="_ _32"></span>的<span class="_ _32"></span>背<span class="_ _4c"></span>景<span class="_ _32"> </span>色<span class="_ _32"></span>表<span class="_ _32"></span>示<span class="_ _4c"></span>不<span class="_ _32"> </span>同<span class="_ _32"></span>的<span class="_ _32"></span>分<span class="_ _4c"></span>类</span></div><div class="t m0 x3 h2d y111 ff1d fs2 fc0 sc0 ls0 ws0">xx,yy = np.meshgrid(np.arange(x_min, x_max,.02),</div><div class="t m0 x3 h2d y1d ff1d fs2 fc0 sc0 ls0 ws0">np.arange(y_min, y_max, .02))</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">25</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1f" class="pf w0 h0" data-page-no="1f"><div class="pc pc1f w0 h0"><img class="bi xd1 y3a4 wc h2f" alt="" src="bg1f.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.4<span class="_ _15"> </span>PYTHON<span class="_ _27"> </span><span class="ff8">示例</span></div><div class="t m0 x3 h2d y1f ff1d fs2 fc0 sc0 ls0 ws0">np.arange(x_min, x_max,.02).shape</div><div class="t m0 x3 h2d y380 ff1d fs2 fc0 sc0 ls0 ws0">z = nb.predict(np.c_[(xx.ravel(),yy.ravel())]).reshape(xx.shape)</div><div class="t m0 x3 h2d y384 ff1d fs2 fc0 sc0 ls0 ws0">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</div><div class="t m0 x3 h6 y385 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">将<span class="_ _4c"></span>训<span class="_ _32"> </span>练<span class="_ _32"></span>集<span class="_ _32"></span>和<span class="_ _4c"></span>测<span class="_ _32"> </span>试<span class="_ _32"></span>集<span class="_ _32"></span>用<span class="_ _4c"></span>散<span class="_ _32"> </span>点<span class="_ _32"></span>图<span class="_ _32"></span>表<span class="_ _4c"></span>示</span></div><div class="t m0 x3 h2d y386 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap=plt.cm.cool,edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h2d y3a5 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_test[:,0],X_test[:,1],c=y_test,cmap=plt.cm.cool,marker=&apos;*&apos;,</div><div class="t m0 x3 h2d y387 ff1d fs2 fc0 sc0 ls0 ws0">edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h2d y388 ff1d fs2 fc0 sc0 ls0 ws0">plt.xlim(xx.min(),xx.max())</div><div class="t m0 x3 h2d y389 ff1d fs2 fc0 sc0 ls0 ws0">plt.ylim(yy.min(),yy.max())</div><div class="t m0 x3 h6 y3a6 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">定<span class="_ _4c"></span>义<span class="_ _32"> </span>图<span class="_ _32"></span>题</span></div><div class="t m0 x3 h2d y38a ff1d fs2 fc0 sc0 ls0 ws0">plt.title(&apos;Classiﬁer: BernoulliNB&apos;)</div><div class="t m0 x3 h6 y3a7 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">现<span class="_ _4c"></span>实<span class="_ _32"> </span>图<span class="_ _32"></span>片</span></div><div class="t m0 x3 h2d y38b ff1d fs2 fc0 sc0 ls0 ws0">plt.show()</div><div class="t m0 x8d h6 y3a8 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">3.2:</span></div><div class="t m0 x3 h6 y3a9 ff1 fs2 fc0 sc0 ls0 ws0">再使用高斯朴素贝叶斯。</div><div class="t m0 x3 h6 y397 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">导<span class="_ _4c"></span>入<span class="_ _32"> </span>高<span class="_ _32"></span>斯<span class="_ _32"></span>贝<span class="_ _4c"></span>叶<span class="_ _32"> </span>斯</span></div><div class="t m0 x3 h2d y398 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.naive_bayes import GaussianNB</div><div class="t m0 x3 h6 y399 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">使<span class="_ _4c"></span>用<span class="_ _32"> </span>高<span class="_ _32"></span>斯<span class="_ _32"></span>贝<span class="_ _4c"></span>叶<span class="_ _32"> </span>斯<span class="_ _32"></span>拟<span class="_ _32"></span>合<span class="_ _4c"></span>数<span class="_ _32"> </span>据</span></div><div class="t m0 x3 h2d y39a ff1d fs2 fc0 sc0 ls0 ws0">gnb = GaussianNB()</div><div class="t m0 x3 h2d y3aa ff1d fs2 fc0 sc0 ls0 ws0">gnb.ﬁt(X_train, y_train)</div><div class="t m0 x3 h2d y39b ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n\n\n&apos;)</div><div class="t m0 x3 h6 y3ab ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;<span class="_ _1f"></span><span class="ff5">代<span class="_ _4c"></span>码<span class="_ _32"> </span>运<span class="_ _32"></span>行<span class="_ _32"></span>结<span class="_ _4c"></span>果<span class="_ _32"> </span>：<span class="_ _1f"></span></span>&apos;)</div><div class="t m0 x3 h2d y39c ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;==============================\n&apos;)</div><div class="t m0 x3 h6 y39d ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">打<span class="_ _4c"></span>印<span class="_ _32"> </span>模<span class="_ _32"></span>型<span class="_ _32"></span>得<span class="_ _4c"></span>分</span></div><div class="t m0 x3 h6 y39e ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;<span class="_ _1f"></span><span class="ff5">模<span class="_ _4c"></span>型<span class="_ _32"> </span>得<span class="_ _32"></span>分<span class="_ _32"></span>：<span class="_ _1f"></span></span>{:.3f}&apos;.format(gnb.score(X_test, y_test)))</div><div class="t m0 x3 h2d y3ac ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n==============================&apos;)</div><div class="t m0 x3 h2d y3ad ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n\n\n&apos;)</div><div class="t m0 x3 h6 y3ae ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">用<span class="_ _4c"></span>不<span class="_ _32"> </span>同<span class="_ _32"></span>色<span class="_ _32"></span>块<span class="_ _4c"></span>来<span class="_ _32"> </span>表<span class="_ _32"></span>示<span class="_ _32"></span>不<span class="_ _4c"></span>同<span class="_ _32"> </span>的<span class="_ _32"></span>分<span class="_ _32"></span>类</span></div><div class="t m0 x3 h2d y3a1 ff1d fs2 fc0 sc0 ls0 ws0">z = gnb.predict(np.c_[(xx.ravel(),yy.ravel())]).reshape(xx.shape)</div><div class="t m0 x3 h2d y3a2 ff1d fs2 fc0 sc0 ls0 ws0">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</div><div class="t m0 x3 h6 y3a3 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">用<span class="_ _4c"></span>散<span class="_ _32"> </span>点<span class="_ _32"></span>图<span class="_ _32"></span>画<span class="_ _4c"></span>出<span class="_ _32"> </span>训<span class="_ _32"></span>练<span class="_ _32"></span>集<span class="_ _4c"></span>和<span class="_ _32"> </span>测<span class="_ _32"></span>试<span class="_ _32"></span>集<span class="_ _4c"></span>数<span class="_ _32"></span>据</span></div><div class="t m0 x3 h2d y1c6 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap=plt.cm.cool,edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h2d y111 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_test[:,0],X_test[:,1],c=y_test,cmap=plt.cm.cool,marker=&apos;*&apos;,</div><div class="t m0 x3 h2d y1d ff1d fs2 fc0 sc0 ls0 ws0">edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">26</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf20" class="pf w0 h0" data-page-no="20"><div class="pc pc20 w0 h0"><img class="bi xd1 y3af wc h2f" alt="" src="bg20.png"/><div class="t m0 x14d h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.4<span class="_ _15"> </span>PYTHON<span class="_ _27"> </span><span class="ff8">示例</span></div><div class="t m0 x3 h6 y1f ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">设<span class="_ _4c"></span>定<span class="_ _32"> </span>横<span class="_ _32"></span>轴<span class="_ _32"></span>纵<span class="_ _4c"></span>轴<span class="_ _32"> </span>的<span class="_ _32"></span>范<span class="_ _32"></span>围</span></div><div class="t m0 x3 h2d y1ef ff1d fs2 fc0 sc0 ls0 ws0">plt.xlim(xx.min(),xx.max())</div><div class="t m0 x3 h2d y380 ff1d fs2 fc0 sc0 ls0 ws0">plt.ylim(yy.min(),yy.max())</div><div class="t m0 x3 h6 y381 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">设<span class="_ _4c"></span>定<span class="_ _32"> </span>图<span class="_ _32"></span>题</span></div><div class="t m0 x3 h2d y382 ff1d fs2 fc0 sc0 ls0 ws0">plt.title(&apos;Classiﬁ er: GaussianNB&apos;)</div><div class="t m0 x3 h6 y383 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">画<span class="_ _4c"></span>出<span class="_ _32"> </span>图<span class="_ _32"></span>形</span></div><div class="t m0 x3 h2d y384 ff1d fs2 fc0 sc0 ls0 ws0">plt.show()</div><div class="t m0 x8d h6 y3b0 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">3.3:</span></div><div class="t m0 x3 h6 y3b1 ff1 fs2 fc0 sc0 ls0 ws0">最后使用多项式朴素贝叶斯</div><div class="t m0 x3 h2d y3b2 ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y3b3 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _20"> </span><span class="ff5">下<span class="_ _4c"></span>面<span class="_ _32"></span>这<span class="_ _4c"></span>段<span class="_ _32"></span>代<span class="_ _32"></span>码<span class="_ _32"></span>和<span class="_ _4c"></span>我<span class="_ _32"></span>们<span class="_ _32"></span>使<span class="_ _4c"></span>用<span class="_ _32"> </span>贝<span class="_ _32"></span>努<span class="_ _32"></span>利<span class="_ _4c"></span>朴<span class="_ _32"> </span>素<span class="_ _32"></span>贝<span class="_ _32"></span>叶<span class="_ _4c"></span>斯<span class="_ _32"> </span>或<span class="_ _32"></span>是<span class="_ _32"></span>高<span class="_ _4c"></span>斯<span class="_ _32"> </span>朴<span class="_ _32"></span>素<span class="_ _32"></span>贝<span class="_ _4c"></span>叶<span class="_ _32"></span>斯<span class="_ _32"></span>看<span class="_ _32"></span>起<span class="_ _4c"></span>来<span class="_ _32"></span>没<span class="_ _32"></span>有<span class="_ _4c"></span>什<span class="_ _32"> </span>么<span class="_ _32"></span>区<span class="_ _32"></span>别<span class="_ _4c"></span>，</span></div><div class="t m0 x3 h6 y3b4 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _20"> </span><span class="ff5">但<span class="_ _4c"></span>是<span class="_ _32"></span>这<span class="_ _4c"></span>样<span class="_ _32"></span>使<span class="_ _32"></span>用<span class="_ _32"></span>多<span class="_ _4c"></span>项<span class="_ _32"></span>式<span class="_ _32"></span>朴<span class="_ _4c"></span>素<span class="_ _32"> </span>贝<span class="_ _32"></span>叶<span class="_ _32"></span>斯<span class="_ _4c"></span>是<span class="_ _32"> </span>错<span class="_ _32"></span>误<span class="_ _32"></span>的<span class="_ _4c"></span>。</span></div><div class="t m0 x3 h6 y3b5 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _20"> </span><span class="ff5">提<span class="_ _4c"></span>示<span class="_ _32"></span>信<span class="_ _4c"></span>息<span class="_ _32"></span>告<span class="_ _32"></span>诉<span class="_ _32"></span>我<span class="_ _4c"></span>们<span class="_ _32"></span>，<span class="_ _32"></span>输<span class="_ _4c"></span>入<span class="_ _32"> </span>的<span class="_ _20"> </span></span>X<span class="_ _4d"> </span><span class="ff5">值<span class="_ _4c"></span>必<span class="_ _32"> </span>须<span class="_ _32"></span>是<span class="_ _32"></span>非<span class="_ _4c"></span>负<span class="_ _32"> </span>的<span class="_ _32"></span>，<span class="_ _32"></span>这<span class="_ _4c"></span>样<span class="_ _32"> </span>的<span class="_ _32"></span>话<span class="_ _32"></span>，<span class="_ _4c"></span>我<span class="_ _32"> </span>们<span class="_ _32"></span>需<span class="_ _32"></span>要<span class="_ _4c"></span>对<span class="_ _32"></span>数<span class="_ _32"></span>据<span class="_ _32"></span>进<span class="_ _4c"></span>行<span class="_ _32"></span>一<span class="_ _32"></span>下<span class="_ _4c"></span>预<span class="_ _32"> </span>处<span class="_ _32"></span>理<span class="_ _32"></span>才<span class="_ _4c"></span>行<span class="_ _32"> </span>。</span></div><div class="t m0 x3 h2d y3b6 ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y393 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">导<span class="_ _4c"></span>入<span class="_ _32"> </span>多<span class="_ _32"></span>项<span class="_ _32"></span>式<span class="_ _4c"></span>朴<span class="_ _32"> </span>素<span class="_ _32"></span>贝<span class="_ _32"></span>叶<span class="_ _4c"></span>斯</span></div><div class="t m0 x3 h2d y394 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.naive_bayes import MultinomialNB</div><div class="t m0 x3 h6 y3b7 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">用<span class="_ _4c"></span>多<span class="_ _32"> </span>项<span class="_ _32"></span>式<span class="_ _32"></span>朴<span class="_ _4c"></span>素<span class="_ _32"> </span>贝<span class="_ _32"></span>叶<span class="_ _32"></span>斯<span class="_ _4c"></span>拟<span class="_ _32"> </span>合<span class="_ _32"></span>数<span class="_ _32"></span>据</span></div><div class="t m0 x3 h2d y395 ff1d fs2 fc0 sc0 ls0 ws0">mnb = MultinomialNB()</div><div class="t m0 x3 h2d y396 ff1d fs2 fc0 sc0 ls0 ws0">mnb.ﬁt(X_train, y_train)</div><div class="t m0 x3 h2d y397 ff1d fs2 fc0 sc0 ls0 ws0">mnb.score(X_test, y_test)</div><div class="t m0 x3 h2d y39a ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y3aa ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff5">非<span class="_ _32"></span>负<span class="_ _4c"></span>处<span class="_ _32"> </span>理</span></div><div class="t m0 x3 h2d y39b ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y39c ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">导<span class="_ _4c"></span>入<span class="_ _32"> </span>多<span class="_ _32"></span>项<span class="_ _32"></span>式<span class="_ _4c"></span>朴<span class="_ _32"> </span>素<span class="_ _32"></span>贝<span class="_ _32"></span>叶<span class="_ _4c"></span>斯</span></div><div class="t m0 x3 h2d y39d ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.naive_bayes import MultinomialNB</div><div class="t m0 x3 h6 y39e ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">导<span class="_ _4c"></span>入<span class="_ _32"> </span>数<span class="_ _32"></span>据<span class="_ _32"></span>预<span class="_ _4c"></span>处<span class="_ _32"> </span>理<span class="_ _32"></span>工<span class="_ _32"></span>具<span class="_ _1f"></span></span>MinMaxScaler</div><div class="t m0 x3 h2d y3ac ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.preprocessing import MinMaxScaler</div><div class="t m0 x3 h6 y3ad ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">使<span class="_ _4c"></span>用<span class="_ _1f"></span></span>MinMaxScaler<span class="_ _1f"></span><span class="ff5">对<span class="_ _32"> </span>数<span class="_ _32"></span>据<span class="_ _32"></span>进<span class="_ _4c"></span>行<span class="_ _32"></span>预<span class="_ _32"></span>处<span class="_ _32"></span>理<span class="_ _4c"></span>，<span class="_ _32"></span>使<span class="_ _32"></span>数<span class="_ _4c"></span>据<span class="_ _32"> </span>全<span class="_ _32"></span>部<span class="_ _32"></span>为<span class="_ _4c"></span>非<span class="_ _32"> </span>负<span class="_ _32"></span>值</span></div><div class="t m0 x3 h2d y39f ff1d fs2 fc0 sc0 ls0 ws0">scaler = MinMaxScaler()</div><div class="t m0 x3 h2d y3a0 ff1d fs2 fc0 sc0 ls0 ws0">scaler.ﬁt(X_train)</div><div class="t m0 x3 h2d y3ae ff1d fs2 fc0 sc0 ls0 ws0">X_train_scaled = scaler.transform(X_train)</div><div class="t m0 x3 h2d y3a1 ff1d fs2 fc0 sc0 ls0 ws0">X_test_scaled = scaler.transform(X_test)</div><div class="t m0 x3 h6 y3a2 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">使<span class="_ _4c"></span>用<span class="_ _32"> </span>多<span class="_ _32"></span>项<span class="_ _32"></span>式<span class="_ _4c"></span>朴<span class="_ _32"> </span>素<span class="_ _32"></span>贝<span class="_ _32"></span>叶<span class="_ _4c"></span>斯<span class="_ _32"> </span>拟<span class="_ _32"></span>合<span class="_ _32"></span>经<span class="_ _4c"></span>过<span class="_ _32"></span>预<span class="_ _32"></span>处<span class="_ _32"></span>理<span class="_ _4c"></span>之<span class="_ _32"></span>后<span class="_ _32"></span>的<span class="_ _32"></span>数<span class="_ _4c"></span>据</span></div><div class="t m0 x3 h2d y3a3 ff1d fs2 fc0 sc0 ls0 ws0">mnb = MultinomialNB()</div><div class="t m0 x3 h2d y1c6 ff1d fs2 fc0 sc0 ls0 ws0">mnb.ﬁt(X_train_scaled, y_train)</div><div class="t m0 x3 h2d y111 ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n\n\n&apos;)</div><div class="t m0 x3 h6 y1d ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;<span class="_ _1f"></span><span class="ff5">代<span class="_ _4c"></span>码<span class="_ _32"> </span>运<span class="_ _32"></span>行<span class="_ _32"></span>结<span class="_ _4c"></span>果<span class="_ _32"> </span>：<span class="_ _1f"></span></span>&apos;)</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">27</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf21" class="pf w0 h0" data-page-no="21"><div class="pc pc21 w0 h0"><img class="bi xd1 y3b8 wc h2f" alt="" src="bg21.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">3.4<span class="_ _15"> </span>PYTHON<span class="_ _27"> </span><span class="ff8">示例</span></div><div class="t m0 x3 h2d y1f ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;==============================\n&apos;)</div><div class="t m0 x3 h6 y1ef ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">打<span class="_ _4c"></span>印<span class="_ _32"> </span>模<span class="_ _32"></span>型<span class="_ _32"></span>得<span class="_ _4c"></span>分</span></div><div class="t m0 x3 h6 y380 ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;<span class="_ _1f"></span><span class="ff5">模<span class="_ _4c"></span>型<span class="_ _32"> </span>得<span class="_ _32"></span>分<span class="_ _32"></span>：<span class="_ _1f"></span></span>{:.3f}&apos;.format(mnb.score(X_test_scaled, y_test)))</div><div class="t m0 x3 h2d y381 ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n==============================&apos;)</div><div class="t m0 x3 h2d y382 ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n\n\n&apos;)</div><div class="t m0 x3 h2d y385 ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y386 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff5">如<span class="_ _32"></span>果<span class="_ _4c"></span>我<span class="_ _32"> </span>们<span class="_ _32"></span>用<span class="_ _32"></span>图<span class="_ _4c"></span>形<span class="_ _32"> </span>来<span class="_ _32"></span>表<span class="_ _32"></span>示<span class="_ _4c"></span>的<span class="_ _32"></span>话<span class="_ _32"></span>，<span class="_ _32"></span>也<span class="_ _4c"></span>可<span class="_ _32"></span>以<span class="_ _32"></span>直<span class="_ _4c"></span>观<span class="_ _32"> </span>地<span class="_ _32"></span>看<span class="_ _32"></span>出<span class="_ _4c"></span>多<span class="_ _32"> </span>项<span class="_ _32"></span>式<span class="_ _32"></span>朴<span class="_ _4c"></span>素<span class="_ _32"> </span>贝<span class="_ _32"></span>叶<span class="_ _32"></span>斯<span class="_ _4c"></span>并<span class="_ _32"> </span>不<span class="_ _32"></span>适<span class="_ _32"></span>合<span class="_ _4c"></span>用<span class="_ _32"></span>来<span class="_ _32"></span>拟<span class="_ _32"></span>合<span class="_ _4c"></span>这<span class="_ _32"></span>个<span class="_ _32"></span>数<span class="_ _4c"></span>据<span class="_ _32"> </span>集</span></div><div class="t m0 x3 h2d y3a5 ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y388 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">用<span class="_ _4c"></span>不<span class="_ _32"> </span>同<span class="_ _32"></span>颜<span class="_ _32"></span>色<span class="_ _4c"></span>区<span class="_ _32"> </span>分<span class="_ _32"></span>不<span class="_ _32"></span>同<span class="_ _4c"></span>的<span class="_ _32"> </span>分<span class="_ _32"></span>类</span></div><div class="t m0 x3 h2d y389 ff1d fs2 fc0 sc0 ls0 ws0">z = mnb.predict(np.c_[(xx.ravel(),yy.ravel())]).reshape(xx.shape)</div><div class="t m0 x3 h2d y3a6 ff1d fs2 fc0 sc0 ls0 ws0">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</div><div class="t m0 x3 h6 y38a ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">用<span class="_ _4c"></span>散<span class="_ _32"> </span>点<span class="_ _32"></span>图<span class="_ _32"></span>表<span class="_ _4c"></span>示<span class="_ _32"> </span>训<span class="_ _32"></span>练<span class="_ _32"></span>集<span class="_ _4c"></span>和<span class="_ _32"> </span>测<span class="_ _32"></span>试<span class="_ _32"></span>集</span></div><div class="t m0 x3 h2d y3a7 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap=plt.cm.cool,edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h2d y38b ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_test[:,0],X_test[:,1],c=y_test,cmap=plt.cm.cool,marker=&apos;*&apos;,</div><div class="t m0 x3 h2d y3b9 ff1d fs2 fc0 sc0 ls0 ws0">edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h6 y38c ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">设<span class="_ _4c"></span>定<span class="_ _32"> </span>横<span class="_ _32"></span>纵<span class="_ _32"></span>轴<span class="_ _4c"></span>范<span class="_ _32"> </span>围</span></div><div class="t m0 x3 h2d y38d ff1d fs2 fc0 sc0 ls0 ws0">plt.xlim(xx.min(),xx.max())</div><div class="t m0 x3 h2d y38e ff1d fs2 fc0 sc0 ls0 ws0">plt.ylim(yy.min(),yy.max())</div><div class="t m0 x3 h6 y38f ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">设<span class="_ _4c"></span>定<span class="_ _32"> </span>图<span class="_ _32"></span>题</span></div><div class="t m0 x3 h2d y390 ff1d fs2 fc0 sc0 ls0 ws0">plt.title(&apos;Classiﬁ er: MultinomialNB&apos;)</div><div class="t m0 x3 h6 y3ba ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1f"></span><span class="ff5">显<span class="_ _4c"></span>示<span class="_ _32"> </span>图<span class="_ _32"></span>片</span></div><div class="t m0 x3 h2d y3bb ff1d fs2 fc0 sc0 ls0 ws0">plt.show()</div><div class="t m0 x8d h6 y3bc ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">3.4:</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">28</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf22" class="pf w0 h0" data-page-no="22"><div class="pc pc22 w0 h0"><div class="t m0 x45 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第四章 决策树</div><div class="t m0 x46 h4 y3bd ff3 fs2 fc0 sc0 ls0 ws0">Ent<span class="ffb">(<span class="ffa">D<span class="_ _f"></span></span>)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="fff">−</span></span></div><div class="t m0 x147 ha y3be ff12 fs6 fc0 sc0 ls0 ws0">|Y<span class="_ _1f"></span>|</div><div class="t m0 x104 he y3bf ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x104 ha y3c0 ffd fs6 fc0 sc0 ls0 ws0">k<span class="ffc">=1</span></div><div class="t m0 x13e hc y3bd ffa fs2 fc0 sc0 ls0 ws0">p</div><div class="t m0 xaf hb y3c1 ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 xd6 h4 y3bd ff3 fs2 fc0 sc0 ls0 ws0">log</div><div class="t m0 x62 ha y3c2 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x63 hc y3bd ffa fs2 fc0 sc0 ls0 ws0">p</div><div class="t m0 xf7 hb y3c1 ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">29</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf23" class="pf w0 h0" data-page-no="23"><div class="pc pc23 w0 h0"><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">30</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf24" class="pf w0 h0" data-page-no="24"><div class="pc pc24 w0 h0"><div class="t m0 x8 h5 y44 ff4 fs3 fc0 sc0 ls0 ws0">第三部分</div><div class="t m0 x9 h5 y45 ff4 fs3 fc0 sc0 ls0 ws0">机器学习高阶</div><div class="t m0 x0 h1 y46 ff5 fs0 fc0 sc0 ls0 ws0">优化方法</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">31</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf25" class="pf w0 h0" data-page-no="25"><div class="pc pc25 w0 h0"></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf26" class="pf w0 h0" data-page-no="26"><div class="pc pc26 w0 h0"><img class="bi xc3 y3c3 w8 h30" alt="" src="bg26.png"/><div class="t m0 x97 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第五章 梯度下降</div><div class="t m0 x1d h9 y48 ff6 fs5 fc0 sc0 ls0 ws0">5.1<span class="_ _21"> </span><span class="ff9">梯度下降原理</span></div><div class="t m0 x44 h4 y3c4 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>θ<span class="_ _f"></span><span class="ffb">)<span class="_ _2c"> </span><span class="fff">≈<span class="_ _2c"> </span></span></span>f<span class="_ _32"> </span><span class="ffb">(</span>θ</div><div class="t m0 xa6 ha y3c5 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xfa h4 y3c4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span>+<span class="_ _25"> </span>(<span class="ff11">θ<span class="_ _25"> </span><span class="fff">−<span class="_ _25"> </span></span>θ</span></div><div class="t m0 xaf ha y3c5 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xbf h4 y3c4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">·<span class="_ _25"> </span><span class="ff1f">∇<span class="ff11">f<span class="_ _32"></span><span class="ff20">(</span>θ</span></span></span></div><div class="t m0 x28 ha y3c5 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x14e h4 y3c4 ff20 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h4 y3c6 ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _25"> </span><span class="fff">−<span class="_ _33"> </span></span>θ</div><div class="t m0 x114 ha y3c7 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x109 h6 y3c6 ff1 fs2 fc0 sc0 ls0 ws0">是微小向量，它的大小就是步进长度，<span class="_ _2f"></span>即学习率<span class="_ _c"> </span><span class="ffa">α</span>，<span class="ffa">α<span class="_ _c"> </span></span>是一个标量，而<span class="_ _27"> </span><span class="ff11">θ<span class="_ _2c"> </span><span class="fff">−<span class="_ _33"></span></span>θ</span></div><div class="t m0 xe ha y3c7 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x14f h6 y3c6 ff1 fs2 fc0 sc0 ls0 ws0">的单位向</div><div class="t m0 x3 h6 y3c8 ff1 fs2 fc0 sc0 ls0 ws0">量用<span class="_ _c"> </span><span class="ff11">v<span class="_ _0"> </span></span>表示，因此<span class="_ _c"> </span><span class="ff11">θ<span class="_ _2c"> </span><span class="fff">−<span class="_ _33"> </span></span>θ</span></div><div class="t m0 xe8 ha y3c9 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xa7 h6 y3c8 ff1 fs2 fc0 sc0 ls0 ws0">可表示为：</div><div class="t m0 x49 h4 y3ca ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _25"> </span><span class="fff">−<span class="_ _25"> </span></span>θ</div><div class="t m0 x5b ha y3cb ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xfc h4 y3ca ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">α<span class="ff11">v</span></span></div><div class="t m0 x3 h6 y3cc ff1 fs2 fc0 sc0 ls0 ws0">特别需要注意的是，<span class="_ _22"></span><span class="ff11">θ<span class="_ _33"> </span><span class="fff">−<span class="_ _2d"></span></span>θ</span></div><div class="t m0 x38 ha y3cd ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xd2 h6 y3cc ff1 fs2 fc0 sc0 ls0 ws0">不能太大，<span class="_ _22"></span>因为太大的话，<span class="_ _22"></span>线性近似就不够准确，<span class="_ _22"></span>一阶泰勒近似也不</div><div class="t m0 x3 h6 y3ce ff1 fs2 fc0 sc0 ls0 ws0">成立了，替换之后，<span class="ffa">f<span class="_ _32"></span><span class="ffb">(</span>θ<span class="_ _f"></span><span class="ffb">)<span class="_ _c"> </span></span></span>的表达式为：</div><div class="t m0 x1d h4 y3cf ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>θ<span class="_ _f"></span><span class="ffb">)<span class="_ _2c"> </span><span class="fff">≈<span class="_ _2c"> </span></span></span>f<span class="_ _32"> </span><span class="ffb">(</span>θ</div><div class="t m0 x1 ha y3d0 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xf9 h4 y3cf ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span>+<span class="_ _25"> </span><span class="ffa">α<span class="ff11">v<span class="_ _25"> </span><span class="fff">·<span class="_ _25"> </span><span class="ff1f">∇</span></span>f<span class="_ _32"> </span><span class="ff20">(</span>θ</span></span></div><div class="t m0 xf7 ha y3d0 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x27 h4 y3cf ff20 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y3d1 ff1 fs2 fc0 sc0 ls0 ws0">局部<span class="_ _f"></span>下<span class="_ _f"></span>降<span class="_ _f"></span>的<span class="_ _f"></span>目的<span class="_ _f"></span>是<span class="_ _f"></span>希<span class="_ _f"></span>望<span class="_ _f"></span>每次<span class="_ _2e"> </span><span class="ffa">θ<span class="_ _1c"> </span></span>更<span class="_ _f"></span>新，<span class="_ _f"></span>都<span class="_ _f"></span>能<span class="_ _f"></span>让函<span class="_ _f"></span>数<span class="_ _f"></span>值<span class="_ _1c"> </span><span class="ffa">f<span class="_ _32"> </span><span class="ffb">(</span>θ<span class="_ _f"></span><span class="ffb">)<span class="_ _1c"> </span></span></span>变<span class="_ _f"></span>小。<span class="_ _f"></span>也<span class="_ _f"></span>就<span class="_ _f"></span>是说，<span class="_ _f"></span>上<span class="_ _f"></span>式<span class="_ _f"></span>中，<span class="_ _f"></span>我们<span class="_ _f"></span>希<span class="_ _f"></span>望</div><div class="t m0 x3 h4 y3d2 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>θ<span class="_ _f"></span><span class="ffb">)<span class="_ _2c"> </span><span class="fff">≤<span class="_ _2c"> </span></span></span>f<span class="_ _32"> </span><span class="ffb">(</span>θ</div><div class="t m0 x67 ha y3d3 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xd9 h6 y3d2 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">。则有：</span></div><div class="t m0 x39 h4 y3d4 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(</span>θ<span class="_ _f"></span><span class="ffb">)<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span></span></span>f<span class="_ _32"></span><span class="ffb">(</span>θ</div><div class="t m0 x150 ha y3d5 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xbc h4 y3d4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff">≈<span class="_ _2c"> </span><span class="ffa">α<span class="ff11">v<span class="_ _2c"> </span></span></span>·<span class="_ _33"> </span>∇<span class="ff11">f<span class="_ _2b"> </span><span class="ff20">(</span>θ</span></span></div><div class="t m0 x143 ha y3d5 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x110 h4 y3d4 ff20 fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff">≤<span class="_ _2c"> </span><span class="ffb">0</span></span></div><div class="t m0 x3 h6 y3d6 ff1 fs2 fc0 sc0 ls0 ws0">因为<span class="_ _c"> </span><span class="ffa">α<span class="_ _c"> </span></span>为标量，且一般设定为正值，所以可以忽略，不等式变成了：</div><div class="t m0 x0 h4 y3d7 ff11 fs2 fc0 sc0 ls0 ws0">v<span class="_ _25"> </span><span class="fff">·<span class="_ _25"> </span>∇<span class="ffa">f<span class="_ _32"></span><span class="ffb">(</span>θ</span></span></div><div class="t m0 x132 ha y3d8 ffc fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x91 h4 y3d7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff">≤<span class="_ _2c"> </span></span>0</div><div class="t m0 x3 h6 y3d9 ff1 fs2 fc0 sc0 ls0 ws0">上面这个不等式非常重要！<span class="_ _31"></span><span class="ff11">v<span class="_ _c"> </span><span class="ff1">和<span class="_ _c"> </span><span class="ff1f">∇</span></span>f<span class="_ _32"></span><span class="ff20">(</span>θ</span></div><div class="t m0 x10f ha y3da ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xa8 h6 y3d9 ff20 fs2 fc0 sc0 ls0 ws0">)<span class="_ _27"> </span><span class="ff1">都是向量，<span class="_ _22"></span><span class="ff1f">∇<span class="ff11">f<span class="_ _32"> </span><span class="ff20">(</span>θ</span></span></span></div><div class="t m0 x151 ha y3da ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x50 h6 y3d9 ff20 fs2 fc0 sc0 ls0 ws0">)<span class="_ _27"> </span><span class="ff1">是当前位置的梯度方向，<span class="_ _22"></span><span class="ff11">v<span class="_ _0"> </span><span class="ff1">表示下</span></span></span></div><div class="t m0 x3 h6 y3db ff1 fs2 fc0 sc0 ls0 ws0">一步前进的单位向量，是需要我们求解的，有了它，就能根据<span class="_ _c"> </span><span class="ff11">θ<span class="_ _25"> </span><span class="fff">−<span class="_ _25"> </span></span>θ</span></div><div class="t m0 xa4 ha y3dc ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x2b h6 y3db ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">α<span class="ff11">v<span class="_ _11"> </span><span class="ff1">来确定<span class="_ _c"> </span></span>θ<span class="_ _0"> </span><span class="ff1">的值了。</span></span></span></div><div class="t m0 x3 h6 y3dd ff1 fs2 fc0 sc0 ls0 ws0">想要两个向量的乘积小于零，我们先来看一下两个向量乘积包含哪几种情况：</div><div class="t m0 x3 h6 y3de ff1 fs2 fc0 sc0 ls0 ws0">上图中，<span class="ff11">A<span class="_ _c"> </span></span>和<span class="_ _c"> </span><span class="ff11">B<span class="_ _11"> </span></span>均为向量，<span class="ffa">α<span class="_ _c"> </span></span>为两个向量之间的夹角。<span class="ff11">A<span class="_ _c"> </span></span>和<span class="_ _c"> </span><span class="ff11">B<span class="_ _11"> </span></span>的乘积为：</div><div class="t m0 x14a h4 y3df ff11 fs2 fc0 sc0 ls0 ws0">A<span class="_ _33"> </span><span class="fff">·<span class="_ _25"> </span></span>B<span class="_ _c"> </span><span class="ffb">=<span class="_ _2c"> </span><span class="fff">||</span></span>A<span class="fff">||<span class="_ _33"> </span>·<span class="_ _25"> </span>||</span>B<span class="_ _1f"></span><span class="fff">||<span class="_ _33"> </span>·<span class="_ _25"> </span><span class="ffa">cos<span class="ffb">(</span>α<span class="ffb">)</span></span></span></div><div class="t m0 x3 h6 y3e0 fff fs2 fc0 sc0 ls0 ws0">||<span class="ff11">A</span>||<span class="_ _c"> </span><span class="ff1">和<span class="_ _0"> </span></span>||<span class="ff11">B<span class="_ _1f"></span></span>||<span class="_ _0"> </span><span class="ff1">均为标量，<span class="_ _f"></span>在<span class="_ _0"> </span></span>||<span class="ff11">A</span>||<span class="_ _c"> </span><span class="ff1">和<span class="_ _0"> </span></span>||<span class="ff11">B<span class="_ _1f"></span></span>||<span class="_ _0"> </span><span class="ff1">确定的情<span class="_ _f"></span>况下，只要<span class="_ _0"> </span><span class="ffa">cos<span class="ffb">(</span>α<span class="ffb">)<span class="_ _c"> </span>=<span class="_ _27"> </span></span></span></span>−<span class="ffb">1<span class="ff1">，即<span class="_ _0"> </span><span class="ff11">A<span class="_ _0"> </span></span>和<span class="_ _0"> </span><span class="ff11">B<span class="_ _11"> </span></span>完<span class="_ _f"></span>全</span></span></div><div class="t m0 x3 h6 y3e1 ff1 fs2 fc0 sc0 ls0 ws0">相反，就能让<span class="_ _c"> </span><span class="ff11">A<span class="_ _c"> </span></span>和<span class="_ _c"> </span><span class="ff11">B<span class="_ _11"> </span></span>的向量乘积最小（负最大值）<span class="_ _23"></span>。</div><div class="t m0 x3 h6 y3e2 ff1 fs2 fc0 sc0 ls0 ws0">顾名思义，<span class="_ _35"></span>当<span class="_ _2c"> </span><span class="ff11">v<span class="_ _c"> </span></span>和<span class="_ _2c"> </span><span class="ff1f">∇<span class="ff11">f<span class="_ _32"> </span><span class="ff20">(</span>θ</span></span></div><div class="t m0 x18 ha y3e3 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xc h6 y3e2 ff20 fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="ff1">互为反向，<span class="_ _2a"></span>即当<span class="_ _25"> </span><span class="ff11">v<span class="_ _c"> </span></span>为当前梯度方向的负方向的时候，<span class="_ _35"></span>能让<span class="_ _2c"> </span><span class="ff11">v<span class="_ _2d"> </span><span class="fff">·<span class="_ _32"></span><span class="ff1f">∇</span></span>f<span class="_ _32"> </span><span class="ff20">(</span>θ</span></span></div><div class="t m0 xb3 ha y3e3 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x79 h4 y3e2 ff20 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y3e4 ff1 fs2 fc0 sc0 ls0 ws0">最大程度地小，也就保证了<span class="_ _c"> </span><span class="ff11">v<span class="_ _0"> </span></span>的方向是局部下降最快的方向。</div><div class="t m0 x3 h6 y3e5 ff1 fs2 fc0 sc0 ls0 ws0">知道了<span class="_ _c"> </span><span class="ff11">v<span class="_ _0"> </span></span>是<span class="_ _c"> </span><span class="ff1f">∇<span class="ff11">f<span class="_ _32"> </span><span class="ff20">(</span>θ</span></span></div><div class="t m0 xc7 ha y3e6 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xf3 h6 y3e5 ff20 fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">的反方向后，可直接得到：</span></div><div class="t m0 x8 h4 y3e7 ff11 fs2 fc0 sc0 ls0 ws0">v<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span><span class="fff">−</span></span></div><div class="t m0 x9f h4 y3e8 ff1f fs2 fc0 sc0 ls0 ws0">∇<span class="ff11">f<span class="_ _32"></span><span class="ff20">(</span>θ</span></div><div class="t m0 x26 ha y3e9 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xd6 h4 y3e8 ff20 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xa3 h4 y3ea fff fs2 fc0 sc0 ls0 ws0">||<span class="ff1f">∇<span class="ff11">f<span class="_ _32"></span><span class="ff20">(</span>θ</span></span></div><div class="t m0 x26 ha y3eb ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xd6 h4 y3ea ff20 fs2 fc0 sc0 ls0 ws0">)<span class="fff">||</span></div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">33</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf27" class="pf w0 h0" data-page-no="27"><div class="pc pc27 w0 h0"><img class="bi x5c y3ec wd h31" alt="" src="bg27.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">5.1<span class="_ _15"> </span><span class="ff8">梯度下降原理</span></div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">之所以要除以<span class="_ _c"> </span><span class="ff1f">∇<span class="ff11">f<span class="_ _32"></span><span class="ff20">(</span>θ</span></span></div><div class="t m0 xc1 ha y2c3 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x6d h6 y1f ff20 fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">的模<span class="_ _c"> </span><span class="fff">||<span class="ff1f">∇<span class="ff11">f<span class="_ _32"></span></span></span></span></span>(<span class="ff11">θ</span></div><div class="t m0 x87 ha y2c3 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x48 h6 y1f ff20 fs2 fc0 sc0 ls0 ws0">)<span class="fff">||<span class="ff1">，是因为<span class="_ _c"> </span><span class="ff11">v<span class="_ _0"> </span></span>是单位向量。</span></span></div><div class="t m0 x3 h6 y3c ff1 fs2 fc0 sc0 ls0 ws0">求出最优解<span class="_ _c"> </span><span class="ff11">v<span class="_ _0"> </span></span>之后，带入到<span class="_ _c"> </span><span class="ff11">θ<span class="_ _2c"> </span><span class="fff">−<span class="_ _33"> </span></span>θ</span></div><div class="t m0 xf6 ha y3ed ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x87 h6 y3c ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">α<span class="ff11">v<span class="_ _11"> </span><span class="ff1">中，得：</span></span></span></div><div class="t m0 xa9 h4 y3ee ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span></span>θ</div><div class="t m0 x150 ha y3ef ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x21 h4 y3ee fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">α</span></div><div class="t m0 x138 h4 y3f0 ff1f fs2 fc0 sc0 ls0 ws0">∇<span class="ff11">f<span class="_ _32"></span><span class="ff20">(</span>θ</span></div><div class="t m0 xc0 ha y3f1 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x152 h4 y3f0 ff20 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x24 h4 y263 fff fs2 fc0 sc0 ls0 ws0">||<span class="ff1f">∇<span class="ff11">f<span class="_ _32"></span><span class="ff20">(</span>θ</span></span></div><div class="t m0 xc0 ha y3f2 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x152 h4 y263 ff20 fs2 fc0 sc0 ls0 ws0">)<span class="fff">||</span></div><div class="t m0 x3 h6 y3f3 ff1 fs2 fc0 sc0 ls0 ws0">一般的，因为<span class="_ _c"> </span><span class="fff">||<span class="ff1f">∇<span class="ff11">f<span class="_ _32"></span><span class="ff20">(</span>θ</span></span></span></div><div class="t m0 x113 ha y3f4 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x153 h6 y3f3 ff20 fs2 fc0 sc0 ls0 ws0">)<span class="fff">||<span class="_ _c"> </span><span class="ff1">是标量，可以并入到学习率<span class="_ _c"> </span><span class="ffa">α<span class="_ _c"> </span></span>中，即简化为：</span></span></div><div class="t m0 x47 h4 y3f5 ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span></span>θ</div><div class="t m0 x21 ha y3f6 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xa3 h4 y3f5 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">α<span class="ff1f">∇<span class="ff11">f<span class="_ _2b"> </span><span class="ff20">(</span>θ</span></span></span></div><div class="t m0 xc0 ha y3f6 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x152 h4 y3f5 ff20 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y3f7 ff1 fs2 fc0 sc0 ls0 ws0">把<span class="_ _c"> </span><span class="ffa">f<span class="_ _32"></span><span class="ffb">(</span>θ<span class="_ _f"></span><span class="ffb">)<span class="_ _c"> </span></span></span>换为目标函数<span class="_ _c"> </span><span class="ffa">J<span class="_ _32"></span><span class="ffb">(</span>θ<span class="ffb">)</span></span>，就是我们上面的梯度下降公式了：</div><div class="t m0 x154 h4 y3f8 ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span></span>θ</div><div class="t m0 x46 ha y3f9 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 xa9 h4 y3f8 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">α<span class="ff1f">∇<span class="ff11">J<span class="_ _32"> </span><span class="ff20">(</span>θ</span></span></span></div><div class="t m0 x90 ha y3f9 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x104 h4 y3f8 ff20 fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="ffb">=<span class="_ _2c"> </span><span class="ff11">θ</span></span></div><div class="t m0 x26 ha y3f9 ff1e fs6 fc0 sc0 ls0 ws0">0</div><div class="t m0 x41 h4 y3f8 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">α<span class="_ _25"> </span></span>·</div><div class="t m0 x4f h4 y3fa ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>J<span class="_ _32"></span><span class="ffb">(</span>θ<span class="ffb">)</span></div><div class="t m0 x9d hc y3fb ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>θ</div><div class="t m0 x3 h6 y3fc ff1 fs2 fc4 sc0 ls0 ws0">梯度下降算法总结</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">34</div><a class="l" href="https://lumingdong.cn/summary-of-gradient-descent-algorithm.html"><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:899.832000px;width:87.273000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf28" class="pf w0 h0" data-page-no="28"><div class="pc pc28 w0 h0"><div class="t m0 x119 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第六章 <span class="ff6">Bac<span class="_ _2f"></span>kpropagation</span></div><div class="t m0 x106 h9 y48 ff6 fs5 fc0 sc0 ls0 ws0">6.1<span class="_ _21"> </span><span class="ff9">神经网络</span></div><div class="t m0 x3 h6 y3fd ff1 fs2 fc0 sc0 ls0 ws0">神经网络是按照一定规则连接起来的多个神经元。神经网络按照层级来布局神经元。</div><div class="t m0 x9a h6 y3fe ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">最左边的层叫做输入层（</span>input<span class="_ _c"> </span>la<span class="_ _10"></span>y<span class="_ _10"></span>er<span class="ff1">）<span class="_ _23"></span>，主要负责接收输入数据。</span></div><div class="t m0 x9a h6 y3ff ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">最右边的层叫输出层（</span>output<span class="_ _c"> </span>la<span class="_ _10"></span>y<span class="_ _10"></span>er<span class="ff1">）<span class="_ _23"></span>，可以从这一层获取神经网络输出数据。</span></div><div class="t m0 x9a h6 y400 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">输入层与输出层之间的层<span class="_ _f"></span>叫做隐藏层，可以包含多个<span class="_ _f"></span>隐藏层，之所以叫做隐藏层，<span class="_ _f"></span>是因为</span></div><div class="t m0 x9b h6 y401 ff1 fs2 fc0 sc0 ls0 ws0">它们对于外部来说是不可见的。</div><div class="t m0 x3 h6 y402 ff1 fs2 fc0 sc0 ls0 ws0">全连接神经网络的特征如下：</div><div class="t m0 x9a h6 y403 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _6"> </span><span class="ff1">位于同一层的各个神经元没有任何连接。</span></div><div class="t m0 x9a h6 y404 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _6"> </span><span class="ff1">位于第<span class="_ _c"> </span></span>N<span class="_ _27"> </span><span class="ff1">层的每个神经元都与第<span class="_ _c"> </span></span>N-1<span class="_ _c"> </span><span class="ff1">层的所有神经元相连，<span class="_ _2f"></span>也就是全连接<span class="_ _2f"></span>（<span class="ff3">F<span class="_ _31"></span>ull<span class="_ _c"> </span>Connec-</span></span></div><div class="t m0 x9b h6 y405 ff3 fs2 fc0 sc0 ls0 ws0">tion<span class="ff1">）<span class="_ _23"></span>，第<span class="_ _c"> </span><span class="ff3">N-1<span class="_ _c"> </span></span>层神经元的输出就是第<span class="_ _c"> </span><span class="ff3">N<span class="_ _c"> </span></span>层神经元的输入。</span></div><div class="t m0 x9a h6 y406 ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _6"> </span><span class="ff1">全连接的每个连接都有一个权值。</span></div><div class="t m0 x3 h6 y407 ff1 fs2 fc0 sc0 ls0 ws0">事实上还存在很多其它结构的神经网络，<span class="_ _10"></span>比如卷积神经网络<span class="_ _c"> </span><span class="ff3">(CNN)</span>、<span class="_ _10"></span>循环神经网络<span class="_ _c"> </span><span class="ff3">(RNN)</span>，<span class="_ _2f"></span>他</div><div class="t m0 x3 h6 y408 ff1 fs2 fc0 sc0 ls0 ws0">们都具有不同的连接规则。</div><div class="t m0 x106 h9 y409 ff6 fs5 fc0 sc0 ls0 ws0">6.2<span class="_ _21"> </span><span class="ff9">基本函数</span></div><div class="t m0 x3 h6 y40a ff1 fs2 fc0 sc0 ls0 ws0">推导<span class="_ _c"> </span><span class="ff3">BP<span class="_ _c"> </span></span>算法的过程中需要注意几个要点：</div><div class="t m0 x9a h6 y40b ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">网络函数</span></div><div class="t m0 x9a h6 y40c ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">激活函数：</span>sigmoid</div><div class="t m0 x9a h6 y40d ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">误差函数：平方误差</span></div><div class="t m0 x9a h6 y40e ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">优化方法：梯度下降，降低误差大的网络的权值，增加误差小的网络的权值。</span></div><div class="t m0 x3 h6 y40f ff1 fs2 fc0 sc0 ls0 ws0">下面先来介绍几个在神经网络反向传播算法的推导<span class="_ _c"> </span>过程中用到的几个函数：</div><div class="t m0 x3 h6 y410 ff7 fs2 fc0 sc0 ls0 ws0">1.Net<span class="_ _10"></span>w<span class="_ _10"></span>ork<span class="_ _11"> </span>function(<span class="ff4">网络函数</span>)</div><div class="t m0 x3 h4 y411 ff3 fs2 fc0 sc0 ls0 ws0">The netw<span class="_ _2f"></span>ork is<span class="_ _27"> </span>a particular<span class="_ _27"> </span>implementation of a comp<span class="_ _f"></span>osite<span class="_ _27"> </span>function from<span class="_ _27"> </span>input to<span class="_ _27"> </span>output<span class="_ _27"> </span>space,</div><div class="t m0 x3 h4 y412 ff3 fs2 fc0 sc0 ls0 ws0">whic<span class="_ _10"></span>h<span class="_ _c"> </span>w<span class="_ _10"></span>e<span class="_ _c"> </span>call<span class="_ _c"> </span>the<span class="_ _c"> </span>netw<span class="_ _2f"></span>ork<span class="_ _c"> </span>function.</div><div class="t m0 x87 h4 y413 ffa fs2 fc0 sc0 ls0 ws0">h<span class="ffb">(</span>x<span class="ffb">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span></span>w</div><div class="t m0 xa3 hb y414 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x9f h4 y413 ffa fs2 fc0 sc0 ls0 ws0">x<span class="_ _2c"> </span><span class="ffb">=</span></div><div class="t m0 xbe hb y415 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x4c he y416 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x13e ha y417 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 xab hc y413 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x152 hb y418 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x143 hc y413 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x110 hb y418 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x3 h6 y28a ff7 fs2 fc0 sc0 ls0 ws0">2.A<span class="_ _10"></span>ctiv<span class="_ _2f"></span>ation<span class="_ _0"> </span>function(<span class="ff4">激活函数</span>)</div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">这里使用的激活函数是<span class="_ _c"> </span><span class="ff3">Sigmoid<span class="_ _c"> </span></span>函数：</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">35</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf29" class="pf w0 h0" data-page-no="29"><div class="pc pc29 w0 h0"><img class="bi x3 y419 w2 h32" alt="" src="bg29.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">6.3<span class="_ _15"> </span><span class="ff8">前向传播</span></div><div class="t m0 x47 h4 y41a ffa fs2 fc0 sc0 ls0 ws0">y<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span></span>f<span class="_ _32"></span><span class="ffb">(</span>z<span class="_ _f"></span><span class="ffb">)<span class="_ _27"> </span>=</span></div><div class="t m0 x4d h4 y41b ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x91 h4 y41c ffb fs2 fc0 sc0 ls0 ws0">1<span class="_ _33"> </span>+<span class="_ _25"> </span><span class="ffa">e</span></div><div class="t m0 xab ha y41d ff12 fs6 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 x3 h4 y41e ff7 fs2 fc0 sc0 ls0 ws0">3.Error<span class="_ _11"> </span>function</div><div class="t m0 x75 h6 y41f ff4 fs2 fc0 sc0 ls0 ws0">（误差函数）</div><div class="t m0 x3 h6 y420 ff1 fs2 fc0 sc0 ls0 ws0">采用平方误差作为目标函数<span class="ff3">:</span></div><div class="t m0 x2 h4 y421 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _c"> </span><span class="ffb">=</span></div><div class="t m0 x4 h4 y422 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4 h4 y423 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8f hb y424 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x22 he y425 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf9 ha y426 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x132 h4 y421 ffb fs2 fc0 sc0 ls0 ws0">[<span class="ffa">t</span></div><div class="t m0 xa0 hb y427 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xaa h4 y421 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 xab hb y427 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x42 h4 y421 ffb fs2 fc0 sc0 ls0 ws0">]</div><div class="t m0 x142 ha y428 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x3 h6 y429 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _c"> </span><span class="ffa">t</span></div><div class="t m0 x155 hb y42a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13d h6 y429 ff1 fs2 fc0 sc0 ls0 ws0">为真实值，<span class="ffa">y</span></div><div class="t m0 x12a hb y42a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6d h6 y429 ff1 fs2 fc0 sc0 ls0 ws0">为计算值，等于<span class="_ _c"> </span><span class="ffa">y</span></div><div class="t m0 xa8 hb y42a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x20 h4 y429 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f<span class="_ _32"></span></span>(<span class="ffa">h</span>(<span class="ffa">x</span></div><div class="t m0 x138 hb y42a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x91 h6 y429 ffb fs2 fc0 sc0 ls0 ws0">))<span class="ff1">。下面对<span class="_ _c"> </span><span class="ff3">BP<span class="_ _c"> </span></span>算法的计算过程进行推导。</span></div><div class="t m0 x106 h9 y42b ff6 fs5 fc0 sc0 ls0 ws0">6.3<span class="_ _21"> </span><span class="ff9">前向传播</span></div><div class="t m0 x1f h6 y42c ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">6.1:<span class="_ _2e"> </span></span>神经网络示意图</div><div class="t m0 x3 h6 y42d ff1 fs2 fc0 sc0 ls0 ws0">上图展示的是一个经典的三层神经网络，<span class="_ _31"></span>包括输入层、<span class="_ _31"></span>隐藏层、<span class="_ _31"></span>输出层。<span class="_ _2f"></span>为了体现一般性，<span class="_ _31"></span>现在</div><div class="t m0 x3 h6 y42e ff1 fs2 fc0 sc0 ls0 ws0">用数学语言进行描述：</div><div class="t m0 x3 h6 y42f ff1 fs2 fc0 sc0 ls0 ws0">给定一个训练集<span class="_ _0"> </span><span class="fff">{<span class="ffb">(<span class="ffa">x</span></span></span></div><div class="t m0 x12a ha y430 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x12f hc y42f ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>t</div><div class="t m0 x153 ha y430 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xae h4 y42f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2d"> </span><span class="ffa">,<span class="_ _2d"> </span></span>(<span class="ffa">x</span></div><div class="t m0 xd ha y430 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x1a hc y42f ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>t</div><div class="t m0 x9e ha y430 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8c h4 y42f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2d"> </span><span class="ffa">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>.<span class="_ _2d"> </span>,<span class="_ _2d"> </span></span>(<span class="ffa">x</span></div><div class="t m0 x20 hb y430 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x150 hc y42f ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>t</div><div class="t m0 x8d hb y430 ffd fs6 fc0 sc0 ls0 ws0">n</div><div class="t m0 x22 h6 y42f ffb fs2 fc0 sc0 ls0 ws0">)<span class="fff">}<span class="ff1">，目标变量<span class="_ _0"> </span><span class="ffa">t</span></span></span></div><div class="t m0 x4f hb y430 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x9d h6 y42f ff1 fs2 fc0 sc0 ls0 ws0">的取值可以有多个，<span class="_ _f"></span>其中<span class="_ _c"> </span><span class="ffa">x</span></div><div class="t m0 x149 hb y430 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x32 h6 y42f ff1 fs2 fc0 sc0 ls0 ws0">是一</div><div class="t m0 x3 h6 y431 ff1 fs2 fc0 sc0 ls0 ws0">个<span class="_ _c"> </span><span class="ffa">m<span class="_ _0"> </span></span>维<span class="_ _f"></span>向量（对应<span class="_ _f"></span>输入层的<span class="_ _0"> </span><span class="ffa">m<span class="_ _0"> </span></span>个神经<span class="_ _f"></span>元）<span class="_ _24"></span>，表达式为<span class="_ _0"> </span><span class="ffa">x</span></div><div class="t m0 x62 hb y432 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x63 h4 y431 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _27"> </span>(<span class="ffa">x</span></div><div class="t m0 x156 ha y432 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">1</span></div><div class="t m0 xec hc y431 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>x</div><div class="t m0 x157 ha y432 ffd fs6 fc0 sc0 ls0 ws0">i<span class="ffc">2</span></div><div class="t m0 x8a h4 y431 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2b"> </span>x</div><div class="t m0 x56 hb y432 ffd fs6 fc0 sc0 ls0 ws0">im</div><div class="t m0 x158 h6 y431 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">。我们将输<span class="_ _f"></span>入层、</span></div><div class="t m0 x3 h6 y433 ff1 fs2 fc0 sc0 ls0 ws0">隐藏层、<span class="_ _2f"></span>输出层合并在一起，<span class="_ _31"></span>就形成了一个<span class="_ _c"> </span><span class="ff3">net<span class="_ _10"></span>work<span class="_ _10"></span><span class="ff1">。<span class="_ _2f"></span>在这个<span class="_ _c"> </span><span class="ff3">net<span class="_ _10"></span>w<span class="_ _10"></span>ork<span class="_ _c"> </span><span class="ff1">里，<span class="_ _31"></span>除输入层外，<span class="_ _2f"></span>其他层</span></span></span></span></div><div class="t m0 x3 h6 y434 ff1 fs2 fc0 sc0 ls0 ws0">上的每个神经元都是上一层神经元的全连接，<span class="_ _22"></span>不同的是全连接的权值不一样。<span class="_ _22"></span>现在，<span class="_ _28"></span>我们需要通</div><div class="t m0 x3 h6 y435 ff1 fs2 fc0 sc0 ls0 ws0">过训练，来求出各个神经元的权重值，也就是<span class="_ _c"> </span><span class="ffa">w<span class="_ _f"></span></span>。</div><div class="t m0 x3 h6 y436 ff1 fs2 fc0 sc0 ls0 ws0">那么现在的问题是，这些权值应该如何计算呢？</div><div class="t m0 x3 h6 y437 ff1 fs2 fc0 sc0 ls0 ws0">刚刚说到，<span class="_ _22"></span>除输入层外，<span class="_ _31"></span>其他层上的每个神经元都是上一层神经元的全连接<span class="ff3">,<span class="_ _27"> </span></span>比如隐藏层<span class="_ _c"> </span><span class="ffa">h</span></div><div class="t m0 x11 ha y438 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x159 h6 y437 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _22"></span>是</div><div class="t m0 x3 h6 y439 ff1 fs2 fc0 sc0 ls0 ws0">隐藏层的第一个神经元，它的输出值是输入层的全连接，即：</div><div class="t m0 xeb hc y43a ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x146 ha y43b ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xbc h4 y43a ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x7 he y43c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x147 h21 y43a ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y43d ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y43e ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd4 h4 y43a fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _33"> </span><span class="ff11">x</span></div><div class="t m0 x137 he y43c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y43a ff3 fs2 fc0 sc0 ls0 ws0">(6.1)</div><div class="t m0 x77 hc y43f ffa fs2 fc0 sc0 ls0 ws0">net</div><div class="t m0 xf5 ha y440 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xf5 ha y441 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa h4 y43f ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">w</span></div><div class="t m0 x8 ha y440 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8 ha y441 ffc fs6 fc0 sc0 ls0 ws0">11</div><div class="t m0 xb6 hc y43f ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x133 ha y442 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x21 h4 y43f ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x5c ha y440 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x104 ha y443 ffc fs6 fc0 sc0 ls0 ws0">12</div><div class="t m0 x5d hc y43f ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x15a ha y442 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x15b h4 y43f ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x152 ha y440 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x142 ha y443 ffc fs6 fc0 sc0 ls0 ws0">13</div><div class="t m0 x63 hc y43f ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf7 ha y442 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x13b h4 y43f ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x2a ha y440 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2a ha y443 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x32 h4 y43f ff3 fs2 fc0 sc0 ls0 ws0">(6.2)</div><div class="t m0 x1e h6 y444 ff1 fs2 fc0 sc0 ls0 ws0">行标表示当前层的第几个节点，列标表示上一层的第几个节点，<span class="_ _10"></span>上标表示当前是第几个隐</div><div class="t m0 x1e h6 y445 ff1 fs2 fc0 sc0 ls0 ws0">藏层</div><div class="t m0 x3 h6 y446 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _c"> </span><span class="ffa">f<span class="_ _2e"> </span></span>为<span class="_ _0"> </span><span class="ff3">sigmoid<span class="_ _c"> </span></span>函数，<span class="ff11">w</span></div><div class="t m0 xe9 ha y447 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe9 hb y448 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x77 h6 y446 ff1 fs2 fc0 sc0 ls0 ws0">表示隐藏层的第<span class="_ _c"> </span><span class="ffa">i<span class="_ _0"> </span></span>个节点与输入层的<span class="_ _f"></span>第<span class="_ _c"> </span><span class="ffa">j<span class="_ _1c"> </span></span>个节点的权重值，<span class="ffa">b</span></div><div class="t m0 x15c ha y447 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x15c hb y448 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb3 h6 y446 ff1 fs2 fc0 sc0 ls0 ws0">表</div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">示第<span class="_ _c"> </span><span class="ffa">i<span class="_ _c"> </span></span>个隐藏层全连接中的偏置，<span class="ffa">x</span></div><div class="t m0 x1f hb y97 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xea h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">为输入层的值，即样本的输入值。</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">36</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2a" class="pf w0 h0" data-page-no="2a"><div class="pc pc2a w0 h0"><img class="bi xb y449 w1 h33" alt="" src="bg2a.png"/><div class="t m0 x84 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">6.3<span class="_ _15"> </span><span class="ff8">前向传播</span></div><div class="t m0 x3c h6 y44a ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">6.2:<span class="_ _2e"> </span></span>前向传播</div><div class="t m0 x3 h6 y44b ff1 fs2 fc0 sc0 ls0 ws0">类似的，可以计算出<span class="_ _c"> </span><span class="ffa">h</span></div><div class="t m0 xe6 ha y44c ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x64 h6 y44b ff1 fs2 fc0 sc0 ls0 ws0">、<span class="ffa">h</span></div><div class="t m0 xd2 ha y44c ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x83 h6 y44b ff1 fs2 fc0 sc0 ls0 ws0">、<span class="ffa">h</span></div><div class="t m0 x9c ha y44c ffc fs6 fc0 sc0 ls0 ws0">4</div><div class="t m0 x15d h6 y44b ff1 fs2 fc0 sc0 ls0 ws0">：</div><div class="t m0 x154 hc y44d ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1b ha y44e ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9c h4 y44d ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x87 he y44f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x15e hc y44d ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x8 ha y450 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8 ha y451 ffc fs6 fc0 sc0 ls0 ws0">11</div><div class="t m0 xb6 hc y44d ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x150 ha y44e ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8e h4 y44d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x104 ha y450 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x104 ha y451 ffc fs6 fc0 sc0 ls0 ws0">12</div><div class="t m0 xb0 hc y44d ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb2 ha y44e ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbe h4 y44d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x142 ha y450 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x142 ha y451 ffc fs6 fc0 sc0 ls0 ws0">13</div><div class="t m0 x63 hc y44d ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf7 ha y44e ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x139 h4 y44d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x2a ha y450 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2a ha y451 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x144 he y44f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x154 hc y452 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1b ha y453 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x9c h4 y452 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x87 he y454 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x15e hc y452 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x8 ha y455 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8 ha y456 ffc fs6 fc0 sc0 ls0 ws0">21</div><div class="t m0 xb6 hc y452 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x150 ha y453 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8e h4 y452 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x104 ha y455 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x104 ha y456 ffc fs6 fc0 sc0 ls0 ws0">22</div><div class="t m0 xb0 hc y452 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb2 ha y453 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbe h4 y452 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x142 ha y455 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x142 ha y456 ffc fs6 fc0 sc0 ls0 ws0">23</div><div class="t m0 x63 hc y452 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf7 ha y453 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x139 h4 y452 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x2a ha y455 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2a ha y456 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x144 he y454 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x154 hc y457 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1b ha y458 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x9c h4 y457 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x87 he y459 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x15e hc y457 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x8 ha y45a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8 ha y45b ffc fs6 fc0 sc0 ls0 ws0">31</div><div class="t m0 xb6 hc y457 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x150 ha y458 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8e h4 y457 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x104 ha y45a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x104 ha y45b ffc fs6 fc0 sc0 ls0 ws0">32</div><div class="t m0 xb0 hc y457 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb2 ha y458 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbe h4 y457 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x142 ha y45a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x142 ha y45b ffc fs6 fc0 sc0 ls0 ws0">33</div><div class="t m0 x63 hc y457 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf7 ha y458 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x139 h4 y457 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x2a ha y45a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2a ha y45b ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x144 he y459 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x154 hc y45c ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1b ha y45d ffc fs6 fc0 sc0 ls0 ws0">4</div><div class="t m0 x9c h4 y45c ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x87 he y45e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x15e hc y45c ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x8 ha y45f ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8 ha y460 ffc fs6 fc0 sc0 ls0 ws0">41</div><div class="t m0 xb6 hc y45c ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x150 ha y45d ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8e h4 y45c ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x104 ha y45f ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x104 ha y460 ffc fs6 fc0 sc0 ls0 ws0">42</div><div class="t m0 xb0 hc y45c ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb2 ha y45d ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbe h4 y45c ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x142 ha y45f ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x142 ha y460 ffc fs6 fc0 sc0 ls0 ws0">43</div><div class="t m0 x63 hc y45c ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf7 ha y45d ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x139 h4 y45c ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x2a ha y45f ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2a ha y460 ffc fs6 fc0 sc0 ls0 ws0">4</div><div class="t m0 x144 he y45e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y461 ff3 fs2 fc0 sc0 ls0 ws0">(6.3)</div><div class="t m0 x3 h6 y462 ff1 fs2 fc0 sc0 ls0 ws0">因此，我们可以将隐藏层表示为如下通式：</div><div class="t m0 x46 h4 y463 ff11 fs2 fc0 sc0 ls0 ws0">h<span class="_ _2c"> </span><span class="ffb">=<span class="_ _2c"> </span><span class="ffa">f<span class="_ _32"> </span></span>(</span>net</div><div class="t m0 xa3 ha y464 ff1e fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9f h4 y463 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 xbe he y465 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xdf h21 y463 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x42 ha y464 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xc0 ha y466 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x62 h4 y463 fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _33"> </span><span class="ff11">x</span></div><div class="t m0 xf7 he y465 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y463 ff3 fs2 fc0 sc0 ls0 ws0">(6.4)</div><div class="t m0 x98 h21 y467 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x15f ha y468 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8c h4 y467 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x9 he y469 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 he y46a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 he y46b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 he y46c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 he y46d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x9 he y46e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xea h21 y46f ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3c ha y470 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3c ha y471 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xea h21 y472 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3c ha y473 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3c ha y474 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xea h21 y475 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3c ha y476 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3c ha y477 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xea h21 y478 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3c ha y479 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3c ha y47a ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 xea h21 y47b ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3c ha y47c ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3c ha y47d ffc fs6 fc0 sc0 ls0 ws0">4</div><div class="t m0 x146 he y469 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x146 he y46a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x146 he y46b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x146 he y46c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x146 he y46d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x146 he y46e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4 h4 y467 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x5a he y47e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a he y46b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a he y46c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a he y47f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xfc hc y480 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y481 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y482 ffc fs6 fc0 sc0 ls0 ws0">11</div><div class="t m0 x13a hc y480 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xab ha y481 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xab ha y482 ffc fs6 fc0 sc0 ls0 ws0">12</div><div class="t m0 xcc hc y480 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xe0 ha y481 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe0 ha y482 ffc fs6 fc0 sc0 ls0 ws0">13</div><div class="t m0 x13b hc y480 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>b</div><div class="t m0 xa1 ha y481 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa1 ha y482 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xfc hc y483 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y484 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y485 ffc fs6 fc0 sc0 ls0 ws0">21</div><div class="t m0 x13a hc y483 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xab ha y484 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xab ha y485 ffc fs6 fc0 sc0 ls0 ws0">22</div><div class="t m0 xcc hc y483 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xe0 ha y484 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe0 ha y485 ffc fs6 fc0 sc0 ls0 ws0">23</div><div class="t m0 x13b hc y483 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>b</div><div class="t m0 xa1 ha y484 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa1 ha y485 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xfc hc y486 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y487 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y488 ffc fs6 fc0 sc0 ls0 ws0">31</div><div class="t m0 x13a hc y486 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xab ha y487 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xab ha y488 ffc fs6 fc0 sc0 ls0 ws0">32</div><div class="t m0 xcc hc y486 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xe0 ha y487 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe0 ha y488 ffc fs6 fc0 sc0 ls0 ws0">33</div><div class="t m0 x13b hc y486 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>b</div><div class="t m0 xa1 ha y487 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa1 ha y488 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 xfc hc y489 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y48a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y48b ffc fs6 fc0 sc0 ls0 ws0">41</div><div class="t m0 x13a hc y489 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xab ha y48a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xab ha y48b ffc fs6 fc0 sc0 ls0 ws0">42</div><div class="t m0 xcc hc y489 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xe0 ha y48a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe0 ha y48b ffc fs6 fc0 sc0 ls0 ws0">43</div><div class="t m0 x13b hc y489 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>b</div><div class="t m0 xa1 ha y48a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa1 ha y48b ffc fs6 fc0 sc0 ls0 ws0">4</div><div class="t m0 x144 he y47e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x144 he y46b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x144 he y46c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x144 he y47f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y467 ff3 fs2 fc0 sc0 ls0 ws0">(6.5)</div><div class="t m0 x3 h6 y48c ff1 fs2 fc0 sc0 ls0 ws0">对于输出层，<span class="_ _31"></span>也是同样的计算方式，<span class="_ _22"></span>只不过对于输出层而言，<span class="_ _31"></span>它们的输入为隐藏层的输出，<span class="_ _31"></span>即<span class="_ _27"> </span><span class="ff11">h</span></div><div class="t m0 x3 h6 y48d ff1 fs2 fc0 sc0 ls0 ws0">，输出层的表达式为：</div><div class="t m0 x88 h4 y48e ff11 fs2 fc0 sc0 ls0 ws0">y<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span><span class="ffa">f</span></span></div><div class="t m0 x23 he y48f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x7 h21 y48e ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x99 ha y490 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x25 h4 y48e fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _33"> </span><span class="ff11">h</span></div><div class="t m0 x41 he y48f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x17 h21 y491 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x35 ha y492 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xd h4 y491 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x160 he y493 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x148 h21 y494 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xba ha y495 ff1e fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xa ha y496 ff1e fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x148 h21 y497 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xba ha y498 ff1e fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xa ha y499 ff1e fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8 he y493 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 h4 y491 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x4 he y493 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a hc y494 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x40 ha y49a ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x40 ha y496 ffc fs6 fc0 sc0 ls0 ws0">11</div><div class="t m0 x91 hc y494 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xaf ha y49a ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x15b ha y496 ffc fs6 fc0 sc0 ls0 ws0">12</div><div class="t m0 x92 hc y494 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xd5 ha y49a ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xd5 ha y496 ffc fs6 fc0 sc0 ls0 ws0">13</div><div class="t m0 x161 hc y494 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x6b ha y49a ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x6b ha y496 ffc fs6 fc0 sc0 ls0 ws0">14</div><div class="t m0 x144 hc y494 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>b</div><div class="t m0 x89 ha y49a ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x89 ha y496 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5a hc y497 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x40 ha y498 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x40 ha y499 ffc fs6 fc0 sc0 ls0 ws0">21</div><div class="t m0 x91 hc y497 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xaf ha y498 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x15b ha y499 ffc fs6 fc0 sc0 ls0 ws0">22</div><div class="t m0 x92 hc y497 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 xd5 ha y498 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xd5 ha y499 ffc fs6 fc0 sc0 ls0 ws0">23</div><div class="t m0 x161 hc y497 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>w</div><div class="t m0 x6b ha y498 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x6b ha y499 ffc fs6 fc0 sc0 ls0 ws0">24</div><div class="t m0 x144 hc y497 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>b</div><div class="t m0 x89 ha y498 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x89 ha y499 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x162 he y493 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe6 hc y49b ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 xe7 ha y49c ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x35 h4 y49b ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 xd3 he y49d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x44 hc y49b ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3a ha y49e ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x3a ha y49f ffc fs6 fc0 sc0 ls0 ws0">11</div><div class="t m0 xa hc y49b ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa9 ha y49c ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x47 h4 y49b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x59 ha y49e ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x59 ha y49f ffc fs6 fc0 sc0 ls0 ws0">12</div><div class="t m0 x1 hc y49b ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x163 ha y49c ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x7 h4 y49b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x4c ha y49e ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4c ha y49f ffc fs6 fc0 sc0 ls0 ws0">13</div><div class="t m0 xbf hc y49b ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xab ha y49c ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x152 h4 y49b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x4f ha y49e ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4f ha y49f ffc fs6 fc0 sc0 ls0 ws0">13</div><div class="t m0 x6b hc y49b ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x12b ha y49c ffc fs6 fc0 sc0 ls0 ws0">4</div><div class="t m0 xe2 h4 y49b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x164 ha y49e ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x164 ha y49f ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x165 he y49d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe6 hc y4a0 ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 xe7 ha y4a1 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x35 h4 y4a0 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 xd3 he y4a2 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x44 hc y4a0 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3a ha y4a3 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x3a ha y4a4 ffc fs6 fc0 sc0 ls0 ws0">21</div><div class="t m0 xa hc y4a0 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa9 ha y4a1 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x47 h4 y4a0 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x59 ha y4a3 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x59 ha y4a4 ffc fs6 fc0 sc0 ls0 ws0">22</div><div class="t m0 x1 hc y4a0 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x163 ha y4a1 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x7 h4 y4a0 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x4c ha y4a3 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4c ha y4a4 ffc fs6 fc0 sc0 ls0 ws0">23</div><div class="t m0 xbf hc y4a0 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xab ha y4a1 ffc fs6 fc0 sc0 ls0 ws0">3</div><div class="t m0 x152 h4 y4a0 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x4f ha y4a3 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4f ha y4a4 ffc fs6 fc0 sc0 ls0 ws0">13</div><div class="t m0 x6b hc y4a0 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x12b ha y4a1 ffc fs6 fc0 sc0 ls0 ws0">4</div><div class="t m0 xe2 h4 y4a0 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x164 ha y4a3 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x164 ha y4a4 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x165 he y4a2 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3 h6 y4a5 ff1 fs2 fc0 sc0 ls0 ws0">即：</div><div class="t m0 x131 h21 y4a6 ff11 fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 xa2 hb y4a7 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x97 h4 y4a6 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x166 he y4a8 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x1f hc y4a6 ffa fs2 fc0 sc0 ls0 ws0">net</div><div class="t m0 x8 ha y4a9 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x8 hb y4aa ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x49 he y4a8 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4 h4 y4a6 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x104 he y4ab ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x104 he y4ac ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5d he y4ad ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x167 ha y4ae ffd fs6 fc0 sc0 ls0 ws0">j<span class="_ _f"></span><span class="ffc">=1</span></div><div class="t m0 xdf hc y4a6 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x92 ha y4a9 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x92 hb y4aa ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x60 hc y4a6 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x151 hb y4a7 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x161 h4 y4a6 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x14e ha y4a9 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x14e hb y4aa ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x168 he y4ab ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x168 he y4ac ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y4a6 ff3 fs2 fc0 sc0 ls0 ws0">(6.6)</div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">上述部分属于<span class="_ _27"> </span><span class="ff3">feed-forward </span>部分，<span class="_ _31"></span>从前往后依次计算出各个输出层，<span class="_ _31"></span>最后求得<span class="_ _27"> </span><span class="ffa">y<span class="_ _f"></span></span>。<span class="_ _31"></span>但此时这些权</div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">值还未知。</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">37</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2b" class="pf w0 h0" data-page-no="2b"><div class="pc pc2b w0 h0"><img class="bi x169 y4af we h34" alt="" src="bg2b.png"/><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">6.4<span class="_ _15"> </span><span class="ff8">反向传播</span></div><div class="t m0 x106 h9 ya9 ff6 fs5 fc0 sc0 ls0 ws0">6.4<span class="_ _21"> </span><span class="ff9">反向传播</span></div><div class="t m0 x3 h6 y4b0 ff1 fs2 fc0 sc0 ls0 ws0">首先，<span class="_ _26"></span>对所有的权值<span class="_ _27"> </span><span class="ffa">w<span class="_ _c"> </span></span>给定一个初始值，<span class="_ _26"></span>然后根据前向传播的方式来计算出输出值<span class="_ _27"> </span><span class="ffa">y<span class="_ _1f"></span></span>，<span class="_ _26"></span>为了评估</div><div class="t m0 x3 h6 y4b1 ff1 fs2 fc0 sc0 ls0 ws0">此次训<span class="_ _f"></span>练模<span class="_ _f"></span>型是<span class="_ _f"></span>否合理，<span class="_ _f"></span>我们<span class="_ _f"></span>取网<span class="_ _f"></span>络所有<span class="_ _f"></span>输出<span class="_ _f"></span>层节<span class="_ _f"></span>点的误<span class="_ _f"></span>差平<span class="_ _f"></span>方和<span class="_ _f"></span>作为目<span class="_ _f"></span>标函<span class="_ _f"></span>数，对<span class="_ _f"></span>于样本<span class="_ _11"> </span><span class="ffa">k<span class="_ _f"></span></span>，</div><div class="t m0 x3 h6 y4b2 ff1 fs2 fc0 sc0 ls0 ws0">其误差表达式为：</div><div class="t m0 x87 hc y4b3 ffa fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x47 hb y4b4 ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 xa8 h4 y4b3 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x133 h4 y4b5 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x133 h4 y4b6 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8d h1f y4b7 ff16 fs6 fc0 sc0 ls0 ws0">output</div><div class="t m0 xf9 he y4b8 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa3 ha y4b9 ffd fs6 fc0 sc0 ls0 ws0">j<span class="_ _f"></span><span class="ffc">=1</span></div><div class="t m0 xa0 h4 y4b3 ffb fs2 fc0 sc0 ls0 ws0">[<span class="ffa">t</span></div><div class="t m0 x25 hb y4ba ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x16a h4 y4b3 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 xcc hb y4ba ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x60 h4 y4b3 ffb fs2 fc0 sc0 ls0 ws0">]</div><div class="t m0 x63 ha y4bb ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x32 h4 y4b3 ff3 fs2 fc0 sc0 ls0 ws0">(6.7)</div><div class="t m0 x3 h6 y4bc ff1 fs2 fc0 sc0 ls0 ws0">有了目标函数之后，现在我们采用梯度下降来寻找最优解。</div><div class="t m0 x3 h12 y4bd ff6 fs7 fc0 sc0 ls0 ws0">6.4.1<span class="_ _36"> </span><span class="ff9">输出层</span></div><div class="t m0 x3 h6 y4be ff1 fs2 fc0 sc0 ls0 ws0">对于输出层节点，第<span class="_ _c"> </span><span class="ffa">i<span class="_ _c"> </span></span>个输出节点与第<span class="_ _c"> </span><span class="ffa">j<span class="_ _11"> </span></span>个隐藏节点的权值更新规则为：</div><div class="t m0 x106 hc y4bf ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x10a ha y4c0 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x10f hb y4c1 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xa6 h4 y4bf fff fs2 fc0 sc0 ls0 ws0">←<span class="_ _2c"> </span><span class="ffa">w</span></div><div class="t m0 x8f ha y4c0 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x8f hb y4c1 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x138 h4 y4bf fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">η</span></div><div class="t m0 x16b hc y4c2 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>E</div><div class="t m0 xcc hb y4c3 ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 x26 hc y4c4 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 xfd ha y4c5 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xfd hb y4c6 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x32 h4 y4bf ff3 fs2 fc0 sc0 ls0 ws0">(6.8)</div><div class="t m0 x3 h6 y4c7 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _c"> </span><span class="ffa">η<span class="_ _0"> </span></span>为学习率，由于<span class="_ _c"> </span><span class="ffa">E</span></div><div class="t m0 x16c hb y4c8 ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 x131 h6 y4c7 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _c"> </span><span class="ffa">y</span></div><div class="t m0 xb9 hb y4c9 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x148 h6 y4c7 ff1 fs2 fc0 sc0 ls0 ws0">的函数，<span class="ffa">y</span></div><div class="t m0 x8e hb y4c9 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xbd h6 y4c7 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _c"> </span><span class="ffa">net</span></div><div class="t m0 xaa ha y4ca ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x41 h6 y4c7 ff1 fs2 fc0 sc0 ls0 ws0">的函数，<span class="ffa">net</span></div><div class="t m0 x157 ha y4ca ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x16d h6 y4c7 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _c"> </span><span class="ffa">w</span></div><div class="t m0 x125 hb y4c9 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xef h6 y4c7 ff1 fs2 fc0 sc0 ls0 ws0">的函数，根据链式</div><div class="t m0 x3 h6 y4cb ff1 fs2 fc0 sc0 ls0 ws0">求导法则，有：</div><div class="t m0 xf6 hc y4cc ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>E</div><div class="t m0 x15e hb y4cd ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 x16e hc y4ce ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 x106 ha y4cf ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x106 hb y4d0 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xeb h4 y4d1 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xfa hc y4cc ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>E</div><div class="t m0 x163 hb y4cd ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 xbc hc y4d2 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 xa3 hb y4d3 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x138 hc y4cc ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 xd4 hb y4d4 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x7 hc y4ce ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x25 ha y4cf ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x25 hb y4d0 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xab hc y4d5 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 xf7 ha y4d6 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xf7 hb y4d7 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x42 hc y4ce ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 x110 ha y4cf ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x110 hb y4d0 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x32 h4 y4d1 ff3 fs2 fc0 sc0 ls0 ws0">(6.9)</div><div class="t m0 x3 h6 y4d8 ff1 fs2 fc0 sc0 ls0 ws0">根据上述公式，可以分别求出偏导数：</div><div class="t m0 x16f hc y4d9 ffa fs2 fc1 sc0 ls0 ws0">∂<span class="_ _1f"></span>E</div><div class="t m0 xe6 hb y4da ffd fs6 fc1 sc0 ls0 ws0">k</div><div class="t m0 xf3 hc y4db ffa fs2 fc1 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 x16 hb y4dc ffd fs6 fc1 sc0 ls0 ws0">i</div><div class="t m0 x130 h4 y4dd ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x83 hc y4d9 ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x43 hc y4db ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 xd3 hb y4dc ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x44 he y4de ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x44 he y4df ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3a h4 y4d9 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3a h4 y4db ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x9 h1f y4e0 ff16 fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x87 he y4e1 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x48 hb y4e2 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x49 h4 y4dd ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">t</span></div><div class="t m0 x4 hb y4e3 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x3f h4 y4dd fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 x24 hb y4e3 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x99 h4 y4dd ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x91 ha y4e4 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x15a he y4de ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x15a he y4df ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x130 h4 y4e5 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x83 hc y4e6 ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x43 hc y4e7 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 xd3 hb y4e8 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x44 he y4e9 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x45 h4 y4e6 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x45 h4 y4e7 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 xf6 h4 y4e5 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">t</span></div><div class="t m0 xc5 hb y4ea ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x15e h4 y4e5 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 xb6 hb y4ea ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x59 h4 y4e5 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xfa ha y4eb ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8e he y4e9 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xbd ha y4ec ffd fs6 fc0 sc0 ls0 ws0">j<span class="_ _f"></span><span class="ffc">=</span>i</div><div class="t m0 x170 h4 y4e5 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x25 hc y4e6 ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 xb2 hc y4e7 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 x16a hb y4e8 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xab he y4ed ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xab he y4ee ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x152 h4 y4e6 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x152 h4 y4e7 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x63 h1f y4ef ff16 fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x50 he y4f0 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x13b hb y4f1 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x144 h4 y4e5 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">t</span></div><div class="t m0 x157 hb y4ea ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xfb h4 y4e5 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 x13f hb y4ea ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x12c h4 y4e5 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x171 ha y4eb ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xee he y4ed ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xee he y4ee ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xd7 ha y4f2 ffd fs6 fc0 sc0 ls0 ws0">j<span class="_ _f"></span><span class="ff12"≯<span class="ffc">=</span></span>i</div><div class="t m0 x130 h4 y4f3 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x83 hc y4f4 ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x43 hc y4f5 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 xd3 hb y4f6 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x44 he y4f7 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x45 h4 y4f4 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x45 h4 y4f5 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 xf6 h4 y4f3 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">t</span></div><div class="t m0 xc5 hb y4f8 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xea h4 y4f3 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 x172 hb y4f8 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x49 h4 y4f3 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x133 ha y4f9 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 x4 he y4f7 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xbd h4 y4f3 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span>0</div><div class="t m0 x130 h4 y4fa ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="fff">−<span class="_ _2d"></span></span>(<span class="ffa">t</span></div><div class="t m0 x160 hb y4fb ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x9c h4 y4fa fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 x136 hb y4fb ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x87 h4 y4fa ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xb4 hc y4fc ffa fs2 fc1 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 x119 hb y4fd ffd fs6 fc1 sc0 ls0 ws0">i</div><div class="t m0 xc6 hc y4fe ffa fs2 fc1 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x12f ha y4ff ffc fs6 fc1 sc0 ls0 ws0">(2)</div><div class="t m0 x12f hb y500 ffd fs6 fc1 sc0 ls0 ws0">i</div><div class="t m0 x130 h4 y501 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">y</span></div><div class="t m0 xcb hb y502 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x154 h4 y501 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">y</span></span></div><div class="t m0 xba hb y502 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1f h4 y501 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xc6 hc y503 ffa fs2 fc1 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x12f ha y504 ffc fs6 fc1 sc0 ls0 ws0">(2)</div><div class="t m0 x12f hb y505 ffd fs6 fc1 sc0 ls0 ws0">i</div><div class="t m0 x173 hc y506 ffa fs2 fc1 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 xc1 ha y507 ffc fs6 fc1 sc0 ls0 ws0">(2)</div><div class="t m0 x174 hb y508 ffd fs6 fc1 sc0 ls0 ws0">ij</div><div class="t m0 x130 h4 y509 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">h</span></div><div class="t m0 x83 hb y50a ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb7 h4 y50b ff3 fs2 fc0 sc0 ls0 ws0">(6.10)</div><div class="t m0 x175 hb y50c ffd fs6 fc0 sc0 ls0 ws0">∂<span class="_ _f"></span>y</div><div class="t m0 x103 h22 y50d ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x169 hb y50e ffd fs6 fc0 sc0 ls0 ws0">∂<span class="_ _f"></span>net</div><div class="t m0 x176 h1a y50f ff14 fs8 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x176 h22 y510 ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x134 h6 y511 ff1 fs2 fc0 sc0 ls0 ws0">就是激活函数求导：</div><div class="t m0 x97 h4 y512 ffa fs2 fc0 sc0 ls0 ws0">y<span class="_ _27"> </span><span class="ffb">=<span class="_ _27"> </span></span>f<span class="_ _32"></span><span class="ffb">(</span>z<span class="_ _f"></span><span class="ffb">)<span class="_ _27"> </span>=</span></div><div class="t m0 xa3 h4 y513 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x133 h4 y514 ffb fs2 fc0 sc0 ls0 ws0">1<span class="_ _33"> </span>+<span class="_ _25"> </span><span class="ffa">e</span></div><div class="t m0 x40 ha y515 ff12 fs6 fc0 sc0 ls0 ws0">−</div><div class="t m0 xfc hb y516 ffd fs6 fc0 sc0 ls0 ws0">z</div><div class="t m0 xc2 hc y517 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 x136 ha y518 ff12 fs6 fc0 sc0 ls0 ws0">′</div><div class="t m0 xc5 h4 y517 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">z<span class="_ _f"></span></span>)<span class="_ _27"> </span>=</div><div class="t m0 xa3 hc y519 ffa fs2 fc0 sc0 ls0 ws0">e</div><div class="t m0 x9f ha y51a ff12 fs6 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 x133 h4 y51b ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">e</span></div><div class="t m0 x1 ha y51c ff12 fs6 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 x7 h4 y51b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span>1)</div><div class="t m0 xaa ha y51d ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xa8 h4 y51e ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xa3 h4 y51f ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x133 h4 y520 ffb fs2 fc0 sc0 ls0 ws0">1<span class="_ _33"> </span>+<span class="_ _25"> </span><span class="ffa">e</span></div><div class="t m0 x40 ha y521 ff12 fs6 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 xa0 h4 y51e fff fs2 fc0 sc0 ls0 ws0">−</div><div class="t m0 x26 he y522 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5f h4 y51f ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xab h4 y520 ffb fs2 fc0 sc0 ls0 ws0">1<span class="_ _33"> </span>+<span class="_ _25"> </span><span class="ffa">e</span></div><div class="t m0 x177 ha y521 ff12 fs6 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 x28 he y522 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x12b ha y523 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xa8 h4 y524 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">y<span class="_ _2c"> </span><span class="fff">−<span class="_ _33"> </span></span>y</span></div><div class="t m0 x7 ha y525 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb7 h4 y526 ff3 fs2 fc0 sc0 ls0 ws0">(6.11)</div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">由此可得，</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">38</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2c" class="pf w0 h0" data-page-no="2c"><div class="pc pc2c w0 h0"><img class="bi x10b y527 wf h35" alt="" src="bg2c.png"/><div class="t m0 x76 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">6.5<span class="_ _15"> </span><span class="ff8">权值更新归纳</span></div><div class="t m0 x9e hc y528 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>E</div><div class="t m0 xf6 hb y529 ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 x15f hc y52a ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 x16e ha y52b ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x16e hb y52c ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x1c h4 y52d ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="fff">−<span class="_ _2d"></span></span>(<span class="ffa">t</span></div><div class="t m0 x4 hb y52e ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x3f h4 y52d fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 x24 hb y52e ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xfc h4 y52d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">·<span class="_ _25"> </span><span class="ffa">y</span></span></div><div class="t m0 xbe hb y52e ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xdf h4 y52d ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">y</span></span></div><div class="t m0 xf7 hb y52e ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x161 h4 y52d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">·<span class="_ _25"> </span><span class="ffa">h</span></span></div><div class="t m0 x12b hb y52e ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb7 h4 y52d ff3 fs2 fc0 sc0 ls0 ws0">(6.12)</div><div class="t m0 x3 h12 y52f ff6 fs7 fc0 sc0 ls0 ws0">6.4.2<span class="_ _36"> </span><span class="ff9">隐藏层</span></div><div class="t m0 x3 h6 y530 ff1 fs2 fc0 sc0 ls0 ws0">首先，<span class="_ _31"></span>对于隐藏层的任意一个神经元，<span class="_ _22"></span>输出层的每个神经单元的误差对其都有影响。<span class="_ _31"></span>因此，<span class="_ _22"></span>对于</div><div class="t m0 x3 h6 y531 ff1 fs2 fc0 sc0 ls0 ws0">隐藏层第<span class="_ _c"> </span><span class="ffa">i<span class="_ _c"> </span></span>个神经元，它与输入层的第<span class="_ _c"> </span><span class="ffa">j<span class="_ _11"> </span></span>个神经元的权值更新规则为：</div><div class="t m0 xea hc y532 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x8 ha y533 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x8 hb y534 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x150 h4 y532 fff fs2 fc0 sc0 ls0 ws0">←<span class="_ _2c"> </span><span class="ffa">w</span></div><div class="t m0 x9f ha y533 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x9f hb y534 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x5d h4 y532 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">η</span></div><div class="t m0 x16b hc y535 ffa fs2 fc1 sc0 ls0 ws0">∂<span class="_ _1f"></span>E</div><div class="t m0 xcc hb y536 ffd fs6 fc1 sc0 ls0 ws0">k</div><div class="t m0 x16a hc y537 ffa fs2 fc1 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 x142 hb y538 ffd fs6 fc1 sc0 ls0 ws0">ij</div><div class="t m0 xb7 h4 y532 ff3 fs2 fc0 sc0 ls0 ws0">(6.13)</div><div class="t m0 x3 h6 y539 ff1 fs2 fc0 sc0 ls0 ws0">接着由链式法则，我们对上面红色部分进行展开：</div><div class="t m0 x64 hc y53a ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>E</div><div class="t m0 xb5 hb y53b ffd fs6 fc0 sc0 ls0 ws0">k</div><div class="t m0 x153 hc y53c ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 xc ha y53d ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xc hb y53e ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xa5 h4 y53f ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xc2 hc y53a ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x9c hc y53c ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 xa ha y53d ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xa hb y53e ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x2 he y540 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xeb hb y541 ffd fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x146 he y542 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4a hb y543 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x8f hc y53f ffa fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x24 hb y544 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x99 he y540 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa5 h4 y545 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb9 hb y546 ffd fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x148 he y547 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf6 hb y548 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x10f hc y549 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>E</div><div class="t m0 x49 hb y54a ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x10a hc y54b ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>y</div><div class="t m0 x20 hb y54c ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 xf9 hc y549 ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 x90 hb y54a ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x3e hc y54d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x40 ha y54e ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x40 hb y54f ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 xa0 hc y549 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x92 ha y550 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x92 hb y551 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x13a hc y54b ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>h</div><div class="t m0 xab hb y54c ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x177 hc y549 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>h</div><div class="t m0 x28 hb y54a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x5f hc y54d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x28 ha y54e ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x28 hb y552 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x144 hc y553 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x2b ha y554 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x2b hb y555 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x178 hc y54b ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 x179 hb y54c ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xa5 h4 y556 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb9 hb y557 ffd fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x148 he y558 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf6 hb y559 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x2 he y55a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xeb h4 y55b fff fs2 fc0 sc0 ls0 ws0">−</div><div class="t m0 x17a hc y556 ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x3e hb y55c ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x17b h4 y556 fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 xa3 hc y55d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x4b ha y55e ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4b hb y55f ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x40 hc y560 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>h</div><div class="t m0 x91 hb y561 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xab hc y562 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>h</div><div class="t m0 x60 hb y563 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4d hc y564 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 xd5 ha y565 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xd5 hb y566 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x94 hc y55d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x144 ha y55e ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x144 hb y55f ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x61 hc y564 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 x17c ha y565 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x2a hb y566 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x82 he y55a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa5 h4 y567 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb9 hb y568 ffd fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x148 he y569 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf6 hb y56a ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x2 he y56b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xeb h4 y567 fff fs2 fc0 sc0 ls0 ws0">−<span class="ffa">δ</span></div><div class="t m0 x3e hb y56c ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x17b h4 y567 fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x7 ha y56d ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x5b hb y56e ffd fs6 fc0 sc0 ls0 ws0">si</div><div class="t m0 x91 h4 y567 fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 x4d hc y56f ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>h</div><div class="t m0 x93 hb y570 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13e hc y571 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 xfd ha y572 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xfd hb y573 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4e hc y574 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x29 ha y575 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x29 hb y576 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xf7 hc y571 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 xe1 ha y572 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xe1 hb y573 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xde he y56b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa5 h4 y577 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb9 h1f y578 ff16 fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x148 he y579 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf6 hb y57a ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x2 he y57b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xeb h4 y577 fff fs2 fc0 sc0 ls0 ws0">−<span class="ffa">δ</span></div><div class="t m0 x3e hb y57c ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x17b h4 y577 fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _33"> </span><span class="ffa">w</span></div><div class="t m0 x7 ha y57d ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x17d hb y57e ffd fs6 fc0 sc0 ls0 ws0">si</div><div class="t m0 x91 h4 y577 fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _33"> </span><span class="ffa">h</span></div><div class="t m0 x15b hb y57c ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xdf h4 y577 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">h</span></span></div><div class="t m0 x177 hb y57c ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4f h4 y577 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">·</span></div><div class="t m0 xa1 hc y57f ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>net</div><div class="t m0 x82 ha y580 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x82 hb y581 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x51 hc y582 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>w</div><div class="t m0 x157 ha y583 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x157 hb y584 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x54 he y57b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa5 h4 y585 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb9 h1f y586 ff16 fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x148 he y587 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf6 hb y588 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x2 he y589 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x10c h4 y585 fff fs2 fc0 sc0 ls0 ws0">−<span class="ffa">δ</span></div><div class="t m0 x133 hb y58a ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x4 hc y585 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xbd ha y58b ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xbd hb y58c ffd fs6 fc0 sc0 ls0 ws0">si</div><div class="t m0 x40 hc y585 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xfc hb y58a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x5d h4 y585 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">h</span></span></div><div class="t m0 xfd hb y58a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xcc h4 y585 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2d"> </span><span class="ffa">x</span></div><div class="t m0 xe0 hb y58a ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x161 he y589 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa5 h4 y58d ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="fff">−<span class="ffa">h</span></span></div><div class="t m0 x46 hb y58e ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc5 h4 y58d ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">h</span></span></div><div class="t m0 x150 hb y58e ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x3e h4 y58d ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x17b he y58f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a h1f y590 ff16 fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x40 he y591 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xfc hb y592 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 xbe hc y58d ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x16a hb y58e ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x137 hc y58d ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xfd ha y593 ffc fs6 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xfd hb y594 ffd fs6 fc0 sc0 ls0 ws0">si</div><div class="t m0 x63 he y58f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x94 hc y58d ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x9d hb y58e ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb7 h4 y595 ff3 fs2 fc0 sc0 ls0 ws0">(6.14)</div><div class="t m0 x3 h6 y596 ff1 fs2 fc0 sc0 ls0 ws0">代入到上式，得到隐藏层的权值更新公式：</div><div class="t m0 x16c hc y597 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x131 ha y598 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x131 hb y599 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x15f h4 y597 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">w</span></div><div class="t m0 x9 ha y598 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x9 hb y599 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xb1 h4 y597 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">η<span class="_ _1f"></span>h</span></div><div class="t m0 x4a hb y59a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x8e h4 y597 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">h</span></span></div><div class="t m0 x167 hb y59a ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x17e h4 y597 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x25 he y59b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x16b hb y59c ffd fs6 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 xab he y59d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5e hb y59e ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x50 hc y597 ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x139 hb y59a ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x9d hc y597 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x14e hb y59a ffd fs6 fc0 sc0 ls0 ws0">si</div><div class="t m0 x17f he y59b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x89 hc y597 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x8a hb y59a ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb7 h4 y597 ff3 fs2 fc0 sc0 ls0 ws0">(6.15)</div><div class="t m0 x3 h6 y59f ff1 fs2 fc0 sc0 ls0 ws0">令<span class="_ _c"> </span><span class="ffa">δ</span></div><div class="t m0 x180 hb y5a0 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x114 h4 y59f ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x181 hb y5a1 ffd fs6 fc0 sc0 ls0 ws0">∂<span class="_ _f"></span>E</div><div class="t m0 x182 h22 y5a2 ff17 fs8 fc0 sc0 ls0 ws0">k</div><div class="t m0 x34 hb y5a3 ffd fs6 fc0 sc0 ls0 ws0">∂<span class="_ _f"></span>net</div><div class="t m0 xd9 h22 y5a4 ff17 fs8 fc0 sc0 ls0 ws0">i</div><div class="t m0 x107 h4 y59f ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="fff">−<span class="ffa">h</span></span></div><div class="t m0 x75 hb y5a0 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x16f h4 y59f ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">h</span></span></div><div class="t m0 x38 hb y5a0 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6f h4 y59f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2d"> </span>(</div><div class="t m0 xd he y5a5 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x160 hb y5a6 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x8c hc y59f ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x148 hb y5a0 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x3b hc y59f ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x1f hb y5a0 ffd fs6 fc0 sc0 ls0 ws0">si</div><div class="t m0 x15e h6 y59f ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">，则公式简化为：</span></div><div class="t m0 x47 hc y5a7 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x88 ha y5a8 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xa8 hb y5a9 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x3e h4 y5a7 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">w</span></div><div class="t m0 x5b ha y5a8 ffc fs6 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x5b hb y5a9 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x167 h4 y5a7 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">η<span class="_ _1f"></span>δ</span></div><div class="t m0 x137 hb y5aa ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x92 hc y5a7 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x152 hb y5aa ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb7 h4 y5a7 ff3 fs2 fc0 sc0 ls0 ws0">(6.16)</div><div class="t m0 x1d h9 y5ab ff6 fs5 fc0 sc0 ls0 ws0">6.5<span class="_ _21"> </span><span class="ff9">权值更新归纳</span></div><div class="t m0 x3 h6 y5ac ff1 fs2 fc0 sc0 ls0 ws0">通过<span class="_ _c"> </span><span class="ff3">BP<span class="_ _0"> </span></span>推导，现在我<span class="_ _f"></span>们知道如何更新<span class="_ _f"></span>权值了，下面来总<span class="_ _f"></span>结一下。假定每个<span class="_ _f"></span>节点的误差项<span class="_ _f"></span>为<span class="_ _c"> </span><span class="ffa">δ</span></div><div class="t m0 x183 hb y5ad ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x184 h6 y5ac ff1 fs2 fc0 sc0 ls0 ws0">，</div><div class="t m0 x3 h6 y5ae ff1 fs2 fc0 sc0 ls0 ws0">不管是隐藏节点还是输出节点，其输出值统一使用<span class="_ _c"> </span><span class="ffa">x</span></div><div class="t m0 xaf hb y5af ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x137 h6 y5ae ff1 fs2 fc0 sc0 ls0 ws0">来表示，那么权值更新规则为：</div><div class="t m0 x10a hc y1c5 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x0 hb y5b0 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xfa h4 y1c5 fff fs2 fc0 sc0 ls0 ws0">←<span class="_ _2c"> </span><span class="ffa">w</span></div><div class="t m0 x7 hb y5b0 ffd fs6 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x138 h4 y1c5 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">η<span class="_ _1f"></span>δ</span></div><div class="t m0 xbf hb y5b0 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x137 hc y1c5 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x93 hb y5b0 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb7 h4 y1c5 ff3 fs2 fc0 sc0 ls0 ws0">(6.17)</div><div class="t m0 x3 h6 y5b1 ff1 fs2 fc0 sc0 ls0 ws0">当节点为输出层神经元时，</div><div class="t m0 x1f hc y1d ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x106 hb y97 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x2 h4 y1d ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="fff">−<span class="ffa">y</span></span></div><div class="t m0 x4 hb y97 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x8d h4 y1d ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">y</span></span></div><div class="t m0 x4b hb y97 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb2 h4 y1d ffb fs2 fc0 sc0 ls0 ws0">)(<span class="ffa">t</span></div><div class="t m0 xdf hb y97 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xab h4 y1d fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 x185 hb y97 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4e h4 y1d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _4e"> </span><span class="ff3">(6.18)</span></div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">39</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2d" class="pf w0 h0" data-page-no="2d"><div class="pc pc2d w0 h0"><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">6.5<span class="_ _15"> </span><span class="ff8">权值更新归纳</span></div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">当节点为隐藏层神经元时，</div><div class="t m0 x15d hc y5b2 ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 xc2 hb y5b3 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x136 h4 y5b2 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="fff">−<span class="ffa">h</span></span></div><div class="t m0 x20 hb y5b3 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa6 h4 y5b2 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _33"> </span><span class="fff">−<span class="_ _25"> </span><span class="ffa">h</span></span></div><div class="t m0 x24 hb y5b3 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xfc h4 y5b2 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x167 he y5b4 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xd4 he y5b5 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x26 hb y5b6 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x42 hc y5b2 ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x152 hb y5b3 ffd fs6 fc0 sc0 ls0 ws0">s</div><div class="t m0 x143 hc y5b2 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x186 hb y5b3 ffd fs6 fc0 sc0 ls0 ws0">si</div><div class="t m0 x4f he y5b4 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xb7 h4 y5b2 ff3 fs2 fc0 sc0 ls0 ws0">(6.19)</div><div class="t m0 x3 h6 y5b7 ff1 fs2 fc0 sc0 ls0 ws0">其中，<span class="ffa">δ</span></div><div class="t m0 x10b hb y5b8 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x187 h6 y5b7 ff1 fs2 fc0 sc0 ls0 ws0">是节点的误差项，<span class="ffa">y</span></div><div class="t m0 xa2 hb y5b8 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1b h6 y5b7 ff1 fs2 fc0 sc0 ls0 ws0">是输出节点的输出值，<span class="ffa">t</span></div><div class="t m0 x137 hb y5b8 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x93 h6 y5b7 ff1 fs2 fc0 sc0 ls0 ws0">是样本<span class="_ _c"> </span><span class="ffa">i<span class="_ _0"> </span></span>对应的目标值，<span class="ffa">h</span></div><div class="t m0 x188 hb y5b8 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x2f h6 y5b7 ff1 fs2 fc0 sc0 ls0 ws0">为隐藏节点</div><div class="t m0 x3 h6 y5b9 ff1 fs2 fc0 sc0 ls0 ws0">的输出值。权值更新归纳</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">40</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2e" class="pf w0 h0" data-page-no="2e"><div class="pc pc2e w0 h0"><div class="t m0 x8 h5 y5ba ff4 fs3 fc0 sc0 ls0 ws0">第四部分</div><div class="t m0 x8 h5 y5bb ff4 fs3 fc0 sc0 ls0 ws0">神经网络</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">41</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2f" class="pf w0 h0" data-page-no="2f"><div class="pc pc2f w0 h0"></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf30" class="pf w0 h0" data-page-no="30"><div class="pc pc30 w0 h0"><img class="bi xc3 y5bc w10 h36" alt="" src="bg30.png"/><div class="t m0 x187 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第七章 <span class="ff6">Recurren<span class="_ _2f"></span>t<span class="_ _16"> </span>Neural<span class="_ _16"> </span>Net<span class="_ _2f"></span>w<span class="_ _2f"></span>orks</span></div><div class="t m0 x189 h37 y5bd ff6 fs5 fc0 sc0 ls0 ws0">7.1<span class="_ _21"> </span>Simple<span class="_ _9"> </span>Recurren<span class="_ _2f"></span>t<span class="_ _9"> </span>Net<span class="_ _2f"></span>w<span class="_ _2f"></span>ork</div><div class="t m0 x3 h12 y5be ff6 fs7 fc0 sc0 ls0 ws0">7.1.1<span class="_ _36"> </span><span class="ff9">前向传播</span></div><div class="t m0 x3 h6 y5bf ff1 fs2 fc0 sc0 ls0 ws0">我们熟悉的神经网络可能是这样的：</div><div class="c xc3 y5c0 w11 h38"><div class="t m0 x18a h39 y5c1 ff21 fsa fc0 sc0 ls0 ws0">input</div><div class="t m0 x18a h39 y5c2 ff21 fsa fc0 sc0 ls0 ws0">layer</div></div><div class="c xd6 y5c3 w12 h3a"><div class="t m0 x18b h3b y5c4 ff22 fsb fc0 sc0 ls0 ws0">input→hidden</div></div><div class="c xc3 y5c0 w11 h38"><div class="t m0 x18c h39 y5c1 ff21 fsa fc0 sc0 ls0 ws0">hidden</div><div class="t m0 x9a h39 y5c2 ff21 fsa fc0 sc0 ls0 ws0">layer</div><div class="t m0 xcf h39 y5c1 ff21 fsa fc0 sc0 ls0 ws0">output</div><div class="t m0 x37 h39 y5c2 ff21 fsa fc0 sc0 ls0 ws0">layer</div></div><div class="c xd6 y5c5 w13 h3c"><div class="t m0 x18b h3b y5c6 ff22 fsb fc0 sc0 ls0 ws0">hidden→output</div></div><div class="c xd6 y5c7 w14 h3d"><div class="t m0 x18b h3e y5c8 ff23 fsc fc0 sc0 ls0 ws0">Description</div><div class="t m0 x18b h3f y5c9 ff24 fsd fc0 sc0 ls0 ws0">Uistheweightmatrixfromthe</div><div class="t m0 x18b h3f y5ca ff24 fsd fc0 sc0 ls0 ws0">inputlayertothehiddenlayer</div><div class="t m0 x18b h3f y5cb ff24 fsd fc0 sc0 ls0 ws0">Vistheweightmatrixfromthe</div><div class="t m0 x18b h3f y5cc ff24 fsd fc0 sc0 ls0 ws0">hiddenlayertotheoutputlayer</div></div><div class="t m0 x1d h6 y5cd ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">7.1:<span class="_ _2e"> </span></span>三层神经网络示意图</div><div class="t m0 x3 h6 y5ce ff1 fs2 fc0 sc0 ls0 ws0">这是一个简单的多层神经网络。它的<span class="_ _f"></span>输入维度是<span class="_ _c"> </span><span class="ff3">5</span>，输出维度是<span class="_ _0"> </span><span class="ff3">2</span>，隐藏层的维度是<span class="_ _0"> </span><span class="ff3">3</span>。用数学</div><div class="t m0 x3 h6 y5cf ff1 fs2 fc0 sc0 ls0 ws0">公式表示：</div><div class="t m0 x45 h4 y5d0 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(<span class="ff11">U</span></span></div><div class="t m0 x106 ha y5d1 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>5</div><div class="t m0 x88 h21 y5d0 ff11 fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x150 ha y5d1 ffc fs6 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>1</div><div class="t m0 x5a h4 y5d0 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff11">B</span></div><div class="t m0 x4b ha y5d1 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 xdf h4 y5d0 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff11">H</span></div><div class="t m0 xf7 ha y5d1 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x18d h13 y5d2 ff3 fs4 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3 h6 y5d3 ff1 fs2 fc0 sc0 ls0 ws0">其中，<span class="ffa">f<span class="_ _2e"> </span></span>是隐藏<span class="_ _f"></span>层的激活函数，<span class="ff11">U<span class="_ _b"> </span></span>是隐藏层的权<span class="_ _f"></span>重矩阵，<span class="ff11">B<span class="_ _1c"> </span></span>是隐藏层的偏置向<span class="_ _f"></span>量，当然以下两</div><div class="t m0 x3 h6 y5d4 ff1 fs2 fc0 sc0 ls0 ws0">种写法在数学上也是等价的：</div><div class="t m0 x45 h4 y5d5 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(<span class="ff11">U</span></span></div><div class="t m0 x106 hb y5d6 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x106 ha y5d7 ffc fs6 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>3</div><div class="t m0 x88 h21 y5d5 ff11 fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x150 ha y5d8 ffc fs6 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>1</div><div class="t m0 x5a h4 y5d5 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff11">B</span></div><div class="t m0 x4b ha y5d8 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 xdf h4 y5d5 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff11">H</span></div><div class="t m0 xf7 ha y5d8 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x18d h13 y5d9 ff3 fs4 fc0 sc0 ls0 ws0">2</div><div class="t m0 x45 h4 y5da ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(<span class="ff11">X</span></span></div><div class="t m0 x1c ha y5db ffc fs6 fc0 sc0 ls0 ws0">1<span class="ff12">×</span>5</div><div class="t m0 xbb h21 y5da ff11 fs2 fc0 sc0 ls0 ws0">U</div><div class="t m0 x150 ha y5db ffc fs6 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>3</div><div class="t m0 x5a h4 y5da ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff11">B</span></div><div class="t m0 x4b ha y5db ffc fs6 fc0 sc0 ls0 ws0">1<span class="ff12">×</span>3</div><div class="t m0 xdf h4 y5da ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff11">H</span></div><div class="t m0 xf7 ha y5db ffc fs6 fc0 sc0 ls0 ws0">1<span class="ff12">×</span>3</div><div class="t m0 x18d h13 y5dc ff3 fs4 fc0 sc0 ls0 ws0">3</div><div class="t m0 x3 h6 y5dd ff1 fs2 fc0 sc0 ls0 ws0">一般在机<span class="_ _f"></span>器学习<span class="_ _f"></span>的书籍<span class="_ _f"></span>中惯用<span class="_ _f"></span>的写法<span class="_ _f"></span>是</div><div class="t m0 x172 h13 y5de ff3 fs4 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbc h6 y5dd ff1 fs2 fc0 sc0 ls0 ws0">。在这里<span class="_ _f"></span>遵循惯<span class="_ _f"></span>例，沿用</div><div class="t m0 x2b h13 y5de ff3 fs4 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc9 h6 y5dd ff1 fs2 fc0 sc0 ls0 ws0">的写法。那<span class="_ _f"></span>么，从隐<span class="_ _f"></span>藏</div><div class="t m0 x3 h6 y5df ff1 fs2 fc0 sc0 ls0 ws0">层到输出层则表示为：</div><div class="t m0 x15d h4 y5e0 ffa fs2 fc0 sc0 ls0 ws0">g<span class="_ _f"></span><span class="ffb">(<span class="ff11">V</span></span></div><div class="t m0 xea hb y5e1 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x18e ha y5e2 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>2</div><div class="t m0 x88 h21 y5e0 ff11 fs2 fc0 sc0 ls0 ws0">H</div><div class="t m0 x150 ha y5e3 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x5a h4 y5e0 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff11">C</span></div><div class="t m0 x91 ha y5e3 ffc fs6 fc0 sc0 ls0 ws0">2<span class="ff12">×</span>1</div><div class="t m0 x16a h4 y5e0 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff11">O</span></div><div class="t m0 xe0 ha y5e3 ffc fs6 fc0 sc0 ls0 ws0">2<span class="ff12">×</span>1</div><div class="t m0 x3 h6 y5e4 ff1 fs2 fc0 sc0 ls0 ws0">数据在这样的网络中流动<span class="_ _22"></span>（向前传播）<span class="_ _22"></span>的过程是很容易理解和想象的，<span class="_ _28"></span>如果将每一层用一个单元</div><div class="t m0 x3 h6 y5e5 ff1 fs2 fc0 sc0 ls0 ws0">来表示，可以有更简洁的图例：</div><div class="c x75 y5e6 w15 h40"><div class="t m0 x18f h41 y5e7 ff25 fse fc0 sc0 ls0 ws0">X<span class="_ _4f"> </span>H<span class="_ _50"> </span>O</div><div class="t m0 x190 h42 y5e8 ff26 fsf fc0 sc0 ls0 ws0">U<span class="_ _51"> </span>V</div><div class="t m0 x35 h41 y5e7 ff25 fse fc0 sc0 ls0 ws0">L<span class="_ _52"> </span>Y</div></div><div class="t m0 x191 h6 y5e9 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">7.2:<span class="_ _2e"> </span></span>三层神经网络简要示意图（包括反向传播过程）</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">43</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf31" class="pf w0 h0" data-page-no="31"><div class="pc pc31 w0 h0"><img class="bi xb y5bc w16 h43" alt="" src="bg31.png"/><div class="t m0 x3 h13 y1e ff3 fs4 fc0 sc0 ls0 ws0">7.1<span class="_ _15"> </span>SIMPLE<span class="_ _27"> </span>RECURRENT<span class="_ _27"> </span>NETWORK</div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">如果加上<span class="_ _c"> </span><span class="ff3">batc<span class="_ _10"></span>h<span class="_ _c"> </span>size<span class="_ _c"> </span><span class="ff1">的话，是这个样子的：</span></span></div><div class="c xb y5ea w17 h44"><div class="t m0 x192 h45 y5eb ff27 fs10 fc6 sc0 ls0 ws0">X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x145 h46 y5ec ff28 fs11 fc6 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 xbe h45 y5eb ff27 fs10 fc6 sc0 ls0 ws0">Y<span class="_ _56"></span>X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x145 h46 y5ec ff28 fs11 fc6 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 xbe h45 y5eb ff27 fs10 fc6 sc0 ls0 ws0">Y</div><div class="t m0 x193 h45 y5ed ff27 fs10 fc6 sc0 ls0 ws0">X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x3 h46 y5ee ff28 fs11 fc6 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 x16a h45 y5ed ff27 fs10 fc6 sc0 ls0 ws0">Y<span class="_ _56"></span>X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x3 h46 y5ee ff28 fs11 fc6 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 x16a h45 y5ed ff27 fs10 fc6 sc0 ls0 ws0">Y</div><div class="t m0 x194 h45 y5ef ff27 fs10 fc6 sc0 ls0 ws0">X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x10d h46 y5f0 ff28 fs11 fc6 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 x137 h45 y5ef ff27 fs10 fc6 sc0 ls0 ws0">Y<span class="_ _56"></span>X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x10d h46 y5f0 ff28 fs11 fc6 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 x137 h45 y5ef ff27 fs10 fc6 sc0 ls0 ws0">Y</div><div class="t m0 x190 h45 y5f1 ff27 fs10 fc6 sc0 ls0 ws0">X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x175 h46 y5f2 ff28 fs11 fc6 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 xc0 h45 y5f1 ff27 fs10 fc6 sc0 ls0 ws0">Y<span class="_ _56"></span>X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x175 h46 y5f2 ff28 fs11 fc6 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 xc0 h45 y5f1 ff27 fs10 fc6 sc0 ls0 ws0">Y</div><div class="t m0 x195 h45 y5f3 ff27 fs10 fc0 sc0 ls0 ws0">X<span class="_ _53"> </span>H<span class="_ _54"> </span>O</div><div class="t m0 x9a h46 y5f4 ff28 fs11 fc0 sc0 ls0 ws0">U<span class="_ _55"> </span>V</div><div class="t m0 x5e h45 y5f3 ff27 fs10 fc0 sc0 ls0 ws0">Y</div><div class="t m0 x3c h45 y5ef ff27 fs10 fc0 sc0 ls0 ws0">L</div><div class="t m2 x18a h47 y5f5 ff29 fs12 fc0 sc0 ls0 ws0">batchsize=5</div></div><div class="t m0 x36 h6 y5f6 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">7.3:<span class="_ _2e"> </span></span>三层神经网络简要示意图<span class="_ _c"> </span><span class="ff3">(batc<span class="_ _10"></span>h<span class="_ _c"> </span>size)</span></div><div class="t m0 x3 h6 y5f7 ff1 fs2 fc0 sc0 ls0 ws0">与<span class="_ _2c"> </span><span class="ff3">DNN </span>不同，<span class="_ _57"></span><span class="ff3">Simple RNN <span class="ff1">是包含循环结构的网络，<span class="_ _49"></span>几乎没有平面图能很好地展示<span class="_ _2c"> </span><span class="ff3">Simple RNN</span></span></span></div><div class="t m0 x3 h6 y5f8 ff1 fs2 fc0 sc0 ls0 ws0">的循环过程，但我尝试画了一张示意图：</div><div class="t m0 x9e h6 y5f9 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">7.4:<span class="_ _2e"> </span>Simple<span class="_ _c"> </span>RNN<span class="_ _c"> </span></span>展开示意图</div><div class="t m0 x3 h6 y5fa ff1 fs2 fc0 sc0 ls0 ws0">图中，<span class="_ _f"></span>正<span class="_ _f"></span>方形<span class="_ _f"></span>单<span class="_ _f"></span>元存<span class="_ _f"></span>在<span class="_ _f"></span>激活<span class="_ _f"></span>函<span class="_ _f"></span>数，而<span class="_ _f"></span>圆<span class="_ _f"></span>形单<span class="_ _f"></span>元<span class="_ _f"></span>则<span class="_ _f"></span>没有<span class="_ _f"></span>激<span class="_ _f"></span>活函<span class="_ _f"></span>数，<span class="_ _f"></span>因此，<span class="_ _f"></span>圆<span class="_ _f"></span>形单<span class="_ _f"></span>元<span class="_ _f"></span>会将<span class="_ _f"></span>输<span class="_ _f"></span>入<span class="_ _f"></span>值直</div><div class="t m0 x3 h6 y5fb ff1 fs2 fc0 sc0 ls0 ws0">接输出，<span class="_ _f"></span>不会对<span class="_ _f"></span>输入的<span class="_ _f"></span>数值作<span class="_ _f"></span>改动。在<span class="_ _f"></span>同一<span class="_ _f"></span>层中，实<span class="_ _f"></span>线和虚<span class="_ _f"></span>线代表<span class="_ _f"></span>着不同<span class="_ _f"></span>的权<span class="_ _f"></span>重矩阵。<span class="_ _f"></span>实际上，</div><div class="t m0 x3 h6 y5fc ff1 fs2 fc0 sc0 ls0 ws0">图<span class="ff3">7.4</span>的输入数据<span class="_ _f"></span>只有一个时<span class="_ _f"></span>间步（<span class="ff3">time<span class="_ _0"> </span>step</span>）<span class="_ _24"></span>，这并没有<span class="_ _f"></span>发挥<span class="_ _0"> </span><span class="ff3">RNN<span class="_ _0"> </span></span>的长处。<span class="ff3">RNN<span class="_ _0"> </span></span>处理的数<span class="_ _f"></span>据</div><div class="t m0 x3 h6 y5fd ff1 fs2 fc0 sc0 ls0 ws0">应该是序列数据，并且具有多个时间步，如图</div><div class="t m0 x5a h6 y5fe ff3 fs2 fc0 sc0 ls0 ws0">7.5<span class="ff1">：</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">44</div><div class="c xce y5ff w18 h48"><div class="t m0 x6f h49 y600 ff2a fs13 fc0 sc0 ls0 ws0">A</div></div><div class="c x37 y601 w19 h4a"><div class="t m0 x18b h4b y602 ff2b fs14 fc0 sc0 ls0 ws0">Description</div><div class="t m0 x18b h4c y603 ff2c fs15 fc0 sc0 ls0 ws0">Round units have no activation</div><div class="t m0 x18b h4c y604 ff2c fs15 fc0 sc0 ls0 ws0">functions.</div><div class="t m0 x18b h4c y605 ff2c fs15 fc0 sc0 ls0 ws0">Square units have activation</div><div class="t m0 x18b h4c y606 ff2c fs15 fc0 sc0 ls0 ws0">function.</div><div class="t m0 x18b h4d y607 ff2d fs15 fc0 sc0 ls0 ws0">Wistherecurrentweightmatrixof</div><div class="t m0 x18b h4d y608 ff2d fs15 fc0 sc0 ls0 ws0">thehiddenlayer<span class="_ _2f"></span>.</div></div><div class="c x95 y609 w1a h4e"><div class="t m0 x18b h4f y60a ff2e fs16 fc0 sc0 ls0 ws0">a sample</div><div class="t m0 x18b h4f y60b ff2e fs16 fc0 sc0 ls0 ws0">input <span class="ff2f">→</span> hidden</div><div class="t m0 x18b h4f y60c ff2e fs16 fc0 sc0 ls0 ws0">hidden <span class="ff2f">→</span> output</div></div><div class="c xce y5ff w18 h48"><div class="t m0 x196 h50 y60d ff30 fs17 fc0 sc0 ls0 ws0">3timesteps</div></div><div class="t m0 xba h6 y60e ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">7.5:<span class="_ _2e"> </span>Simple<span class="_ _c"> </span>RNN<span class="_ _c"> </span></span>展开示意图</div><a class="l" href="#pf31" data-dest-detail='[49,"XYZ",390.16,420.34,null]'><div class="d m1" style="border-style:none;position:absolute;left:122.662500px;bottom:489.750000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf31" data-dest-detail='[49,"XYZ",485.48,93.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:433.572000px;bottom:469.426500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf32" class="pf w0 h0" data-page-no="32"><div class="pc pc32 w0 h0"><img class="bi x3 y60f w2 h51" alt="" src="bg32.png"/><div class="t m0 x5e h13 y1e ff3 fs4 fc0 sc0 ls0 ws0">7.1<span class="_ _15"> </span>SIMPLE<span class="_ _27"> </span>RECURRENT<span class="_ _27"> </span>NETWORK</div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">图<span class="ff3">7.5</span>中展示的样本数据有<span class="_ _c"> </span><span class="ff3">3<span class="_ _c"> </span></span>个时间步，每一个时间步的数据都是<span class="_ _27"> </span><span class="ff3">5<span class="_ _c"> </span></span>维的，也就是说这个样本是</div><div class="t m0 x3 h6 y1ef ff1 fs2 fc0 sc0 ls0 ws0">这样的：</div><div class="c xf5 y610 w1b h52"><div class="t m0 x155 h53 y611 ff31 fs18 fc0 sc0 ls0 ws0">3 time steps</div><div class="t m0 x197 h53 y612 ff31 fs18 fc0 sc0 ls0 ws0">dimensions per time step</div></div><div class="t m0 x3 h6 y613 ff1 fs2 fc0 sc0 ls0 ws0">各个样本时间步数可能不一样，<span class="_ _22"></span>一般而言，<span class="_ _22"></span>在数据预处理时，<span class="_ _28"></span>我们会将所有样本的时间步处理成</div><div class="t m0 x3 h6 y614 ff1 fs2 fc0 sc0 ls0 ws0">等长的。<span class="_ _2f"></span>从图<span class="ff3">7.5</span>可以看出隐藏层<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 xca h16 y615 ff11 fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xea h6 y614 ff1 fs2 fc0 sc0 ls0 ws0">不仅由<span class="_ _c"> </span><span class="ff11">x</span></div><div class="t m0 x8f h16 y615 ff11 fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x24 h6 y614 ff1 fs2 fc0 sc0 ls0 ws0">决定，<span class="_ _2f"></span>也受到<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 xec ha y615 ff11 fs6 fc0 sc0 ls0 ws0">t<span class="ff1f">−<span class="ff1e">1</span></span></div><div class="t m0 xed h6 y614 ff1 fs2 fc0 sc0 ls0 ws0">的影响<span class="_ _10"></span>（<span class="ffa">t<span class="_ _c"> </span></span>代表第<span class="_ _27"> </span><span class="ffa">t<span class="_ _c"> </span></span>个时间</div><div class="t m0 x3 h6 y616 ff1 fs2 fc0 sc0 ls0 ws0">步）<span class="_ _23"></span>，<span class="_ _31"></span>这是<span class="_ _27"> </span><span class="ff3">RNN<span class="_ _c"> </span></span>和<span class="_ _c"> </span><span class="ff3">DNN<span class="_ _27"> </span></span>的不同点，<span class="_ _31"></span>也正是<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _27"> </span></span>循环思想的体现。<span class="_ _2f"></span>而<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _27"> </span></span>的输出层<span class="_ _c"> </span><span class="ff11">O</span></div><div class="t m0 x149 h16 y617 ff11 fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x32 h6 y616 ff1 fs2 fc0 sc0 ls0 ws0">只由</div><div class="t m0 x3 h6 y618 ff1 fs2 fc0 sc0 ls0 ws0">当前时间步的隐藏层<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 x64 h16 y619 ff11 fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xe8 h6 y618 ff1 fs2 fc0 sc0 ls0 ws0">决定，这点和<span class="_ _c"> </span><span class="ff3">DNN<span class="_ _c"> </span></span>是一样的。</div><div class="t m0 x3 h6 y61a ff1 fs2 fc0 sc0 ls0 ws0">对于任意<span class="_ _c"> </span><span class="ffa">t<span class="_ _c"> </span></span>时刻，从输入层到隐藏层，用数学公式表示如下：</div><div class="t m0 x9 h4 y61b ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(<span class="ff11">U</span></span></div><div class="t m0 x8 hb y61c ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x0 h4 y61b ff11 fs2 fc0 sc0 ls0 ws0">X<span class="_ _27"> </span><span class="ffb">+<span class="_ _25"> </span></span>W<span class="_ _2b"> </span>H</div><div class="t m0 xb2 ha y61d ff11 fs6 fc0 sc0 ls0 ws0">t<span class="ff1f">−<span class="ff1e">1</span></span></div><div class="t m0 x41 h4 y61b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff11">B<span class="_ _1f"></span></span>)<span class="_ _2c"> </span>=<span class="_ _27"> </span><span class="ff11">H</span></div><div class="t m0 x17f hb y61d ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb5 h4 y61e ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _32"></span><span class="ffb">(<span class="ff32">□</span></span></div><div class="t m0 x15f hb y61f ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x15f ha y620 ffc fs6 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>3</div><div class="t m0 x14a h54 y61e ff32 fs2 fc0 sc0 ls0 ws0">□</div><div class="t m0 x1f ha y621 ffc fs6 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>1</div><div class="t m0 x10c h4 y61e ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff32">□</span></div><div class="t m0 x8e ha y621 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>3</div><div class="t m0 x5b h54 y61e ff32 fs2 fc0 sc0 ls0 ws0">□</div><div class="t m0 xfc ha y621 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x15b h4 y61e ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff32">□</span></div><div class="t m0 xcc ha y621 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x4f h4 y61e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ff32">□</span></div><div class="t m0 xec ha y621 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x82 h4 y61e ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y622 ff1 fs2 fc0 sc0 ls0 ws0">其中，<span class="_ _31"></span><span class="ff11">U<span class="_ _2e"> </span><span class="ff1">是输入层到隐藏层的权重矩阵，<span class="_ _31"></span><span class="ff11">W<span class="_ _b"> </span><span class="ff1">是隐藏层的循环权重矩阵。<span class="_ _2f"></span>隐藏层到输出层的公式</span></span></span></span></div><div class="t m0 x3 h6 y623 ff1 fs2 fc0 sc0 ls0 ws0">为：</div><div class="t m0 xa8 h4 y624 ffa fs2 fc0 sc0 ls0 ws0">g<span class="_ _f"></span><span class="ffb">(<span class="ff11">V</span></span></div><div class="t m0 x8d hb y625 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 xf9 h21 y624 ff11 fs2 fc0 sc0 ls0 ws0">H</div><div class="t m0 x104 h16 y626 ff11 fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x99 h4 y624 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff11">C<span class="_ _4c"></span></span>)<span class="_ _2c"> </span>=<span class="_ _27"> </span><span class="ff11">O</span></div><div class="t m0 x186 h16 y626 ff11 fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x148 h4 y627 ffa fs2 fc0 sc0 ls0 ws0">g<span class="_ _f"></span><span class="ffb">(<span class="ff32">□</span></span></div><div class="t m0 x1c hb y628 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x1c ha y629 ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>2</div><div class="t m0 xbb h54 y627 ff32 fs2 fc0 sc0 ls0 ws0">□</div><div class="t m0 x150 ha y62a ffc fs6 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x5a h4 y627 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ff32">□</span></div><div class="t m0 x91 ha y62a ffc fs6 fc0 sc0 ls0 ws0">2<span class="ff12">×</span>1</div><div class="t m0 x16a h4 y627 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span><span class="ff32">□</span></div><div class="t m0 x186 ha y62a ffc fs6 fc0 sc0 ls0 ws0">2<span class="ff12">×</span>1</div><div class="t m0 x3 h6 y62b ff11 fs2 fc0 sc0 ls0 ws0">U<span class="_ _32"> </span><span class="ff1">、</span>W<span class="_ _6"> </span><span class="ff1">和<span class="_ _c"> </span></span>V<span class="_ _4d"> </span><span class="ff1">三个权重矩阵和传播过程中是权值共享的。</span></div><div class="t m0 x1e h6 y62c ff1 fs2 fc0 sc0 ls0 ws0">权值共享是指<span class="_ _27"> </span><span class="ff11">U<span class="_ _32"> </span></span>、<span class="_ _22"></span><span class="ff11">W<span class="_ _2e"> </span><span class="ff1">和<span class="_ _27"> </span></span>V<span class="_ _9"> </span><span class="ff1">三个权重矩阵在前向传播的过程中不会改变，<span class="_ _28"></span>不同时间步所使</span></span></div><div class="t m0 x1e h6 y62d ff1 fs2 fc0 sc0 ls0 ws0">用的权重矩阵都是一样的。</div><div class="t m0 x3 h6 y62e ff1 fs2 fc0 sc0 ls0 ws0">将<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _c"> </span></span>每一层用一个单元表示，并加上<span class="_ _c"> </span><span class="ff3">batc<span class="_ _10"></span>h<span class="_ _c"> </span>size<span class="ff1">，可以得到以下图示：</span></span></div><div class="c x187 y62f w1c h55"><div class="t m0 xbd h56 y630 ff33 fs19 fc0 sc0 ls0 ws0">L</div><div class="t m0 x5 h56 y631 ff33 fs19 fc7 sc0 ls0 ws0">X</div><div class="t m0 xe3 h57 y632 ff34 fs1a fc7 sc0 ls0 ws0">U<span class="_ _58"> </span>V</div><div class="t m0 x4d h56 y631 ff33 fs19 fc7 sc0 ls0 ws0">Y<span class="_ _59"></span>H<span class="_ _3f"> </span>O<span class="_ _5a"></span>X<span class="_ _5b"></span>X</div><div class="t m0 xdc h57 y633 ff34 fs1a fc7 sc0 ls0 ws0">W</div><div class="t m0 x180 h56 y634 ff33 fs19 fc7 sc0 ls0 ws0">X</div><div class="t m0 x67 h57 y635 ff34 fs1a fc7 sc0 ls0 ws0">U<span class="_ _58"> </span>V</div><div class="t m0 xd6 h56 y634 ff33 fs19 fc7 sc0 ls0 ws0">Y<span class="_ _59"></span>H<span class="_ _3f"> </span>O<span class="_ _5a"></span>X<span class="_ _5b"></span>X</div><div class="t m0 x13 h57 y636 ff34 fs1a fc7 sc0 ls0 ws0">W</div><div class="t m0 x116 h56 y637 ff33 fs19 fc7 sc0 ls0 ws0">X</div><div class="t m0 x198 h57 y638 ff34 fs1a fc7 sc0 ls0 ws0">U<span class="_ _58"> </span>V</div><div class="t m0 xab h56 y637 ff33 fs19 fc7 sc0 ls0 ws0">Y<span class="_ _59"></span>H<span class="_ _3f"> </span>O<span class="_ _5a"></span>X<span class="_ _5b"></span>X</div><div class="t m0 x37 h57 y639 ff34 fs1a fc7 sc0 ls0 ws0">W</div><div class="t m0 x9b h56 y63a ff33 fs19 fc7 sc0 ls0 ws0">X</div><div class="t m0 x11e h57 y63b ff34 fs1a fc7 sc0 ls0 ws0">U<span class="_ _58"> </span>V</div><div class="t m0 x42 h56 y63a ff33 fs19 fc7 sc0 ls0 ws0">Y<span class="_ _59"></span>H<span class="_ _3f"> </span>O<span class="_ _5a"></span>X<span class="_ _5b"></span>X</div><div class="t m0 xd0 h57 y63c ff34 fs1a fc7 sc0 ls0 ws0">W</div><div class="t m0 x33 h56 y63d ff33 fs19 fc7 sc0 ls0 ws0">X</div><div class="t m0 x118 h57 y63e ff34 fs1a fc7 sc0 ls0 ws0">U<span class="_ _58"> </span>V</div><div class="t m0 x142 h56 y63d ff33 fs19 fc7 sc0 ls0 ws0">Y<span class="_ _59"></span>H<span class="_ _3f"> </span>O<span class="_ _5a"></span>X<span class="_ _5b"></span>X</div><div class="t m0 x75 h57 y63f ff34 fs1a fc7 sc0 ls0 ws0">W</div><div class="t m0 x109 h56 y630 ff33 fs19 fc0 sc0 ls0 ws0">X</div><div class="t m0 x199 h57 y640 ff34 fs1a fc0 sc0 ls0 ws0">U<span class="_ _58"> </span>V</div><div class="t m0 x65 h56 y630 ff33 fs19 fc0 sc0 ls0 ws0">Y<span class="_ _59"></span>H<span class="_ _3f"> </span>O<span class="_ _5c"></span>X<span class="_ _5b"></span>X</div><div class="t m0 x16f h57 y641 ff34 fs1a fc0 sc0 ls0 ws0">W</div><div class="t m0 x190 h58 y642 ff35 fs1b fc0 sc0 ls0 ws0">batchsize=5</div></div><div class="t m0 x3 h12 y643 ff6 fs7 fc0 sc0 ls0 ws0">7.1.2<span class="_ _36"> </span><span class="ff9">反向传播</span></div><div class="t m0 x3 h6 y644 ff1 fs2 fc0 sc0 ls0 ws0">与<span class="_ _c"> </span><span class="ff3">DNN<span class="_ _c"> </span></span>一致，<span class="_ _10"></span><span class="ff3">RNN<span class="_ _c"> </span><span class="ff1">也是通过梯度下降的方法来寻找<span class="_ _c"> </span></span>U<span class="ff1">、<span class="_ _10"></span><span class="ff3">V<span class="ff1">、<span class="_ _10"></span><span class="ff3">W<span class="_ _c"> </span><span class="ff1">这三个参数的最优解，此处我</span></span></span></span></span></span></div><div class="t m0 x3 h6 y645 ff1 fs2 fc0 sc0 ls0 ws0">们考虑较复杂的<span class="_ _27"> </span><span class="ff3">Many to<span class="_ _c"> </span>Man<span class="_ _2f"></span>y<span class="_ _c"> </span><span class="ff1">形式，<span class="_ _22"></span>损失函数暂定为<span class="_ _27"> </span><span class="ff3">MSE<span class="_ _27"> </span></span>损失函数，<span class="_ _31"></span>由于序列的每个位置都</span></span></div><div class="t m0 x3 h6 y646 ff1 fs2 fc0 sc0 ls0 ws0">有损失函数，因此最终损失为：</div><div class="t m0 x133 h4 y647 ffa fs2 fc0 sc0 ls0 ws0">L<span class="_ _2c"> </span><span class="ffb">=</span></div><div class="t m0 x147 hb y648 ffd fs6 fc0 sc0 ls0 ws0">τ</div><div class="t m0 x17d he y649 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x147 ha y64a ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xb2 hc y647 ffa fs2 fc0 sc0 ls0 ws0">L</div><div class="t m0 xbe hb y64b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x32 h4 y647 ff3 fs2 fc0 sc0 ls0 ws0">(7.1)</div><div class="t m0 x3 h6 y64c ff1 fs2 fc0 sc0 ls0 ws0">假定我们最终的损失函数为<span class="_ _c"> </span><span class="ffa">L</span>，这里假设为<span class="_ _c"> </span><span class="ffa">M<span class="_ _32"></span>S<span class="_ _1f"></span>E<span class="_ _1f"></span></span>，即：</div><div class="t m0 xa9 h4 y64d ffa fs2 fc0 sc0 ls0 ws0">L<span class="_ _2c"> </span><span class="ffb">=</span></div><div class="t m0 x146 h4 y64e ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x146 h4 y64f ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbc h1f y650 ff16 fs6 fc0 sc0 ls0 ws0">output</div><div class="t m0 x17b he y651 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x1 ha y652 ffd fs6 fc0 sc0 ls0 ws0">j<span class="_ _f"></span><span class="ffc">=1</span></div><div class="t m0 x138 he y653 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa0 h4 y64d ffb fs2 fc0 sc0 ls0 ws0">ˆ<span class="_ _5d"></span><span class="ffa">y</span></div><div class="t m0 xaa hb y654 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x13e hb y655 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x26 h4 y64d fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 x142 hb y654 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x5e hb y655 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x65 he y653 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5f ha y656 ffc fs6 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">45</div><a class="l" href="#pf31" data-dest-detail='[49,"XYZ",485.48,93.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:122.662500px;bottom:1177.872000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf31" data-dest-detail='[49,"XYZ",485.48,93.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:203.844000px;bottom:964.323000px;width:13.941000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf33" class="pf w0 h0" data-page-no="33"><div class="pc pc33 w0 h0"><img class="bi xc3 y657 w8 h59" alt="" src="bg33.png"/><div class="t m0 x3 h13 y1e ff3 fs4 fc0 sc0 ls0 ws0">7.2<span class="_ _15"> </span>LSTM</div><div class="t m0 x3 h5a y658 ff9 fs1c fc0 sc0 ls0 ws0">输出层</div><div class="t m0 xa5 hc y659 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>L</div><div class="t m0 x154 h4 y65a ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _32"> </span><span class="ffb">ˆ<span class="_ _5d"></span><span class="ffa">y</span></span></div><div class="t m0 xb9 hb y65b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xf5 h4 y65c ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xa9 hc y659 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>L</div><div class="t m0 xc5 hc y65a ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>L</div><div class="t m0 x8 hb y65b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xbb hc y659 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>L</div><div class="t m0 xbc hb y65d ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x0 h4 y65a ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _32"> </span><span class="ffb">ˆ<span class="_ _5d"></span><span class="ffa">y</span></span></div><div class="t m0 xbc hb y65b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x3f h4 y65c ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>1<span class="_ _25"> </span><span class="fff">×</span></div><div class="t m0 xaa hc y659 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>L</div><div class="t m0 x137 ha y65d ffc fs6 fc0 sc0 ls0 ws0">(<span class="ffd">t</span>)</div><div class="t m0 xd4 hc y65e ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _1f"></span>o</div><div class="t m0 x12e ha y65f ffc fs6 fc0 sc0 ls0 ws0">(<span class="ffd">t</span>)</div><div class="t m0 x143 h4 y65c ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _c"> </span>ˆ<span class="_ _5d"></span><span class="ffa">y</span></div><div class="t m0 x139 hb y660 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x96 h4 y65c fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _33"> </span><span class="ffa">y</span></div><div class="t m0 xe2 hb y660 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x32 h4 y65c ff3 fs2 fc0 sc0 ls0 ws0">(7.2)</div><div class="t m0 x3 h6 y661 ff1 fs2 fc0 sc0 ls0 ws0">关于<span class="_ _c"> </span><span class="ff11">W</span></div><div class="t m0 x13d h16 y662 ff11 fs6 fc0 sc0 ls0 ws0">O</div><div class="t m0 x117 h6 y661 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _c"> </span><span class="ff11">B</span></div><div class="t m0 x69 h16 y662 ff11 fs6 fc0 sc0 ls0 ws0">O</div><div class="t m0 x173 h6 y661 ff1 fs2 fc0 sc0 ls0 ws0">的梯度计算如下：</div><div class="t m0 x3 h5b y663 ff6 fs7 fc0 sc0 ls0 ws0">7.1.3<span class="_ _36"> </span>title</div><div class="t m0 xb1 h37 y664 ff6 fs5 fc0 sc0 ls0 ws0">7.2<span class="_ _21"> </span>LSTM</div><div class="t m0 x3 h12 y665 ff6 fs7 fc0 sc0 ls0 ws0">7.2.1<span class="_ _36"> </span>LSTM<span class="_ _6"> </span><span class="ff9">概述</span></div><div class="t m0 x3 h6 y666 ff1 fs2 fc0 sc0 ls0 ws0">传统<span class="_ _27"> </span><span class="ff3">RNN<span class="_ _c"> </span></span>模型容易产生梯度消失的问题，<span class="_ _31"></span>难以处理长序列的数据。<span class="_ _31"></span>而造成梯度消失的原因，<span class="_ _31"></span>本</div><div class="t m0 x3 h6 y667 ff1 fs2 fc0 sc0 ls0 ws0">质<span class="_ _f"></span>上<span class="_ _f"></span>是<span class="_ _f"></span>因<span class="_ _f"></span>为<span class="_ _1f"></span>隐<span class="_ _f"></span>藏<span class="_ _f"></span>层<span class="_ _f"></span>状<span class="_ _f"></span>态<span class="_ _2e"> </span><span class="ffa">H</span></div><div class="t m0 x19a hb y668 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x83 h6 y667 ff1 fs2 fc0 sc0 ls0 ws0">的<span class="_ _f"></span>计<span class="_ _f"></span>算<span class="_ _f"></span>方<span class="_ _f"></span>式<span class="_ _1f"></span>导<span class="_ _f"></span>致<span class="_ _f"></span>梯<span class="_ _f"></span>度<span class="_ _f"></span>被<span class="_ _f"></span>表<span class="_ _1f"></span>示<span class="_ _f"></span>为<span class="_ _f"></span>连<span class="_ _f"></span>乘<span class="_ _f"></span>积<span class="_ _f"></span>的<span class="_ _1f"></span>形<span class="_ _f"></span>式，<span class="_ _f"></span>因<span class="_ _f"></span>此<span class="_ _2e"> </span><span class="ff3">Ho<span class="_ _f"></span>chreater<span class="_ _2e"> </span></span>和</div><div class="t m0 x3 h6 y669 ff3 fs2 fc0 sc0 ls0 ws0">Sc<span class="_ _10"></span>hmidh<span class="_ _10"></span>ub<span class="_ _f"></span>er<span class="_ _27"> </span><span class="ff1">在<span class="_ _c"> </span></span>1997 <span class="ff1">年提出了长短期记忆网络<span class="_ _c"> </span></span>LSTM<span class="ff1">，<span class="_ _28"></span>通过精心设计的隐藏层神经元缓解了传</span></div><div class="t m0 x3 h6 y66a ff1 fs2 fc0 sc0 ls0 ws0">统<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _c"> </span></span>的梯度消失问题。</div><div class="t m0 x3 h12 y66b ff6 fs7 fc0 sc0 ls0 ws0">7.2.2<span class="_ _36"> </span>LSTM<span class="_ _6"> </span><span class="ff9">与<span class="_ _7"> </span></span>RNN<span class="_ _7"> </span><span class="ff9">的区别</span></div><div class="t m0 x3 h6 y66c ff1 fs2 fc0 sc0 ls0 ws0">如果我们略去<span class="_ _25"> </span><span class="ff3">RNN<span class="_ _25"> </span></span>网络的输出层和损失函数，<span class="_ _34"></span>那么模型可以简化为如图<span class="ff3">7.6</span>的形式<span class="_ _49"></span>（只保留<span class="_ _25"> </span><span class="ff3">RNN</span></div><div class="t m0 x3 h6 y66d ff1 fs2 fc0 sc0 ls0 ws0">的隐藏层）<span class="_ _23"></span>，<span class="_ _2f"></span>通过线条指示的路径可以清晰地看出隐藏状态<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 x61 hb y66e ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x156 h6 y66d ff1 fs2 fc0 sc0 ls0 ws0">由<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 xa4 ha y66e ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x13f h6 y66d ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _c"> </span><span class="ff11">x</span></div><div class="t m0 x14d hb y66e ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x76 h6 y66d ff1 fs2 fc0 sc0 ls0 ws0">共同决定。<span class="_ _2f"></span><span class="ff11">H</span></div><div class="t m0 x105 hb y66e ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb3 h6 y66d ff1 fs2 fc0 sc0 ls0 ws0">一</div><div class="t m0 x3 h6 y66f ff1 fs2 fc0 sc0 ls0 ws0">方面是<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _c"> </span></span>层当前的输出，另一方面用于计算<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 x15a ha y670 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ffc">+1</span></div><div class="t m0 x48 h6 y671 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">7.6:<span class="_ _2e"> </span>RNN<span class="_ _c"> </span></span>隐藏层</div><div class="t m0 x3 h6 y672 ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _1c"> </span><span class="ff1">和<span class="_ _2e"> </span></span>RNN<span class="_ _1c"> </span><span class="ff1">区<span class="_ _f"></span>别<span class="_ _f"></span>在<span class="_ _f"></span>于<span class="_ _f"></span>隐<span class="_ _f"></span>藏<span class="_ _f"></span>层<span class="_ _f"></span>的<span class="_ _f"></span>不<span class="_ _f"></span>同。<span class="_ _f"></span>虽<span class="_ _f"></span>然<span class="_ _1c"> </span></span>LSTM<span class="_ _2e"> </span><span class="ff1">也有<span class="_ _f"></span>这<span class="_ _f"></span>种<span class="_ _f"></span>链<span class="_ _f"></span>状<span class="_ _f"></span>结<span class="_ _f"></span>构，<span class="_ _f"></span>不<span class="_ _f"></span>过<span class="_ _f"></span>其<span class="_ _f"></span>循<span class="_ _f"></span>环<span class="_ _f"></span>结<span class="_ _f"></span>构<span class="_ _f"></span>和</span></div><div class="t m0 x3 h6 y673 ff3 fs2 fc0 sc0 ls0 ws0">RNN<span class="_ _c"> </span><span class="ff1">不同。</span>LSTM<span class="_ _c"> </span><span class="ff1">的循环结构中有<span class="_ _c"> </span></span>4<span class="_ _c"> </span><span class="ff1">个神经网络层，并且他们之间的交互非常特别。</span></div><div class="t m0 x106 h6 y674 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">7.7:<span class="_ _2e"> </span>LSTM<span class="_ _c"> </span></span>隐藏层</div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">可以发现，<span class="_ _10"></span><span class="ff3">LSTM<span class="_ _c"> </span><span class="ff1">和<span class="_ _c"> </span></span>RNN<span class="_ _c"> </span><span class="ff1">的隐藏层都只有一个输出，<span class="_ _10"></span>就是<span class="_ _c"> </span><span class="ff11">H</span></span></span></div><div class="t m0 xe1 hb y675 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x29 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _10"></span>并且<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 x7b hb y675 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x125 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">都参与了下一时刻的</div><div class="t m0 x3 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">前向传播。<span class="_ _2f"></span>但除了<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 x12f hb y97 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x113 h6 y1d ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _31"></span><span class="ff3">LSTM<span class="_ _c"> </span><span class="ff1">还有一个隐藏状态也参与了前向传播，<span class="_ _2f"></span>但这个隐藏状态没有被输</span></span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">46</div><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",458.19,312.33,null]'><div class="d m1" style="border-style:none;position:absolute;left:616.666500px;bottom:683.982000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf34" class="pf w0 h0" data-page-no="34"><div class="pc pc34 w0 h0"><img class="bi x75 y676 w3 h5c" alt="" src="bg34.png"/><div class="t m0 x2f h13 y1e ff3 fs4 fc0 sc0 ls0 ws0">7.2<span class="_ _15"> </span>LSTM</div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">出。我们称这个隐藏状态<span class="_ _f"></span>为细胞状态<span class="_ _c"> </span><span class="ff11">C</span></div><div class="t m0 x10c hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xbb h6 y1f ff3 fs2 fc0 sc0 ls0 ws0">(Cell<span class="_ _c"> </span>State)<span class="ff1">。<span class="ff11">C</span></span></div><div class="t m0 x5e hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xd5 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">在<span class="_ _c"> </span><span class="ff3">LSTM<span class="_ _c"> </span></span>中实<span class="_ _f"></span>质上起到了<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _0"> </span></span>中隐</div><div class="t m0 x3 h6 y1ef ff1 fs2 fc0 sc0 ls0 ws0">藏状态<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 x135 hb y677 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x198 h6 y1ef ff1 fs2 fc0 sc0 ls0 ws0">的作用。</div><div class="t m0 x3 h6 y1f0 ff1 fs2 fc0 sc0 ls0 ws0">除了<span class="_ _c"> </span><span class="ff11">H</span></div><div class="t m0 x7a hb y678 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb h6 y1f0 ff1 fs2 fc0 sc0 ls0 ws0">和细胞状态<span class="_ _c"> </span><span class="ff11">C</span></div><div class="t m0 x153 hb y678 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xe7 h6 y1f0 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _31"></span>图中还有三个结构，<span class="_ _2f"></span>这些结构一般称之为门控结构<span class="_ _c"> </span><span class="ff3">(Gate)</span>。<span class="_ _2f"></span><span class="ff3">LSTM<span class="_ _c"> </span><span class="ff1">的</span></span></div><div class="t m0 x3 h6 y1f1 ff1 fs2 fc0 sc0 ls0 ws0">门控结构一般包括遗忘门，输入门和输出门三种，这三个门结构都是用来控制<span class="_ _c"> </span><span class="ff11">C</span></div><div class="t m0 xf1 hb y1f2 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x2d h6 y1f1 ff1 fs2 fc0 sc0 ls0 ws0">的状态。</div><div class="t m0 x3c h6 y679 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _c"> </span><span class="ff3">7.8:<span class="_ _2e"> </span>cell<span class="_ _c"> </span>state</span></div><div class="t m0 x3 h6 y67a ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _c"> </span><span class="ff1">的关键是细胞状态<span class="_ _27"> </span><span class="ff11">C</span></span></div><div class="t m0 x83 hb y67b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xa2 h6 y67a ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _2f"></span><span class="ff11">C</span></div><div class="t m0 x15d hb y67b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x166 h6 y67a ff1 fs2 fc0 sc0 ls0 ws0">横穿整个<span class="_ _c"> </span><span class="ff3">LSTM<span class="_ _27"> </span></span>单元顶部的水平线。<span class="_ _10"></span><span class="ff3">LSTM<span class="_ _c"> </span><span class="ff1">通过门结构对细</span></span></div><div class="t m0 x3 h6 y67c ff1 fs2 fc0 sc0 ls0 ws0">胞状态<span class="_ _f"></span>添加<span class="_ _f"></span>或者删<span class="_ _f"></span>除信<span class="_ _f"></span>息。门<span class="_ _f"></span>是一种<span class="_ _f"></span>选择<span class="_ _f"></span>性让<span class="_ _f"></span>信息通<span class="_ _f"></span>过的<span class="_ _f"></span>方法。<span class="_ _f"></span>它们由<span class="_ _f"></span>一个<span class="_ _11"> </span><span class="ff3">Sigmoid<span class="_ _11"> </span></span>神经网<span class="_ _f"></span>络</div><div class="t m0 x3 h6 y67d ff1 fs2 fc0 sc0 ls0 ws0">层和一个元素级相乘操作组成。</div><div class="t m0 x3 h6 y67e ff1 fs2 fc0 sc0 ls0 ws0">在开始之介绍<span class="_ _c"> </span><span class="ff3">LSTM<span class="_ _c"> </span></span>各个门结构前，我们先介绍一下将用到的标记。</div><div class="t m0 x3 h6 y67f ff1 fs2 fc0 sc0 ls0 ws0">在上图中，<span class="_ _22"></span>每条线表示向量的传递，<span class="_ _28"></span>从一个结点的输出传递到另外结点的输入。<span class="_ _22"></span>粉红圆表示向量</div><div class="t m0 x3 h6 y680 ff1 fs2 fc0 sc0 ls0 ws0">的元素级操作，<span class="_ _22"></span>比如相加或者相乘。<span class="_ _31"></span>黄色方框表示神经网络的层。<span class="_ _31"></span>线合并表示向量的连接，<span class="_ _22"></span>线分</div><div class="t m0 x3 h6 y681 ff1 fs2 fc0 sc0 ls0 ws0">叉表示向量复制。接下来按运算顺序介绍<span class="_ _c"> </span><span class="ff3">LSTM<span class="_ _c"> </span></span>的三个门结构。</div><div class="t m0 x3 h12 y682 ff6 fs7 fc0 sc0 ls0 ws0">7.2.3<span class="_ _36"> </span><span class="ff9">遗忘门</span></div><div class="t m0 x3 h6 y683 ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _c"> </span><span class="ff1">的第一步是决定我们将要从细胞状态中扔掉哪些信息。<span class="_ _2f"></span>该决定由一个叫做<span class="_ _10"></span>“遗忘门<span class="_ _c"> </span><span class="ff3">(F<span class="_ _31"></span>or-</span></span></div><div class="t m0 x3 h4 y684 ff3 fs2 fc0 sc0 ls0 ws0">get<span class="_ _c"> </span>Gate)</div><div class="t m0 xe3 h6 y685 ff1 fs2 fc0 sc0 ls0 ws0">”<span class="_ _10"></span>的</div><div class="t m0 xdb h4 y684 ff3 fs2 fc0 sc0 ls0 ws0">Sigmoid</div><div class="t m0 x64 h6 y685 ff1 fs2 fc0 sc0 ls0 ws0">层控制。</div><div class="t m0 x3a h21 y684 ff11 fs2 fc0 sc0 ls0 ws0">H</div><div class="t m0 xa ha y686 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x10a h6 y685 ff1 fs2 fc0 sc0 ls0 ws0">和</div><div class="t m0 x17a h21 y684 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x4 hb y686 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x19b h6 y685 ff1 fs2 fc0 sc0 ls0 ws0">被输入遗忘门，<span class="_ _2f"></span>经过</div><div class="t m0 xde h4 y684 ff3 fs2 fc0 sc0 ls0 ws0">Sigmoid</div><div class="t m0 x125 h6 y685 ff1 fs2 fc0 sc0 ls0 ws0">激活函数，<span class="_ _2f"></span>输出一个</div><div class="t m0 x3 h6 y687 ff1 fs2 fc0 sc0 ls0 ws0">向量<span class="_ _c"> </span><span class="ffa">f</span></div><div class="t m0 x33 hb y688 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x78 h6 y687 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="ffa">f</span></div><div class="t m0 x67 hb y688 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x11e h6 y687 ff1 fs2 fc0 sc0 ls0 ws0">的元素与<span class="_ _c"> </span><span class="ff11">C</span></div><div class="t m0 xae ha y688 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xe9 h6 y687 ff1 fs2 fc0 sc0 ls0 ws0">的元素一一对应，并且<span class="_ _0"> </span><span class="ffa">f</span></div><div class="t m0 x26 hb y688 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x137 h6 y687 ff1 fs2 fc0 sc0 ls0 ws0">的元素都是<span class="_ _c"> </span><span class="ffb">0<span class="_ _27"> </span><span class="fff">∼<span class="_ _27"> </span></span>1<span class="_ _0"> </span></span>之间的数，<span class="ff3">1<span class="_ _c"> </span></span>表示“完</div><div class="t m0 x3 h6 y689 ff1 fs2 fc0 sc0 ls0 ws0">全保留该信息”<span class="_ _23"></span>，<span class="_ _31"></span><span class="ff3">0<span class="_ _27"> </span><span class="ff1">表示<span class="_ _2f"></span>“完全丢弃该信息”<span class="_ _23"></span>。<span class="_ _31"></span>即遗忘门以一定的概率控制是否遗忘上一个时刻的</span></span></div><div class="t m0 x3 h6 y68a ff1 fs2 fc0 sc0 ls0 ws0">细胞状态。</div><div class="t m0 xf5 hc y68b ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 x166 hb y68c ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x1f h4 y68b ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">σ<span class="_ _33"> </span></span>(<span class="ffa">W</span></div><div class="t m0 xbc hb y68d ffd fs6 fc0 sc0 ls0 ws0">f</div><div class="t m0 x17b hc y68b ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa3 ha y68c ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x138 h4 y68b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y68d ffd fs6 fc0 sc0 ls0 ws0">f</div><div class="t m0 x12e hc y68b ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x42 hb y68c ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x62 h4 y68b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x50 hb y68d ffd fs6 fc0 sc0 ls0 ws0">f</div><div class="t m0 x13b h4 y68b ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _5e"> </span><span class="ff3">(7.3)</span></div><div class="t m0 x3 h12 y68e ff6 fs7 fc0 sc0 ls0 ws0">7.2.4<span class="_ _36"> </span><span class="ff9">输入门</span></div><div class="t m0 x3 h6 y28a ff1 fs2 fc0 sc0 ls0 ws0">第二步是决定我们将会把哪些新信息存储到元胞状态中。这步分为两部分：</div><div class="t m0 x9a h6 y1d ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">首先，有一个叫做“输入门<span class="_ _c"> </span></span>(Input<span class="_ _c"> </span>Gate)<span class="ff1">”的<span class="_ _c"> </span></span>Sigmoid<span class="_ _c"> </span><span class="ff1">层决定我们要更新哪些信息。</span></div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">47</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf35" class="pf w0 h0" data-page-no="35"><div class="pc pc35 w0 h0"><div class="t m0 x3 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">7.3<span class="_ _15"> </span><span class="ff8">带窥孔的<span class="_ _27"> </span></span>LSTM</div><div class="t m0 x9a h6 y1f ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _6"> </span><span class="ff1">接下来，一个<span class="_ _c"> </span></span>tanh<span class="_ _c"> </span><span class="ff1">层创造了一个新的候选值</span></div><div class="t m0 x13a h4 y68f ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 xd4 hc y1f ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 x16a hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x12e h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">，该值可能被加入到元胞状态中。</div><div class="t m0 x3 h6 y3c ff1 fs2 fc0 sc0 ls0 ws0">在第三步中，<span class="ff3">LSTM<span class="_ _c"> </span></span>把这两个值组合起来用于更新元胞状态。</div><div class="t m0 x3b hc y690 ffa fs2 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa hb y691 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xa9 h4 y690 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">σ<span class="_ _33"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x8e hb y691 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1 hc y690 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x163 ha y691 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x138 h4 y690 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y691 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 xbf hc y690 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x92 hb y691 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x142 h4 y690 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 xf7 hb y691 ffd fs6 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4f h4 y690 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _5f"> </span><span class="ff3">(7.4)</span></div><div class="t m0 x39 h4 y692 ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x160 hc y693 ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 x45 hb y694 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xc2 h4 y693 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ff3">tanh<span class="_ _2d"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x1 hb y695 ffd fs6 fc0 sc0 ls0 ws0">C</div><div class="t m0 x5a hc y693 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x40 ha y694 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xb2 h4 y693 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">U</span></div><div class="t m0 xab hb y695 ffd fs6 fc0 sc0 ls0 ws0">C</div><div class="t m0 x5e hc y693 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x60 hb y694 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x151 h4 y693 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x96 hb y695 ffd fs6 fc0 sc0 ls0 ws0">C</div><div class="t m0 x14e h4 y693 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _60"> </span><span class="ff3">(7.5)</span></div><div class="t m0 x3 h12 y696 ff6 fs7 fc0 sc0 ls0 ws0">7.2.5<span class="_ _36"> </span><span class="ff9">细胞状态更新</span></div><div class="t m0 x3 h6 y697 ff1 fs2 fc0 sc0 ls0 ws0">现在我们该将旧细胞状态<span class="_ _c"> </span><span class="ff11">C</span></div><div class="t m0 xe9 ha y698 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x39 h6 y697 ff1 fs2 fc0 sc0 ls0 ws0">更新到新状态<span class="_ _c"> </span><span class="ff11">C</span></div><div class="t m0 x24 hb y698 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x5d h6 y697 ff1 fs2 fc0 sc0 ls0 ws0">了。上面的步骤中已经决定了该怎么做，<span class="_ _10"></span>这一</div><div class="t m0 x3 h6 y699 ff1 fs2 fc0 sc0 ls0 ws0">步我们只需要实际执行即可。</div><div class="t m0 xca hc y69a ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 xea hb y69b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x10a h4 y69a ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">C</span></div><div class="t m0 xfa ha y69b ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x8f h4 y69a fff fs2 fc0 sc0 ls0 ws0">⊙<span class="_ _33"> </span><span class="ffa">f</span></div><div class="t m0 x5d hb y69b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb2 h4 y69a ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">i</span></div><div class="t m0 xd6 hb y69b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xc0 h4 y69a fff fs2 fc0 sc0 ls0 ws0">⊙</div><div class="t m0 x5f h4 y69c ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x60 hc y69a ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 xe0 hb y69b ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x32 h4 y69a ff3 fs2 fc0 sc0 ls0 ws0">(7.6)</div><div class="t m0 x3 h6 y69d fff fs2 fc0 sc0 ls0 ws0">⊙<span class="_ _c"> </span><span class="ff1">是矩阵的<span class="_ _0"> </span><span class="ff3">Hadamard<span class="_ _c"> </span></span>积<span class="_ _c"> </span><span class="ff3">(</span>两个矩<span class="_ _f"></span>阵相同位置元素的乘积<span class="ff3">)</span>。新<span class="_ _f"></span>状态即为旧状态乘以需要<span class="_ _f"></span>忘记的</span></div><div class="t m0 x3 h6 y69e ff1 fs2 fc0 sc0 ls0 ws0">概率，加上新的候选值乘以需要更新的比率。</div><div class="t m0 x3 h12 y69f ff6 fs7 fc0 sc0 ls0 ws0">7.2.6<span class="_ _36"> </span><span class="ff9">输出门</span></div><div class="t m0 x3 h6 y6a0 ff1 fs2 fc0 sc0 ls0 ws0">最后，<span class="_ _22"></span>我们需要决定最终的输出。<span class="_ _31"></span>输出将会基于目前的细胞状态，<span class="_ _31"></span>并且会加入一些过滤。<span class="_ _22"></span>首先我</div><div class="t m0 x3 h6 y6a1 ff1 fs2 fc0 sc0 ls0 ws0">们建立一个<span class="_ _27"> </span><span class="ff3">Sigmoid<span class="_ _27"> </span></span>层的输出门<span class="_ _c"> </span><span class="ff3">(Output Gate)</span>，<span class="_ _22"></span>来决定我们将输出元胞的哪些部分。<span class="_ _22"></span>然后我们</div><div class="t m0 x3 h6 y6a2 ff1 fs2 fc0 sc0 ls0 ws0">将元胞状态通过<span class="_ _c"> </span><span class="ff3">tanh<span class="_ _c"> </span></span>之后（使得输<span class="_ _f"></span>出值在<span class="ff3">-1<span class="_ _c"> </span></span>到<span class="_ _c"> </span><span class="ff3">1<span class="_ _c"> </span></span>之间）<span class="_ _30"></span>，与输出门相乘，这样我们只会输出我</div><div class="t m0 x3 h6 y6a3 ff1 fs2 fc0 sc0 ls0 ws0">们想输出的部分。</div><div class="t m0 x16e hc y6a4 ffa fs2 fc0 sc0 ls0 ws0">o</div><div class="t m0 x9 hb y6a5 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x87 h4 y6a4 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">σ<span class="_ _33"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x4 hb y6a5 ffd fs6 fc0 sc0 ls0 ws0">o</div><div class="t m0 x1 hc y6a4 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x163 ha y6a5 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x138 h4 y6a4 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y6a5 ffd fs6 fc0 sc0 ls0 ws0">o</div><div class="t m0 x12e hc y6a4 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x42 hb y6a5 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xcc h4 y6a4 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x50 hb y6a5 ffd fs6 fc0 sc0 ls0 ws0">o</div><div class="t m0 x139 h4 y6a4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _61"> </span><span class="ff3">(7.7)</span></div><div class="t m0 x19c hc y6a6 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x8 hb y6a7 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x0 h4 y6a6 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">o</span></div><div class="t m0 x8d hb y6a7 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xf9 h4 y6a6 fff fs2 fc0 sc0 ls0 ws0">⊙<span class="_ _33"> </span><span class="ff3">tanh</span></div><div class="t m0 x15b he y6a8 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x137 h4 y6a9 ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 xd6 hc y6a6 ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 x42 hb y6a7 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x142 he y6a8 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y6a6 ff3 fs2 fc0 sc0 ls0 ws0">(7.8)</div><div class="t m0 x160 h9 y6aa ff6 fs5 fc0 sc0 ls0 ws0">7.3<span class="_ _21"> </span><span class="ff9">带窥孔的<span class="_ _9"> </span></span>LSTM</div><div class="t m0 x3 h6 y6ab ff1 fs2 fc0 sc0 ls0 ws0">本文前<span class="_ _f"></span>面所<span class="_ _f"></span>介绍的<span class="_ _11"> </span><span class="ff3">LSTM<span class="_ _11"> </span></span>是最普<span class="_ _f"></span>通的<span class="_ _11"> </span><span class="ff3">LSTM</span>，但<span class="_ _f"></span>并非所<span class="_ _f"></span>有的<span class="_ _11"> </span><span class="ff3">LSTM<span class="_ _11"> </span></span>模型都<span class="_ _f"></span>与前面<span class="_ _f"></span>相同。<span class="_ _f"></span>事实</div><div class="t m0 x3 h6 y6ac ff1 fs2 fc0 sc0 ls0 ws0">上，似乎每一篇<span class="_ _27"> </span><span class="ff3">pap<span class="_ _1f"></span>er<span class="_ _c"> </span></span>中所用到的<span class="_ _c"> </span><span class="ff3">LSTM<span class="_ _c"> </span></span>都是稍微不一样的版本。不同之处很微小，<span class="_ _2f"></span>不过其中</div><div class="t m0 x3 h6 y6ad ff1 fs2 fc0 sc0 ls0 ws0">一些值得介绍。</div><div class="t m0 x3 h6 y6ae ff1 fs2 fc0 sc0 ls0 ws0">一个流行的<span class="_ _27"> </span><span class="ff3">LSTM<span class="_ _c"> </span></span>变种，<span class="_ _31"></span>由<span class="_ _27"> </span><span class="ff3">Gers<span class="_ _c"> </span>&amp;<span class="_ _c"> </span>Sc<span class="_ _2f"></span>hmidhuber<span class="_ _c"> </span>(2000)<span class="_ _27"> </span><span class="ff1">提出，<span class="_ _31"></span>加入了<span class="_ _10"></span>“窥视孔连接<span class="_ _27"> </span><span class="ff3">(p<span class="_ _1f"></span>eephole</span></span></span></div><div class="t m0 x3 h6 y6af ff3 fs2 fc0 sc0 ls0 ws0">connection)<span class="ff1">”<span class="_ _23"></span>。也就是说我们让各种门可以观察到元胞状态。</span></div><div class="t m0 x3c h37 y6b0 ff6 fs5 fc0 sc0 ls0 ws0">7.4<span class="_ _21"> </span>GR<span class="_ _2f"></span>U</div><div class="t m0 x3 h6 y6b1 ff1 fs2 fc0 sc0 ls0 ws0">另一个变化更大一些的<span class="_ _25"> </span><span class="ff3">LSTM </span>变种叫做<span class="_ _25"> </span><span class="ff3">Gated<span class="_ _25"> </span>Recurrent<span class="_ _25"> </span>Unit</span>，<span class="_ _30"></span>或者<span class="_ _25"> </span><span class="ff3">GRU</span>，<span class="_ _30"></span>由<span class="_ _25"> </span><span class="ff3">Cho, et al.<span class="_ _11"> </span>(2014)</span></div><div class="t m0 x3 h6 y6b2 ff1 fs2 fc0 sc0 ls0 ws0">提出。<span class="ff3">GR<span class="_ _10"></span>U<span class="_ _c"> </span><span class="ff1">将遗忘<span class="_ _f"></span>门和输入门合并成<span class="_ _f"></span>为单一的“更新门<span class="_ _0"> </span></span>(Up<span class="_ _f"></span>date<span class="_ _c"> </span>Gate)<span class="ff1">”<span class="_ _30"></span>。<span class="ff3">GRU<span class="_ _c"> </span></span>同时也将元胞</span></span></div><div class="t m0 x3 h6 y5ac ff1 fs2 fc0 sc0 ls0 ws0">状态<span class="_ _11"> </span><span class="ff3">(Cell<span class="_ _11"> </span>State)<span class="_ _11"> </span></span>和<span class="_ _f"></span>隐状<span class="_ _f"></span>态<span class="_ _11"> </span><span class="ff3">(Hidden<span class="_ _11"> </span>State)<span class="_ _11"> </span></span>合<span class="_ _f"></span>并，同<span class="_ _f"></span>时引<span class="_ _f"></span>入其<span class="_ _f"></span>他<span class="_ _f"></span>的一<span class="_ _f"></span>些变<span class="_ _f"></span>化。该<span class="_ _f"></span>模型<span class="_ _f"></span>比标<span class="_ _f"></span>准<span class="_ _f"></span>的</div><div class="t m0 x3 h6 y5ae ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _c"> </span><span class="ff1">模型更加简化，同时现在也变得越来越流行。</span></div><div class="t m0 x3 h6 y6b3 ff1 fs2 fc0 sc0 ls0 ws0">图中，<span class="ffa">r</span></div><div class="t m0 x10b hb y6b4 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x187 h6 y6b3 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _c"> </span><span class="ff3">GR<span class="_ _10"></span>U<span class="_ _c"> </span><span class="ff1">模型的重置门部分，用于控制前一时刻隐藏状态<span class="_ _c"> </span><span class="ffa">h</span></span></span></div><div class="t m0 xed ha y6b4 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xc9 h6 y6b3 ff1 fs2 fc0 sc0 ls0 ws0">对当前状态的影响。若</div><div class="t m0 x3 hc y6b5 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x102 ha y6b6 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x13c h6 y6b5 ff1 fs2 fc0 sc0 ls0 ws0">不重要，<span class="_ _22"></span>从语言模型角度看，<span class="_ _22"></span>即从当前开始表达新的意思，<span class="_ _22"></span>与上文无关，<span class="_ _31"></span>则重置门关闭，<span class="_ _22"></span>数</div><div class="t m0 x3 h6 y6b7 ff1 fs2 fc0 sc0 ls0 ws0">学表达式为：</div><div class="t m0 x16e hc y1d ffa fs2 fc0 sc0 ls0 ws0">r</div><div class="t m0 x9 hb y97 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xc5 h4 y1d ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">σ<span class="_ _33"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x4 hb y97 ffd fs6 fc0 sc0 ls0 ws0">r</div><div class="t m0 x1 hc y1d ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa3 ha y97 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x138 h4 y1d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y97 ffd fs6 fc0 sc0 ls0 ws0">r</div><div class="t m0 x12e hc y1d ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x19d hb y97 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xcc h4 y1d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x50 hb y97 ffd fs6 fc0 sc0 ls0 ws0">r</div><div class="t m0 x27 h4 y1d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _61"> </span><span class="ff3">(7.9)</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">48</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf36" class="pf w0 h0" data-page-no="36"><div class="pc pc36 w0 h0"><div class="t m0 x19e h13 y1e ff3 fs4 fc0 sc0 ls0 ws0">7.4<span class="_ _15"> </span>GR<span class="_ _10"></span>U</div><div class="t m0 x3 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">图中<span class="_ _0"> </span><span class="ffa">z</span></div><div class="t m0 x108 hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x34 h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _0"> </span><span class="ff3">GRU<span class="_ _c"> </span></span>模<span class="_ _f"></span>型的<span class="_ _f"></span>更新门<span class="_ _f"></span>部分，用<span class="_ _f"></span>于决<span class="_ _f"></span>定是否<span class="_ _f"></span>忽略<span class="_ _f"></span>当前输<span class="_ _f"></span>入<span class="_ _0"> </span><span class="ffa">x</span></div><div class="t m0 x82 hb y2c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xed h6 y1f ff1 fs2 fc0 sc0 ls0 ws0">，类似<span class="_ _11"> </span><span class="ff3">LSTM<span class="_ _0"> </span></span>中<span class="_ _f"></span>的输入<span class="_ _f"></span>门</div><div class="t m0 x3 hc y1ef ffa fs2 fc0 sc0 ls0 ws0">i</div><div class="t m0 x19f hb y677 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x129 h6 y1ef ff1 fs2 fc0 sc0 ls0 ws0">。从语言模型角度看，即判断当前词<span class="_ _c"> </span><span class="ffa">x</span></div><div class="t m0 x0 hb y677 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x17a h6 y1ef ff1 fs2 fc0 sc0 ls0 ws0">对整体意思的表达是否重要，数学表达式为：</div><div class="t m0 x1d hc y6b8 ffa fs2 fc0 sc0 ls0 ws0">z</div><div class="t m0 x9 hb y6b9 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xc5 h4 y6b8 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">σ<span class="_ _33"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x4 hb y6b9 ffd fs6 fc0 sc0 ls0 ws0">z</div><div class="t m0 x1 hc y6b8 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa3 ha y6b9 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x138 h4 y6b8 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y6b9 ffd fs6 fc0 sc0 ls0 ws0">z</div><div class="t m0 x12e hc y6b8 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x19d hb y6b9 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xcc h4 y6b8 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 x50 hb y6b9 ffd fs6 fc0 sc0 ls0 ws0">z</div><div class="t m0 x139 h4 y6b8 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _62"> </span><span class="ff3">(7.10)</span></div><div class="t m0 x3 h6 y1f3 ff1 fs2 fc0 sc0 ls0 ws0">定义完<span class="_ _11"> </span><span class="ff3">GRU<span class="_ _0"> </span></span>的重<span class="_ _f"></span>置门<span class="_ _f"></span>和更<span class="_ _f"></span>新门<span class="_ _f"></span>之后，<span class="_ _f"></span>我们<span class="_ _f"></span>再来<span class="_ _f"></span>看<span class="_ _0"> </span><span class="ff3">GRU<span class="_ _0"> </span></span>的<span class="_ _f"></span>细胞<span class="_ _f"></span>更新。当<span class="_ _f"></span>更新<span class="_ _f"></span>门打<span class="_ _f"></span>开时，<span class="ffa">h</span></div><div class="t m0 x105 hb y6ba ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb3 h6 y1f3 ff1 fs2 fc0 sc0 ls0 ws0">由</div><div class="t m0 x3 hc y6bb ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x102 ha y6bc ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x13c h6 y6bb ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _27"> </span><span class="ffa">x</span></div><div class="t m0 x187 hb y6bc ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x182 h6 y6bb ff1 fs2 fc0 sc0 ls0 ws0">决定；<span class="_ _31"></span>当更新门被关闭时，<span class="_ _31"></span><span class="ffa">h</span></div><div class="t m0 x3c ha y6bc ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xbc h6 y6bb ff1 fs2 fc0 sc0 ls0 ws0">将仅由<span class="_ _27"> </span><span class="ffa">h</span></div><div class="t m0 x25 ha y6bc ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x93 h6 y6bb ff1 fs2 fc0 sc0 ls0 ws0">决定，<span class="_ _31"></span>帮助梯度反向传播，<span class="_ _31"></span>与<span class="_ _c"> </span><span class="ff3">LSTM </span>相</div><div class="t m0 x3 h6 y6bd ff1 fs2 fc0 sc0 ls0 ws0">同，这种机制有效地缓解了梯度消失现象。数学表达式为：</div><div class="t m0 x97 h4 y6be ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x77 hc y6bf ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x39 hb y6c0 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x15d h4 y6bf ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ff3">tanh<span class="_ _2d"> </span></span>(<span class="ffa">W<span class="_ _2b"> </span>r</span></div><div class="t m0 x3f hb y6c0 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x23 h4 y6bf fff fs2 fc0 sc0 ls0 ws0">⊙<span class="_ _33"> </span><span class="ffa">h</span></div><div class="t m0 x5d ha y6c0 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x4d h4 y6bf ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">U<span class="_ _32"> </span>x</span></div><div class="t m0 x110 hb y6c0 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x50 h4 y6bf ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">b</span></div><div class="t m0 xa1 hb y6c1 ffd fs6 fc0 sc0 ls0 ws0">f</div><div class="t m0 x2a h4 y6bf ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _63"> </span><span class="ff3">(7.11)</span></div><div class="t m0 x15d hc y6c2 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xf6 hb y6c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x1f h4 y6c2 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>(1<span class="_ _25"> </span><span class="fff">−<span class="_ _33"></span><span class="ffa">z</span></span></div><div class="t m0 x8d hb y6c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x19b h4 y6c2 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="fff">⊙<span class="_ _25"> </span><span class="ffa">h</span></span></div><div class="t m0 x167 ha y6c3 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xdf h4 y6c2 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _33"> </span><span class="ffa">z</span></div><div class="t m0 x62 hb y6c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x5f h4 y6c2 fff fs2 fc0 sc0 ls0 ws0">⊙</div><div class="t m0 x4f h4 y6c4 ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x4f hc y6c2 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x70 hb y6c3 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb7 h4 y6c2 ff3 fs2 fc0 sc0 ls0 ws0">(7.12)</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">49</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf37" class="pf w0 h0" data-page-no="37"><div class="pc pc37 w0 h0"><div class="t m0 x3 h13 y1e ff3 fs4 fc0 sc0 ls0 ws0">7.4<span class="_ _15"> </span>GR<span class="_ _10"></span>U</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">50</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf38" class="pf w0 h0" data-page-no="38"><div class="pc pc38 w0 h0"><img class="bi x3 y2c2 w1d h5d" alt="" src="bg38.png"/><div class="t m0 x97 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第八章 <span class="ff6">Seq2Seq</span></div><div class="t m0 xa5 h37 y48 ff6 fs5 fc0 sc0 ls0 ws0">8.1<span class="_ _21"> </span>Enco<span class="_ _f"></span>der-Deco<span class="_ _1f"></span>der</div><div class="t m0 x3 h6 y6c5 ff3 fs2 fc0 sc0 ls0 ws0">Kyungh<span class="_ _10"></span>yun Cho<span class="_ _c"> </span><span class="ff1">等人在<span class="_ _2c"> </span></span>2014<span class="_ _27"> </span><span class="ff1">年<span class="_ _27"> </span></span>6<span class="_ _27"> </span><span class="ff1">月<span class="_ _c"> </span></span>3 <span class="ff1">日将论文<span class="_ _22"></span>《<span class="ff3">Learning Phrase<span class="_ _27"> </span>Representations using RNN</span></span></div><div class="t m0 x3 h6 y6c6 ff3 fs2 fc0 sc0 ls0 ws0">Enco<span class="_ _f"></span>der<span class="_ _2a"></span><span class="ff1">–<span class="_ _2a"></span><span class="ff3">Deco<span class="_ _f"></span>der<span class="_ _27"> </span>for<span class="_ _c"> </span>Statistical Machine T<span class="_ _31"></span>ranslation<span class="ff1">》<span class="_ _31"></span>发布于<span class="_ _2c"> </span><span class="ff3">Arxiv</span>，<span class="_ _22"></span>提出了<span class="_ _27"> </span><span class="ff3">Enco<span class="_ _f"></span>der<span class="_ _2a"></span><span class="ff1">–<span class="_ _2a"></span><span class="ff3">Deco<span class="_ _f"></span>der</span></span></span></span></span></span></div><div class="t m0 x3 h6 y6c7 ff1 fs2 fc0 sc0 ls0 ws0">模型结构。论文提出的<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _c"> </span>Enco<span class="_ _f"></span>der-Deco<span class="_ _f"></span>der<span class="_ _c"> </span></span>模型由两个<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _c"> </span></span>组成：</div><div class="t m0 x3 h6 y6c8 ff4 fs2 fc0 sc0 ls0 ws0">简要地回顾<span class="_ _11"> </span><span class="ff7">RNN<span class="_ _11"> </span></span>的知识：</div><div class="t m0 x3 h6 y6c9 ff3 fs2 fc0 sc0 ls0 ws0">RNN <span class="ff1">是一个包含隐藏状态<span class="_ _27"> </span><span class="ff11">h<span class="_ _27"> </span></span>和可选输出<span class="_ _27"> </span><span class="ff11">y<span class="_ _c"> </span></span>的神经网络，<span class="_ _28"></span>它接受可变长序列<span class="_ _2c"> </span><span class="ff11">x<span class="_ _27"> </span><span class="ffb">=<span class="_ _2c"> </span>(<span class="ffa">x</span></span></span></span></div><div class="t m0 xfe ha y6ca ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xf4 hc y6c9 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x1a0 hb y6cb ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x105 h6 y6c9 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _27"> </span><span class="ff1">的</span></div><div class="t m0 x3 h6 y6cc ff1 fs2 fc0 sc0 ls0 ws0">输入。在每个时间步，隐藏状态<span class="_ _c"> </span><span class="ff11">h</span></div><div class="t m0 xf6 ha y6cd ff12 fs6 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 x15e h6 y6cc ff1 fs2 fc0 sc0 ls0 ws0">按照如下公式更新：</div><div class="t m0 x47 h4 y6ce ff7 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x10c ha y6cf ff12 fs6 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 x150 h4 y6ce ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x90 he y6d0 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x40 h4 y6ce ff7 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x99 ha y6cf ff12 fs6 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>−<span class="ffc">1</span>⟩</div><div class="t m0 x16a hc y6ce ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>x</div><div class="t m0 x93 hb y6d1 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x152 he y6d0 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3 h6 y6d2 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _27"> </span><span class="ffa">f<span class="_ _1c"> </span></span>是非线性激活函数。<span class="_ _22"></span><span class="ffa">f<span class="_ _1c"> </span><span class="ff1">可以像<span class="_ _c"> </span><span class="ff3">logistic</span>、<span class="_ _22"></span><span class="ff3">sigmoid function<span class="_ _27"> </span><span class="ff1">一样简单，<span class="_ _22"></span>也可以像<span class="_ _2c"> </span><span class="ff3">long<span class="_ _c"> </span>short-</span></span></span></span></span></div><div class="t m0 x3 h6 y6d3 ff3 fs2 fc0 sc0 ls0 ws0">term<span class="_ _c"> </span>memory<span class="ff1">（</span>LSTM<span class="ff1">）一样复杂。</span></div><div class="t m0 x3 h6 y6d4 ff1 fs2 fc0 sc0 ls0 ws0">以输入序列的下一个字符作为预测目标来训练，<span class="_ _29"></span><span class="ff3">RNN<span class="_ _27"> </span><span class="ff1">可以学习序列上的概率分布</span></span></div><div class="t m0 x121 h1f y6d5 ff16 fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2d h6 y6d4 ff1 fs2 fc0 sc0 ls0 ws0">。<span class="_ _28"></span>在这种情况</div><div class="t m0 x3 h6 y6d6 ff1 fs2 fc0 sc0 ls0 ws0">下，<span class="_ _31"></span>每个时间步长<span class="_ _27"> </span><span class="ff3">t<span class="_ _27"> </span></span>的输出是条件分布<span class="_ _c"> </span><span class="ffa">p<span class="_ _2d"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x4 hb y6d7 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x8d h4 y6d6 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 x5a ha y6d7 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x99 hc y6d6 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x19d ha y6d7 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x152 h6 y6d6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">。<span class="_ _31"></span>例如，<span class="_ _31"></span>对于所有<span class="_ _2c"> </span><span class="ffa">j<span class="_ _0"> </span><span class="ffb">=<span class="_ _2c"> </span>1</span>,<span class="_ _2d"> </span><span class="fff">·<span class="_ _2d"></span>·<span class="_ _2d"></span>·<span class="_ _c"> </span></span>,<span class="_ _2d"> </span>K<span class="_ _1f"></span></span>，<span class="_ _31"></span>可以</span></div><div class="t m0 x3 h6 y6d8 ff1 fs2 fc0 sc0 ls0 ws0">使用<span class="_ _c"> </span><span class="ff3">softmax<span class="_ _c"> </span></span>激活函数输出多项式分布（<span class="ff3">1-K<span class="_ _c"> </span></span>编码）</div><div class="t m0 x130 h4 y6d9 ffa fs2 fc0 sc0 ls0 ws0">p<span class="_ _2d"> </span><span class="ffb">(</span>x</div><div class="t m0 x83 hb y6da ffd fs6 fc0 sc0 ls0 ws0">t,j</div><div class="t m0 x160 h4 y6d9 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span>1<span class="fff">|<span class="ffa">x</span></span></div><div class="t m0 xa9 ha y6da ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x10c hc y6d9 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x5a ha y6da ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5b h4 y6d9 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=</div><div class="t m0 xab h4 y6db ff3 fs2 fc0 sc0 ls0 ws0">exp</div><div class="t m0 x110 he y6dc ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf7 h4 y6db ff7 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x61 hb y6dd ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x28 h4 y6db ff7 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x51 ha y6de ff12 fs6 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 xde he y6dc ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4c he y6df ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xdf hb y6e0 ffd fs6 fc0 sc0 ls0 ws0">K</div><div class="t m0 xdf hb y6e1 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x137 h1d y6e2 ff15 fs8 fc0 sc0 ls0 ws0">′</div><div class="t m0 xab ha y6e1 ffc fs6 fc0 sc0 ls0 ws0">=1</div><div class="t m0 xd5 h4 y6e3 ff3 fs2 fc0 sc0 ls0 ws0">exp</div><div class="t m0 x70 he y6e4 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe1 h4 y6e3 ff7 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x17c hb y6e5 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 x144 h1d y6e6 ff15 fs8 fc0 sc0 ls0 ws0">′</div><div class="t m0 xde h4 y6e3 ff7 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xac ha y6e7 ff12 fs6 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 x179 he y6e4 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y6d9 ff3 fs2 fc0 sc0 ls0 ws0">(8.1)</div><div class="t m0 x3 h6 y6e8 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _c"> </span><span class="ff11">w</span></div><div class="t m0 x78 hb y6e9 ffd fs6 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb h6 y6e8 ff1 fs2 fc0 sc0 ls0 ws0">是权重矩阵<span class="_ _c"> </span><span class="ff11">W<span class="_ _b"> </span></span>的行。通过组合这些概率，我们可以用如下公式计算序列<span class="_ _c"> </span><span class="ff11">x<span class="_ _c"> </span></span>的概率<span class="ff3">:</span></div><div class="t m0 xf5 h4 y6ea ffa fs2 fc0 sc0 ls0 ws0">p<span class="ffb">(<span class="ff7">x</span>)<span class="_ _2c"> </span>=</span></div><div class="t m0 xa6 hb y6eb ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 xb6 he y6ec ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xb6 ha y6ed ffd fs6 fc0 sc0 ls0 ws0">t<span class="ffc">=1</span></div><div class="t m0 x17b h4 y6ea ffa fs2 fc0 sc0 ls0 ws0">p<span class="_ _2d"> </span><span class="ffb">(</span>x</div><div class="t m0 x24 hb y6ee ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xfc h4 y6ea fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 x17e ha y6ee ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x16b hc y6ea ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x161 ha y6ee ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13b h4 y6ea ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _64"> </span><span class="ff3">(8.2)</span></div><div class="t m0 x3 h6 y6ef ff1 fs2 fc0 sc0 ls0 ws0">从这个学习的分布中，通过在每个时间步长迭代采样符号来直接抽样新序列。</div><div class="t m0 x10e h27 y31a ff18 fs8 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5 h29 y1d ff1 fs9 fc0 sc0 ls0 ws0">此时，<span class="ff1c">RNN<span class="_ _2c"> </span></span>的拟合目标就是这个概率分布。</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">51</div><a class="l" href="#pf38" data-dest-detail='[56,"XYZ",87.01,53.48,null]'><div class="d m1" style="border-style:none;position:absolute;left:684.250500px;bottom:340.692000px;width:4.232000px;height:11.294000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf39" class="pf w0 h0" data-page-no="39"><div class="pc pc39 w0 h0"><img class="bi x68 y6f0 w8 h5e" alt="" src="bg39.png"/><div class="t m0 x3 h13 y1e ff3 fs4 fc0 sc0 ls0 ws0">8.2<span class="_ _15"> </span>SEQ2SEQ</div><div class="t m0 x3 h6 y1f ff7 fs2 fc0 sc0 ls0 ws0">RNN<span class="_ _11"> </span>Enco<span class="_ _f"></span>der-Deco<span class="_ _f"></span>der<span class="_ _11"> </span><span class="ff4">模型：</span></div><div class="t m0 x3 h6 y3c ff3 fs2 fc1 sc0 ls0 ws0">Enco<span class="_ _f"></span>der<span class="_ _c"> </span><span class="ff1">将输入序<span class="_ _f"></span>列<span class="_ _c"> </span><span class="ffa">X<span class="_ _2e"> </span></span>编码为一个<span class="ff4">固定长度</span>的向量<span class="_ _0"> </span><span class="ff11">c</span>，</span>Deco<span class="_ _f"></span>der<span class="_ _c"> </span><span class="ff1">将输<span class="_ _f"></span>入的<span class="ff4">固定长度</span>向量<span class="_ _0"> </span><span class="ff11">c<span class="_ _c"> </span></span>解码</span></div><div class="t m0 x3 h6 y1f0 ff1 fs2 fc1 sc0 ls0 ws0">成输出<span class="_ _f"></span>序列<span class="_ _11"> </span><span class="ffa">Y<span class="_ _25"> </span></span>。<span class="fc0">从概率<span class="_ _f"></span>的角<span class="_ _f"></span>度来<span class="_ _f"></span>看，这<span class="_ _f"></span>种结<span class="_ _f"></span>构是<span class="_ _f"></span>一种<span class="_ _f"></span>通用<span class="_ _f"></span>方法，<span class="_ _f"></span>可学<span class="_ _f"></span>习一<span class="_ _f"></span>个可<span class="_ _f"></span>变长<span class="_ _f"></span>序列<span class="_ _f"></span>在另一</span></div><div class="t m0 x3 h6 y1f1 ff1 fs2 fc0 sc0 ls0 ws0">个可变长序列下的条件分布：<span class="_ _2f"></span><span class="ffa">p<span class="_ _2d"> </span><span class="ffb">(</span>y</span></div><div class="t m0 x148 ha y1f2 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3b hc y1f1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>y</div><div class="t m0 x0 hb y6f1 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x17a h1d y6f2 ff15 fs8 fc0 sc0 ls0 ws0">′</div><div class="t m0 x4a h4 y1f1 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 x1 ha y1f2 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa3 hc y1f1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x25 hb y6f3 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x16a h6 y1f1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">，<span class="_ _2f"></span>值得注意的是代表了输入序列长度的<span class="_ _c"> </span><span class="ffa">T</span></span></div><div class="t m0 x3 h6 y1f3 ff1 fs2 fc0 sc0 ls0 ws0">和输出序列长度<span class="_ _c"> </span><span class="ffa">T</span></div><div class="t m0 xb4 ha y6f4 ff12 fs6 fc0 sc0 ls0 ws0">′</div><div class="t m0 x191 h6 y1f3 ff1 fs2 fc0 sc0 ls0 ws0">可以不一样。</div><div class="t m0 x3 h6 y6f5 ff1 fs2 fc0 sc0 ls0 ws0">编码器是一个<span class="_ _c"> </span><span class="ff3">RNN</span>，<span class="_ _f"></span>依次读取输入序列<span class="_ _0"> </span><span class="ff11">x<span class="_ _c"> </span></span>的每个字<span class="_ _f"></span>符。当它读取每个字符时，<span class="_ _f"></span><span class="ff3">RNN<span class="_ _c"> </span></span>的隐层状</div><div class="t m0 x3 h6 y6f6 ff1 fs2 fc0 sc0 ls0 ws0">态会根据公式（<span class="ff3">1</span>）改变。当读到序列的结尾（由<span class="_ _c"> </span><span class="ff3">end-of-sequence<span class="_ _c"> </span></span>符号标记）后，<span class="ff3">RNN<span class="_ _c"> </span></span>隐层状</div><div class="t m0 x3 h6 y6f7 ff1 fs2 fc0 sc0 ls0 ws0">态<span class="_ _c"> </span><span class="ff11">c<span class="_ _c"> </span></span>包含了整个输入序列的信息。</div><div class="t m0 x3 h6 y6f8 ff1 fs2 fc0 sc0 ls0 ws0">模型的解码器是另一个<span class="_ _27"> </span><span class="ff3">RNN</span>，<span class="_ _22"></span>通过给定隐藏状态<span class="_ _27"> </span><span class="ff11">h</span></div><div class="t m0 x13e ha y6f9 ff12 fs6 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 x12e h6 y6f8 ff1 fs2 fc0 sc0 ls0 ws0">和下一个输出字符<span class="_ _27"> </span><span class="ffa">y</span></div><div class="t m0 x55 hb y6fa ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x1a1 h6 y6f8 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _22"></span>解码器被训练输出</div><div class="t m0 x3 h6 y6fb ff1 fs2 fc0 sc0 ls0 ws0">序列。<span class="_ _10"></span>然而，<span class="_ _2f"></span>与上述的<span class="_ _c"> </span><span class="ff3">RNN<span class="_ _c"> </span></span>不同，<span class="_ _2f"></span><span class="ffa">y</span></div><div class="t m0 x15e hb y6fc ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x3d h6 y6fb ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _c"> </span><span class="ffa">h</span></div><div class="t m0 x1a2 hb y6fc ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x3f h6 y6fb ff1 fs2 fc0 sc0 ls0 ws0">都受制于<span class="_ _c"> </span><span class="ffa">y</span></div><div class="t m0 x93 ha y6fc ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff16">−<span class="ffc">1</span></span></div><div class="t m0 xf7 h6 y6fb ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _c"> </span><span class="ff3">Encoder<span class="_ _c"> </span></span>隐藏状态<span class="_ _c"> </span><span class="ffa">c</span>。<span class="_ _10"></span>因此，<span class="_ _2f"></span>在<span class="_ _c"> </span><span class="ff3">t</span></div><div class="t m0 x3 h6 y6fd ff1 fs2 fc0 sc0 ls0 ws0">时刻解码器的隐藏状态是由下述公式计算：</div><div class="t m0 x1f h4 y6fe ff7 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xea ha y6ff ff12 fs6 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 xeb h4 y6fe ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2c"> </span><span class="ffa">f</span></div><div class="t m0 x17b he y700 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf9 h4 y6fe ff7 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x9f ha y6ff ff12 fs6 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>−<span class="ffc">1</span>⟩</div><div class="t m0 x4c hc y6fe ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>y</div><div class="t m0 x16a ha y701 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x142 h4 y6fe ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="ff7">c</span></div><div class="t m0 x110 he y700 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y6fe ff3 fs2 fc0 sc0 ls0 ws0">(8.3)</div><div class="t m0 x3 h6 y702 ff1 fs2 fc0 sc0 ls0 ws0">类似的，下一个<span class="_ _c"> </span><span class="ff3">sym<span class="_ _10"></span>b<span class="_ _f"></span>ol<span class="_ _c"> </span><span class="ff1">的条件分布为：</span></span></div><div class="t m0 x6f h4 y703 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _27"> </span><span class="ffb">(</span>y</div><div class="t m0 x1b hb y704 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x123 h4 y703 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">y</span></div><div class="t m0 x15d ha y704 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x1f hc y703 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>y</div><div class="t m0 x2 ha y704 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">2</span></span></div><div class="t m0 x20 hc y703 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>y</div><div class="t m0 x40 ha y704 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x170 h4 y703 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="ff7">c<span class="ffb">)<span class="_ _2c"> </span>=<span class="_ _2c"> </span></span></span>g</div><div class="t m0 x5e he y705 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x65 h4 y703 ff7 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x110 ha y706 ffc fs6 fc0 sc0 ls0 ws0">(<span class="ffd">t</span>)</div><div class="t m0 x27 hc y703 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>y</div><div class="t m0 x156 ha y704 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x168 h4 y703 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span><span class="ff7">c</span></div><div class="t m0 xa4 he y705 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x32 h4 y703 ff3 fs2 fc0 sc0 ls0 ws0">(8.4)</div><div class="t m0 x3 h6 y707 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2e"> </span><span class="ff1">与<span class="_ _c"> </span></span>g<span class="_ _0"> </span><span class="ff1">为激活函数，</span>g<span class="_ _0"> </span><span class="ff1">必须能生成有效的概率，比如利用<span class="_ _c"> </span><span class="ff3">softmax</span>。</span></div><div class="t m0 x106 h37 y708 ff6 fs5 fc0 sc0 ls0 ws0">8.2<span class="_ _21"> </span>Seq2Seq</div><div class="t m0 x3 h6 y709 ff1 fs2 fc0 sc0 ls0 ws0">正式<span class="_ _f"></span>提<span class="_ _f"></span>出<span class="_ _1c"> </span><span class="ff3">Sequence<span class="_ _2e"> </span>to<span class="_ _11"> </span>Sequence<span class="_ _2e"> </span></span>的文<span class="_ _f"></span>章<span class="_ _f"></span>是《<span class="ff3">Sequence<span class="_ _2e"> </span>to<span class="_ _11"> </span>Sequence<span class="_ _2e"> </span>Learning<span class="_ _1c"> </span>with<span class="_ _1c"> </span>Neural<span class="_ _1c"> </span>Net-</span></div><div class="t m0 x3 h6 y70a ff3 fs2 fc0 sc0 ls0 ws0">w<span class="_ _10"></span>orks<span class="ff1">》<span class="_ _24"></span>。<span class="ff7">Sequence<span class="_ _1c"> </span>to<span class="_ _1c"> </span>Sequence<span class="_ _1c"> </span><span class="ff4">的意<span class="_ _f"></span>思是：输入<span class="_ _f"></span>一个序列，<span class="_ _f"></span>输出另一个<span class="_ _f"></span>序列。<span class="ff3">Seq2Seq<span class="_ _0"> </span></span></span></span>一词</span></div><div class="t m0 x3 h6 y70b ff1 fs2 fc0 sc0 ls0 ws0">带有<span class="_ _f"></span>歧<span class="_ _f"></span>义，<span class="_ _f"></span>在<span class="_ _f"></span>原论<span class="_ _f"></span>文<span class="_ _f"></span>中，<span class="ff3">Seq2Seq<span class="_ _1c"> </span></span>指<span class="_ _f"></span>代<span class="_ _f"></span>输<span class="_ _f"></span>入和<span class="_ _f"></span>输<span class="_ _f"></span>出<span class="_ _f"></span>都<span class="_ _f"></span>是<span class="_ _f"></span>序列<span class="_ _f"></span>的<span class="_ _f"></span>机<span class="_ _f"></span>器<span class="_ _f"></span>学习<span class="_ _f"></span>任<span class="_ _f"></span>务，<span class="_ _f"></span>但<span class="_ _f"></span>现<span class="_ _f"></span>在很<span class="_ _f"></span>多<span class="_ _f"></span>人<span class="_ _f"></span>都</div><div class="t m0 x3 h6 y70c ff1 fs2 fc0 sc0 ls0 ws0">将<span class="_ _11"> </span><span class="ff3">Seq2Seq<span class="_ _11"> </span></span>视作一<span class="_ _f"></span>种模<span class="_ _f"></span>型，或<span class="_ _f"></span>者特<span class="_ _f"></span>指原<span class="_ _f"></span>文论<span class="_ _f"></span>中的<span class="_ _f"></span>模型。<span class="_ _f"></span>在<span class="_ _f"></span>我看<span class="_ _f"></span>来，<span class="ff3">Seq2Seq<span class="_ _11"> </span></span>更准确<span class="_ _f"></span>的<span class="_ _f"></span>含义是<span class="_ _f"></span>序</div><div class="t m0 x3 h6 y70d ff1 fs2 fc0 sc0 ls0 ws0">列学习<span class="_ _f"></span>任务，而<span class="_ _f"></span>不是<span class="_ _f"></span>作为模<span class="_ _f"></span>型的<span class="_ _f"></span>概念。即<span class="_ _f"></span>使<span class="_ _0"> </span><span class="ff3">Seq2Seq<span class="_ _11"> </span></span>指代模<span class="_ _f"></span>型，也<span class="_ _f"></span>应该是<span class="_ _f"></span>一类<span class="_ _f"></span>模型（输<span class="_ _f"></span>入和输</div><div class="t m0 x3 h6 y70e ff1 fs2 fc0 sc0 ls0 ws0">出都<span class="_ _f"></span>是序列<span class="_ _f"></span>的模<span class="_ _f"></span>型）<span class="_ _57"></span>，而不<span class="_ _f"></span>是一<span class="_ _f"></span>种模<span class="_ _f"></span>型。之<span class="_ _f"></span>所以<span class="_ _f"></span>强调<span class="_ _11"> </span><span class="ff3">Seq2Seq<span class="_ _11"> </span></span>的<span class="_ _f"></span>含义，<span class="_ _f"></span>是因<span class="_ _f"></span>为<span class="_ _11"> </span><span class="ff3">Seq2Seq<span class="_ _11"> </span></span>往往<span class="_ _f"></span>和</div><div class="t m0 x3 h6 y70f ff3 fs2 fc0 sc0 ls0 ws0">Enco<span class="_ _f"></span>der-Deco<span class="_ _f"></span>der<span class="_ _27"> </span><span class="ff1">有关，<span class="_ _28"></span>如果模糊<span class="_ _c"> </span><span class="ff3">Seq2Seq </span>的含义，<span class="_ _28"></span><span class="ff3">Seq2Seq<span class="_ _27"> </span><span class="ff1">和<span class="_ _c"> </span></span>Encoder-Deco<span class="_ _f"></span>der<span class="_ _c"> </span><span class="ff1">两者同时出现</span></span></span></div><div class="t m0 x3 h6 y710 ff1 fs2 fc0 sc0 ls0 ws0">容易让人感到混乱。</div><div class="t m0 x3 h6 y711 ff1 fs2 fc0 sc0 ls0 ws0">这篇论文提出了如下图结构的模型（<span class="ff3">&lt;EOS&gt;<span class="_ _c"> </span></span>是句子结束的标识符）<span class="_ _23"></span>：</div><div class="t m0 x3 h6 y712 ff1 fs2 fc0 sc0 ls0 ws0">实际<span class="_ _f"></span>上，<span class="_ _f"></span>这<span class="_ _f"></span>就是<span class="_ _f"></span>一<span class="_ _f"></span>个<span class="_ _1c"> </span><span class="ff3">Enco<span class="_ _f"></span>der-Deco<span class="_ _f"></span>der<span class="_ _1c"> </span></span>结<span class="_ _f"></span>构<span class="_ _f"></span>的模<span class="_ _f"></span>型，<span class="_ _f"></span>但<span class="_ _f"></span>是它<span class="_ _f"></span>比<span class="_ _1c"> </span><span class="ff3">RNN<span class="_ _1c"> </span>Enco<span class="_ _f"></span>der-Deco<span class="_ _f"></span>der<span class="_ _1c"> </span></span>模<span class="_ _f"></span>型<span class="_ _f"></span>简</div><div class="t m0 x3 h6 y713 ff1 fs2 fc0 sc0 ls0 ws0">单一<span class="_ _f"></span>些。<span class="_ _f"></span>因为<span class="_ _1c"> </span><span class="ff3">Deco<span class="_ _f"></span>der<span class="_ _1c"> </span></span>在<span class="_ _1c"> </span><span class="ffa">t<span class="_ _1c"> </span></span>时刻<span class="_ _f"></span>是<span class="_ _f"></span>由<span class="_ _11"> </span><span class="ffa">h</span></div><div class="t m0 x0 hb y714 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x150 h6 y713 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _11"> </span><span class="ffa">y</span></div><div class="t m0 x90 ha y714 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff16">−<span class="ffc">1</span></span></div><div class="t m0 xa0 h6 y713 ff1 fs2 fc0 sc0 ls0 ws0">计算<span class="_ _f"></span>出<span class="_ _1c"> </span><span class="ffa">y</span></div><div class="t m0 xf7 hb y714 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 x161 h6 y713 ff1 fs2 fc0 sc0 ls0 ws0">，而<span class="_ _f"></span>没<span class="_ _f"></span>有<span class="_ _11"> </span><span class="ffa">c</span>。<span class="_ _f"></span>论<span class="_ _f"></span>文<span class="_ _f"></span>中的<span class="_ _1c"> </span><span class="ff3">Enco<span class="_ _f"></span>der<span class="_ _1c"> </span></span>和</div><div class="t m0 x3 h6 y715 ff3 fs2 fc0 sc0 ls0 ws0">Deco<span class="_ _f"></span>der<span class="_ _c"> </span><span class="ff1">都是用<span class="_ _c"> </span></span>4<span class="_ _c"> </span><span class="ff1">层<span class="_ _c"> </span></span>LSTM<span class="ff1">。</span></div><div class="t m0 x3 h6 y716 ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _33"> </span><span class="ff1">的目标是估计条件概率<span class="_ _25"> </span><span class="ffa">p<span class="_ _2d"> </span><span class="ffb">(</span>y</span></span></div><div class="t m0 xc2 ha y717 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa hc y716 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>y</div><div class="t m0 x146 hb y718 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x4a h1d y719 ff15 fs8 fc0 sc0 ls0 ws0">′</div><div class="t m0 x1a2 h4 y716 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 x22 ha y717 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x23 hc y716 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x15b hb y71a ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 xd6 h6 y716 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="ff1">，<span class="_ _3d"></span>其中<span class="_ _25"> </span><span class="ffb">(<span class="ffa">x</span></span></span></div><div class="t m0 x14e ha y717 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x17c hc y716 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x53 hb y71a ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 xc9 h6 y716 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _33"> </span><span class="ff1">是输入序列，<span class="_ _3d"></span><span class="ffa">y</span></span></div><div class="t m0 x1a3 ha y717 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x1a4 hc y716 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>y</div><div class="t m0 x74 hb y718 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x1a5 h1d y719 ff15 fs8 fc0 sc0 ls0 ws0">′</div><div class="t m0 x3 h6 y71b ff1 fs2 fc0 sc0 ls0 ws0">是对应的输出序列。模型先获得<span class="_ _f"></span>输入序列<span class="_ _c"> </span><span class="ffb">(<span class="ffa">x</span></span></div><div class="t m0 x1 ha y71c ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xf9 hc y71b ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x25 hb y71d ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x4d h6 y71b ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _c"> </span><span class="ff1">的固定维度的向量表<span class="_ _f"></span>示<span class="_ _c"> </span><span class="ffa">v<span class="_ _f"></span></span>，<span class="ffa">v<span class="_ _11"> </span></span>是<span class="_ _0"> </span><span class="ff3">Enco<span class="_ _f"></span>der</span></span></div><div class="t m0 x3 h6 y71e ff1 fs2 fc0 sc0 ls0 ws0">的最后一个隐藏状态，<span class="_ _2f"></span>同时也是<span class="_ _c"> </span><span class="ff3">Decoder<span class="_ _c"> </span></span>的初始隐藏状态。<span class="_ _2f"></span>然后模型通过标准的<span class="_ _c"> </span><span class="ff3">LSTM<span class="_ _c"> </span></span>计算公</div><div class="t m0 x3 h6 y71f ff1 fs2 fc0 sc0 ls0 ws0">式计算出<span class="_ _c"> </span><span class="ffa">y</span></div><div class="t m0 x66 ha y720 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x11e hc y71f ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>y</div><div class="t m0 x111 hb y721 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x16f h1d y722 ff15 fs8 fc0 sc0 ls0 ws0">′</div><div class="t m0 x119 h6 y71f ff1 fs2 fc0 sc0 ls0 ws0">的条件概率：</div><div class="t m0 xe6 h4 y723 ffa fs2 fc0 sc0 ls0 ws0">p<span class="_ _2d"> </span><span class="ffb">(</span>y</div><div class="t m0 x19 ha y724 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x43 hc y723 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>y</div><div class="t m0 xf5 hb y725 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x9 h1d y726 ff15 fs8 fc0 sc0 ls0 ws0">′</div><div class="t m0 xba h4 y723 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 xea ha y724 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2 hc y723 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>x</div><div class="t m0 x3f hb y727 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x23 h4 y723 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>=</div><div class="t m0 x17e hb y728 ffd fs6 fc0 sc0 ls0 ws0">T</div><div class="t m0 x25 h1d y729 ff15 fs8 fc0 sc0 ls0 ws0">′</div><div class="t m0 x91 he y72a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x91 ha y3eb ffd fs6 fc0 sc0 ls0 ws0">t<span class="ffc">=1</span></div><div class="t m0 xdf h4 y723 ffa fs2 fc0 sc0 ls0 ws0">p<span class="_ _2d"> </span><span class="ffb">(</span>y</div><div class="t m0 x65 hb y724 ffd fs6 fc0 sc0 ls0 ws0">t</div><div class="t m0 xd5 h4 y723 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">v<span class="_ _f"></span>,<span class="_ _2d"> </span>y</span></div><div class="t m0 x70 ha y724 ffc fs6 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe1 hc y723 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2d"> </span>.<span class="_ _2b"> </span>,<span class="_ _2d"> </span>y</div><div class="t m0 x164 ha y724 ffd fs6 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x13f h4 y723 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">52</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3a" class="pf w0 h0" data-page-no="3a"><div class="pc pc3a w0 h0"><div class="t m0 x1a6 h7 y1e ff3 fs4 fc0 sc0 ls0 ws0">8.3<span class="_ _15"> </span>A<span class="_ _31"></span>TTENTION<span class="_ _27"> </span><span class="ff8">机制</span></div><div class="t m0 x39 h9 ya9 ff6 fs5 fc0 sc0 ls0 ws0">8.3<span class="_ _21"> </span>A<span class="_ _2f"></span>tten<span class="_ _10"></span>tion<span class="_ _9"> </span><span class="ff9">机制</span></div><div class="t m0 x3 h6 yaa ff3 fs2 fc0 sc0 ls0 ws0">A<span class="_ _10"></span>tten<span class="_ _10"></span>tion<span class="_ _27"> </span><span class="ff1">机制由视觉图像领域提出来，<span class="_ _22"></span>在<span class="_ _2c"> </span><span class="ff3">2014<span class="_ _c"> </span></span>年，<span class="_ _28"></span><span class="ff3">Bahdanau<span class="_ _27"> </span><span class="ff1">在<span class="_ _31"></span>《<span class="ff3">Neural Machine T<span class="_ _31"></span>ranslation</span></span></span></span></div><div class="t m0 x3 h6 yab ff3 fs2 fc0 sc0 ls0 ws0">b<span class="_ _10"></span>y<span class="_ _27"> </span>Jointly<span class="_ _27"> </span>Learning<span class="_ _c"> </span>to<span class="_ _27"> </span>Align<span class="_ _c"> </span>and<span class="_ _27"> </span>T<span class="_ _31"></span>ranslate<span class="ff1">》<span class="_ _2f"></span>上将其应用到机器翻译任务上，<span class="_ _31"></span>这是第一个应用到</span></div><div class="t m0 x3 h6 yac ff3 fs2 fc0 sc0 ls0 ws0">NLP <span class="ff1">领域的论文。<span class="_ _35"></span>之后，<span class="_ _35"></span><span class="ff3">15<span class="ff1">、<span class="_ _35"></span><span class="ff3">16<span class="ff1">、<span class="_ _35"></span><span class="ff3">17 <span class="ff1">乃至今年，<span class="_ _57"></span>都有各式各样的<span class="_ _2c"> </span><span class="ff3">attention<span class="_ _25"> </span></span>机制结合深度学习网络</span></span></span></span></span></span></span></div><div class="t m0 x3 h6 yad ff1 fs2 fc0 sc0 ls0 ws0">模型被用于处理各种</div><div class="t m0 x12f h4 yae ff3 fs2 fc0 sc0 ls0 ws0">NLP</div><div class="t m0 xb5 h6 yad ff1 fs2 fc0 sc0 ls0 ws0">的任务。<span class="_ _35"></span>在</div><div class="t m0 x47 h4 yae ff3 fs2 fc0 sc0 ls0 ws0">2017</div><div class="t m0 x1a2 h6 yad ff1 fs2 fc0 sc0 ls0 ws0">年，</div><div class="t m0 x17d h4 yae ff3 fs2 fc0 sc0 ls0 ws0">go<span class="_ _f"></span>ogle</div><div class="t m0 x12e h6 yad ff1 fs2 fc0 sc0 ls0 ws0">机器翻译团队发表的<span class="_ _2a"></span>《</div><div class="t m0 x14d h4 yae ff3 fs2 fc0 sc0 ls0 ws0">A<span class="_ _10"></span>tten<span class="_ _10"></span>tion is all y<span class="_ _2f"></span>ou</div><div class="t m0 x3 h6 yaf ff3 fs2 fc0 sc0 ls0 ws0">need<span class="ff1">》中大<span class="_ _f"></span>量使<span class="_ _f"></span>用了自<span class="_ _f"></span>注意<span class="_ _f"></span>力机制<span class="_ _f"></span>（</span>self-attention<span class="ff1">）来学习文<span class="_ _f"></span>本表示，<span class="_ _f"></span>脱离<span class="_ _f"></span>传统<span class="_ _f"></span>的<span class="_ _0"> </span></span>RNN/CNN<span class="ff1">，</span></div><div class="t m0 x3 h6 yb0 ff1 fs2 fc0 sc0 ls0 ws0">同时也使用<span class="_ _f"></span>了新颖的<span class="_ _0"> </span><span class="ff3">multi-head<span class="_ _c"> </span></span>机制。自<span class="_ _f"></span>注意力机<span class="_ _f"></span>制也成为了<span class="_ _f"></span>大家近期<span class="_ _f"></span>研究的热<span class="_ _f"></span>点，可以应用</div><div class="t m0 x3 h6 yb1 ff1 fs2 fc0 sc0 ls0 ws0">到各种<span class="_ _c"> </span><span class="ff3">NLP<span class="_ _c"> </span></span>任务上。</div><div class="t m0 x3 h6 y72b ff3 fs2 fc0 sc0 ls0 ws0">A<span class="_ _10"></span>tten<span class="_ _10"></span>tion<span class="_ _c"> </span><span class="ff1">机制经过长时间的发<span class="_ _f"></span>展，虽然不同论文里的实现方法可能各不一样，<span class="_ _f"></span>但是基本上都遵</span></div><div class="t m0 x3 h6 y72c ff1 fs2 fc0 sc0 ls0 ws0">循着同一个范式。其中包含三个成分<span class="ff3">:</span></div><div class="t m0 x3 h6 y72d ff3 fs2 fc0 sc0 ls0 ws0">Key(<span class="ff1">键</span>)<span class="_ _c"> </span><span class="ff1">与值相对应同时又用来与查询计算相似度作为<span class="_ _c"> </span></span>A<span class="_ _10"></span>tten<span class="_ _10"></span>tion<span class="_ _c"> </span><span class="ff1">选取的依据</span></div><div class="t m0 x3 h6 y72e ff3 fs2 fc0 sc0 ls0 ws0">Query(<span class="ff1">查询</span>)<span class="_ _c"> </span><span class="ff1">一次执行<span class="_ _c"> </span></span>A<span class="_ _10"></span>tten<span class="_ _10"></span>tion<span class="_ _c"> </span><span class="ff1">时的查询</span></div><div class="t m0 x3 h6 y72f ff3 fs2 fc0 sc0 ls0 ws0">V<span class="_ _31"></span>alue(<span class="ff1">值</span>)<span class="_ _c"> </span><span class="ff1">被注意并选取的数据</span></div><div class="t m0 x3 h6 y730 ff1 fs2 fc0 sc0 ls0 ws0">对应的公式为：</div><div class="t m0 x6c h4 y731 ff3 fs2 fc0 sc0 ls0 ws0">A<span class="_ _10"></span>tten<span class="_ _10"></span>tion<span class="_ _c"> </span><span class="ffb">(<span class="ffa">K,<span class="_ _2d"> </span>Q,<span class="_ _2d"> </span>V<span class="_ _25"> </span></span>)<span class="_ _2c"> </span>=<span class="_ _2c"> </span></span>softmax<span class="ffb">(</span>Similarity<span class="ffb">(<span class="ffa">K<span class="_ _f"></span>,<span class="_ _2d"> </span>Q</span>))<span class="ffa">V<span class="_ _65"> </span></span></span>(8.5)</div><div class="t m0 x3 h6 y732 ff1 fs2 fc0 sc0 ls0 ws0">可以看出<span class="_ _c"> </span><span class="ff3">atten<span class="_ _10"></span>tion<span class="_ _c"> </span><span class="ff1">的计算分为三步：</span></span></div><div class="t m0 x3 h6 y733 ff1 fs2 fc0 sc0 ls0 ws0">计算<span class="_ _c"> </span><span class="ff3">K</span>、<span class="ff3">Q<span class="_ _c"> </span></span>的相似矩阵</div><div class="t m0 x3 h6 y734 ff1 fs2 fc0 sc0 ls0 ws0">对相似矩阵作归一化处理</div><div class="t m0 x3 h6 y735 ff1 fs2 fc0 sc0 ls0 ws0">其中，相似矩阵的计算有很多种方式：</div><div class="t m0 xb3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">53</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
</div>
<div class="loading-indicator">
<img alt="" src="pdf2htmlEX-64x64.png"/>
</div>
</body>
</html>
