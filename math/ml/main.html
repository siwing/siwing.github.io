<!DOCTYPE html>
<!-- Created by pdf2htmlEX (https://github.com/coolwanglu/pdf2htmlex) -->
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta charset="utf-8"/>
<meta name="generator" content="pdf2htmlEX"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
<link rel="stylesheet" href="base.min.css"/>
<link rel="stylesheet" href="fancy.min.css"/>
<link rel="stylesheet" href="main.css"/>
<script src="compatibility.min.js"></script>
<script src="pdf2htmlEX.min.js"></script>
<script>
try{
pdf2htmlEX.defaultViewer = new pdf2htmlEX.Viewer({});
}catch(e){}
</script>
<title></title>
</head>
<body>
<div id="sidebar">
<div id="outline">
<ul><li><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",70.87,568.85,null]'>第一部分 机器学习初步 </a><ul><li><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,799.37,null]'>误差与过拟合</a><ul><li><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,662.93,null]'>模型的参数和超参数</a></li><li><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,140.44,null]'>误差与过拟合</a></li><li><a class="l" href="#pfa" data-dest-detail='[10,"XYZ",70.87,42.52,null]'>交叉验证</a><ul><li><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,493.06,null]'>简单交叉验证</a></li><li><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,331,null]'>K 折交叉验证</a></li><li><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,42.52,null]'>留一法和留 P 法</a></li><li><a class="l" href="#pfc" data-dest-detail='[12,"XYZ",70.87,686.75,null]'>时序交叉验证</a></li></ul></li></ul></li><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,799.37,null]'>性能度量——模型的好坏</a><ul><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,483.26,null]'>回归</a><ul><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,407.18,null]'>均方误差</a></li></ul></li><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,212.42,null]'>分类</a><ul><li><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,134.81,null]'>混淆矩阵</a></li><li><a class="l" href="#pff" data-dest-detail='[15,"XYZ",70.87,264.88,null]'>Error Rate与accuracy</a></li><li><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",70.87,533.97,null]'>Precision、Recall</a></li><li><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",70.87,42.52,null]'>TPR、FPR</a></li><li><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",70.87,577.87,null]'>ROC、AUC</a></li><li><a class="l" href="#pf14" data-dest-detail='[20,"XYZ",70.87,267.14,null]'>代价敏感错误率</a></li></ul></li></ul></li></ul></li><li><a class="l" href="#pf16" data-dest-detail='[22,"XYZ",70.87,577.15,null]'>第二部分 机器学习中阶  传统模型</a><ul><li><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,799.37,null]'>贝叶斯分类器</a><ul><li><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,662.85,null]'>判别规则</a><ul><li><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,42.52,null]'>特殊情形</a></li></ul></li><li><a class="l" href="#pf19" data-dest-detail='[25,"XYZ",70.87,624.89,null]'>参数估计</a><ul><li><a class="l" href="#pf19" data-dest-detail='[25,"XYZ",70.87,39.79,null]'>极大似然估计</a></li></ul></li><li><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",70.87,560.37,null]'>朴素贝叶斯分类器</a><ul><li><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",70.87,464.27,null]'>统计语言模型简述</a></li><li><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",70.87,531.57,null]'>朴素贝叶斯</a></li><li><a class="l" href="#pf1c" data-dest-detail='[28,"XYZ",70.87,731.28,null]'>修正</a></li><li><a class="l" href="#pf1c" data-dest-detail='[28,"XYZ",70.87,243.23,null]'>朴素贝叶斯算法的不同方法</a></li></ul></li><li><a class="l" href="#pf1d" data-dest-detail='[29,"XYZ",70.87,464.62,null]'>python示例</a><ul><li><a class="l" href="#pf1d" data-dest-detail='[29,"XYZ",70.87,405.42,null]'>伯努利朴素贝叶斯的示例</a></li><li><a class="l" href="#pf1e" data-dest-detail='[30,"XYZ",70.87,636.56,null]'>对比</a></li></ul></li></ul></li><li><a class="l" href="#pf22" data-dest-detail='[34,"XYZ",70.87,799.37,null]'>决策树</a></li></ul></li><li><a class="l" href="#pf24" data-dest-detail='[36,"XYZ",70.87,577.15,null]'>第三部分 机器学习高阶  优化方法</a><ul><li><a class="l" href="#pf26" data-dest-detail='[38,"XYZ",70.87,799.37,null]'>梯度下降</a><ul><li><a class="l" href="#pf26" data-dest-detail='[38,"XYZ",70.87,662.93,null]'>梯度下降原理</a></li></ul></li><li><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,799.37,null]'>Backpropagation</a><ul><li><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,660.96,null]'>神经网络</a></li><li><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,391.25,null]'>基本函数</a></li><li><a class="l" href="#pf29" data-dest-detail='[41,"XYZ",70.87,664.07,null]'>前向传播</a></li><li><a class="l" href="#pf2a" data-dest-detail='[42,"XYZ",70.87,41.41,null]'>反向传播</a><ul><li><a class="l" href="#pf2b" data-dest-detail='[43,"XYZ",70.87,647.03,null]'>输出层</a></li><li><a class="l" href="#pf2c" data-dest-detail='[44,"XYZ",70.87,743.58,null]'>隐藏层</a></li></ul></li><li><a class="l" href="#pf2c" data-dest-detail='[44,"XYZ",70.87,203.12,null]'>权值更新归纳</a></li></ul></li></ul></li><li><a class="l" href="#pf2e" data-dest-detail='[46,"XYZ",70.87,568.85,null]'>第四部分 神经网络</a><ul><li><a class="l" href="#pf30" data-dest-detail='[48,"XYZ",70.87,799.37,null]'>Perceptron</a><ul><li><a class="l" href="#pf31" data-dest-detail='[49,"XYZ",70.87,564.77,null]'>参数学习</a></li><li><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,315.25,null]'>感知器收敛性</a></li><li><a class="l" href="#pf34" data-dest-detail='[52,"XYZ",70.87,787.3,null]'>感知机的缺陷</a></li></ul></li><li><a class="l" href="#pf36" data-dest-detail='[54,"XYZ",70.87,799.37,null]'>Recurrent Neural Networks</a><ul><li><a class="l" href="#pf36" data-dest-detail='[54,"XYZ",70.87,682.86,null]'>Simple Recurrent Network</a><ul><li><a class="l" href="#pf36" data-dest-detail='[54,"XYZ",70.87,640.54,null]'>前向传播</a></li><li><a class="l" href="#pf38" data-dest-detail='[56,"XYZ",70.87,260.69,null]'>反向传播</a></li><li><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,718.64,null]'>title</a></li></ul></li><li><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,665.75,null]'>LSTM </a><ul><li><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,626.63,null]'>LSTM 概述</a></li><li><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,531.4,null]'>LSTM与RNN的区别</a></li><li><a class="l" href="#pf3a" data-dest-detail='[58,"XYZ",70.87,398.71,null]'>遗忘门</a></li><li><a class="l" href="#pf3a" data-dest-detail='[58,"XYZ",70.87,134.81,null]'>输入门</a></li><li><a class="l" href="#pf3b" data-dest-detail='[59,"XYZ",70.87,709.21,null]'>细胞状态更新</a></li><li><a class="l" href="#pf3b" data-dest-detail='[59,"XYZ",70.87,559.23,null]'>输出门</a></li></ul></li><li><a class="l" href="#pf3b" data-dest-detail='[59,"XYZ",70.87,381.09,null]'>带窥孔的LSTM</a></li><li><a class="l" href="#pf3b" data-dest-detail='[59,"XYZ",70.87,238.54,null]'>GRU</a></li></ul></li><li><a class="l" href="#pf3e" data-dest-detail='[62,"XYZ",70.87,799.37,null]'>Seq2Seq</a><ul><li><a class="l" href="#pf3e" data-dest-detail='[62,"XYZ",70.87,661.1,null]'>Encoder-Decoder</a></li><li><a class="l" href="#pf3f" data-dest-detail='[63,"XYZ",70.87,525.87,null]'>Seq2Seq</a></li><li><a class="l" href="#pf3f" data-dest-detail='[63,"XYZ",70.87,29.4,null]'>Attention机制</a></li></ul></li></ul></li></ul></div>
</div>
<div id="page-container">
<div id="pf1" class="pf w0 h0" data-page-no="1"><div class="pc pc1 w0 h0"><div class="t m0 x0 h1 y0 ff1 fs0 fc0 sc0 ls0 ws0">机器学习</div><div class="t m0 x1 h2 y1 ff2 fs1 fc0 sc0 ls0 ws0">siwing</div><div class="t m0 x2 h3 y2 ff2 fs1 fc0 sc0 ls0 ws0">2020<span class="_ _0"> </span><span class="ff1">年<span class="_ _0"> </span></span>7<span class="_ _0"> </span><span class="ff1">月<span class="_ _0"> </span></span>19<span class="_ _0"> </span><span class="ff1">日</span></div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2" class="pf w0 h0" data-page-no="2"><div class="pc pc2 w0 h0"><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">2</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3" class="pf w0 h0" data-page-no="3"><div class="pc pc3 w0 h0"><div class="t m0 x4 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">目录</div><div class="t m0 x3 h5 y5 ff4 fs4 fc0 sc0 ls0 ws0">第一部分 <span class="fs3">机器学习初步<span class="_ _1"> </span></span><span class="ff5">1</span></div><div class="t m0 x3 h6 y6 ff4 fs2 fc0 sc0 ls0 ws0">第一章<span class="_ _2"> </span>误差与过拟合<span class="_ _3"> </span><span class="ff6">3</span></div><div class="t m0 x5 h4 y7 ff3 fs2 fc0 sc0 ls0 ws0">1.1</div><div class="t m0 x6 h6 y8 ff1 fs2 fc0 sc0 ls0 ws0">模型的参数和超参数</div><div class="t m0 x7 h4 y7 ff3 fs2 fc0 sc0 ls0 ws0">.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _5"> </span>3</div><div class="t m0 x5 h6 y9 ff3 fs2 fc0 sc0 ls0 ws0">1.2<span class="_ _6"> </span><span class="ff1">误差与过拟合<span class="_ _7"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _5"> </span>3</div><div class="t m0 x5 h6 ya ff3 fs2 fc0 sc0 ls0 ws0">1.3<span class="_ _6"> </span><span class="ff1">交叉验证 </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _5"> </span>6</div><div class="t m0 x6 h6 yb ff3 fs2 fc0 sc0 ls0 ws0">1.3.1<span class="_ _8"> </span><span class="ff1">简单交叉验证<span class="_ _0"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _5"> </span>6</div><div class="t m0 x6 h6 yc ff3 fs2 fc0 sc0 ls0 ws0">1.3.2<span class="_ _8"> </span>K<span class="_ _9"> </span><span class="ff1">折交叉验证<span class="_ _a"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _5"> </span>6</div><div class="t m0 x6 h6 yd ff3 fs2 fc0 sc0 ls0 ws0">1.3.3<span class="_ _8"> </span><span class="ff1">留一法和留<span class="_ _9"> </span></span>P<span class="_ _9"> </span><span class="ff1">法<span class="_ _b"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _5"> </span>7</div><div class="t m0 x6 h6 ye ff3 fs2 fc0 sc0 ls0 ws0">1.3.4<span class="_ _8"> </span><span class="ff1">时序交叉验证<span class="_ _0"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _5"> </span>7</div><div class="t m0 x3 h6 yf ff4 fs2 fc0 sc0 ls0 ws0">第二章<span class="_ _2"> </span>性能度量——模型的好坏<span class="_ _c"> </span><span class="ff6">9</span></div><div class="t m0 x5 h6 y10 ff3 fs2 fc0 sc0 ls0 ws0">2.1<span class="_ _6"> </span><span class="ff1">回归<span class="_ _b"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _5"> </span>9</div><div class="t m0 x6 h6 y11 ff3 fs2 fc0 sc0 ls0 ws0">2.1.1<span class="_ _8"> </span><span class="ff1">均方误差<span class="_ _d"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _5"> </span>9</div><div class="t m0 x5 h6 y12 ff3 fs2 fc0 sc0 ls0 ws0">2.2<span class="_ _6"> </span><span class="ff1">分类<span class="_ _b"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _5"> </span>9</div><div class="t m0 x6 h6 y13 ff3 fs2 fc0 sc0 ls0 ws0">2.2.1<span class="_ _8"> </span><span class="ff1">混淆矩阵<span class="_ _d"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _5"> </span>9</div><div class="t m0 x6 h6 y14 ff3 fs2 fc0 sc0 ls0 ws0">2.2.2<span class="_ _8"> </span>Error<span class="_ _9"> </span>Rate<span class="_ _9"> </span><span class="ff1">与<span class="_ _9"> </span></span>accuracy<span class="_ _d"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>10</div><div class="t m0 x6 h6 y15 ff3 fs2 fc0 sc0 ls0 ws0">2.2.3<span class="_ _8"> </span>Precision<span class="ff1">、</span>Recall<span class="_ _a"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>11</div><div class="t m0 x6 h6 y16 ff3 fs2 fc0 sc0 ls0 ws0">2.2.4<span class="_ _8"> </span>TPR<span class="ff1">、</span>FPR<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>13</div><div class="t m0 x6 h6 y17 ff3 fs2 fc0 sc0 ls0 ws0">2.2.5<span class="_ _8"> </span>R<span class="_ _e"></span>OC<span class="ff1">、</span>A<span class="_ _e"></span>UC .<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>13</div><div class="t m0 x6 h6 y18 ff3 fs2 fc0 sc0 ls0 ws0">2.2.6<span class="_ _8"> </span><span class="ff1">代价敏感错误率<span class="_ _f"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>15</div><div class="t m0 x3 h5 y19 ff4 fs4 fc0 sc0 ls0 ws0">第二部分 <span class="fs3">机器学习中阶</span></div><div class="t m0 x3 h3 y1a ff7 fs1 fc0 sc0 ls0 ws0">传统模型<span class="_ _10"> </span><span class="ff5 fs4">17</span></div><div class="t m0 x3 h6 y1b ff4 fs2 fc0 sc0 ls0 ws0">第三章<span class="_ _2"> </span>贝叶斯分类器<span class="_ _11"> </span><span class="ff6">19</span></div><div class="t m0 x5 h6 y1c ff3 fs2 fc0 sc0 ls0 ws0">3.1<span class="_ _6"> </span><span class="ff1">判别规则 </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>19</div><div class="t m0 x6 h6 y1d ff3 fs2 fc0 sc0 ls0 ws0">3.1.1<span class="_ _8"> </span><span class="ff1">特殊情形<span class="_ _d"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>20</div><div class="t m0 x5 h6 y1e ff3 fs2 fc0 sc0 ls0 ws0">3.2<span class="_ _6"> </span><span class="ff1">参数估计 </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>20</div><div class="t m0 x8 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">3</div><a class="l" href="#pf6" data-dest-detail='[6,"XYZ",70.87,568.85,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:949.791000px;width:183.751000px;height:20.662000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:901.899000px;width:106.909000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,662.93,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:866.007000px;width:123.272000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf8" data-dest-detail='[8,"XYZ",70.87,140.44,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:832.557000px;width:90.545000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfa" data-dest-detail='[10,"XYZ",70.87,42.52,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:799.108500px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,493.06,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:765.660000px;width:100.363000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,331,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:732.211500px;width:101.574000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfb" data-dest-detail='[11,"XYZ",70.87,42.52,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:698.763000px;width:115.058000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfc" data-dest-detail='[12,"XYZ",70.87,686.75,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:665.313000px;width:100.363000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:617.809500px;width:161.412000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,483.26,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:581.916000px;width:46.909000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,407.18,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:548.467500px;width:78.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,212.42,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:515.019000px;width:46.909000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pfe" data-dest-detail='[14,"XYZ",70.87,134.81,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:481.570500px;width:78.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pff" data-dest-detail='[15,"XYZ",70.87,264.88,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:448.120500px;width:146.541000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf10" data-dest-detail='[16,"XYZ",70.87,533.97,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:414.672000px;width:118.331000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",70.87,42.52,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:381.223500px;width:91.734000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",70.87,577.87,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:347.775000px;width:93.840000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf14" data-dest-detail='[20,"XYZ",70.87,267.14,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:314.326500px;width:111.272000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf16" data-dest-detail='[22,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:235.683000px;width:183.751000px;height:20.662000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf16" data-dest-detail='[22,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:210.442500px;width:68.862000px;height:17.216000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:161.824500px;width:106.909000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,662.85,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:125.931000px;width:68.727000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf18" data-dest-detail='[24,"XYZ",70.87,42.52,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:92.482500px;width:78.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf19" data-dest-detail='[25,"XYZ",70.87,624.89,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:59.034000px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf4" class="pf w0 h0" data-page-no="4"><div class="pc pc4 w0 h0"><div class="t m0 x3 h7 y1f ff8 fs5 fc0 sc0 ls0 ws0">目录</div><div class="t m0 x6 h6 y20 ff3 fs2 fc0 sc0 ls0 ws0">3.2.1<span class="_ _8"> </span><span class="ff1">极大似然估计<span class="_ _0"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>21</div><div class="t m0 x5 h6 y21 ff3 fs2 fc0 sc0 ls0 ws0">3.3<span class="_ _6"> </span><span class="ff1">朴素贝叶斯分类器<span class="_ _d"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>21</div><div class="t m0 x6 h6 y22 ff3 fs2 fc0 sc0 ls0 ws0">3.3.1<span class="_ _8"> </span><span class="ff1">统计语言模型简述<span class="_ _2"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>21</div><div class="t m0 x6 h6 y23 ff3 fs2 fc0 sc0 ls0 ws0">3.3.2<span class="_ _8"> </span><span class="ff1">朴素贝叶斯<span class="_ _b"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>22</div><div class="t m0 x6 h6 y24 ff3 fs2 fc0 sc0 ls0 ws0">3.3.3<span class="_ _8"> </span><span class="ff1">修正<span class="_ _7"> </span></span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>23</div><div class="t m0 x6 h6 y25 ff3 fs2 fc0 sc0 ls0 ws0">3.3.4<span class="_ _8"> </span><span class="ff1">朴素贝叶斯算法的不同方法<span class="_ _b"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>23</div><div class="t m0 x5 h6 y26 ff3 fs2 fc0 sc0 ls0 ws0">3.4<span class="_ _6"> </span>p<span class="_ _e"></span>ython<span class="_ _9"> </span><span class="ff1">示例<span class="_ _12"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>24</div><div class="t m0 x6 h6 y27 ff3 fs2 fc0 sc0 ls0 ws0">3.4.1<span class="_ _8"> </span><span class="ff1">伯努利朴素贝叶斯的示例<span class="_ _d"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>24</div><div class="t m0 x6 h6 y28 ff3 fs2 fc0 sc0 ls0 ws0">3.4.2<span class="_ _8"> </span><span class="ff1">对比<span class="_ _7"> </span></span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>25</div><div class="t m0 x3 h6 y29 ff4 fs2 fc0 sc0 ls0 ws0">第四章<span class="_ _2"> </span>决策树<span class="_ _13"> </span><span class="ff6">29</span></div><div class="t m0 x3 h5 y2a ff4 fs4 fc0 sc0 ls0 ws0">第三部分 <span class="fs3">机器学习高阶</span></div><div class="t m0 x3 h3 y2b ff7 fs1 fc0 sc0 ls0 ws0">优化方法<span class="_ _10"> </span><span class="ff5 fs4">31</span></div><div class="t m0 x3 h6 y2c ff4 fs2 fc0 sc0 ls0 ws0">第五章<span class="_ _2"> </span>梯度下降<span class="_ _14"> </span><span class="ff6">33</span></div><div class="t m0 x5 h6 y2d ff3 fs2 fc0 sc0 ls0 ws0">5.1<span class="_ _6"> </span><span class="ff1">梯度下降原理<span class="_ _7"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>33</div><div class="t m0 x3 h6 y2e ff4 fs2 fc0 sc0 ls0 ws0">第六章<span class="_ _2"> </span><span class="ff6">Bac<span class="_ _e"></span>kpropagation<span class="_ _15"> </span>35</span></div><div class="t m0 x5 h6 y2f ff3 fs2 fc0 sc0 ls0 ws0">6.1<span class="_ _6"> </span><span class="ff1">神经网络 </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>35</div><div class="t m0 x5 h6 y30 ff3 fs2 fc0 sc0 ls0 ws0">6.2<span class="_ _6"> </span><span class="ff1">基本函数 </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>35</div><div class="t m0 x5 h6 y31 ff3 fs2 fc0 sc0 ls0 ws0">6.3<span class="_ _6"> </span><span class="ff1">前向传播 </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>36</div><div class="t m0 x5 h6 y32 ff3 fs2 fc0 sc0 ls0 ws0">6.4<span class="_ _6"> </span><span class="ff1">反向传播 </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>38</div><div class="t m0 x6 h6 y33 ff3 fs2 fc0 sc0 ls0 ws0">6.4.1<span class="_ _8"> </span><span class="ff1">输出层<span class="_ _a"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>38</div><div class="t m0 x6 h6 y34 ff3 fs2 fc0 sc0 ls0 ws0">6.4.2<span class="_ _8"> </span><span class="ff1">隐藏层<span class="_ _a"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>39</div><div class="t m0 x5 h6 y35 ff3 fs2 fc0 sc0 ls0 ws0">6.5<span class="_ _6"> </span><span class="ff1">权值更新归纳<span class="_ _7"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>39</div><div class="t m0 x3 h5 y36 ff4 fs4 fc0 sc0 ls0 ws0">第四部分 <span class="fs3">神经网络<span class="_ _16"> </span></span><span class="ff5">41</span></div><div class="t m0 x3 h6 y37 ff4 fs2 fc0 sc0 ls0 ws0">第七章<span class="_ _2"> </span><span class="ff6">P<span class="_ _e"></span>erceptron<span class="_ _17"> </span>43</span></div><div class="t m0 x5 h6 y38 ff3 fs2 fc0 sc0 ls0 ws0">7.1<span class="_ _6"> </span><span class="ff1">参数学习 </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>44</div><div class="t m0 x5 h6 y39 ff3 fs2 fc0 sc0 ls0 ws0">7.2<span class="_ _6"> </span><span class="ff1">感知器收敛性<span class="_ _7"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>46</div><div class="t m0 x5 h6 y3a ff3 fs2 fc0 sc0 ls0 ws0">7.3<span class="_ _6"> </span><span class="ff1">感知机的缺陷<span class="_ _7"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>47</div><div class="t m0 x3 h6 y3b ff4 fs2 fc0 sc0 ls0 ws0">第八章<span class="_ _2"> </span><span class="ff6">Recurren<span class="_ _e"></span>t<span class="_ _a"> </span>Neural<span class="_ _12"> </span>Net<span class="_ _e"></span>w<span class="_ _e"></span>orks<span class="_ _18"> </span>49</span></div><div class="t m0 x5 h4 y1e ff3 fs2 fc0 sc0 ls0 ws0">8.1<span class="_ _6"> </span>Simple<span class="_ _9"> </span>Recurren<span class="_ _e"></span>t<span class="_ _9"> </span>Net<span class="_ _e"></span>w<span class="_ _e"></span>ork<span class="_ _12"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _19"> </span>49</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">4</div><a class="l" href="#pf19" data-dest-detail='[25,"XYZ",70.87,39.79,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1177.872000px;width:100.363000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",70.87,560.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:1144.117500px;width:112.363000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",70.87,464.27,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1110.364500px;width:122.181000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",70.87,531.57,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1076.611500px;width:89.454000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1c" data-dest-detail='[28,"XYZ",70.87,731.28,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1042.858500px;width:56.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1c" data-dest-detail='[28,"XYZ",70.87,243.23,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1009.105500px;width:165.818000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1d" data-dest-detail='[29,"XYZ",70.87,464.62,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:975.351000px;width:83.891000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1d" data-dest-detail='[29,"XYZ",70.87,405.42,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:941.598000px;width:154.909000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1e" data-dest-detail='[30,"XYZ",70.87,636.56,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:907.845000px;width:56.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf22" data-dest-detail='[34,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:858.817500px;width:74.182000px;height:10.910000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf24" data-dest-detail='[36,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:776.272500px;width:183.751000px;height:20.662000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf24" data-dest-detail='[36,"XYZ",70.87,577.15,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:751.134000px;width:68.862000px;height:17.215000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf26" data-dest-detail='[38,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:700.992000px;width:85.091000px;height:10.910000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf26" data-dest-detail='[38,"XYZ",70.87,662.93,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:664.795500px;width:90.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:613.242000px;width:133.778000px;height:15.578000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,660.96,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:579.570000px;width:68.727000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf28" data-dest-detail='[40,"XYZ",70.87,391.25,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:545.817000px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf29" data-dest-detail='[41,"XYZ",70.87,664.07,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:512.064000px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2a" data-dest-detail='[42,"XYZ",70.87,41.41,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:478.311000px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2b" data-dest-detail='[43,"XYZ",70.87,647.03,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:444.558000px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2c" data-dest-detail='[44,"XYZ",70.87,743.58,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:410.805000px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2c" data-dest-detail='[44,"XYZ",70.87,203.12,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:377.050500px;width:90.545000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf2e" data-dest-detail='[46,"XYZ",70.87,568.85,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:297.376500px;width:142.426000px;height:20.662000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf30" data-dest-detail='[48,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:245.436000px;width:102.186000px;height:15.578000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf31" data-dest-detail='[49,"XYZ",70.87,564.77,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:211.765500px;width:68.727000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf33" data-dest-detail='[51,"XYZ",70.87,315.25,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:178.011000px;width:90.545000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf34" data-dest-detail='[52,"XYZ",70.87,787.3,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:144.258000px;width:90.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf36" data-dest-detail='[54,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:92.706000px;width:194.226000px;height:15.578000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf36" data-dest-detail='[54,"XYZ",70.87,682.86,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:59.034000px;width:151.691000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf5" class="pf w0 h0" data-page-no="5"><div class="pc pc5 w0 h0"><div class="t m0 x6 h6 y20 ff3 fs2 fc0 sc0 ls0 ws0">8.1.1<span class="_ _8"> </span><span class="ff1">前向传播<span class="_ _d"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>49</div><div class="t m0 x6 h6 y3c ff3 fs2 fc0 sc0 ls0 ws0">8.1.2<span class="_ _8"> </span><span class="ff1">反向传播<span class="_ _d"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>51</div><div class="t m0 x6 h4 y3d ff3 fs2 fc0 sc0 ls0 ws0">8.1.3<span class="_ _8"> </span>title<span class="_ _2"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>52</div><div class="t m0 x5 h4 y3e ff3 fs2 fc0 sc0 ls0 ws0">8.2<span class="_ _6"> </span>LSTM<span class="_ _1a"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>52</div><div class="t m0 x6 h6 y3f ff3 fs2 fc0 sc0 ls0 ws0">8.2.1<span class="_ _8"> </span>LSTM<span class="_ _9"> </span><span class="ff1">概述<span class="_ _4"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>52</div><div class="t m0 x6 h6 y40 ff3 fs2 fc0 sc0 ls0 ws0">8.2.2<span class="_ _8"> </span>LSTM<span class="_ _9"> </span><span class="ff1">与<span class="_ _9"> </span></span>RNN<span class="_ _9"> </span><span class="ff1">的区别<span class="_ _9"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>52</div><div class="t m0 x6 h6 y41 ff3 fs2 fc0 sc0 ls0 ws0">8.2.3<span class="_ _8"> </span><span class="ff1">遗忘门<span class="_ _a"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>53</div><div class="t m0 x6 h6 y42 ff3 fs2 fc0 sc0 ls0 ws0">8.2.4<span class="_ _8"> </span><span class="ff1">输入门<span class="_ _a"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>53</div><div class="t m0 x6 h6 y43 ff3 fs2 fc0 sc0 ls0 ws0">8.2.5<span class="_ _8"> </span><span class="ff1">细胞状态更新<span class="_ _0"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>54</div><div class="t m0 x6 h6 y44 ff3 fs2 fc0 sc0 ls0 ws0">8.2.6<span class="_ _8"> </span><span class="ff1">输出门<span class="_ _a"> </span></span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>54</div><div class="t m0 x5 h6 y45 ff3 fs2 fc0 sc0 ls0 ws0">8.3<span class="_ _6"> </span><span class="ff1">带窥孔的<span class="_ _9"> </span></span>LSTM<span class="_ _1b"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>54</div><div class="t m0 x5 h4 y46 ff3 fs2 fc0 sc0 ls0 ws0">8.4<span class="_ _6"> </span>GR<span class="_ _e"></span>U<span class="_ _1c"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _19"> </span>54</div><div class="t m0 x3 h6 y47 ff4 fs2 fc0 sc0 ls0 ws0">第九章<span class="_ _2"> </span><span class="ff6">Seq2Seq<span class="_ _1d"> </span>57</span></div><div class="t m0 x5 h4 y48 ff3 fs2 fc0 sc0 ls0 ws0">9.1<span class="_ _6"> </span>Enco<span class="_ _1e"></span>der-Deco<span class="_ _1e"></span>der<span class="_ _1a"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>57</div><div class="t m0 x5 h4 y49 ff3 fs2 fc0 sc0 ls0 ws0">9.2<span class="_ _6"> </span>Seq2Seq<span class="_ _b"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _8"> </span>58</div><div class="t m0 x5 h6 y4a ff3 fs2 fc0 sc0 ls0 ws0">9.3<span class="_ _6"> </span>A<span class="_ _e"></span>tten<span class="_ _e"></span>tion<span class="_ _9"> </span><span class="ff1">机制<span class="_ _2"> </span></span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _0"> </span>.<span class="_ _4"> </span>.<span class="_ _8"> </span>59</div><a class="l" href="#pf36" data-dest-detail='[54,"XYZ",70.87,640.54,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1177.872000px;width:78.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf38" data-dest-detail='[56,"XYZ",70.87,260.69,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1144.456500px;width:78.545000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,718.64,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1111.042500px;width:54.305000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,665.75,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:1077.627000px;width:55.854000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,626.63,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1044.213000px;width:91.123000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",70.87,531.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:1010.797500px;width:144.600000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3a" data-dest-detail='[58,"XYZ",70.87,398.71,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:977.383500px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3a" data-dest-detail='[58,"XYZ",70.87,134.81,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:943.968000px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3b" data-dest-detail='[59,"XYZ",70.87,709.21,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:910.554000px;width:100.363000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3b" data-dest-detail='[59,"XYZ",70.87,559.23,null]'><div class="d m1" style="border-style:none;position:absolute;left:168.481500px;bottom:877.138500px;width:67.636000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3b" data-dest-detail='[59,"XYZ",70.87,381.09,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:843.724500px;width:103.123000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3b" data-dest-detail='[59,"XYZ",70.87,238.54,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:810.309000px;width:49.560000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3e" data-dest-detail='[62,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:760.449000px;width:86.411000px;height:15.578000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3e" data-dest-detail='[62,"XYZ",70.87,661.1,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:727.116000px;width:106.974000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3f" data-dest-detail='[63,"XYZ",70.87,525.87,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:693.702000px;width:63.883000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf3f" data-dest-detail='[63,"XYZ",70.87,29.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:130.845000px;bottom:660.286500px;width:96.305000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf6" class="pf w0 h0" data-page-no="6"><div class="pc pc6 w0 h0"><div class="t m0 x9 h5 y4b ff4 fs3 fc0 sc0 ls0 ws0">第一部分</div><div class="t m0 xa h5 y4c ff4 fs3 fc0 sc0 ls0 ws0">机器学习初步</div><div class="t m0 x8 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">1</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf7" class="pf w0 h0" data-page-no="7"><div class="pc pc7 w0 h0"></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf8" class="pf w0 h0" data-page-no="8"><div class="pc pc8 w0 h0"><img class="bi xb y4d w1 h8" alt="" src="bg8.png"/><div class="t m0 xc h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第一章 误差与过拟合</div><div class="t m0 xd h9 y4e ff5 fs6 fc0 sc0 ls0 ws0">1.1<span class="_ _1f"> </span><span class="ff9">模型的参数和超参数</span></div><div class="t m0 x3 h6 y4f ff1 fs2 fc0 sc0 ls0 ws0">参数<span class="_ _20"></span>（<span class="ff3">parameter</span>）<span class="_ _20"></span>和超参数<span class="_ _20"></span>（<span class="ff3">h<span class="_ _e"></span>yp<span class="_ _1e"></span>erparameter<span class="ff1">）<span class="_ _20"></span>在文献中常被混为一谈。<span class="_ _21"></span>研究者经常提到的<span class="_ _22"></span>“调</span></span></div><div class="t m0 x3 h6 y50 ff1 fs2 fc0 sc0 ls0 ws0">参”<span class="_ _23"></span>，实际上是调整超参数。为了防止语言上的混淆，我们首先对两者进行界定。</div><div class="t m0 x3 h6 y51 ff1 fs2 fc0 sc0 ls0 ws0">参数是模型的内部变量，<span class="_ _23"></span>是模型通过学习可以确定的参数。<span class="_ _24"></span>以简单的一元线性回归模型<span class="_ _f"> </span><span class="ffa">y<span class="_ _25"> </span><span class="ffb">=<span class="_ _25"> </span></span>kx<span class="_ _1e"></span><span class="ffb">+<span class="_ _26"></span></span>b</span></div><div class="t m0 x3 h6 y52 ff1 fs2 fc0 sc0 ls0 ws0">为例，<span class="_ _27"></span>斜率<span class="_ _25"> </span><span class="ffa">k<span class="_ _25"> </span></span>和截距<span class="_ _25"> </span><span class="ffa">b<span class="_ _25"> </span></span>是该模型的参数。<span class="_ _21"></span>支持向量机模型的支持向量，<span class="_ _27"></span>神经网络模型的神经元连</div><div class="t m0 x3 h6 y53 ff1 fs2 fc0 sc0 ls0 ws0">接权值都是模型的参数。对于决策树类的模型而言，每一步分裂的规则也属于模型参数的范畴。</div><div class="t m0 x3 h6 y54 ff1 fs2 fc0 sc0 ls0 ws0">超参数是模型的外部变量，<span class="_ _28"></span>是使用者用来确定模型的参数。<span class="_ _27"></span>假设我们希望采用回归模型对一组自</div><div class="t m0 x3 h6 y55 ff1 fs2 fc0 sc0 ls0 ws0">变量<span class="_ _25"> </span><span class="ffa">x<span class="_ _f"> </span></span>和因变量<span class="_ _25"> </span><span class="ffa">y<span class="_ _25"> </span></span>进行拟合，<span class="_ _28"></span>究竟使用线性<span class="_ _28"></span>（一次）<span class="_ _21"></span>模型<span class="_ _25"> </span><span class="ffa">y<span class="_ _25"> </span><span class="ffb">=<span class="_ _f"> </span></span>k<span class="_ _1e"></span>x<span class="_ _29"> </span><span class="ffb">+<span class="_ _29"></span></span>b</span>、<span class="_ _2a"></span>二次模型<span class="_ _25"> </span><span class="ffa">y<span class="_ _25"> </span><span class="ffb">=<span class="_ _f"> </span></span>k</span></div><div class="t m0 xe ha y56 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xe hb y57 ffd fs7 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf h4 y55 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _29"></span><span class="ffa">k</span></div><div class="t m0 x10 ha y58 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x11 h6 y55 ffa fs2 fc0 sc0 ls0 ws0">x<span class="_ _29"> </span><span class="ffb">+<span class="_ _2b"></span></span>b<span class="ff1">、</span></div><div class="t m0 x3 h6 y59 ff1 fs2 fc0 sc0 ls0 ws0">三次模型<span class="_ _25"> </span><span class="ffa">y<span class="_ _25"> </span><span class="ffb">=<span class="_ _25"> </span></span>k</span></div><div class="t m0 x12 ha y5a ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13 hc y59 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x14 ha y5b ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x15 h4 y59 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _2c"> </span><span class="ffa">k</span></div><div class="t m0 x16 ha y5a ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x17 hc y59 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x18 ha y5b ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x19 h4 y59 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _2c"> </span><span class="ffa">k</span></div><div class="t m0 x1a ha y5a ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x1b h6 y59 ffa fs2 fc0 sc0 ls0 ws0">x<span class="_ _2c"> </span><span class="ffb">+<span class="_ _2c"> </span></span>b<span class="_ _25"> </span><span class="ff1">或者更高次的回归模型，<span class="_ _20"></span>这里的多项式次数就是模型的超参</span></div><div class="t m0 x3 h6 y5c ff1 fs2 fc0 sc0 ls0 ws0">数。下图展示了对回归模型中参数和超参数的辨析。</div><div class="t m0 x1c h6 y5d ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">1.1:<span class="_ _1c"> </span></span>超参数和参数</div><div class="t m0 x3 h6 y5e ff1 fs2 fc0 sc0 ls0 ws0">支持向量机模型中核函数类型、<span class="_ _21"></span>惩罚系数等，<span class="_ _27"></span>随机森林模型的树棵数、<span class="_ _21"></span>最大特征数、<span class="_ _21"></span>剪枝参数等，</div><div class="t m0 x3 h6 y5f ff3 fs2 fc0 sc0 ls0 ws0">X<span class="_ _e"></span>GBo<span class="_ _1e"></span>ost<span class="_ _9"> </span><span class="ff1">模型的学习率、<span class="_ _e"></span>最大树深度、<span class="_ _e"></span>行采样比例等、<span class="_ _e"></span>神经网络模型的网络层数、<span class="_ _2d"></span>神经元个数、</span></div><div class="t m0 x3 h6 y60 ff1 fs2 fc0 sc0 ls0 ws0">激活函数类型等，这些都属于模型的超参数。</div><div class="t m0 x3 h6 y61 ff1 fs2 fc0 sc0 ls0 ws0">模型<span class="_ _1e"></span>的参<span class="_ _1e"></span>数可<span class="_ _1e"></span>以<span class="_ _1e"></span>从训<span class="_ _1e"></span>练集<span class="_ _1e"></span>学习<span class="_ _1e"></span>到，模<span class="_ _1e"></span>型<span class="_ _1e"></span>的超<span class="_ _1e"></span>参数<span class="_ _1e"></span>无法<span class="_ _1e"></span>从<span class="_ _1e"></span>训练<span class="_ _1e"></span>集中<span class="_ _1e"></span>直接<span class="_ _1e"></span>学习<span class="_ _1e"></span>到。<span class="_ _1e"></span>模型<span class="_ _1e"></span>的超<span class="_ _1e"></span>参数<span class="_ _1e"></span>应</div><div class="t m0 x3 h6 y62 ff1 fs2 fc0 sc0 ls0 ws0">如何学习？<span class="_ _20"></span>在解答这一问题之前，<span class="_ _28"></span>首先要介绍模型超参数选择不当导致的问题—<span class="_ _2d"></span>—欠拟合和过拟</div><div class="t m0 x3 h6 y63 ff1 fs2 fc0 sc0 ls0 ws0">合。</div><div class="t m0 x1d h9 y64 ff5 fs6 fc0 sc0 ls0 ws0">1.2<span class="_ _1f"> </span><span class="ff9">误差与过拟合</span></div><div class="t m0 x3 h6 y1e ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">1.1<span class="_ _4"> </span></span><span class="fc1">误差<span class="_ _a"> </span><span class="ff6">(error)</span>：<span class="_ _9"> </span></span><span class="ff1">样本的真实值与预测结果之间的差异。</span></div><div class="t m0 x8 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">3</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf9" class="pf w0 h0" data-page-no="9"><div class="pc pc9 w0 h0"><img class="bi x3 y65 w2 hd" alt="" src="bg9.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">1.2<span class="_ _d"> </span><span class="ff8">误差与过拟合</span></div><div class="t m0 x1e h6 y66 ff1 fs2 fc0 sc0 ls0 ws0">训练误差<span class="_ _9"> </span><span class="ff3">(training<span class="_ _9"> </span>error)</span>：在训练集上的误差，又称为经验误差（<span class="ff3">empirical<span class="_ _9"> </span>error</span>）</div><div class="t m0 x1e h6 y67 ff1 fs2 fc0 sc0 ls0 ws0">测试误差（<span class="ff3">test<span class="_ _9"> </span>error</span>）<span class="_ _23"></span>：在测试集上的误差。</div><div class="t m0 x1e h6 y68 ff1 fs2 fc0 sc0 ls0 ws0">泛化误差（<span class="ff3">generalization<span class="_ _9"> </span>error</span>）<span class="_ _23"></span>：在所有新样本上的误差，<span class="_ _e"></span>即测试误差（测试集的样本都</div><div class="t m0 x1e h6 y69 ff1 fs2 fc0 sc0 ls0 ws0">是新样本）<span class="_ _23"></span>。</div><div class="t m0 x3 h6 y6a ff1 fs2 fc0 sc0 ls0 ws0">训练误差很小是没什么用的，<span class="_ _28"></span>我们希望得到在新样本上表现得很好的学习器，<span class="_ _27"></span>即泛化误差小的学</div><div class="t m0 x3 h6 y6b ff1 fs2 fc0 sc0 ls0 ws0">习器。因此，我们应该让学习器尽可能<span class="_ _1e"></span>地从训练集中学出普适性的“一般特征”<span class="_ _2e"></span>，这样在遇到新</div><div class="t m0 x3 h6 y6c ff1 fs2 fc0 sc0 ls0 ws0">样本时才能做出正确的判别。<span class="_ _22"></span>然而，<span class="_ _22"></span>当学习器把训练集学得<span class="_ _2d"></span>“太好”<span class="_ _2d"></span>的时候，<span class="_ _22"></span>即把一些训练样本</div><div class="t m0 x3 h6 y6d ff1 fs2 fc0 sc0 ls0 ws0">的自身特点当做了普遍特征；<span class="_ _28"></span>同时也有学习能力不足的情况，<span class="_ _27"></span>即训练集的基本特征都没有学习出</div><div class="t m0 x3 h6 y6e ff1 fs2 fc0 sc0 ls0 ws0">来。我们定义：</div><div class="t m0 x3 h6 y6f ff1 fs2 fc0 sc0 ls0 ws0">过拟合（<span class="ff3">o<span class="_ _e"></span>v<span class="_ _e"></span>ertting<span class="ff1">）<span class="_ _23"></span>：当训练误差减小，测试误差增大，则存在过拟合。</span></span></div><div class="t m0 x3 h6 y70 ff1 fs2 fc0 sc0 ls0 ws0">欠拟合（<span class="ff3">undertting</span>）<span class="_ _23"></span>：训练误差和测试误差都在减小，则存在欠拟合。</div><div class="t m0 x1f h6 y71 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">1.2:<span class="_ _1c"> </span></span>欠拟合与过拟合</div><div class="t m0 x3 h6 y72 ff1 fs2 fc0 sc0 ls0 ws0">可以得知：<span class="_ _22"></span>在过拟合问题中，<span class="_ _2d"></span>训练误差十分小，<span class="_ _22"></span>但测试误差教大；<span class="_ _2d"></span>在欠拟合问题中，<span class="_ _22"></span>训练误差和</div><div class="t m0 x3 h6 y73 ff1 fs2 fc0 sc0 ls0 ws0">测试误差都比较大。<span class="_ _22"></span>目前，<span class="_ _22"></span>欠拟合问题比较容易克服，<span class="_ _22"></span>例如增加迭代次数等，<span class="_ _22"></span>但过拟合问题还没</div><div class="t m0 x3 h6 y74 ff1 fs2 fc0 sc0 ls0 ws0">有十分好的解决方案，过拟合是机器学习面临的关键障碍。</div><div class="t m0 x3 h6 y75 ff1 fs2 fc0 sc0 ls0 ws0">对于<span class="_ _1e"></span>一般<span class="_ _1e"></span>的<span class="_ _1e"></span>回归<span class="_ _1e"></span>问题，<span class="_ _1e"></span>如<span class="_ _1e"></span>果我<span class="_ _1e"></span>们假<span class="_ _1e"></span>设</div><div class="t m0 x20 h4 y76 ff6 fs2 fc0 sc0 ls0 ws0">Y</div><div class="t m0 x21 h4 y75 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x22 hc y76 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 x23 h4 y75 ffb fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x24 h4 y76 ff6 fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x25 h4 y75 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _f"> </span>+</div><div class="t m0 x26 hc y76 ffa fs2 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 x27 h6 y75 ff1 fs2 fc0 sc0 ls0 ws0">，其<span class="_ _1e"></span>中</div><div class="t m0 x28 h4 y76 ff6 fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x29 h4 y75 ffb fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x2a hc y76 ffa fs2 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 x2b h4 y75 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _12"> </span>=<span class="_ _a"> </span>0</div><div class="t m0 x2c h6 y76 ff1 fs2 fc0 sc0 ls0 ws0">，并<span class="_ _1e"></span>且</div><div class="t m0 x2d h4 y75 ff6 fs2 fc0 sc0 ls0 ws0">Var</div><div class="t m0 x2e h4 y76 ffb fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x2f hc y75 ffa fs2 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 x30 h4 y76 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _12"> </span>=</div><div class="t m0 x31 hc y75 ffa fs2 fc0 sc0 ls0 ws0">σ</div><div class="t m0 x32 ha y77 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x32 hb y78 ffd fs7 fc0 sc0 ls0 ws0">ϵ</div><div class="t m0 x33 h6 y75 ff1 fs2 fc0 sc0 ls0 ws0">。如</div><div class="t m0 x3 h6 y79 ff1 fs2 fc0 sc0 ls0 ws0">果使用均方误差（<span class="ff3">mean<span class="_ _25"> </span>squared<span class="_ _9"> </span>error</span>，<span class="ff3">MSE</span>）来衡量模型拟合程度的优劣的情况下，<span class="_ _2d"></span>在输入点</div><div class="t m0 x3 h4 y7a ff6 fs2 fc0 sc0 ls0 ws0">X <span class="ffb">=<span class="_ _f"> </span><span class="ffa">x</span></span></div><div class="t m0 x34 ha y7b ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x35 h6 y7a ff1 fs2 fc0 sc0 ls0 ws0">处，回归拟合值</div><div class="t m0 x36 h4 y7c ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x37 h6 y7a ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(<span class="ff6">X</span>)<span class="_ _9"> </span><span class="ff1">的均方误差：</span></span></div><div class="t m0 x38 h4 y7d ff3 fs2 fc0 sc0 ls0 ws0">MSE<span class="_ _2c"> </span><span class="ffb">(<span class="ffa">x</span></span></div><div class="t m0 x18 ha y7e ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x39 h4 y7d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff3">E</span></div><div class="t m0 x3a he y7f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3b he y80 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3c h4 y7d ffa fs2 fc0 sc0 ls0 ws0">Y<span class="_ _1c"> </span><span class="fff">−</span></div><div class="t m0 x3d h4 y81 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x3e h4 y7d ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _f"> </span><span class="ffb">(</span>x</div><div class="t m0 x3f ha y7e ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x22 h4 y7d ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x40 he y80 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x24 ha y82 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x41 h4 y7d fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">X<span class="_ _a"> </span><span class="ffb">=<span class="_ _f"> </span></span>x</span></div><div class="t m0 x42 ha y7e ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x43 he y7f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x44 h4 y83 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">σ</span></div><div class="t m0 x7 ha y84 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x7 hb y85 ffd fs7 fc0 sc0 ls0 ws0">ε</div><div class="t m0 x45 h4 y83 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x46 he y86 ffe fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1f h4 y83 ff3 fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x47 h4 y87 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x48 h4 y83 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _f"> </span><span class="ffb">(</span>x</div><div class="t m0 x49 ha y88 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x4a h4 y83 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">f<span class="_ _f"> </span></span></span>(<span class="ffa">x</span></div><div class="t m0 x4b ha y88 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x4c h4 y83 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x26 he y86 ffe fs2 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4d ha y89 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x42 h4 y83 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff3">E</span></div><div class="t m0 x4e he y86 ffe fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x4f h4 y87 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x50 h4 y83 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _f"> </span><span class="ffb">(</span>x</div><div class="t m0 x51 ha y88 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x52 h4 y83 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">E</span></span></div><div class="t m0 x53 h4 y87 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x54 h4 y83 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _f"> </span><span class="ffb">(</span>x</div><div class="t m0 x55 ha y88 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x56 h4 y83 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x57 he y86 ffe fs2 fc0 sc0 ls0 ws0">i</div><div class="t m0 x58 ha y89 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x44 h4 y8a ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">σ</span></div><div class="t m0 x7 ha y8b ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x7 hb y8c ffd fs7 fc0 sc0 ls0 ws0">ε</div><div class="t m0 x45 h4 y8a ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff3">Bias</span></div><div class="t m0 x9 ha y8b ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x59 he y8d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4a h4 y8e ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x5a h4 y8a ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _f"> </span><span class="ffb">(</span>x</div><div class="t m0 x5b ha y8f ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x5c h4 y8a ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x5d he y8d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5e h4 y8a ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff3">Var</span></div><div class="t m0 x5f he y8d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x60 h4 y8e ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x61 h4 y8a ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _f"> </span><span class="ffb">(</span>x</div><div class="t m0 x62 ha y8f ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x29 h4 y8a ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x2a he y8d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x44 h4 y90 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _1a"> </span><span class="ff3">Irreducible<span class="_ _25"> </span>Error<span class="_ _7"> </span></span>+<span class="_ _7"> </span><span class="ff3">Bias</span></div><div class="t m0 x63 ha y91 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x64 h4 y90 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _7"> </span><span class="ff3">V<span class="_ _22"></span>ariance</span></div><div class="t m0 x33 h4 y92 ff3 fs2 fc0 sc0 ls0 ws0">(1.1)</div><div class="t m0 x1e h6 y93 ff1 fs2 fc0 sc0 ls0 ws0">注意，<span class="_ _31"></span>输入点<span class="_ _25"> </span><span class="ff6">X <span class="ffb">=<span class="_ _2f"> </span><span class="ffa">x</span></span></span></div><div class="t m0 x65 ha y94 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x36 h6 y93 ff1 fs2 fc0 sc0 ls0 ws0">是固定的，<span class="_ _31"></span><span class="ff6">Y <span class="ffb">=<span class="_ _f"> </span><span class="ffa">f<span class="_ _29"> </span></span>(</span>X</span></div><div class="t m0 x24 hf y94 ff10 fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x8 h4 y93 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span>+<span class="_ _30"> </span><span class="ffa">ϵ<span class="_ _f"> </span></span>=<span class="_ _2f"> </span><span class="ffa">Y</span></div><div class="t m0 x5f ha y94 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x66 h6 y93 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _32"></span>，<span class="_ _31"></span><span class="ff6">Y<span class="_ _25"> </span><span class="ff1">也是固定的，<span class="_ _31"></span>即常数。<span class="_ _2d"></span>而不固</span></span></div><div class="t m0 x1e h6 y95 ff1 fs2 fc0 sc0 ls0 ws0">定的是</div><div class="t m0 x67 h4 y96 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x68 h4 y95 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>x</div><div class="t m0 x69 ha y97 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x6a h6 y95 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">，显然</span></div><div class="t m0 x6b h4 y96 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x65 h4 y95 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>x</div><div class="t m0 x44 ha y97 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xd h6 y95 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">不固定的原因是</span></div><div class="t m0 x41 h4 y96 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x5c h6 y95 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _1c"> </span><span class="ff1">是不固定的。</span></div><div class="t m0 x2a h4 y96 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x6c h6 y95 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _1c"> </span><span class="ff1">不固定的原因可能是训练集</span></div><div class="t m0 x1e h6 y98 ff1 fs2 fc0 sc0 ls0 ws0">的不同（训练集不同会导致模型参数不同）<span class="_ _23"></span>，或者模型的函数空间不同。</div><div class="t m0 x1e h6 y99 ff1 fs2 fc0 sc0 ls0 ws0">很多资料<span class="_ _1e"></span>在推导均方<span class="_ _1e"></span>误差分解公<span class="_ _1e"></span>式时，并没有<span class="_ _1e"></span>指明<span class="_ _a"> </span><span class="ff6">Y<span class="_ _9"> </span></span>是<span class="_ _1e"></span>常数，或者<span class="_ _1e"></span>将<span class="_ _9"> </span><span class="ff6">Y<span class="_ _9"> </span><span class="ffb">=<span class="_ _25"> </span><span class="ffa">f<span class="_ _29"> </span></span>(</span>X<span class="ffb">)<span class="_ _9"> </span></span></span>描述为</div><div class="t m0 x1e h6 y9a ff1 fs2 fc0 sc0 ls0 ws0">一个确定的函数，<span class="_ _21"></span>这是造成<span class="_ _2f"> </span><span class="ff3">MSE </span>困惑的原因。<span class="_ _20"></span>实际上，<span class="_ _21"></span>确定的函数<span class="_ _21"></span>（参数确定的函数）<span class="_ _20"></span>并</div><div class="t m0 x1e h6 y9b ff1 fs2 fc0 sc0 ls0 ws0">不意味着<span class="_ _9"> </span><span class="ffa">Y<span class="_ _7"> </span></span>值是确定的，<span class="ffa">Y<span class="_ _7"> </span></span>值是否是常数，取决于<span class="_ _25"> </span><span class="ffa">x<span class="_ _9"> </span></span>值是否给定。</div><div class="t m0 x3 h6 y1e ff3 fs2 fc0 sc0 ls0 ws0">V<span class="_ _31"></span>ariance<span class="_ _9"> </span><span class="ff1">代表预测值</span></div><div class="t m0 x6d h4 y9c ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x6e h4 y1e ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>x</div><div class="t m0 x6f ha y9d ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x70 h6 y1e ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">自身的变异性，即过拟合；<span class="ff3">Bias</span></span></div><div class="t m0 x50 ha y9e ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x71 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">代表预测值</div><div class="t m0 x55 h4 y9c ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x72 h4 y1e ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>x</div><div class="t m0 x58 ha y9d ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x73 h6 y1e ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">和真实值<span class="_ _9"> </span><span class="ffa">f<span class="_ _2b"></span></span></span>(<span class="ffa">x</span></div><div class="t m0 x74 ha y9d ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x75 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">4</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfa" class="pf w0 h0" data-page-no="a"><div class="pc pca w0 h0"><img class="bi x76 y9f w3 h10" alt="" src="bga.png"/><div class="t m0 x77 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">1.2<span class="_ _d"> </span><span class="ff8">误差与过拟合</span></div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">的整体偏离程度，即欠拟合。</div><div class="t m0 x0 h6 ya0 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">1.3:<span class="_ _1c"> </span></span>方差和偏差（训练集不同）</div><div class="t m0 x3 h6 ya1 ff1 fs2 fc0 sc0 ls0 ws0">进一<span class="_ _1e"></span>步看，<span class="ff3">V<span class="_ _31"></span>ariance<span class="_ _12"> </span><span class="ff1">代表我<span class="_ _1e"></span>们使<span class="_ _1e"></span>用不<span class="_ _1e"></span>同训<span class="_ _1e"></span>练集时<span class="_ _1e"></span>模型<span class="_ _1e"></span>表现<span class="_ _1e"></span>的差<span class="_ _1e"></span>异。由<span class="_ _1e"></span>于模<span class="_ _1e"></span>型的构<span class="_ _1e"></span>建通<span class="_ _1e"></span>常和<span class="_ _1e"></span>训练</span></span></div><div class="t m0 x3 h6 ya2 ff1 fs2 fc0 sc0 ls0 ws0">集的统计性质有关，<span class="_ _28"></span>不同的训练集会导致模型出现差异。<span class="_ _27"></span>如果某个机器学习方法得到的模型具有</div><div class="t m0 x3 h6 ya3 ff1 fs2 fc0 sc0 ls0 ws0">较大的方差，训练集只要有少许变化，模型会有很大的改变。复杂的模型一般具有更大的方差。</div><div class="t m0 x3 h6 ya4 ff1 fs2 fc0 sc0 ls0 ws0">第二项偏差代表实际模型与理想模型的差别。<span class="_ _27"></span>例如线性模型是最常用的模型之一，<span class="_ _28"></span>而真实世界往</div><div class="t m0 x3 h6 ya5 ff1 fs2 fc0 sc0 ls0 ws0">往是非常复杂的，<span class="_ _21"></span>当我们用线性模型这样的简单模型去解释世界时，<span class="_ _20"></span>很可能会出现问题。<span class="_ _20"></span>如果我</div><div class="t m0 x3 h6 ya6 ff1 fs2 fc0 sc0 ls0 ws0">们用复杂度为<span class="_ _2f"> </span><span class="ff3">2 </span>的线性模型<span class="_ _21"></span>（包含截距和斜率两个参数）<span class="_ _21"></span>拟合一个非线性模型<span class="_ _21"></span>（模型复杂度远大</div><div class="t m0 x3 h6 ya7 ff1 fs2 fc0 sc0 ls0 ws0">于<span class="_ _f"> </span><span class="ff3">2</span>）<span class="_ _32"></span>，<span class="_ _2e"></span>将产生较大的均方误差，<span class="_ _24"></span>其中很大一部分来源于偏差，<span class="_ _24"></span>这种情况称为欠拟合<span class="_ _33"></span>（<span class="ff3">undertting</span>）<span class="_ _32"></span>。</div><div class="t m0 x3 h6 ya8 ff1 fs2 fc0 sc0 ls0 ws0">当我们不<span class="_ _1e"></span>断增加模型<span class="_ _1e"></span>的复杂程<span class="_ _1e"></span>度，模型的均<span class="_ _1e"></span>方误差不<span class="_ _1e"></span>断下<span class="_ _a"> </span>降，整体表现<span class="_ _1e"></span>逐渐提升，<span class="_ _1e"></span>主要原因是</div><div class="t m0 x3 h6 ya9 ff1 fs2 fc0 sc0 ls0 ws0">偏差逐渐下降，<span class="_ _21"></span>说明模型更加符合真实的情况。<span class="_ _20"></span>然而随着模型的复杂程度进一步增加，<span class="_ _20"></span>可以发现</div><div class="t m0 x3 h6 yaa ff1 fs2 fc0 sc0 ls0 ws0">样本差异导致的方差急剧上升，<span class="_ _28"></span>说明复杂的模型更多地把握住了属于训练样本独有的特性，<span class="_ _27"></span>而非</div><div class="t m0 x3 h6 yab ff1 fs2 fc0 sc0 ls0 ws0">数据的共性，<span class="_ _20"></span>这种情况称为过拟合<span class="_ _31"></span>（<span class="ff3">ov<span class="_ _2d"></span>ertting<span class="ff1">）<span class="_ _23"></span>。<span class="_ _22"></span>均方误差、<span class="_ _22"></span>方差和偏差随模型复杂度的变化关</span></span></div><div class="t m0 x3 h6 yac ff1 fs2 fc0 sc0 ls0 ws0">系如下图所示。</div><div class="t m0 x78 h6 yad ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">1.4:<span class="_ _1c"> </span></span>均方误差、方差和偏差随模型复杂度的变化关系（模型的函数空间不同）</div><div class="t m0 x79 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">5</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfb" class="pf w0 h0" data-page-no="b"><div class="pc pcb w0 h0"><img class="bi x7a yae w4 h11" alt="" src="bgb.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">1.3<span class="_ _d"> </span><span class="ff8">交叉验证</span></div><div class="t m0 x1c h9 yaf ff5 fs6 fc0 sc0 ls0 ws0">1.3<span class="_ _1f"> </span><span class="ff9">交叉验证</span></div><div class="t m0 x3 h6 yb0 ff1 fs2 fc0 sc0 ls0 ws0">避免过拟合的重要方法之一是进行交叉验证<span class="_ _21"></span>（<span class="ff3">cross-v<span class="_ _2d"></span>alidation<span class="ff1">）<span class="_ _32"></span>。<span class="_ _21"></span>英国统计学家<span class="_ _f"> </span><span class="ff3">Mervyn<span class="_ _25"> </span>Stone </span>和</span></span></div><div class="t m0 x3 h6 yb1 ff1 fs2 fc0 sc0 ls0 ws0">美国<span class="_ _1e"></span>统计<span class="_ _1e"></span>学家<span class="_ _12"> </span><span class="ff3">Seymour<span class="_ _12"> </span>Geisser<span class="_ _12"> </span></span>是<span class="_ _1e"></span>交叉<span class="_ _1e"></span>验<span class="_ _1e"></span>证理<span class="_ _1e"></span>论的<span class="_ _1e"></span>先驱。<span class="_ _1e"></span>交叉<span class="_ _1e"></span>验<span class="_ _1e"></span>证理<span class="_ _1e"></span>论并<span class="_ _1e"></span>非仅<span class="_ _1e"></span>针对<span class="_ _1e"></span>机<span class="_ _1e"></span>器学<span class="_ _1e"></span>习模</div><div class="t m0 x3 h6 yb2 ff1 fs2 fc0 sc0 ls0 ws0">型，<span class="_ _21"></span>而是针对任何统计模型。<span class="_ _21"></span><span class="ff3 fc2">Stone <span class="ff1">和<span class="_ _25"> </span></span>Geisser<span class="_ _25"> </span><span class="ff1">在<span class="_ _25"> </span></span>1974<span class="_ _25"> </span><span class="ff1">年分别独立地提出，<span class="_ _21"></span>在评价某个统计模型</span></span></div><div class="t m0 x3 h6 yb3 ff1 fs2 fc2 sc0 ls0 ws0">的表现时，应使用在估计模型环节未使用过的数据。</div><div class="t m0 x27 h6 yb4 ff1 fs2 fc0 sc0 ls0 ws0">随后</div><div class="t m0 x60 h4 yb3 ff3 fs2 fc0 sc0 ls0 ws0">Devijv<span class="_ _e"></span>er<span class="_ _9"> </span>Pierre</div><div class="t m0 x7b h6 yb4 ff1 fs2 fc0 sc0 ls0 ws0">（</div><div class="t m0 x7c h4 yb3 ff3 fs2 fc0 sc0 ls0 ws0">1982</div><div class="t m0 x7d h6 yb4 ff1 fs2 fc0 sc0 ls0 ws0">）<span class="_ _23"></span>、</div><div class="t m0 x7e h4 yb3 ff3 fs2 fc0 sc0 ls0 ws0">K<span class="_ _e"></span>oha<span class="_ _e"></span>vi<span class="_ _9"> </span>Ron</div><div class="t m0 x7f h6 yb5 ff1 fs2 fc0 sc0 ls0 ws0">（<span class="ff3">1995</span>）等将交叉验<span class="_ _1e"></span>证的思想引入模<span class="_ _1e"></span>式识别以及机器<span class="_ _1e"></span>学习，在评价机器<span class="_ _1e"></span>学习模型表现时，<span class="_ _1e"></span>使用不</div><div class="t m0 x3 h6 yb6 ff1 fs2 fc0 sc0 ls0 ws0">曾在训练环节出现过的样本进行验证。<span class="_ _27"></span><span class="fc2">如果模型在验证时性能和训练时大致相同，<span class="_ _28"></span>那么就可以确</span></div><div class="t m0 x3 h6 yb7 ff1 fs2 fc2 sc0 ls0 ws0">信模型真的<span class="_ _2d"></span>“学会”<span class="_ _31"></span>了如何发现数据中的一般规律，<span class="_ _22"></span>而不是<span class="_ _2d"></span>“记住”<span class="_ _2d"></span>训练样本。<span class="_ _31"></span><span class="fc0">这和学生考试的</span></div><div class="t m0 x3 h6 yb8 ff1 fs2 fc0 sc0 ls0 ws0">情形类似，要想考察学生是否掌握了<span class="_ _1e"></span>某个知识点，不能使用课堂上讲过的“例题”<span class="_ _2e"></span>，而应当使用</div><div class="t m0 x3 h6 yb9 ff1 fs2 fc0 sc0 ls0 ws0">相似的“习题”<span class="_ _23"></span>。</div><div class="t m0 x3 h6 yba ff1 fs2 fc0 sc0 ls0 ws0">交叉验证的核心思想是先将全部样本划分成两部分，<span class="_ _21"></span>一部分用来训练模型，<span class="_ _20"></span>称为训练集；<span class="_ _20"></span>另外一</div><div class="t m0 x3 h6 ybb ff1 fs2 fc0 sc0 ls0 ws0">部分用来验证模型，<span class="_ _21"></span>称为验证集。<span class="_ _20"></span>随后考察模型在训练集和验证集的表现是否接近。<span class="_ _20"></span>如果两者接</div><div class="t m0 x3 h6 ybc ff1 fs2 fc0 sc0 ls0 ws0">近，<span class="_ _21"></span>说明模型具备较好的预测性能；<span class="_ _20"></span>如果训练集的表现远优于验证集，<span class="_ _20"></span>说明模型存在过拟合的风</div><div class="t m0 x3 h6 ybd ff1 fs2 fc0 sc0 ls0 ws0">险。</div><div class="t m0 x3 h6 ybe ff1 fs2 fc0 sc0 ls0 ws0">当我<span class="_ _1e"></span>们需<span class="_ _1e"></span>要对<span class="_ _1e"></span>不<span class="_ _1e"></span>同超<span class="_ _1e"></span>参数<span class="_ _1e"></span>设置<span class="_ _1e"></span>下的<span class="_ _1e"></span>多<span class="_ _1e"></span>个模<span class="_ _1e"></span>型进<span class="_ _1e"></span>行比<span class="_ _1e"></span>较<span class="_ _1e"></span>时，可<span class="_ _1e"></span>以考<span class="_ _1e"></span>察模<span class="_ _1e"></span>型在<span class="_ _1e"></span>验<span class="_ _1e"></span>证集<span class="_ _1e"></span>的表<span class="_ _1e"></span>现，选<span class="_ _1e"></span>择</div><div class="t m0 x3 h6 ybf ff1 fs2 fc0 sc0 ls0 ws0">验证集表现最优的那组超<span class="_ _1e"></span>参数作为最终模型的超参数，这<span class="_ _1e"></span>一过程称为调参（<span class="ff3">parameter<span class="_ _9"> </span>tuning</span>）<span class="_ _2e"></span>。</div><div class="t m0 x3 h6 yc0 ff1 fs2 fc0 sc0 ls0 ws0">虽然名为“调参”<span class="_ _23"></span>，本质上是“调超参”<span class="_ _23"></span>。</div><div class="t m0 x3 h6 yc1 ff1 fs2 fc0 sc0 ls0 ws0">根据训练集和验证集的划分方式，<span class="_ _21"></span>交叉验证方法又可以细分为简单交叉验证、<span class="_ _21"></span><span class="ff3">K <span class="ff1">折交叉验证、<span class="_ _21"></span>留</span></span></div><div class="t m0 x3 h6 yc2 ff1 fs2 fc0 sc0 ls0 ws0">一法、留<span class="_ _9"> </span><span class="ff3">P<span class="_ _9"> </span></span>法和时序交叉验证。</div><div class="t m0 x3 h12 yc3 ff5 fs8 fc0 sc0 ls0 ws0">1.3.1<span class="_ _34"> </span><span class="ff9">简单交叉验证</span></div><div class="t m0 x3 h6 yc4 ff1 fs2 fc0 sc0 ls0 ws0">从总样本中随机选取一定比例<span class="_ _20"></span>（如<span class="_ _25"> </span><span class="ff3">30%</span>）<span class="_ _22"></span>的样本作为验证集，<span class="_ _21"></span>其余作为训练集。<span class="_ _21"></span>这种方法称为简</div><div class="t m0 x3 h6 yc5 ff1 fs2 fc0 sc0 ls0 ws0">单交叉验证，也称为留出法交叉验证（<span class="ff3">hold-out<span class="_ _9"> </span>cross-v<span class="_ _2d"></span>alidation<span class="ff1">）<span class="_ _23"></span>。</span></span></div><div class="t m0 x3 h6 yc6 ff1 fs2 fc0 sc0 ls0 ws0">优点：</div><div class="t m0 x80 h4 yc7 ff3 fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x81 h6 yc6 ff1 fs2 fc0 sc0 ls0 ws0">只需要训练一次模型，速度较快。</div><div class="t m0 x3 h6 yc8 ff1 fs2 fc0 sc0 ls0 ws0">缺点：</div><div class="t m0 x78 h4 yc9 ff3 fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xb h6 yc8 ff1 fs2 fc0 sc0 ls0 ws0">一部分数据从未参与训练，<span class="_ _20"></span>可能削弱模型的准确性，<span class="_ _21"></span>在极端情况下，<span class="_ _20"></span>当验证集中数据本</div><div class="t m0 x3 h6 yca ff1 fs2 fc0 sc0 ls0 ws0">身就是整体数据的<span class="_ _22"></span>“噪点”<span class="_ _22"></span>时，<span class="_ _21"></span>模型的准确度将会大大降低。<span class="_ _29"> </span><span class="ff3">2<span class="_ _25"> </span></span>最终的模型评价结果可能受到训</div><div class="t m0 x3 h6 ycb ff1 fs2 fc0 sc0 ls0 ws0">练集和验证集划分过程中的随机因素干扰。</div><div class="t m0 x3 h12 ycc ff5 fs8 fc0 sc0 ls0 ws0">1.3.2<span class="_ _34"> </span>K<span class="_ _4"> </span><span class="ff9">折交叉验证</span></div><div class="t m0 x3 h6 ycd ff1 fs2 fc0 sc0 ls0 ws0">针对简单<span class="_ _1e"></span>交叉验<span class="_ _1e"></span>证的缺陷，<span class="_ _1e"></span>研究者<span class="_ _1e"></span>提出<span class="_ _a"> </span><span class="ff3">K<span class="_ _a"> </span></span>折交互<span class="_ _1e"></span>验证（<span class="ff3">K-fold<span class="_ _a"> </span>cross-v<span class="_ _2d"></span>alidation<span class="ff1">）的<span class="_ _1e"></span>方法，随机</span></span></div><div class="t m0 x3 h6 yce ff1 fs2 fc0 sc0 ls0 ws0">将全体样本分为<span class="_ _25"> </span><span class="ff3">K<span class="_ _25"> </span></span>个部分，<span class="_ _21"></span>每次用其中的一部分作为验证集，<span class="_ _21"></span>其余部分作为训练集。<span class="_ _20"></span>重复<span class="_ _2f"> </span><span class="ff3">K<span class="_ _25"> </span></span>次，</div><div class="t m0 x3 h6 ycf ff1 fs2 fc0 sc0 ls0 ws0">直到所有部<span class="_ _1e"></span>分都被验证过。<span class="_ _1e"></span>下图展示了<span class="_ _a"> </span><span class="ff3">5<span class="_ _a"> </span></span>折交互验证的过<span class="_ _1e"></span>程，将全体样<span class="_ _1e"></span>本随机划分成<span class="_ _a"> </span><span class="ff3">5<span class="_ _a"> </span></span>个不重</div><div class="t m0 x3 h6 yd0 ff1 fs2 fc0 sc0 ls0 ws0">叠的部分，每次用<span class="_ _a"> </span><span class="ff3">4/5<span class="_ _9"> </span></span>作为<span class="_ _1e"></span>训练集（粉色部分）<span class="_ _24"></span>，其余<span class="_ _9"> </span><span class="ff3">1/5<span class="_ _a"> </span></span>部分作为验证集（灰<span class="_ _1e"></span>色部分）<span class="_ _2e"></span>。最终</div><div class="t m0 x3 h6 yd1 ff1 fs2 fc0 sc0 ls0 ws0">将得到<span class="_ _9"> </span><span class="ff3">5<span class="_ _9"> </span></span>个验证集的均方误差（或其它损失函数形式）<span class="_ _23"></span>，取均值作为验证集的平均表现。</div><div class="t m0 x82 h6 yd2 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">1.5:<span class="_ _35"> </span>K<span class="_ _9"> </span></span>折交叉验证示意图（<span class="ff3">K=5</span>）</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">6</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfc" class="pf w0 h0" data-page-no="c"><div class="pc pcc w0 h0"><img class="bi x76 yd3 w3 h13" alt="" src="bgc.png"/><div class="t m0 x83 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">1.3<span class="_ _d"> </span><span class="ff8">交叉验证</span></div><div class="t m0 x3 h12 yd4 ff5 fs8 fc0 sc0 ls0 ws0">1.3.3<span class="_ _34"> </span><span class="ff9">留一法和留<span class="_ _4"> </span></span>P<span class="_ _4"> </span><span class="ff9">法</span></div><div class="t m0 x3 h6 yd5 ff1 fs2 fc0 sc0 ls0 ws0">除了<span class="_ _1e"></span>将样<span class="_ _1e"></span>本<span class="_ _1e"></span>分成<span class="_ _1c"> </span><span class="ff3">K<span class="_ _12"> </span></span>个部<span class="_ _1e"></span>分，还<span class="_ _1e"></span>可<span class="_ _1e"></span>以每<span class="_ _1e"></span>次取<span class="_ _1e"></span>一<span class="_ _1e"></span>个固<span class="_ _1e"></span>定数<span class="_ _1e"></span>目<span class="_ _1e"></span>的样<span class="_ _1e"></span>本<span class="_ _1e"></span>作为<span class="_ _1e"></span>验证<span class="_ _1e"></span>集。<span class="_ _1e"></span>假设<span class="_ _1e"></span>样本<span class="_ _1e"></span>量<span class="_ _1e"></span>为<span class="_ _12"> </span><span class="ff3">N</span>，</div><div class="t m0 x3 h6 yd6 ff1 fs2 fc0 sc0 ls0 ws0">如<span class="_ _1e"></span>果<span class="_ _1e"></span>每<span class="_ _1e"></span>次<span class="_ _1e"></span>取<span class="_ _1e"></span>一<span class="_ _1e"></span>个<span class="_ _1e"></span>样<span class="_ _1e"></span>本<span class="_ _1e"></span>验<span class="_ _1e"></span>证，<span class="_ _1e"></span>把<span class="_ _1e"></span>其<span class="_ _1e"></span>余<span class="_ _1e"></span>样<span class="_ _1e"></span>本<span class="_ _1e"></span>用<span class="_ _1e"></span>来<span class="_ _1e"></span>训<span class="_ _1e"></span>练，<span class="_ _1e"></span>重<span class="_ _1e"></span>复<span class="_ _0"> </span><span class="ff3">N<span class="_ _1c"> </span></span>次，这<span class="_ _1e"></span>种<span class="_ _1e"></span>方<span class="_ _1e"></span>法<span class="_ _1e"></span>称<span class="_ _1e"></span>为<span class="_ _26"></span>留一<span class="_ _1e"></span>法<span class="_ _26"></span>交<span class="_ _1e"></span>叉<span class="_ _1e"></span>验<span class="_ _1e"></span>证</div><div class="t m0 x7f h6 yd7 ff1 fs2 fc0 sc0 ls0 ws0">（<span class="ff3">lea<span class="_ _e"></span>v<span class="_ _e"></span>e-one-out<span class="_ _25"> </span>cross-v<span class="_ _2d"></span>alidation<span class="ff1">，<span class="_ _2d"></span><span class="ff3">LOOCV<span class="ff1">）<span class="_ _23"></span>。<span class="_ _31"></span>还可以每次取<span class="_ _9"> </span><span class="ff3">P<span class="_ _9"> </span></span>个样本验证，<span class="_ _31"></span>重复<span class="_ _9"> </span><span class="ff3">C</span></span></span></span></span></div><div class="t m0 x84 hb yd8 ffd fs7 fc0 sc0 ls0 ws0">P</div><div class="t m0 x84 hb yd9 ffd fs7 fc0 sc0 ls0 ws0">N</div><div class="t m0 x85 h6 yd7 ff1 fs2 fc0 sc0 ls0 ws0">次，<span class="_ _31"></span>这种方</div><div class="t m0 x3 h6 yda ff1 fs2 fc0 sc0 ls0 ws0">法称为留<span class="_ _9"> </span><span class="ff3">P<span class="_ _9"> </span></span>法<span class="_ _e"></span>（<span class="ff3">leav<span class="_ _2d"></span>e-p-out<span class="_ _9"> </span>cross-v<span class="_ _31"></span>alidation<span class="ff1">，</span>LPOCV<span class="ff1">）<span class="_ _23"></span>。留一法和留<span class="_ _25"> </span><span class="ff3">P<span class="_ _9"> </span></span>法适用于样本量较小的</span></span></div><div class="t m0 x3 h6 ydb ff1 fs2 fc0 sc0 ls0 ws0">情形。<span class="_ _22"></span>当样本量较大时，<span class="_ _22"></span>上述两种方法所需的重复次数较大，<span class="_ _22"></span>运算速度相对较慢，<span class="_ _22"></span>因此通常不采</div><div class="t m0 x3 h6 ydc ff1 fs2 fc0 sc0 ls0 ws0">用留一法和留<span class="_ _9"> </span><span class="ff3">P<span class="_ _9"> </span></span>法，而是使用<span class="_ _9"> </span><span class="ff3">K<span class="_ _9"> </span></span>折交叉验证。</div><div class="t m0 x3 h12 ydd ff5 fs8 fc0 sc0 ls0 ws0">1.3.4<span class="_ _34"> </span><span class="ff9">时序交叉验证</span></div><div class="t m0 x3 h6 yde ff1 fs2 fc0 sc0 ls0 ws0">以上<span class="_ _1e"></span>四种<span class="_ _1e"></span>传统<span class="_ _1e"></span>交叉<span class="_ _1e"></span>验<span class="_ _1e"></span>证方<span class="_ _1e"></span>法成<span class="_ _1e"></span>立的<span class="_ _1e"></span>前提<span class="_ _1e"></span>是样<span class="_ _1e"></span>本<span class="_ _1e"></span>服从<span class="_ _1e"></span>独立<span class="_ _1e"></span>同分<span class="_ _1e"></span>布。独<span class="_ _1e"></span>立是<span class="_ _1e"></span>指<span class="_ _1e"></span>样本<span class="_ _1e"></span>之间<span class="_ _1e"></span>不存<span class="_ _1e"></span>在相<span class="_ _1e"></span>关</div><div class="t m0 x3 h6 ydf ff1 fs2 fc0 sc0 ls0 ws0">性，<span class="_ _28"></span>从一条样本无法推知另一条样本的取值；<span class="_ _27"></span>同分布是指包括训练集和验证集在内的全部样本需</div><div class="t m0 x3 h6 ye0 ff1 fs2 fc0 sc0 ls0 ws0">取自同一分布。<span class="_ _22"></span>当样本是时间序列时，<span class="_ _22"></span>数据随时间演进的过程生成，<span class="_ _20"></span>可能包含周期性、<span class="_ _31"></span>过去和未</div><div class="t m0 x3 h6 ye1 ff1 fs2 fc0 sc0 ls0 ws0">来数<span class="_ _1e"></span>据间<span class="_ _1e"></span>相互<span class="_ _1e"></span>关<span class="_ _1e"></span>系等<span class="_ _1e"></span>信息，<span class="_ _1e"></span>并不<span class="_ _1e"></span>满足<span class="_ _1e"></span>交<span class="_ _1e"></span>叉验<span class="_ _1e"></span>证中<span class="_ _1e"></span>数据<span class="_ _1e"></span>独<span class="_ _1e"></span>立同<span class="_ _1e"></span>分布<span class="_ _1e"></span>的基<span class="_ _1e"></span>本假<span class="_ _1e"></span>设。<span class="_ _1e"></span>此时<span class="_ _1e"></span>如果<span class="_ _1e"></span>依然<span class="_ _1e"></span>采</div><div class="t m0 x3 h6 ye2 ff1 fs2 fc0 sc0 ls0 ws0">用传统交叉验证方法，<span class="_ _21"></span>可能会将未来时刻的数据划入训练集，<span class="_ _20"></span>历史时刻的数据划入验证集，<span class="_ _20"></span>进而</div><div class="t m0 x3 h6 ye3 ff1 fs2 fc0 sc0 ls0 ws0">出现用未来规律预测历史结果的<span class="_ _31"></span>“作弊”<span class="_ _22"></span>行为。<span class="_ _22"></span>因此需要一种既能保证数据利用率，<span class="_ _20"></span>又能保留时</div><div class="t m0 x3 h6 ye4 ff1 fs2 fc0 sc0 ls0 ws0">序数据之间相互关系的交叉验证方法，<span class="_ _20"></span>这就是时序交<span class="_ _9"> </span>叉验证方法<span class="_ _22"></span>（<span class="ff3">time-series<span class="_ _9"> </span>cross-v<span class="_ _31"></span>alidation<span class="ff1">）<span class="_ _23"></span>，</span></span></div><div class="t m0 x3 h6 ye5 ff1 fs2 fc0 sc0 ls0 ws0">如下图所示。</div><div class="t m0 x46 h6 ye6 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">1.6:<span class="_ _1c"> </span>5<span class="_ _9"> </span></span>折时序交叉验证</div><div class="t m0 x3 h6 ye7 ff1 fs2 fc0 sc0 ls0 ws0">以上图为例说明时序交叉验证方法。<span class="_ _31"></span>假设样本时间跨度为<span class="_ _9"> </span><span class="ff3">10<span class="_ _9"> </span></span>个月，<span class="_ _31"></span>采用<span class="_ _25"> </span><span class="ff3">5<span class="_ _9"> </span></span>折时序交叉验证，<span class="_ _31"></span>那</div><div class="t m0 x3 h6 ye8 ff1 fs2 fc0 sc0 ls0 ws0">么首先<span class="_ _1e"></span>将样本<span class="_ _1e"></span>等分成<span class="_ _a"> </span><span class="ff3">5<span class="_ _12"> </span></span>个部分。以<span class="_ _1e"></span>第<span class="_ _a"> </span><span class="ff3">1<span class="_ _a"> </span>2<span class="_ _a"> </span></span>月<span class="_ _1e"></span>数据作<span class="_ _1e"></span>为训练<span class="_ _1e"></span>集，第<span class="_ _a"> </span><span class="ff3">3<span class="_ _a"> </span>4<span class="_ _12"> </span></span>月作为验<span class="_ _1e"></span>证集，进<span class="_ _1e"></span>行第<span class="_ _a"> </span><span class="ff3">1</span></div><div class="t m0 x3 h6 ye9 ff1 fs2 fc0 sc0 ls0 ws0">次验证。<span class="_ _2d"></span>再以第<span class="_ _25"> </span><span class="ff3">1<span class="_ _9"> </span>4<span class="_ _9"> </span></span>月数据作为训练集，<span class="_ _31"></span>第<span class="_ _9"> </span><span class="ff3">5<span class="_ _25"> </span>6<span class="_ _9"> </span></span>月为验证集，<span class="_ _31"></span>进行第<span class="_ _9"> </span><span class="ff3">2<span class="_ _9"> </span></span>次验证。<span class="_ _31"></span>以此类推，<span class="_ _2d"></span>第<span class="_ _25"> </span><span class="ff3">4</span></div><div class="t m0 x3 h6 yea ff1 fs2 fc0 sc0 ls0 ws0">次验证以第<span class="_ _9"> </span><span class="ff3">1<span class="_ _9"> </span>8<span class="_ _25"> </span></span>月数据作为训练集，第<span class="_ _25"> </span><span class="ff3">9<span class="_ _9"> </span>10<span class="_ _9"> </span></span>月作为验证集。再将总共<span class="_ _25"> </span><span class="ff3">4<span class="_ _9"> </span></span>次验证的模型评价指标</div><div class="t m0 x3 h6 yeb ff1 fs2 fc0 sc0 ls0 ws0">取平<span class="_ _1e"></span>均数。<span class="_ _1e"></span>时序<span class="_ _1e"></span>交<span class="_ _1e"></span>叉验<span class="_ _1e"></span>证避<span class="_ _1e"></span>免了<span class="_ _1e"></span>使用<span class="_ _1e"></span>未<span class="_ _1e"></span>来信<span class="_ _1e"></span>息的<span class="_ _1e"></span>可能，<span class="_ _1e"></span>对<span class="_ _1e"></span>于时<span class="_ _1e"></span>序数<span class="_ _1e"></span>据的<span class="_ _1e"></span>机器<span class="_ _1e"></span>学<span class="_ _1e"></span>习而<span class="_ _1e"></span>言是<span class="_ _1e"></span>较为<span class="_ _1e"></span>合</div><div class="t m0 x3 h6 yec ff1 fs2 fc0 sc0 ls0 ws0">理的选择。</div><div class="t m0 x3 h6 yed ff3 fs2 fc0 sc0 ls0 ws0">T<span class="_ _31"></span>ashman<span class="ff1">（</span>2000<span class="ff1">）<span class="_ _33"></span>、<span class="ff3">V<span class="_ _22"></span>arma<span class="_ _12"> </span><span class="ff1">和<span class="_ _12"> </span></span>Simon<span class="ff1">（</span>2006<span class="ff1">）和<span class="_ _12"> </span></span>Bergmeir<span class="_ _12"> </span><span class="ff1">和<span class="_ _12"> </span></span>Benitez<span class="ff1">（</span>2012<span class="ff1">）等<span class="_ _1e"></span>研究<span class="_ _1e"></span>表明，<span class="_ _1e"></span>时</span></span></span></div><div class="t m0 x3 h6 yee ff1 fs2 fc0 sc0 ls0 ws0">序交叉验<span class="_ _1e"></span>证方法<span class="_ _1e"></span>在时序数<span class="_ _1e"></span>据上的<span class="_ _1e"></span>表现优于<span class="_ _1e"></span>传统交<span class="_ _1e"></span>叉验证方<span class="_ _1e"></span>法。时序<span class="_ _1e"></span>特性是金<span class="_ _1e"></span>融数据<span class="_ _1e"></span>的典型特<span class="_ _1e"></span>征，</div><div class="t m0 x3 h6 yef ff1 fs2 fc0 sc0 ls0 ws0">然而时序交叉验证在投资领域的效果尚没有被系统性地测试。</div><div class="t m0 x79 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">7</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfd" class="pf w0 h0" data-page-no="d"><div class="pc pcd w0 h0"><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">1.3<span class="_ _d"> </span><span class="ff8">交叉验证</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">8</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pfe" class="pf w0 h0" data-page-no="e"><div class="pc pce w0 h0"><img class="bi x86 yf0 w5 h14" alt="" src="bge.png"/><div class="t m0 x6a h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第二章 性能度量——模型的好坏</div><div class="t m0 x3 h6 yf1 ff1 fs2 fc0 sc0 ls0 ws0">好<span class="_ _1e"></span>了，<span class="_ _1e"></span>经<span class="_ _26"></span>过<span class="_ _1e"></span>对<span class="_ _1e"></span>原<span class="_ _26"></span>始<span class="_ _1e"></span>数<span class="_ _1e"></span>据<span class="_ _26"></span>集<span class="_ _1e"></span>进<span class="_ _1e"></span>行<span class="_ _26"></span>有<span class="_ _1e"></span>效<span class="_ _1e"></span>划<span class="_ _26"></span>分，<span class="_ _1e"></span>我<span class="_ _1e"></span>们<span class="_ _26"></span>得<span class="_ _1e"></span>到<span class="_ _1e"></span>了<span class="_ _26"></span>训<span class="_ _1e"></span>练<span class="_ _1e"></span>集<span class="_ _26"></span>和<span class="_ _1e"></span>测<span class="_ _1e"></span>试<span class="_ _26"></span>集。<span class="_ _1e"></span>那<span class="_ _1e"></span>么<span class="_ _26"></span>现<span class="_ _1e"></span>在<span class="_ _1e"></span>的<span class="_ _26"></span>问<span class="_ _1e"></span>题<span class="_ _1e"></span>就<span class="_ _26"></span>是：</div><div class="t m0 x3 h6 yf2 ff1 fs2 fc0 sc0 ls0 ws0">如何<span class="_ _1e"></span>衡量<span class="_ _1e"></span>模型<span class="_ _1e"></span>泛<span class="_ _1e"></span>化能<span class="_ _1e"></span>力呢？<span class="_ _1e"></span>也就<span class="_ _1e"></span>是模<span class="_ _1e"></span>型<span class="_ _1e"></span>的泛<span class="_ _1e"></span>化能<span class="_ _1e"></span>力的<span class="_ _1e"></span>评<span class="_ _1e"></span>价需<span class="_ _1e"></span>要人<span class="_ _1e"></span>为制<span class="_ _1e"></span>定标<span class="_ _1e"></span>准，<span class="_ _1e"></span>这就<span class="_ _1e"></span>是性<span class="_ _1e"></span>能度<span class="_ _1e"></span>量</div><div class="t m0 x3 h6 yf3 ff3 fs2 fc0 sc0 ls0 ws0">(p<span class="_ _1e"></span>erformance<span class="_ _9"> </span>measure)<span class="ff1">。</span></div><div class="t m0 x3 h6 yf4 ff1 fs2 fc2 sc0 ls0 ws0">衡量模型泛化能力也就是计算模型的测试误差<span class="fc0">，性能度量也就是测试误差的具体实例。</span></div><div class="t m0 x3 h6 yf5 ff1 fs2 fc0 sc0 ls0 ws0">性能度量反映了任务需求，<span class="_ _28"></span>在对比不同模型的能力时，<span class="_ _27"></span>使用不同的性能度量往往会导致不同的评</div><div class="t m0 x3 h6 yf6 ff1 fs2 fc0 sc0 ls0 ws0">判结果。<span class="_ _20"></span>也就是模型的好坏并不是绝对的，<span class="_ _21"></span>这视不同的性能度量而定，<span class="_ _20"></span>而选取什么样的性能度量</div><div class="t m0 x3 h6 yf7 ff1 fs2 fc0 sc0 ls0 ws0">取决于任务需求。</div><div class="t m0 x3 h6 yf8 ff1 fs2 fc0 sc0 ls0 ws0">以下介绍常见的性能度量。</div><div class="t m0 x3 h6 yf9 ff1 fs2 fc0 sc0 ls0 ws0">在预测任务中，<span class="_ _21"></span>给定样本集<span class="_ _2f"> </span><span class="ffa">D<span class="_ _25"> </span><span class="ffb">=<span class="_ _25"> </span><span class="fff">{</span>(</span>x</span></div><div class="t m0 x87 hb yfa ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1c hc yf9 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x9 hb yfa ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x88 h6 yf9 ffb fs2 fc0 sc0 ls0 ws0">)<span class="fff">} <span class="ffa">i<span class="_ _2f"> </span></span></span>=<span class="_ _2f"> </span>1<span class="ffa">,<span class="_ _2c"> </span></span>2<span class="ffa">,<span class="_ _29"> </span><span class="fff">·<span class="_ _2c"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>m<span class="ff1">，<span class="_ _21"></span>其中<span class="_ _2f"> </span><span class="ffa">y</span></span></span></div><div class="t m0 x89 hb yfa ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x8a h6 yf9 ff1 fs2 fc0 sc0 ls0 ws0">是实例<span class="_ _25"> </span><span class="ffa">x</span></div><div class="t m0 x58 hb yfa ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x8b h6 yf9 ff1 fs2 fc0 sc0 ls0 ws0">的真实<span class="_ _25"> </span><span class="ff3">lab<span class="_ _1e"></span>el</span>。<span class="_ _21"></span>要</div><div class="t m0 x3 h6 yfb ff1 fs2 fc0 sc0 ls0 ws0">评估学习器<span class="_ _9"> </span><span class="ffa">f<span class="_ _1c"> </span></span>的性能，就要把学习器预测结果<span class="_ _9"> </span><span class="ffa">f<span class="_ _2b"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _9"> </span></span></span>与真实<span class="_ _9"> </span><span class="ff3">lab<span class="_ _1e"></span>el<span class="_ _9"> </span><span class="ffa">y<span class="_ _a"> </span></span></span>进行比较。</div><div class="t m0 x8c h9 yfc ff5 fs6 fc0 sc0 ls0 ws0">2.1<span class="_ _1f"> </span><span class="ff9">回归</span></div><div class="t m0 x3 h12 yfd ff5 fs8 fc0 sc0 ls0 ws0">2.1.1<span class="_ _34"> </span><span class="ff9">均方误差</span></div><div class="t m0 x3 h6 yfe ff1 fs2 fc0 sc0 ls0 ws0">在回归任务中，<span class="_ _31"></span>即预测连续值的问题，<span class="_ _31"></span>最常用的性能度量是<span class="_ _e"></span>“均方误差”<span class="_ _32"></span>（<span class="ff3">mean squared<span class="_ _9"> </span>error</span>）<span class="_ _23"></span>。</div><div class="t m0 x8d h4 yff ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _26"></span><span class="ffb">(</span>f<span class="_ _2b"></span><span class="ffb">;<span class="_ _2c"> </span></span>D<span class="_ _1e"></span><span class="ffb">)<span class="_ _2f"> </span>=</span></div><div class="t m0 x8e h4 y100 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x86 hc y101 ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x8 hb y102 ffd fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x8f he y103 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x90 ha y104 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x91 h4 yff ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _f"> </span></span>(<span class="ff11">x</span></div><div class="t m0 x92 hb y105 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x93 h4 yff ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">y</span></span></div><div class="t m0 x94 hb y105 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x95 h4 yff ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x96 ha y106 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x33 h4 yff ff3 fs2 fc0 sc0 ls0 ws0">(2.1)</div><div class="t m0 x3 h6 y107 ff1 fs2 fc0 sc0 ls0 ws0">更一般的，对于数据分布<span class="_ _9"> </span><span class="fff">D<span class="_ _a"> </span></span>和概率密度函数<span class="_ _9"> </span><span class="ffa">p<span class="ffb">(<span class="fff">·</span>)</span></span>，均方误差可描为：</div><div class="t m0 x97 h4 y108 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _26"></span><span class="ffb">(</span>f<span class="_ _2b"></span><span class="ffb">;<span class="_ _2c"> </span><span class="fff">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</span></div><div class="t m0 x21 he y109 ffe fs2 fc0 sc0 ls0 ws0">Z</div><div class="t m0 x4a ha y10a ff11 fs7 fc0 sc0 ls0 ws0">x<span class="ff12">∼D</span></div><div class="t m0 x90 h4 y108 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _2b"></span></span>(<span class="ff11">x</span>)<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">y<span class="_ _1e"></span></span></span>)</div><div class="t m0 x66 ha y10b ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x60 h4 y108 ffa fs2 fc0 sc0 ls0 ws0">p<span class="ffb">(<span class="ff11">x</span>)<span class="ff3">d<span class="ff11">x<span class="_ _36"> </span></span>(2.2)</span></span></div><div class="t m0 x3 h6 y10c ff1 fs2 fc2 sc0 ls0 ws0">均方误差在数理统计中说过了，<span class="_ _28"></span>这里再强调一下：<span class="_ _27"></span>均方误差是反映估计量与被估计量之间差异程</div><div class="t m0 x3 h6 y10d ff1 fs2 fc2 sc0 ls0 ws0">度的一种度量。当估计量是无偏时，均方误差就是方差。</div><div class="t m0 x8c h9 y10e ff5 fs6 fc0 sc0 ls0 ws0">2.2<span class="_ _1f"> </span><span class="ff9">分类</span></div><div class="t m0 x3 h12 y10f ff5 fs8 fc0 sc0 ls0 ws0">2.2.1<span class="_ _34"> </span><span class="ff9">混淆矩阵</span></div><div class="t m0 x3 h6 y110 ff1 fs2 fc0 sc0 ls0 ws0">对于分类问题来说，<span class="_ _28"></span>很多评价指标都来源于二分类的混淆矩阵，<span class="_ _27"></span>多分类或多标签的评价指标则从</div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">二分类的评价指标拓展得到。</div><div class="t m0 x3 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">对于二分类问题，分类结果混淆矩阵如表<span class="ff3">2.1</span>所示：</div><div class="t m0 x8 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">9</div><a class="l" href="#pff" data-dest-detail='[15,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:400.845000px;bottom:59.034000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pff" class="pf w0 h0" data-page-no="f"><div class="pc pcf w0 h0"><img class="bi x44 y112 w6 h15" alt="" src="bgf.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">2.2<span class="_ _d"> </span><span class="ff8">分类</span></div><div class="t m0 x3d h6 y113 ff1 fs2 fc0 sc0 ls0 ws0">表<span class="_ _9"> </span><span class="ff3">2.1:<span class="_ _1c"> </span></span>混淆矩阵</div><div class="t m0 x98 h6 y114 ff1 fs2 fc0 sc0 ls0 ws0">真实情况</div><div class="t m0 x99 h6 y115 ff1 fs2 fc0 sc0 ls0 ws0">预测结果</div><div class="t m0 x8e h6 y116 ff1 fs2 fc0 sc0 ls0 ws0">正例<span class="_ _37"> </span>反例</div><div class="t m0 x7 h6 y117 ff1 fs2 fc0 sc0 ls0 ws0">正例<span class="_ _38"> </span><span class="ff3">TP(</span>真正例<span class="ff3">)<span class="_ _8"> </span>FN(</span>假反例<span class="ff3">)</span></div><div class="t m0 x7 h6 y118 ff1 fs2 fc0 sc0 ls0 ws0">反例<span class="_ _39"> </span><span class="ff3">FP(</span>假正例<span class="ff3">)<span class="_ _8"> </span>TN(</span>真反例<span class="ff3">)</span></div><div class="t m0 x3 h6 y119 ff1 fs2 fc0 sc0 ls0 ws0">对于二分类问题，<span class="_ _22"></span>样本被分为了正类和负类，<span class="_ _22"></span>其预测结果也只有两种：<span class="_ _22"></span>正类或负类，<span class="_ _22"></span>因此可以将</div><div class="t m0 x3 h6 y11a ff1 fs2 fc0 sc0 ls0 ws0">所有样本分为四类：</div><div class="t m0 x9a h6 y11b ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span>T<span class="_ _22"></span>rue<span class="_ _9"> </span>P<span class="_ _e"></span>ositiv<span class="_ _e"></span>e<span class="ff1">：实际为正类，预测结果也是正类，也称真阳性或者命中<span class="_ _9"> </span></span>(Hit)<span class="ff1">。</span></div><div class="t m0 x9a h6 y11c ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span>T<span class="_ _22"></span>rue<span class="_ _9"> </span>Negative<span class="ff1">：实际为负类，预测结果也是负类，也称真阴性或者正确拒绝<span class="_ _9"> </span></span>(Correct<span class="_ _a"> </span>Re-</div><div class="t m0 x9b h6 y11d ff3 fs2 fc0 sc0 ls0 ws0">jection)<span class="ff1">。</span></div><div class="t m0 x9a h6 y11e ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span>F<span class="_ _22"></span>alse<span class="_ _25"> </span>Positiv<span class="_ _2d"></span>e<span class="ff1">：<span class="_ _2d"></span>实际为负类，<span class="_ _2d"></span>预测结果却是正类，<span class="_ _2d"></span>也称伪阳性或假警报<span class="_ _9"> </span><span class="ff3">(F<span class="_ _22"></span>alse<span class="_ _9"> </span>Alarm)<span class="ff1">，<span class="_ _2d"></span>指</span></span></span></div><div class="t m0 x9b h6 y11f ff1 fs2 fc0 sc0 ls0 ws0">代统计学第一型错误<span class="_ _9"> </span><span class="ff3">(T<span class="_ _e"></span>yp<span class="_ _1e"></span>e<span class="_ _9"> </span>I<span class="_ _9"> </span>Error)<span class="ff1">。</span></span></div><div class="t m0 x9a h6 y120 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span>F<span class="_ _22"></span>alse<span class="_ _25"> </span>Negative<span class="ff1">：<span class="_ _22"></span>实际为正类，<span class="_ _31"></span>预测结果却是负类，<span class="_ _31"></span>也称伪阴性或未命中<span class="_ _9"> </span><span class="ff3">(Miss)</span>，<span class="_ _31"></span>指代统计</span></div><div class="t m0 x9b h6 y121 ff1 fs2 fc0 sc0 ls0 ws0">学第二型错误<span class="_ _9"> </span><span class="ff3">(T<span class="_ _e"></span>yp<span class="_ _1e"></span>e<span class="_ _9"> </span>I<span class="_ _1e"></span>I<span class="_ _9"> </span>Error)<span class="ff1">。</span></span></div><div class="t m0 x3 h6 y122 ff1 fs2 fc0 sc0 ls0 ws0">进一步，<span class="_ _28"></span>为了更好的理解这种样本分类，<span class="_ _27"></span>我们还可以按照三种不同的方法将这四种类别归为两大</div><div class="t m0 x3 h6 y123 ff1 fs2 fc0 sc0 ls0 ws0">类：</div><div class="t m0 x3 h6 y124 ff4 fs2 fc0 sc0 ls0 ws0">按照预测结果是否正确进行归类：</div><div class="t m0 x9a h6 y125 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff1">预测正确的样本：</span>TP<span class="_ _25"> </span>+<span class="_ _9"> </span>TN</div><div class="t m0 x9a h6 y126 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff1">预测错误的样本：</span>FN<span class="_ _25"> </span>+<span class="_ _9"> </span>FP</div><div class="t m0 x3 h6 y127 ff4 fs2 fc0 sc0 ls0 ws0">按照样本的实际类别进行归类：</div><div class="t m0 x9a h6 y128 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff1">实际类别为正类的样本：</span>TP<span class="_ _25"> </span>+<span class="_ _9"> </span>FN</div><div class="t m0 x9a h6 y129 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff1">实际类别为负类的样本：</span>TN<span class="_ _25"> </span>+<span class="_ _9"> </span>FP</div><div class="t m0 x3 h6 y12a ff4 fs2 fc0 sc0 ls0 ws0">按照样本的预测类别进行归类：</div><div class="t m0 x9a h6 y12b ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff1">预测为正类的样本：</span>TP<span class="_ _25"> </span>+<span class="_ _9"> </span>FP</div><div class="t m0 x9a h6 y12c ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff1">预测为负类的样本：</span>TN<span class="_ _25"> </span>+<span class="_ _9"> </span>FN</div><div class="t m0 x3 h6 y12d ff1 fs2 fc2 sc0 ls0 ws0">下面介绍的性能度量，<span class="_ _31"></span>用于从不同的侧面对模型进行描述，<span class="_ _22"></span>其共同之处是都是由<span class="_ _9"> </span><span class="ff3">TP</span>、<span class="_ _31"></span><span class="ff3">TN<span class="ff1">、<span class="_ _31"></span><span class="ff3">FP<span class="ff1">、</span></span></span></span></div><div class="t m0 x3 h6 y12e ff3 fs2 fc2 sc0 ls0 ws0">FN<span class="_ _9"> </span><span class="ff1">中的部分或全部所组成的表达式。</span></div><div class="t m0 x3 h12 y12f ff5 fs8 fc0 sc0 ls0 ws0">2.2.2<span class="_ _34"> </span>Error<span class="_ _4"> </span>Rate<span class="_ _4"> </span><span class="ff9">与<span class="_ _4"> </span></span>accuracy</div><div class="t m0 x3 h6 y130 ff1 fs2 fc0 sc0 ls0 ws0">在分类任务中，即预测离散值的问题，最常用的是错误率和精度。</div><div class="t m0 x3 h6 y131 ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">2.1<span class="_ _4"> </span><span class="fc1">Error<span class="_ _a"> </span>Rate(<span class="ff4">错误率</span>)<span class="ff4">：<span class="_ _9"> </span></span></span><span class="ff1">分类错误的样本数占样本总数的比例。</span></span></div><div class="t m0 x3 h6 y132 ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">2.2<span class="_ _4"> </span><span class="fc1">accuracy(<span class="ff4">精度，准确率</span>)<span class="ff4">：<span class="_ _25"> </span></span></span><span class="ff1">分类正确的样本数占样本总数的比例，简记为<span class="_ _9"> </span><span class="ffa">AC<span class="_ _2b"></span>C<span class="_ _26"></span></span>。</span></span></div><div class="t m0 x3 h6 y133 ff1 fs2 fc0 sc0 ls0 ws0">一般来说，<span class="_ _21"></span>说到<span class="_ _25"> </span><span class="ff3">accuracy</span>，<span class="_ _21"></span>指的都是总的准确率，<span class="_ _21"></span>但实际上，<span class="_ _21"></span>不仅可以计算出总分类的<span class="_ _25"> </span><span class="ff3">accuracy</span></div><div class="t m0 x3 h6 y134 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _9"> </span><span class="ff3">Error<span class="_ _9"> </span>Rate</span>，也可以计算出各分类的<span class="_ _9"> </span><span class="ff3">accuracy<span class="_ _9"> </span></span>和<span class="_ _9"> </span><span class="ff3">Error<span class="_ _9"> </span>Rate</span>。</div><div class="t m0 x3 h6 y135 ff4 fs2 fc0 sc0 ls0 ws0">以下是总分类情形下的定义：</div><div class="t m0 x3 h6 y136 ff1 fs2 fc0 sc0 ls0 ws0">错误率定义为：</div><div class="t m0 x9c h4 y137 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _26"></span><span class="ffb">(</span>f<span class="_ _2b"></span><span class="ffb">;<span class="_ _2c"> </span></span>D<span class="_ _1e"></span><span class="ffb">)<span class="_ _2f"> </span>=</span></div><div class="t m0 x22 h4 y138 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x1 hc y139 ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x5c hb y13a ffd fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x5b he y13b ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x8f ha y13c ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x5e h4 y137 ff13 fs2 fc0 sc0 ls0 ws0">I<span class="_ _2c"> </span><span class="ffb">(<span class="ffa">f<span class="_ _f"> </span></span>(<span class="ff11">x</span></span></div><div class="t m0 x5f hb y13d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x63 h4 y137 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="fff"≯</span>=<span class="_ _2f"> </span><span class="ffa">y</span></div><div class="t m0 x9d hb y13d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x29 h4 y137 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _3a"> </span><span class="ff3">(2.3)</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">10</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf10" class="pf w0 h0" data-page-no="10"><div class="pc pc10 w0 h0"><img class="bi x46 y13e w7 h16" alt="" src="bg10.png"/><div class="t m0 x9e h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">2.2<span class="_ _d"> </span><span class="ff8">分类</span></div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">正确率定义为：</div><div class="t m0 x9f h4 y13f ff3 fs2 fc0 sc0 ls0 ws0">acc<span class="ffb">(<span class="ffa">f<span class="_ _2b"></span></span>;<span class="_ _2c"> </span><span class="ffa">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</span></div><div class="t m0 xa0 h4 y140 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8e hc y141 ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x41 hb y142 ffd fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 xa1 he y143 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x5c ha y144 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 xa2 h4 y13f ff13 fs2 fc0 sc0 ls0 ws0">I<span class="_ _2c"> </span><span class="ffb">(<span class="ffa">f<span class="_ _f"> </span></span>(<span class="ff11">x</span></span></div><div class="t m0 x63 hb y145 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x61 h4 y13f ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ffa">y</span></div><div class="t m0 x29 hb y145 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa3 h4 y13f ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x49 h4 y146 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">E<span class="_ _26"></span></span></span>(<span class="ffa">f<span class="_ _2b"></span></span>;<span class="_ _2c"> </span><span class="ffa">D<span class="_ _1e"></span></span>)</div><div class="t m0 x33 h4 y147 ff3 fs2 fc0 sc0 ls0 ws0">(2.4)</div><div class="t m0 x3 h6 y148 ff1 fs2 fc0 sc0 ls0 ws0">更一般的，对于数据分布<span class="_ _9"> </span><span class="fff">D<span class="_ _a"> </span></span>和概率密度函数<span class="_ _9"> </span><span class="ffa">p<span class="ffb">(<span class="fff">·</span>)<span class="_ _9"> </span></span></span>，错误率与精度可分别描述为：</div><div class="t m0 xa4 h4 y149 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _26"></span><span class="ffb">(</span>f<span class="_ _2b"></span><span class="ffb">;<span class="_ _2c"> </span><span class="fff">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</span></div><div class="t m0 x88 he y14a ffe fs2 fc0 sc0 ls0 ws0">Z</div><div class="t m0 x21 ha y14b ff11 fs7 fc0 sc0 ls0 ws0">x<span class="ff12">∼D</span></div><div class="t m0 xa5 h4 y149 ff13 fs2 fc0 sc0 ls0 ws0">I<span class="ffb">(<span class="ffa">f<span class="_ _2b"></span></span>(<span class="ff11">x</span>)<span class="_ _2f"> </span><span class="fff"≯</span>=<span class="_ _2f"> </span><span class="ffa">y<span class="_ _1e"></span></span>)<span class="ffa">p</span>(<span class="ff11">x</span>)<span class="ff3">d<span class="ff11">x</span></span></span></div><div class="t m0 x33 h4 y14c ff3 fs2 fc0 sc0 ls0 ws0">(2.5)</div><div class="t m0 xa6 h4 y14d ff3 fs2 fc0 sc0 ls0 ws0">acc<span class="ffb">(<span class="ffa">f<span class="_ _2b"></span></span>;<span class="_ _2c"> </span><span class="fff">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</span></div><div class="t m0 xa7 he y14e ffe fs2 fc0 sc0 ls0 ws0">Z</div><div class="t m0 x3f ha y14f ff11 fs7 fc0 sc0 ls0 ws0">x<span class="ff12">∼D</span></div><div class="t m0 x8 h4 y14d ff13 fs2 fc0 sc0 ls0 ws0">I<span class="ffb">(<span class="ffa">f<span class="_ _2b"></span></span>(<span class="ff11">x</span>)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ffa">y<span class="_ _1e"></span></span>)<span class="ffa">p</span>(<span class="ff11">x</span>)<span class="ff3">d<span class="ff11">x</span></span></span></div><div class="t m0 x9 h4 y150 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">E<span class="_ _26"></span></span></span>(<span class="ffa">f<span class="_ _2b"></span></span>;<span class="_ _2c"> </span><span class="fff">D<span class="_ _1e"></span></span>)</div><div class="t m0 x33 h4 y151 ff3 fs2 fc0 sc0 ls0 ws0">(2.6)</div><div class="t m0 x3 h6 y152 ff4 fs2 fc0 sc0 ls0 ws0">以下是各分类情形下的定义：</div><div class="t m0 x3 h6 y153 ff1 fs2 fc0 sc0 ls0 ws0">根据混淆矩阵</div><div class="t m0 xa8 h4 y154 ff3 fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x12 h6 y153 ff1 fs2 fc0 sc0 ls0 ws0">表<span class="ff3">2.1)</span>，各分类的错误率和准确率定义如下：</div><div class="t m0 x65 hc y155 ffa fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x36 hb y156 ffd fs7 fc0 sc0 ls0 ws0">P</div><div class="t m0 xa9 h4 y155 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _2b"></span></span>;<span class="_ _2c"> </span><span class="ffa">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</div><div class="t m0 xaa hc y157 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>N</div><div class="t m0 xab h4 y158 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P<span class="_ _a"> </span><span class="ffb">+<span class="_ _30"> </span></span>F<span class="_ _29"> </span>N</div><div class="t m0 xac hc y155 ffa fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x4d hb y156 ffd fs7 fc0 sc0 ls0 ws0">N</div><div class="t m0 xad h4 y155 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _2b"></span></span>;<span class="_ _2c"> </span><span class="ffa">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</div><div class="t m0 xae hc y157 ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _29"> </span>P</div><div class="t m0 x2b h4 y158 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>N<span class="_ _9"> </span><span class="ffb">+<span class="_ _30"> </span></span>F<span class="_ _29"> </span>P</div><div class="t m0 xaf hc y159 ffa fs2 fc0 sc0 ls0 ws0">acc</div><div class="t m0 xb0 hb y15a ffd fs7 fc0 sc0 ls0 ws0">P</div><div class="t m0 x36 h4 y159 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _2b"></span></span>;<span class="_ _2c"> </span><span class="ffa">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</div><div class="t m0 x20 hc y15b ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P</div><div class="t m0 x46 h4 y15c ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P<span class="_ _a"> </span><span class="ffb">+<span class="_ _30"> </span></span>F<span class="_ _29"> </span>N</div><div class="t m0 x91 hc y159 ffa fs2 fc0 sc0 ls0 ws0">acc</div><div class="t m0 x4d hb y15a ffd fs7 fc0 sc0 ls0 ws0">N</div><div class="t m0 xad h4 y159 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">f<span class="_ _2b"></span></span>;<span class="_ _2c"> </span><span class="ffa">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</div><div class="t m0 xae hc y15b ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>N</div><div class="t m0 x2b h4 y15c ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>N<span class="_ _9"> </span><span class="ffb">+<span class="_ _30"> </span></span>F<span class="_ _29"> </span>P</div><div class="t m0 x33 h4 y15d ff3 fs2 fc0 sc0 ls0 ws0">(2.7)</div><div class="t m0 x3 h12 y15e ff5 fs8 fc0 sc0 ls0 ws0">2.2.3<span class="_ _34"> </span>Precision<span class="ff9">、</span>Recall</div><div class="t m0 x3 h6 y15f ff1 fs2 fc0 sc0 ls0 ws0">错误率和精度虽然常用，<span class="_ _22"></span>但不能满足所有的需求，<span class="_ _22"></span>例如：<span class="_ _22"></span>在推荐系统中，<span class="_ _22"></span>我们只关心推送给用户</div><div class="t m0 x3 h6 y160 ff1 fs2 fc0 sc0 ls0 ws0">的内容用户是否感兴趣（即查准率）<span class="_ _2e"></span>，或者说所有用户感兴趣的内容我们<span class="_ _1e"></span>推送出来了多少（即查</div><div class="t m0 x3 h6 y161 ff1 fs2 fc0 sc0 ls0 ws0">全率）<span class="_ _23"></span>。因此，使用查准<span class="ff3">/</span>查全率更适合描述这类问题。</div><div class="t m0 x3 h6 y162 ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">2.3<span class="_ _4"> </span><span class="fc1">Recall(<span class="ff4">查全率、召回<span class="_ _1e"></span>率</span>)<span class="ff4">：<span class="_ _a"> </span></span></span><span class="ff1">模型<span class="_ _1e"></span>挑选出<span class="_ _1e"></span>正类样本<span class="_ _1e"></span>的能力。<span class="_ _1e"></span>所有正<span class="_ _1e"></span>例样本<span class="_ _1e"></span>中，预测<span class="_ _1e"></span>正确</span></span></div><div class="t m0 x3 h6 y163 ff1 fs2 fc0 sc0 ls0 ws0">的样本所占比例。</div><div class="t m0 x3 h6 y164 ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">2.4<span class="_ _4"> </span><span class="fc1">Precision(<span class="ff4">查准率</span>)<span class="ff4">：<span class="_ _25"> </span></span></span><span class="ff1">在所有预测为正例的样本中，预测正确的样本所占比例。</span></span></div><div class="t m0 x1f h4 y165 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span>recision<span class="_ _25"> </span><span class="ffb">=</span></div><div class="t m0 xb1 hc y166 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P</div><div class="t m0 xb2 h4 y167 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P<span class="_ _a"> </span><span class="ffb">+<span class="_ _30"> </span></span>F<span class="_ _29"> </span>P</div><div class="t m0 x33 h4 y165 ff3 fs2 fc0 sc0 ls0 ws0">(2.8)</div><div class="t m0 xb3 h4 y168 ffa fs2 fc0 sc0 ls0 ws0">Recal<span class="_ _1e"></span>l<span class="_ _2f"> </span><span class="ffb">=</span></div><div class="t m0 xb4 hc y169 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P</div><div class="t m0 x41 h4 y16a ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P<span class="_ _a"> </span><span class="ffb">+<span class="_ _30"> </span></span>F<span class="_ _29"> </span>N</div><div class="t m0 x33 h4 y168 ff3 fs2 fc0 sc0 ls0 ws0">(2.9)</div><div class="t m0 x3 h6 y16b ff1 fs2 fc0 sc0 ls0 ws0">根据上式，可以看出，<span class="ff3">Recall<span class="_ _9"> </span></span>就是各分类情形下的<span class="_ _9"> </span><span class="ff3">accuracy</span>。</div><div class="t m0 x3 h6 y16c ff1 fs2 fc0 sc0 ls0 ws0">很多<span class="_ _1e"></span>时候，<span class="_ _1e"></span>分类<span class="_ _1e"></span>模<span class="_ _1e"></span>型的<span class="_ _1e"></span>精度<span class="_ _1e"></span>与召<span class="_ _1e"></span>回率<span class="_ _1e"></span>之<span class="_ _1e"></span>间存<span class="_ _1e"></span>在着<span class="_ _1e"></span>某种<span class="_ _1e"></span>此<span class="_ _1e"></span>消彼<span class="_ _1e"></span>长的<span class="_ _1e"></span>关系。<span class="_ _1e"></span>通常<span class="_ _1e"></span>只<span class="_ _1e"></span>有在<span class="_ _1e"></span>一些<span class="_ _1e"></span>简单<span class="_ _1e"></span>的</div><div class="t m0 x3 h6 y16d ff1 fs2 fc0 sc0 ls0 ws0">任务中，才可能使<span class="_ _9"> </span><span class="ff3">Recall</span>、<span class="ff3">Precision<span class="_ _9"> </span></span>都很高。</div><div class="t m0 x3 h6 y16e ff1 fs2 fc0 sc0 ls0 ws0">对于某些应用来讲，我们可能希望<span class="_ _25"> </span><span class="ff3">Precision<span class="_ _9"> </span></span>越高越好，那么就需要适当牺牲一些召回率，<span class="_ _e"></span>将分</div><div class="t m0 x3 h6 y16f ff1 fs2 fc0 sc0 ls0 ws0">类阈值调高；<span class="_ _1e"></span>而对于另一<span class="_ _1e"></span>些应用来<span class="_ _1e"></span>讲，我们可能<span class="_ _1e"></span>希望<span class="_ _a"> </span><span class="ff3">Recall<span class="_ _9"> </span></span>越高<span class="_ _1e"></span>越好，那么就<span class="_ _1e"></span>需要适当<span class="_ _1e"></span>牺牲一</div><div class="t m0 x3 h6 y170 ff1 fs2 fc0 sc0 ls0 ws0">些<span class="_ _25"> </span><span class="ff3">Precision</span>，<span class="_ _20"></span>将分类阈值调低，<span class="_ _21"></span>从而使更多的样本被分为正类。<span class="_ _22"></span>因此，<span class="_ _21"></span>对于不同的应用场景，<span class="_ _20"></span>对</div><div class="t m0 x3 h6 y171 ff3 fs2 fc0 sc0 ls0 ws0">Precision<span class="_ _9"> </span><span class="ff1">和<span class="_ _9"> </span></span>Recall<span class="_ _9"> </span><span class="ff1">的关注程度也会有所不同，需要根据实际情况进行权衡。</span></div><div class="t m0 x3 h6 y172 ff1 fs2 fc0 sc0 ls0 ws0">在很<span class="_ _1e"></span>多情<span class="_ _1e"></span>形下，<span class="_ _1e"></span>学<span class="_ _1e"></span>习器<span class="_ _1e"></span>可以<span class="_ _1e"></span>得到<span class="_ _1e"></span>样本<span class="_ _1e"></span>属<span class="_ _1e"></span>于正<span class="_ _1e"></span>类的<span class="_ _1e"></span>概率<span class="_ _1e"></span>（或<span class="_ _1e"></span>者其<span class="_ _1e"></span>他度<span class="_ _1e"></span>量样<span class="_ _1e"></span>本属<span class="_ _1e"></span>于<span class="_ _1e"></span>正类<span class="_ _1e"></span>可能<span class="_ _1e"></span>性大<span class="_ _1e"></span>小</div><div class="t m0 x3 h6 y173 ff1 fs2 fc0 sc0 ls0 ws0">的量）<span class="_ _23"></span>。我们<span class="_ _1e"></span>可以按概率的大小对样本进行排序，然后逐<span class="_ _1e"></span>个把样本对应的概率作为分类阈值，则</div><div class="t m0 x3 h6 y174 ff1 fs2 fc0 sc0 ls0 ws0">每次可以计算出当前的<span class="_ _9"> </span><span class="ff3">Precision<span class="_ _9"> </span></span>和<span class="_ _9"> </span><span class="ff3">Recall</span>。以<span class="_ _25"> </span><span class="ff3">Precision<span class="_ _9"> </span></span>和<span class="_ _9"> </span><span class="ff3">Recall<span class="_ _9"> </span></span>分别作为纵轴、横轴，就得</div><div class="t m0 x3 h6 y175 ff1 fs2 fc0 sc0 ls0 ws0">到了“查准率<span class="ff3">-</span>查全<span class="_ _1e"></span>率曲线”<span class="_ _2e"></span>，简<span class="_ _1e"></span>称<span class="fc2">“<span class="ff3">P-R<span class="_ _9"> </span></span>曲线（<span class="ff3">Precision<span class="_ _a"> </span>Recall<span class="_ _a"> </span>Curv<span class="_ _2d"></span>e<span class="ff1">）<span class="_ _24"></span>”<span class="fc0">，显示该曲线的<span class="_ _1e"></span>图称</span></span></span></span></div><div class="t m0 x3 h6 y176 ff1 fs2 fc0 sc0 ls0 ws0">为<span class="ff3">”P-R<span class="_ _9"> </span></span>图<span class="ff3">”</span>。</div><div class="t m0 x3 h6 y177 ff3 fs2 fc0 sc0 ls0 ws0">P-R<span class="_ _a"> </span><span class="ff1">曲<span class="_ _1e"></span>线的<span class="_ _1e"></span>作用：<span class="_ _1e"></span>很好地<span class="_ _1e"></span>表示<span class="_ _1e"></span>精度<span class="_ _1e"></span>与召<span class="_ _1e"></span>回率<span class="_ _1e"></span>之间的<span class="_ _1e"></span>权衡<span class="_ _1e"></span>关系，<span class="_ _1e"></span>在实<span class="_ _1e"></span>际应<span class="_ _1e"></span>用中可<span class="_ _1e"></span>以根<span class="_ _1e"></span>据实<span class="_ _1e"></span>际情<span class="_ _1e"></span>况</span></div><div class="t m0 x3 h6 y178 ff1 fs2 fc0 sc0 ls0 ws0">选取曲线上合适的点所对于的分类阈值作为最终分类器的阈值。</div><div class="t m0 x3 h6 y179 ff1 fs2 fc0 sc0 ls0 ws0">示意图中有三个学习器的<span class="_ _9"> </span><span class="ff3">P-R<span class="_ _9"> </span></span>曲线。</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">11</div><a class="l" href="#pff" data-dest-detail='[15,"XYZ",70.87,799.37,null]'><div class="d m1" style="border-style:none;position:absolute;left:232.659000px;bottom:893.680500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf11" class="pf w0 h0" data-page-no="11"><div class="pc pc11 w0 h0"><img class="bi x3 y17a w2 h17" alt="" src="bg11.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">2.2<span class="_ _d"> </span><span class="ff8">分类</span></div><div class="t m0 x45 h6 y17b ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">2.1:<span class="_ _1c"> </span>Precision<span class="_ _9"> </span>Recall<span class="_ _9"> </span>Curve</span></div><div class="t m0 x9b h6 y17c ff6 fs2 fc2 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff4">显然，若一个学习器<span class="_ _12"> </span></span>C<span class="_ _a"> </span><span class="ff4">的<span class="_ _12"> </span></span>P-R<span class="_ _12"> </span><span class="ff4">曲线被另一个学习器<span class="_ _12"> </span></span>A<span class="_ _12"> </span><span class="ff4">的<span class="_ _a"> </span></span>P-R<span class="_ _12"> </span><span class="ff4">曲线完全包住，</span></div><div class="t m0 x9b h6 y17d ff4 fs2 fc2 sc0 ls0 ws0">则称：<span class="ff6">A<span class="_ _a"> </span></span>的性能优于<span class="_ _12"> </span><span class="ff6">C</span>。</div><div class="t m0 x3 h6 y17e ff1 fs2 fc0 sc0 ls0 ws0">如果两个学习器的<span class="_ _9"> </span><span class="ff3">P-R<span class="_ _a"> </span></span>曲线发生了交叉，例如图<span class="ff3">2.1</span>中的<span class="_ _9"> </span><span class="ff3">A<span class="_ _a"> </span></span>与<span class="_ _9"> </span><span class="ff3">B<span class="_ _9"> </span></span>，则不能一般性地断言<span class="_ _1e"></span>两者孰</div><div class="t m0 x3 h6 y17f ff1 fs2 fc0 sc0 ls0 ws0">优孰劣。<span class="_ _22"></span>只能在具体的查准率或查全率条件下进行比较。<span class="_ _22"></span>然而，<span class="_ _22"></span>在很多情形下，<span class="_ _22"></span>人们往往仍希望</div><div class="t m0 x3 h6 y180 ff1 fs2 fc0 sc0 ls0 ws0">把学习器<span class="_ _9"> </span><span class="ff3">A<span class="_ _9"> </span></span>与<span class="_ _9"> </span><span class="ff3">B<span class="_ _9"> </span></span>比出个高低。存在以下比较准则：</div><div class="t m0 x9b h6 y181 ff6 fs2 fc2 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff4">若<span class="_ _a"> </span></span>A<span class="_ _12"> </span><span class="ff4">和<span class="_ _a"> </span></span>B<span class="_ _12"> </span><span class="ff4">的曲线发生了交叉，则谁的曲线下的面积大，谁的性能更优。</span></div><div class="t m0 x3 h6 y182 ff1 fs2 fc0 sc0 ls0 ws0">但曲线下的面积难以进行估算，<span class="_ _27"></span>所以，<span class="_ _21"></span>人们设计了<span class="_ _2f"> </span>一些综合考虑查准率、<span class="_ _21"></span>查全率的性能度量，<span class="_ _21"></span>例</div><div class="t m0 x3 h6 y183 ff1 fs2 fc0 sc0 ls0 ws0">如<span class="ff4">平衡点</span>（平衡点如图<span class="ff3">2.1</span>所示）<span class="_ _23"></span>。</div><div class="t m0 x9b h6 y184 ff6 fs2 fc2 sc0 ls0 ws0">3.<span class="_ _7"> </span><span class="ff4">平衡点（</span>Break-Even<span class="_ _2d"></span>t<span class="_ _12"> </span>Poin<span class="_ _2d"></span>t<span class="ff4">，简称<span class="_ _1c"> </span></span>BEP<span class="ff4">）<span class="_ _2e"></span>：即当<span class="_ _12"> </span><span class="ff6">P=R<span class="_ _1c"> </span></span>时的取值，平衡点的</span></div><div class="t m0 x9b h6 y185 ff4 fs2 fc2 sc0 ls0 ws0">取值越高，性能更优。</div><div class="t m0 x3 h6 y186 ff1 fs2 fc0 sc0 ls0 ws0">但<span class="_ _9"> </span><span class="ff3">BEP<span class="_ _9"> </span></span>还是过于简化了些，更常用的是<span class="_ _9"> </span><span class="ff6">F1<span class="_ _9"> </span></span>度量<span class="_ _9"> </span><span class="ff3">(<span class="ff6">F1<span class="_ _9"> </span></span></span>度量实际是<span class="ff4">调和平均值<span class="ff3">)</span></span>：</div><div class="t m0 x9b h6 y187 ff6 fs2 fc2 sc0 ls0 ws0">4.<span class="_ _4"> </span>F1<span class="_ _a"> </span><span class="ff4">值越大，性能越优。</span></div><div class="t m0 xb6 h4 y188 ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _29"> </span><span class="ffb">1<span class="_ _f"> </span>=</span></div><div class="t m0 x1b h4 y189 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x37 ha y18a ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x37 ha y18b ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb7 h4 y18c fff fs2 fc0 sc0 ls0 ws0">×<span class="_ _30"> </span><span class="ffb">(</span></div><div class="t m0 x97 ha y18a ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x0 hb y18b ffd fs7 fc0 sc0 ls0 ws0">P</div><div class="t m0 x8d h4 y18c ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xb8 ha y18a ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa hb y18b ffd fs7 fc0 sc0 ls0 ws0">R</div><div class="t m0 xab h4 y18c ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x20 h4 y188 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb9 h4 y189 ffb fs2 fc0 sc0 ls0 ws0">2<span class="_ _30"> </span><span class="fff">×<span class="_ _30"> </span><span class="ffa">P<span class="_ _a"> </span></span>×<span class="_ _30"> </span><span class="ffa">R</span></span></div><div class="t m0 x3f h4 y18d ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _a"> </span><span class="ffb">+<span class="_ _30"> </span></span>R</div><div class="t m0 x26 h4 y188 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x96 h4 y189 ffb fs2 fc0 sc0 ls0 ws0">2<span class="_ _30"> </span><span class="fff">×<span class="_ _30"> </span><span class="ffa">T<span class="_ _29"> </span>P</span></span></div><div class="t m0 xad h6 y18e ff1 fs2 fc0 sc0 ls0 ws0">样本总数<span class="_ _30"> </span><span class="ffb">+<span class="_ _30"> </span><span class="ffa">T<span class="_ _29"> </span>P<span class="_ _a"> </span><span class="fff">−<span class="_ _30"> </span></span>T<span class="_ _29"> </span>N</span></span></div><div class="t m0 xba h4 y188 ff3 fs2 fc0 sc0 ls0 ws0">(2.10)</div><div class="t m0 x3 h6 y18f ff1 fs2 fc2 sc0 ls0 ws0">容易证明：<span class="_ _27"></span><span class="ff3">F1<span class="_ _25"> </span>Score <span class="ff1">与查准率和召回率之间存在着正向的关系，<span class="_ _21"></span>也就是查准率越高，<span class="_ _28"></span><span class="ff3">F1<span class="_ _25"> </span>Score<span class="_ _25"> </span><span class="ff1">就</span></span></span></span></div><div class="t m0 x3 h6 y190 ff1 fs2 fc2 sc0 ls0 ws0">越大，同样召回率越高，<span class="ff3">F1<span class="_ _9"> </span>Score<span class="_ _9"> </span></span>也就越大。</div><div class="t m0 x3 h6 y191 ff1 fs2 fc0 sc0 ls0 ws0">但是在<span class="_ _1e"></span>一些应用<span class="_ _1e"></span>中，对查<span class="_ _1e"></span>准率和查<span class="_ _1e"></span>全率的<span class="_ _1e"></span>重视程度<span class="_ _1e"></span>有所不<span class="_ _1e"></span>同，这就需<span class="_ _1e"></span>要对它<span class="_ _1e"></span>们赋予<span class="_ _1e"></span>不同的权<span class="_ _1e"></span>重，</div><div class="t m0 x3 h6 y192 ff1 fs2 fc0 sc0 ls0 ws0">因此有<span class="_ _9"> </span><span class="ff3">F1<span class="_ _9"> </span></span>的更一般形式<span class="_ _9"> </span><span class="ffa">F</span></div><div class="t m0 xa9 hb y193 ffd fs7 fc0 sc0 ls0 ws0">β</div><div class="t m0 x82 h6 y192 ff3 fs2 fc0 sc0 ls0 ws0">(<span class="ff4">加权调和平均</span>)<span class="ff1">：</span></div><div class="t m0 xd hc y194 ffa fs2 fc0 sc0 ls0 ws0">F</div><div class="t m0 x0 hb y195 ffd fs7 fc0 sc0 ls0 ws0">β</div><div class="t m0 xbb h4 y194 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xaa h4 y196 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xbc ha y197 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa hb y198 ffd fs7 fc0 sc0 ls0 ws0">β</div><div class="t m0 x1f h18 y199 ff14 fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 x1c h4 y19a ffb fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x20 ha y197 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x47 hb y19b ffd fs7 fc0 sc0 ls0 ws0">P</div><div class="t m0 x8c h4 y19a ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x3f hb y19c ffd fs7 fc0 sc0 ls0 ws0">β</div><div class="t m0 x22 h18 y19d ff14 fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbd hb y19b ffd fs7 fc0 sc0 ls0 ws0">R</div><div class="t m0 xbe h4 y19a ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xa1 h4 y194 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xb2 h4 y196 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span>+<span class="_ _30"> </span><span class="ffa">β</span></div><div class="t m0 x93 ha y19e ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x63 h4 y196 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">×<span class="_ _30"> </span><span class="ffa">P<span class="_ _a"> </span></span>×<span class="_ _30"> </span><span class="ffa">R</span></span></div><div class="t m0 xbf hc y19f ffa fs2 fc0 sc0 ls0 ws0">β</div><div class="t m0 xc0 ha y1a0 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc1 h4 y19f fff fs2 fc0 sc0 ls0 ws0">×<span class="_ _30"> </span><span class="ffa">P<span class="_ _a"> </span><span class="ffb">+<span class="_ _30"> </span></span>R</span></div><div class="t m0 xba h4 y194 ff3 fs2 fc0 sc0 ls0 ws0">(2.11)</div><div class="t m0 x3 h6 y1a1 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _25"> </span><span class="ffa">β<span class="_ _9"> </span>&gt;<span class="_ _2f"> </span><span class="ffb">0<span class="_ _9"> </span></span></span>度量了查全率对查准率的相对重要性。<span class="_ _22"></span><span class="ffa">β<span class="_ _9"> </span><span class="ffb">=<span class="_ _f"> </span>1<span class="_ _9"> </span><span class="ff1">时退化为标准的<span class="_ _25"> </span><span class="ff3">F1;<span class="_ _9"> </span></span></span></span>β<span class="_ _9"> </span>&gt;<span class="_ _2f"> </span><span class="ffb">1<span class="_ _25"> </span><span class="ff1">时查全率有</span></span></span></div><div class="t m0 x3 h6 y1a2 ff1 fs2 fc0 sc0 ls0 ws0">更大影响<span class="ff3">;<span class="_ _9"> </span><span class="ffa">β<span class="_ _9"> </span>&lt;<span class="_ _f"> </span><span class="ffb">1<span class="_ _9"> </span></span></span></span>时查准率有更大影响。</div><div class="t m0 x1e h6 y1a3 ff1 fs2 fc0 sc0 ls0 ws0">与算术平均</div><div class="t m0 x12 ha y1a4 ffd fs7 fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ffc">+</span>R</div><div class="t m0 x38 ha y1a5 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc2 h6 y1a3 ff1 fs2 fc0 sc0 ls0 ws0">和几何平均</div><div class="t m0 x3b h4 y1a6 fff fs2 fc0 sc0 ls0 ws0">√</div><div class="t m0 xa h6 y1a3 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _a"> </span><span class="fff">×<span class="_ _30"> </span></span>R<span class="_ _9"> </span><span class="ff1">相比，调和平均更重视较小值。</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">12</div><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",412.84,620.92,null]'><div class="d m1" style="border-style:none;position:absolute;left:457.413000px;bottom:736.687500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf11" data-dest-detail='[17,"XYZ",412.84,620.92,null]'><div class="d m1" style="border-style:none;position:absolute;left:269.935500px;bottom:581.068500px;width:13.942000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf12" class="pf w0 h0" data-page-no="12"><div class="pc pc12 w0 h0"><img class="bi xc3 y1a7 w8 h19" alt="" src="bg12.png"/><div class="t m0 x9e h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">2.2<span class="_ _d"> </span><span class="ff8">分类</span></div><div class="t m0 x3 h12 yd4 ff5 fs8 fc0 sc0 ls0 ws0">2.2.4<span class="_ _34"> </span>TPR<span class="ff9">、</span>FPR</div><div class="t m0 x3 h6 y1a8 ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">2.5<span class="_ _4"> </span><span class="fc1">TPR<span class="ff4">：<span class="_ _9"> </span></span></span><span class="ff3">T<span class="_ _31"></span>rue<span class="_ _a"> </span>Positiv<span class="_ _2d"></span>e<span class="_ _a"> </span>Rate<span class="ff1">，真<span class="_ _1e"></span>正例率。所<span class="_ _1e"></span>有正例样<span class="_ _1e"></span>本中，预<span class="_ _1e"></span>测正确的<span class="_ _1e"></span>样本所<span class="_ _1e"></span>占比例。</span></span></span></div><div class="t m0 x3 h6 y1a9 ff3 fs2 fc0 sc0 ls0 ws0">TPR<span class="_ _9"> </span><span class="ff1">就是<span class="_ _9"> </span></span>Recall<span class="ff1">。</span></div><div class="t m0 x3 h6 y1aa ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">2.6<span class="_ _4"> </span><span class="fc1">FPR<span class="ff4">：<span class="_ _25"> </span></span></span><span class="ff3">F<span class="_ _31"></span>alse<span class="_ _9"> </span>P<span class="_ _e"></span>ositiv<span class="_ _e"></span>e<span class="_ _9"> </span>Rate<span class="ff1">，伪阳性率、假正例率、也称误报率（</span>Probabilit<span class="_ _2d"></span>y<span class="_ _9"> </span>of<span class="_ _9"> </span>F<span class="_ _31"></span>alse</span></span></div><div class="t m0 x3 h6 y1ab ff3 fs2 fc0 sc0 ls0 ws0">Alarm<span class="ff1">）<span class="_ _23"></span>、错误命中率、<span class="_ _2d"></span>假警报率，简记为<span class="_ _9"> </span><span class="ff3">FPR</span>。在所有实际上为负类的样本中，<span class="_ _e"></span>误判为正类的</span></div><div class="t m0 x3 h6 y1ac ff1 fs2 fc0 sc0 ls0 ws0">样本所占的比例。</div><div class="t m0 x20 h4 y1ad ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _f"> </span><span class="ffb">=</span></div><div class="t m0 x4b hc y1ae ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P</div><div class="t m0 xa1 h4 y1af ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>P<span class="_ _a"> </span><span class="ffb">+<span class="_ _30"> </span></span>F<span class="_ _29"> </span>N</div><div class="t m0 xba h4 y1ad ff3 fs2 fc0 sc0 ls0 ws0">(2.12)</div><div class="t m0 x20 h4 y1b0 ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _f"> </span><span class="ffb">=</span></div><div class="t m0 x4b hc y1b1 ffa fs2 fc0 sc0 ls0 ws0">F<span class="_ _29"> </span>P</div><div class="t m0 x5c h4 y1b2 ffa fs2 fc0 sc0 ls0 ws0">T<span class="_ _29"> </span>N<span class="_ _9"> </span><span class="ffb">+<span class="_ _30"> </span></span>F<span class="_ _29"> </span>P</div><div class="t m0 xba h4 y1b0 ff3 fs2 fc0 sc0 ls0 ws0">(2.13)</div><div class="t m0 x3 h6 y1b3 ff1 fs2 fc0 sc0 ls0 ws0">除了<span class="_ _25"> </span><span class="ff3">TPR</span>、<span class="_ _31"></span><span class="ff3">FPR<span class="ff1">，<span class="_ _22"></span>还有真负例率和假负例率。<span class="_ _31"></span><span class="ff3 fc2">TPR<span class="ff1">、<span class="_ _22"></span><span class="ff3">FPR<span class="_ _9"> </span><span class="ff1">有一个很好的特性：<span class="_ _22"></span>对数据集是否均</span></span></span></span></span></span></div><div class="t m0 x3 h6 y1b4 ff1 fs2 fc2 sc0 ls0 ws0">衡不敏感<span class="fc0">，<span class="_ _2a"></span>因为<span class="_ _9"> </span><span class="ff6">TPR<span class="ff4">、<span class="_ _27"></span><span class="ff6">FPR<span class="_ _9"> </span><span class="ff4">的分子和分母只涉及了单一类别的样本<span class="ff1">。<span class="_ _28"></span><span class="ff3">ROC <span class="ff1">曲线以<span class="_ _2f"> </span></span>TPR<span class="ff1">、<span class="_ _28"></span><span class="ff3">FPR</span></span></span></span></span></span></span></span></span></div><div class="t m0 x3 h6 y1b5 ff1 fs2 fc0 sc0 ls0 ws0">基础的，所以这也是<span class="_ _9"> </span><span class="ff3">R<span class="_ _e"></span>OC<span class="_ _9"> </span><span class="ff1">曲线的优点。</span></span></div><div class="t m0 x3 h12 y1b6 ff5 fs8 fc0 sc0 ls0 ws0">2.2.5<span class="_ _34"> </span>R<span class="_ _2d"></span>OC<span class="ff9">、</span>A<span class="_ _e"></span>UC</div><div class="t m0 x3 h6 y1b7 ff1 fs2 fc0 sc0 ls0 ws0">很多学习器是为测试样本产生一个实值或概率预测，<span class="_ _21"></span>然后将这个预测值与一个分类阈值<span class="_ _2f"> </span><span class="ff3">(thresh-</span></div><div class="t m0 x3 h6 y1b8 ff3 fs2 fc0 sc0 ls0 ws0">old)<span class="_ _12"> </span><span class="ff1">进行比<span class="_ _1e"></span>较，若<span class="_ _1e"></span>大于<span class="_ _1e"></span>阈值<span class="_ _1e"></span>则分<span class="_ _1e"></span>为正<span class="_ _1e"></span>类，否<span class="_ _1e"></span>则为<span class="_ _1e"></span>反类。<span class="_ _1e"></span>这个<span class="_ _1e"></span>实值<span class="_ _1e"></span>或概<span class="_ _1e"></span>率预<span class="_ _1e"></span>测<span class="_ _1e"></span>结果<span class="_ _1e"></span>的好<span class="_ _1e"></span>坏，直<span class="_ _1e"></span>接</span></div><div class="t m0 x3 h6 y1b9 ff1 fs2 fc0 sc0 ls0 ws0">决定<span class="_ _1e"></span>了学<span class="_ _1e"></span>习<span class="_ _1e"></span>器的<span class="_ _1e"></span>泛化<span class="_ _1e"></span>能力。<span class="_ _1e"></span>实<span class="_ _1e"></span>际上，<span class="_ _1e"></span>根据<span class="_ _1e"></span>这个<span class="_ _1e"></span>实<span class="_ _1e"></span>值或<span class="_ _1e"></span>概率<span class="_ _1e"></span>预测<span class="_ _1e"></span>结<span class="_ _1e"></span>果，我<span class="_ _1e"></span>们可<span class="_ _1e"></span>将测<span class="_ _1e"></span>试<span class="_ _1e"></span>样本<span class="_ _1e"></span>进行<span class="_ _1e"></span>排</div><div class="t m0 x3 h6 y1ba ff1 fs2 fc0 sc0 ls0 ws0">序，<span class="_ _3b"></span>“最可能”<span class="_ _31"></span>是正例的排在最前面，<span class="_ _22"></span><span class="ff3">”<span class="_ _25"> </span><span class="ff1">最不可能</span>”<span class="_ _9"> </span><span class="ff1">是正例的排在最后面。<span class="_ _22"></span>这样，<span class="_ _22"></span>分类过程就相当</span></span></div><div class="t m0 x3 h6 y1bb ff1 fs2 fc0 sc0 ls0 ws0">于在这个排序中以某个<span class="ff3">”<span class="_ _9"> </span></span>截断点<span class="ff3">”<span class="_ _25"> </span>(cut<span class="_ _9"> </span>p<span class="_ _1e"></span>oint) </span>将样本分为两部分，<span class="_ _2d"></span>前一部分判作正例，<span class="_ _2d"></span>后一部分</div><div class="t m0 x3 h6 y1bc ff1 fs2 fc0 sc0 ls0 ws0">则判作反例。</div><div class="t m0 x3 h6 y1bd ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">2.7<span class="_ _4"> </span><span class="fc1">R<span class="_ _2d"></span>OC<span class="ff4">：<span class="_ _2d"></span><span class="ff3 fc0">ROC<span class="_ _f"> </span><span class="ff1">曲线的全称为<span class="_ _f"> </span></span>Receiver<span class="_ _30"> </span>Op<span class="_ _1e"></span>erating Characteristic<span class="ff1">，<span class="_ _3c"></span>其纵轴为<span class="_ _f"> </span><span class="ff3">T<span class="_ _31"></span>rue P<span class="_ _2d"></span>ositive</span></span></span></span></span></span></div><div class="t m0 x3 h6 y1be ff3 fs2 fc0 sc0 ls0 ws0">Rate<span class="_ _25"> </span>(TPR)<span class="ff1">，<span class="_ _22"></span>也就是召回率，<span class="_ _20"></span>横轴为伪阳性率<span class="_ _9"> </span><span class="ff3">F<span class="_ _22"></span>alse<span class="_ _9"> </span>P<span class="_ _2d"></span>ositive Rate<span class="_ _9"> </span>(FPR)<span class="ff1">。<span class="_ _22"></span>显示<span class="_ _25"> </span><span class="ff3">ROC </span>曲线的图</span></span></span></div><div class="t m0 x3 h6 y1bf ff1 fs2 fc0 sc0 ls0 ws0">称为<span class="ff3">”R<span class="_ _e"></span>OC<span class="_ _9"> </span><span class="ff1">图。</span></span></div><div class="t m0 x3 h6 y1c0 ff1 fs2 fc0 sc0 ls0 ws0">下图给出了一个示意图：</div><div class="t m0 xc4 h6 y1c1 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">2.2:<span class="_ _1c"> </span>ro<span class="_ _1e"></span>c<span class="_ _9"> </span></span>与<span class="_ _9"> </span><span class="ff3">auc<span class="_ _9"> </span></span>曲线</div><div class="t m0 x3 h6 y1c2 ff1 fs2 fc0 sc0 ls0 ws0">看几个特殊点或特殊曲线：</div><div class="t m0 x9a h6 y1c3 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">第一个点：<span class="ffb">(0<span class="ffa">,<span class="_ _29"> </span></span>1)</span>，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>0</span>T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>1<span class="_ _9"> </span></span></span>，这意味着所有的样本都分类正确。</span></div><div class="t m0 x9a h6 y1c4 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">第二个点：<span class="ffb">(1<span class="ffa">,<span class="_ _29"> </span></span>0)</span>，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _9"> </span><span class="ffb">=<span class="_ _25"> </span>1</span>T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _25"> </span><span class="ffb">=<span class="_ _25"> </span>0<span class="_ _a"> </span></span></span>，和第一<span class="_ _1e"></span>个点比较，这是<span class="_ _1e"></span>第一个点的完<span class="_ _1e"></span>全反面，意</span></div><div class="t m0 x9b h6 y1c5 ff1 fs2 fc0 sc0 ls0 ws0">味着是个最糟糕的分类器，<span class="_ _22"></span>将所有的样本都分类错误了<span class="_ _2d"></span>（但其实可以直接取反，<span class="_ _22"></span>就<span class="_ _9"> </span>是最好</div><div class="t m0 x9b h6 y1c6 ff1 fs2 fc0 sc0 ls0 ws0">的模型，因为是二分类问题）<span class="_ _23"></span>。</div><div class="t m0 x9a h6 y1c7 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">第三个点：<span class="ffb">(0<span class="ffa">,<span class="_ _29"> </span></span>0)</span>，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _9"> </span><span class="ffb">=<span class="_ _25"> </span>0</span>T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _25"> </span><span class="ffb">=<span class="_ _25"> </span>0<span class="_ _a"> </span></span></span>也就是原<span class="_ _1e"></span>点，这个点表示<span class="_ _1e"></span>的意思是，分类<span class="_ _1e"></span>器预测所</span></div><div class="t m0 x9b h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">有的样本都为负类。</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">13</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf13" class="pf w0 h0" data-page-no="13"><div class="pc pc13 w0 h0"><img class="bi xc5 y1c8 w9 h1a" alt="" src="bg13.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">2.2<span class="_ _d"> </span><span class="ff8">分类</span></div><div class="t m0 x9a h6 y20 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">第四个点：<span class="_ _20"></span><span class="ffb">(1<span class="ffa">,<span class="_ _2c"> </span></span>1)<span class="ff1">，<span class="_ _22"></span><span class="ffa">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>1</span>T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>1<span class="ff1">，<span class="_ _22"></span>和第三个点对应，<span class="_ _22"></span>表示分类器预测所有的样本都为</span></span></span></span></span></span></div><div class="t m0 x9b h6 y1c9 ff1 fs2 fc0 sc0 ls0 ws0">正类。</div><div class="t m0 x9a h6 y1ca ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">一条线：<span class="ffa">y<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span></span>x</span>，对角线对应于“随机猜测”模型。</span></div><div class="t m0 x3 h6 y1cb ff1 fs2 fc0 sc0 ls0 ws0">于是，对<span class="_ _1e"></span>于特<span class="_ _1e"></span>定的分<span class="_ _1e"></span>类模型，<span class="_ _1e"></span>如果<span class="_ _12"> </span><span class="ff3">R<span class="_ _2d"></span>OC<span class="_ _12"> </span><span class="ff1">曲线位<span class="_ _1e"></span>于对<span class="_ _1e"></span>角线左<span class="_ _1e"></span>上方，说<span class="_ _1e"></span>明模<span class="_ _1e"></span>型性能<span class="_ _1e"></span>好于随<span class="_ _1e"></span>机猜<span class="_ _1e"></span>测，</span></span></div><div class="t m0 x3 h6 y1cc ff1 fs2 fc0 sc0 ls0 ws0">如果<span class="_ _9"> </span><span class="ff3">R<span class="_ _e"></span>OC<span class="_ _9"> </span><span class="ff1">曲线位于对角线右下方，说明模型性能劣于随机猜测。</span></span></div><div class="t m0 x3 h6 y1cd ff1 fs2 fc0 sc0 ls0 ws0">图<span class="ff3">2.2(a) </span>是理想化的<span class="_ _2f"> </span><span class="ff3">ROC </span>曲线图，<span class="_ _2a"></span>但在现实任务中，<span class="_ _3d"></span>通常只能利用有限个测试样本来绘制<span class="_ _2f"> </span><span class="ff3">ROC</span></div><div class="t m0 x3 h6 y1ce ff1 fs2 fc0 sc0 ls0 ws0">图，此时只<span class="_ _1e"></span>有有限<span class="_ _1e"></span>个<span class="_ _a"> </span><span class="ffb">(<span class="ffa">T<span class="_ _29"> </span>P<span class="_ _29"> </span>R,<span class="_ _29"> </span>F<span class="_ _29"> </span>P<span class="_ _29"> </span>R</span>)<span class="_ _a"> </span></span>坐<span class="_ _1e"></span>标对，无法<span class="_ _1e"></span>产生图<span class="ff3">2.2(a)<span class="_ _a"> </span></span>中<span class="_ _1e"></span>的光滑<span class="_ _a"> </span><span class="ff3">ROC<span class="_ _9"> </span></span>曲线，<span class="_ _1e"></span>只能绘<span class="_ _1e"></span>制</div><div class="t m0 x3 h6 y1cf ff1 fs2 fc0 sc0 ls0 ws0">出图<span class="ff3">2.2(b)<span class="_ _9"> </span></span>中的近似<span class="_ _9"> </span><span class="ff3">R<span class="_ _e"></span>OC<span class="_ _9"> </span><span class="ff1">曲线。<span class="ff4">绘制<span class="_ _a"> </span><span class="ff6">ROC<span class="_ _a"> </span></span>曲线的过程如下：</span></span></span></div><div class="t m0 x3 h6 y1d0 ff1 fs2 fc0 sc0 ls0 ws0">设数据集共有<span class="_ _9"> </span><span class="ffa">m</span></div><div class="t m0 xc6 ha y1d1 ffc fs7 fc0 sc0 ls0 ws0">+</div><div class="t m0 xc7 h6 y1d0 ff1 fs2 fc0 sc0 ls0 ws0">个正例，<span class="ffa">m</span></div><div class="t m0 x0 ha y1d1 ff12 fs7 fc0 sc0 ls0 ws0">−</div><div class="t m0 x8d h6 y1d0 ff1 fs2 fc0 sc0 ls0 ws0">个反例</div><div class="t m0 x9a h6 y1d2 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff1">将所有的样本按模型的预测打分<span class="_ _25"> </span></span>(score)<span class="_ _9"> </span><span class="ff1">由大到小排序；</span></div><div class="t m0 x9a h6 y1d3 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff1">将分类阈值设为<span class="_ _1e"></span>最大，即把<span class="_ _1e"></span>所有样本<span class="_ _1e"></span>都归类为<span class="_ _1e"></span>反例，此<span class="_ _1e"></span>时<span class="_ _a"> </span><span class="ffa">T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _25"> </span><span class="ffb">=<span class="_ _9"> </span></span>F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _9"> </span><span class="ffb">=<span class="_ _9"> </span>0</span></span>，得到<span class="_ _a"> </span><span class="ffb">(0<span class="ffa">,<span class="_ _2c"> </span></span>0)</span></span></div><div class="t m0 x9b h6 y1d4 ff1 fs2 fc0 sc0 ls0 ws0">坐标点；</div><div class="t m0 x9a h6 y1d5 ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _4"> </span><span class="ff1">将分类阈值依次设为每个样本的打分，即依次把每个样<span class="_ _1e"></span>本划分为正例。设前一个标记点<span class="_ _1e"></span>的</span></div><div class="t m0 x9b h6 y1d6 ff1 fs2 fc0 sc0 ls0 ws0">坐标为<span class="_ _2f"> </span><span class="ffb">(<span class="ffa">x,<span class="_ _2c"> </span>y<span class="_ _26"></span></span>)</span>，<span class="_ _21"></span>若当前为真正例，<span class="_ _27"></span>则当前标记点的坐标为<span class="_ _25"> </span><span class="ffb">(<span class="ffa">x,<span class="_ _2c"> </span>y<span class="_ _3e"> </span></span>+</span></div><div class="t m0 x54 ha y1d7 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xc8 hb y1d8 ffd fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 x53 h18 y1d9 ff14 fs9 fc0 sc0 ls0 ws0">+</div><div class="t m0 xc9 h6 y1d6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">，<span class="_ _21"></span>若当前为假正例，<span class="_ _27"></span>则</span></div><div class="t m0 x9b h6 y1da ff1 fs2 fc0 sc0 ls0 ws0">当前标记点的坐标为<span class="_ _9"> </span><span class="ffb">(<span class="ffa">x<span class="_ _30"> </span></span>+</span></div><div class="t m0 x1d ha y1db ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8d hb y1dc ffd fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 xca h1b y1dd ff15 fs9 fc0 sc0 ls0 ws0">−</div><div class="t m0 xcb h6 y1da ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y<span class="_ _26"></span><span class="ffb">)<span class="ff1">。</span></span></div><div class="t m0 x3 h6 y1de ff1 fs2 fc0 sc0 ls0 ws0">现设数<span class="_ _1e"></span>据集共<span class="_ _1e"></span>有<span class="_ _a"> </span><span class="ffb">10<span class="_ _a"> </span></span>个正<span class="_ _1e"></span>例，<span class="ffb">10<span class="_ _a"> </span></span>个反<span class="_ _1e"></span>例，如下<span class="_ _1e"></span>表。<span class="ff3">Class<span class="_ _a"> </span></span>一栏表<span class="_ _1e"></span>示每个<span class="_ _1e"></span>测试样<span class="_ _1e"></span>本真正<span class="_ _1e"></span>的标签<span class="_ _1e"></span>（<span class="ff3">p</span></div><div class="t m0 x3 h6 y1df ff1 fs2 fc0 sc0 ls0 ws0">表示正样本，<span class="_ _21"></span><span class="ff3">n<span class="_ _25"> </span><span class="ff1">表示负样本）<span class="_ _23"></span>，<span class="_ _20"></span><span class="ff3">Score <span class="ff1">表示每个测试样本属于正样本的概率。<span class="_ _22"></span>我们根据每个测试样</span></span></span></span></div><div class="t m0 x3 h6 y1e0 ff1 fs2 fc0 sc0 ls0 ws0">本属于正样本的概率值从大到小排序。</div><div class="t m0 xb0 h4 y1e1 ff6 fs2 fc0 sc0 ls0 ws0">n<span class="_ _2d"></span>um<span class="_ _3f"> </span>Class<span class="_ _3f"> </span>Score<span class="_ _40"> </span>n<span class="_ _2d"></span>um<span class="_ _3f"> </span>Class<span class="_ _40"> </span>Score</div><div class="t m0 xcc h4 y1e2 ff3 fs2 fc0 sc0 ls0 ws0">1<span class="_ _40"> </span><span class="ff6">p<span class="_ _41"> </span></span>0.9<span class="_ _42"> </span>11<span class="_ _40"> </span><span class="ff6">p<span class="_ _41"> </span></span>0.4</div><div class="t m0 xcc h4 y1e3 ff3 fs2 fc0 sc0 ls0 ws0">2<span class="_ _40"> </span><span class="ff6">p<span class="_ _41"> </span></span>0.8<span class="_ _42"> </span>12<span class="_ _40"> </span><span class="ff6">n<span class="_ _43"> </span></span>0.39</div><div class="t m0 xcc h4 y1e4 ff3 fs2 fc0 sc0 ls0 ws0">3<span class="_ _40"> </span><span class="ff6">n<span class="_ _41"> </span></span>0.7<span class="_ _42"> </span>13<span class="_ _40"> </span><span class="ff6">p<span class="_ _43"> </span></span>0.38</div><div class="t m0 xcc h4 y1e5 ff3 fs2 fc0 sc0 ls0 ws0">4<span class="_ _40"> </span><span class="ff6">p<span class="_ _41"> </span></span>0.6<span class="_ _42"> </span>14<span class="_ _40"> </span><span class="ff6">n<span class="_ _43"> </span></span>0.37</div><div class="t m0 xcc h4 y1e6 ff3 fs2 fc0 sc0 ls0 ws0">5<span class="_ _40"> </span><span class="ff6">p<span class="_ _43"> </span></span>0.55<span class="_ _42"> </span>15<span class="_ _40"> </span><span class="ff6">n<span class="_ _43"> </span></span>0.36</div><div class="t m0 xcc h4 y1e7 ff3 fs2 fc0 sc0 ls0 ws0">6<span class="_ _40"> </span><span class="ff6">p<span class="_ _43"> </span></span>0.54<span class="_ _42"> </span>16<span class="_ _40"> </span><span class="ff6">n<span class="_ _43"> </span></span>0.35</div><div class="t m0 xcc h4 y1e8 ff3 fs2 fc0 sc0 ls0 ws0">7<span class="_ _40"> </span><span class="ff6">n<span class="_ _43"> </span></span>0.53<span class="_ _42"> </span>17<span class="_ _40"> </span><span class="ff6">p<span class="_ _43"> </span></span>0.34</div><div class="t m0 xcc h4 y1e9 ff3 fs2 fc0 sc0 ls0 ws0">8<span class="_ _40"> </span><span class="ff6">n<span class="_ _43"> </span></span>0.52<span class="_ _42"> </span>18<span class="_ _40"> </span><span class="ff6">n<span class="_ _43"> </span></span>0.33</div><div class="t m0 xcc h4 y1ea ff3 fs2 fc0 sc0 ls0 ws0">9<span class="_ _40"> </span><span class="ff6">p<span class="_ _43"> </span></span>0.51<span class="_ _42"> </span>19<span class="_ _40"> </span><span class="ff6">p<span class="_ _41"> </span></span>0.3</div><div class="t m0 xa9 h4 y1eb ff3 fs2 fc0 sc0 ls0 ws0">10<span class="_ _40"> </span><span class="ff6">n<span class="_ _44"> </span></span>0.505<span class="_ _42"> </span>20<span class="_ _40"> </span><span class="ff6">n<span class="_ _41"> </span></span>0.1</div><div class="t m0 x9a h6 y1ec ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff1">阈值<span class="_ _25"> </span><span class="ffa">t<span class="_ _2f"> </span>&gt;<span class="_ _2f"> </span><span class="ffb">0</span>.<span class="ffb">9</span></span>，则<span class="_ _9"> </span><span class="ffa">T<span class="_ _29"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _f"> </span></span>F<span class="_ _29"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _f"> </span>0</span></span>，<span class="ffa">T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>0</span></span>，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>0</span></span>；</span></div><div class="t m0 x9a h6 y1ed ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff1">阈值<span class="_ _25"> </span><span class="ffa">t<span class="_ _2f"> </span><span class="fff">≥<span class="_ _2f"> </span><span class="ffb">0</span></span>.<span class="ffb">9</span></span>，则<span class="_ _9"> </span><span class="ffa">T<span class="_ _29"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _f"> </span>1</span></span>，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _f"> </span>0</span></span>，<span class="ffa">T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=</span></span></span></div><div class="t m0 xbf ha y1ee ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x26 ha y1ef ffc fs7 fc0 sc0 ls0 ws0">10</div><div class="t m0 xcd h6 y1ed ff1 fs2 fc0 sc0 ls0 ws0">，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _f"> </span><span class="ffb">=<span class="_ _2f"> </span>0 </span></span>；</div><div class="t m0 x9a h6 y1f0 ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _4"> </span><span class="ff1">阈值<span class="_ _25"> </span><span class="ffa">t<span class="_ _2f"> </span><span class="fff">≥<span class="_ _2f"> </span><span class="ffb">0</span></span>.<span class="ffb">9</span></span>，则<span class="_ _9"> </span><span class="ffa">T<span class="_ _29"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _f"> </span>1</span></span>，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _f"> </span>0</span></span>，<span class="ffa">T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=</span></span></span></div><div class="t m0 xbf ha y1f1 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x26 ha y1f2 ffc fs7 fc0 sc0 ls0 ws0">10</div><div class="t m0 xcd h6 y1f0 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _f"> </span><span class="ffb">=<span class="_ _2f"> </span>0 </span></span>；</div><div class="t m0 x9a h4 y1f3 ff3 fs2 fc0 sc0 ls0 ws0">4.<span class="_ _4"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·</span></div><div class="t m0 x9a h6 y1f4 ff3 fs2 fc0 sc0 ls0 ws0">5.<span class="_ _4"> </span><span class="ff1">阈值<span class="_ _25"> </span><span class="ffa">t<span class="_ _2f"> </span><span class="fff">≥<span class="_ _2f"> </span><span class="ffb">0</span></span>.<span class="ffb">1</span></span>，则<span class="_ _9"> </span><span class="ffa">T<span class="_ _29"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _f"> </span>10</span></span>，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _1c"> </span><span class="ffb">=<span class="_ _f"> </span>10</span></span>，<span class="ffa">T<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>1</span></span>，<span class="ffa">F<span class="_ _29"> </span>P<span class="_ _29"> </span>R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>1</span></span>。</span></div><div class="t m0 x3 h6 y1f5 ff1 fs2 fc0 sc0 ls0 ws0">最后绘制出来的<span class="_ _9"> </span><span class="ff3">R<span class="_ _e"></span>OC<span class="_ _9"> </span><span class="ff1">图如下所示：</span></span></div><div class="t m0 x3 h6 y1f6 ff3 fs2 fc0 sc0 ls0 ws0">R<span class="_ _e"></span>OC<span class="_ _9"> </span><span class="ff1">曲线可<span class="_ _1e"></span>以很直观的展示<span class="_ _1e"></span>模型的好坏，但是如<span class="_ _1e"></span>果不同模型的<span class="_ _a"> </span></span>R<span class="_ _e"></span>OC<span class="_ _9"> </span><span class="ff1">曲线存<span class="_ _1e"></span>在交叉，则很难依</span></div><div class="t m0 x3 h6 y1f7 ff1 fs2 fc0 sc0 ls0 ws0">靠视觉来对<span class="_ _1e"></span>模型的优劣<span class="_ _1e"></span>进行比较，此<span class="_ _1e"></span>时可以使<span class="_ _1e"></span>用曲线下面<span class="_ _1e"></span>积<span class="_ _9"> </span><span class="ff3">(Area<span class="_ _a"> </span>Under<span class="_ _a"> </span>Curv<span class="_ _e"></span>e,<span class="_ _a"> </span>A<span class="_ _e"></span>UC)<span class="_ _9"> </span><span class="ff1">这<span class="_ _1e"></span>个指</span></span></div><div class="t m0 x3 h6 y1f8 ff1 fs2 fc0 sc0 ls0 ws0">标来进行评价。</div><div class="t m0 x3 h6 y1f9 ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">2.8<span class="_ _4"> </span><span class="fc1">A<span class="_ _2d"></span>UC<span class="ff4">：<span class="_ _3e"> </span><span class="ff1 fc0">指的是<span class="_ _25"> </span><span class="ff3">ROC </span>曲线右下方的面积，<span class="_ _22"></span>该面积越大，<span class="_ _20"></span>一般表示模型的预测能力越好，</span></span></span></span></div><div class="t m0 x3 h6 y110 ff1 fs2 fc0 sc0 ls0 ws0">此时可以将<span class="_ _9"> </span><span class="ff3">R<span class="_ _e"></span>OC<span class="_ _9"> </span><span class="ff1">曲线上离左上角最近的点所对于的分类阈值作为最终分类器的阈值。</span></span></div><div class="t m0 x3 h6 y1c7 ff1 fs2 fc0 sc0 ls0 ws0">由定义可<span class="_ _1e"></span>知，<span class="ff3">A<span class="_ _e"></span>UC<span class="_ _a"> </span><span class="ff1">可通过对<span class="_ _a"> </span></span>ROC<span class="_ _9"> </span><span class="ff1">曲线下各<span class="_ _1e"></span>部分的面<span class="_ _1e"></span>积求和而<span class="_ _1e"></span>得。假定<span class="_ _a"> </span></span>ROC<span class="_ _9"> </span><span class="ff1">曲线是由<span class="_ _1e"></span>坐标为</span></span></div><div class="t m0 x3 h4 y1e fff fs2 fc0 sc0 ls0 ws0">{<span class="ffb">(<span class="ffa">x</span></span></div><div class="t m0 x5 ha y9d ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xce hc y1e ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x34 ha y9d ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x80 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">)<span class="ffa">,<span class="_ _2c"> </span></span>(<span class="ffa">x</span></div><div class="t m0 xcf ha y9d ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xd0 hc y1e ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 xd1 ha y9d ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xd2 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">)<span class="ffa">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span></span>(<span class="ffa">x</span></div><div class="t m0 x6b hb y9d ffd fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 xc hc y1e ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 xcc hb y9d ffd fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 xd3 h6 y1e ffb fs2 fc0 sc0 ls0 ws0">)<span class="fff">}<span class="_ _25"> </span><span class="ff1">的点按序连接而形成<span class="_ _25"> </span></span></span>(<span class="ffa">x</span></div><div class="t m0 x5f ha y9d ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x60 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>0<span class="ffa">,<span class="_ _2c"> </span>x</span></div><div class="t m0 xd4 hb y9d ffd fs7 fc0 sc0 ls0 ws0">m</div><div class="t m0 xd5 h6 y1e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>1)<span class="ff1">，<span class="_ _20"></span>参见图<span class="ff3">2.2(b)</span>，<span class="_ _20"></span>则<span class="_ _9"> </span><span class="ff3">A<span class="_ _e"></span>UC</span></span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">14</div><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",458.19,207.43,null]'><div class="d m1" style="border-style:none;position:absolute;left:122.662500px;bottom:1041.888000px;width:13.942000px;height:15.459000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",458.19,207.43,null]'><div class="d m1" style="border-style:none;position:absolute;left:509.788500px;bottom:1021.564500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",458.19,207.43,null]'><div class="d m1" style="border-style:none;position:absolute;left:139.026000px;bottom:1001.241000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf12" data-dest-detail='[18,"XYZ",458.19,207.43,null]'><div class="d m1" style="border-style:none;position:absolute;left:672.174000px;bottom:59.034000px;width:13.941000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf14" class="pf w0 h0" data-page-no="14"><div class="pc pc14 w0 h0"><img class="bi x3 y1fa w2 h1c" alt="" src="bg14.png"/><div class="t m0 x9e h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">2.2<span class="_ _d"> </span><span class="ff8">分类</span></div><div class="t m0 x3 h6 y1fb ff1 fs2 fc0 sc0 ls0 ws0">可估算为：</div><div class="t m0 xa4 h4 y1fc ff3 fs2 fc0 sc0 ls0 ws0">AUC <span class="ffb">=</span></div><div class="t m0 x48 h4 y1fd ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x48 h4 y1fe ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x9 ha y1ff ffd fs7 fc0 sc0 ls0 ws0">m<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x3d he y200 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xaa ha y201 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x4 h4 y1fc ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span></div><div class="t m0 xa5 ha y202 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">+1</span></div><div class="t m0 x99 h4 y1fc fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">x</span></div><div class="t m0 xb1 hb y202 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd6 h4 y1fc ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">·<span class="_ _30"> </span></span>(<span class="ffa">y</span></div><div class="t m0 x60 hb y202 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd7 h4 y1fc ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 xd8 ha y202 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">+1</span></div><div class="t m0 xd9 h4 y1fc ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _45"> </span><span class="ff3">(2.14)</span></div><div class="t m0 x1e h6 y203 ff1 fs2 fc0 sc0 ls0 ws0">这是梯形面积的计算公式，因为当存在正例和反例的打分相等时，则会出现梯形；<span class="_ _e"></span>若不存</div><div class="t m0 x1e h6 y204 ff1 fs2 fc0 sc0 ls0 ws0">在这种情况，则只会出现长方形，而长方形的面积亦可使用梯形面积公式计算。</div><div class="t m0 x3 h6 y205 ff1 fs2 fc0 sc0 ls0 ws0">形式化地看，<span class="_ _2d"></span><span class="ff3">AUC<span class="_ _25"> </span><span class="ff1">考虑的是样本预测的排序质量，<span class="_ _e"></span>因此它与排序误差有紧密联系，<span class="_ _2d"></span>给定<span class="_ _9"> </span><span class="ffa">m</span></span></span></div><div class="t m0 x33 ha y206 ffc fs7 fc0 sc0 ls0 ws0">+</div><div class="t m0 xb5 h6 y205 ff1 fs2 fc0 sc0 ls0 ws0">个</div><div class="t m0 x3 h6 y207 ff1 fs2 fc0 sc0 ls0 ws0">正例和<span class="_ _9"> </span><span class="ffa">m</span></div><div class="t m0 xda ha y208 ff12 fs7 fc0 sc0 ls0 ws0">−</div><div class="t m0 xdb h6 y207 ff1 fs2 fc0 sc0 ls0 ws0">个反例，另<span class="_ _9"> </span><span class="ffa">D</span></div><div class="t m0 x19 ha y208 ffc fs7 fc0 sc0 ls0 ws0">+</div><div class="t m0 x82 h6 y207 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _9"> </span><span class="ffa">D</span></div><div class="t m0 x1d ha y208 ff12 fs7 fc0 sc0 ls0 ws0">−</div><div class="t m0 xcb h6 y207 ff1 fs2 fc0 sc0 ls0 ws0">分别表示正、反例集合，则排序“损失”<span class="ff3">(loss)<span class="_ _9"> </span></span>定义为</div><div class="t m0 x78 hc y209 ffa fs2 fc0 sc0 ls0 ws0">ℓ</div><div class="t m0 x35 h1d y20a ff16 fs7 fc0 sc0 ls0 ws0">rank</div><div class="t m0 xdc h4 y209 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xdd h4 y20b ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x6a hc y20c ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x38 ha y20d ffc fs7 fc0 sc0 ls0 ws0">+</div><div class="t m0 xb6 hc y20c ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 xc2 ha y20d ff12 fs7 fc0 sc0 ls0 ws0">−</div><div class="t m0 xb7 he y20e ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xc5 h1e y20f ff11 fs7 fc0 sc0 ls0 ws0">x</div><div class="t m0 xde h18 y210 ff14 fs9 fc0 sc0 ls0 ws0">+</div><div class="t m0 xdf ha y20f ff12 fs7 fc0 sc0 ls0 ws0">∈<span class="ffd">D</span></div><div class="t m0 xe0 h18 y210 ff14 fs9 fc0 sc0 ls0 ws0">+</div><div class="t m0 xa4 h1e y20f ff11 fs7 fc0 sc0 ls0 ws0">x</div><div class="t m0 x97 h1b y210 ff15 fs9 fc0 sc0 ls0 ws0">−</div><div class="t m0 x3a h1e y20f ff11 fs7 fc0 sc0 ls0 ws0">p</div><div class="t m0 x45 h1b y210 ff15 fs9 fc0 sc0 ls0 ws0">−</div><div class="t m0 x3c he y211 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x1f h1f y209 ff13 fs2 fc0 sc0 ls0 ws0">I</div><div class="t m0 xe1 he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 hc y209 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 xe2 he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x21 h20 y209 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x4a ha y213 ffc fs7 fc0 sc0 ls0 ws0">+</div><div class="t m0 x8e he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5b hc y209 ffa fs2 fc0 sc0 ls0 ws0">&lt;<span class="_ _2f"> </span>f</div><div class="t m0 x91 he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4c h20 y209 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb1 ha y213 ff12 fs7 fc0 sc0 ls0 ws0">−</div><div class="t m0 xcd he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe3 h4 y209 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xd7 h4 y20b ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd7 h4 y20c ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x94 h1f y209 ff13 fs2 fc0 sc0 ls0 ws0">I</div><div class="t m0 x9d he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x6c hc y209 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 xe4 he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xd9 h20 y209 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x89 ha y213 ffc fs7 fc0 sc0 ls0 ws0">+</div><div class="t m0 xe5 he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x54 h4 y209 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 xe6 he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x7c h20 y209 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xe7 ha y213 ff12 fs7 fc0 sc0 ls0 ws0">−</div><div class="t m0 xe8 he y212 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe9 he y211 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xba h4 y209 ff3 fs2 fc0 sc0 ls0 ws0">(2.15)</div><div class="t m0 x3 h6 y214 ff1 fs2 fc0 sc0 ls0 ws0">即考虑每一对正、<span class="_ _2d"></span>反例，<span class="_ _31"></span>若正例的预测值小于反例，<span class="_ _2d"></span>则记一个罚分，<span class="_ _2d"></span>若相等，<span class="_ _2d"></span>记<span class="_ _25"> </span><span class="ff3">0.5<span class="_ _9"> </span></span>个罚分。<span class="_ _2d"></span>容</div><div class="t m0 x3 h6 y215 ff1 fs2 fc0 sc0 ls0 ws0">易看出，<span class="_ _21"></span><span class="ffa">ℓ</span></div><div class="t m0 xda h1d y216 ff16 fs7 fc0 sc0 ls0 ws0">rank</div><div class="t m0 xea h6 y215 ff1 fs2 fc0 sc0 ls0 ws0">对应的是<span class="_ _25"> </span><span class="ff3">R<span class="_ _e"></span>OC<span class="_ _25"> </span><span class="ff1">曲线之上的面积：<span class="_ _21"></span>若一个正例在<span class="_ _2f"> </span><span class="ff3">ROC </span>曲线上对应标记点的坐标为</span></span></div><div class="t m0 x3 h6 y217 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x,<span class="_ _29"> </span>y<span class="_ _26"></span></span>)<span class="ff1">，则<span class="_ _9"> </span><span class="ffa">x<span class="_ _9"> </span></span>恰是排序在其之前的反例所占的比例，即假正率。因此有</span></div><div class="t m0 x3d h4 y218 ff3 fs2 fc0 sc0 ls0 ws0">AUC <span class="ffb">=<span class="_ _f"> </span>1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">ℓ</span></span></span></div><div class="t m0 xb1 h1d y219 ff16 fs7 fc0 sc0 ls0 ws0">rank</div><div class="t m0 xba h4 y218 ff3 fs2 fc0 sc0 ls0 ws0">(2.16)</div><div class="t m0 x3 h12 y21a ff5 fs8 fc0 sc0 ls0 ws0">2.2.6<span class="_ _34"> </span><span class="ff9">代价敏感错误率</span></div><div class="t m0 x3 h6 y21b ff1 fs2 fc0 sc0 ls0 ws0">有时候，<span class="_ _21"></span>不同类型的错误所造成的后果不同。<span class="_ _20"></span>为权衡不同类型错误所造成的不同损失，<span class="_ _20"></span>可为错误</div><div class="t m0 x3 h6 y21c ff1 fs2 fc0 sc0 ls0 ws0">赋予“非均等代价”<span class="ff3">(unequa1<span class="_ _9"> </span>cost)</span>。</div><div class="t m0 x3 h6 y21d ff1 fs2 fc0 sc0 ls0 ws0">以二分类任务为例，<span class="_ _2d"></span>我们可以根据任务的领域知识设定一个<span class="_ _2d"></span>“代价矩阵”<span class="ff3">(cost<span class="_ _25"> </span>matrix)</span>，<span class="_ _2d"></span>如下表</div><div class="t m0 x3 h6 y21e ff1 fs2 fc0 sc0 ls0 ws0">所示。其中，<span class="ffa">cost</span></div><div class="t m0 x14 hb y21f ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xeb h6 y21e ff1 fs2 fc0 sc0 ls0 ws0">表示将第<span class="_ _9"> </span><span class="ffa">i<span class="_ _9"> </span></span>类样本预测为第<span class="_ _9"> </span><span class="ffa">j<span class="_ _12"> </span></span>类样本的代价。一般来说，<span class="ffa">cost</span></div><div class="t m0 x84 hb y21f ffd fs7 fc0 sc0 ls0 ws0">ii</div><div class="t m0 xec h6 y21e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>0<span class="ff1">。</span></div><div class="t m0 xed h6 y220 ff1 fs2 fc0 sc0 ls0 ws0">真实情况</div><div class="t m0 x99 h6 y221 ff1 fs2 fc0 sc0 ls0 ws0">预测结果</div><div class="t m0 xbe h6 y222 ff1 fs2 fc0 sc0 ls0 ws0">第<span class="_ _9"> </span><span class="ff3">0<span class="_ _9"> </span></span>类<span class="_ _40"> </span>第<span class="_ _9"> </span><span class="ff3">1<span class="_ _9"> </span></span>类</div><div class="t m0 xee h6 y223 ff1 fs2 fc0 sc0 ls0 ws0">第<span class="_ _9"> </span><span class="ff3">0<span class="_ _9"> </span></span>类<span class="_ _46"> </span><span class="ff3">0<span class="_ _47"> </span><span class="ffa">cost</span></span></div><div class="t m0 xef ha y224 ffc fs7 fc0 sc0 ls0 ws0">01</div><div class="t m0 xee h6 y225 ff1 fs2 fc0 sc0 ls0 ws0">第<span class="_ _9"> </span><span class="ff3">1<span class="_ _9"> </span></span>类<span class="_ _48"> </span><span class="ffa">cost</span></div><div class="t m0 x5e ha y226 ffc fs7 fc0 sc0 ls0 ws0">10</div><div class="t m0 x60 h4 y225 ff3 fs2 fc0 sc0 ls0 ws0">0</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">15</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf15" class="pf w0 h0" data-page-no="15"><div class="pc pc15 w0 h0"><img class="bi x3 y227 w2 h21" alt="" src="bg15.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">2.2<span class="_ _d"> </span><span class="ff8">分类</span></div><div class="t m0 x1e h6 y228 ff1 fs2 fc0 sc0 ls0 ws0">重要的是代价比值而非绝对值，例如<span class="_ _9"> </span><span class="ffa">cost</span></div><div class="t m0 xa0 ha y229 ffc fs7 fc0 sc0 ls0 ws0">01</div><div class="t m0 x8 h4 y228 ffb fs2 fc0 sc0 ls0 ws0">:<span class="_ _2f"> </span><span class="ffa">cost</span></div><div class="t m0 xbf ha y229 ffc fs7 fc0 sc0 ls0 ws0">01</div><div class="t m0 xad h6 y228 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>5<span class="_ _2f"> </span>:<span class="_ _2f"> </span>1<span class="_ _9"> </span><span class="ff1">与<span class="_ _9"> </span></span>50<span class="_ _2f"> </span>:<span class="_ _2f"> </span>10<span class="_ _9"> </span><span class="ff1">的效果是一样的。</span></div><div class="t m0 x3 h6 y22a ff1 fs2 fc0 sc0 ls0 ws0">前面介绍的性能度量都是假设均等代价，<span class="_ _21"></span>也就是犯错误次数越少越好。<span class="_ _20"></span>在非均等错误代价下，<span class="_ _20"></span>我</div><div class="t m0 x3 h6 y22b ff1 fs2 fc0 sc0 ls0 ws0">们希望的是最小化“总体代价”<span class="_ _23"></span>，则“代价敏感”错误率为：</div><div class="t m0 xc5 h4 y22c ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _26"></span><span class="ffb">(</span>f<span class="_ _2b"></span><span class="ffb">;<span class="_ _2c"> </span></span>D<span class="_ _1e"></span><span class="ffb">;<span class="_ _2c"> </span><span class="ff3">cos<span class="_ _29"> </span></span></span>t<span class="ffb">)<span class="_ _2f"> </span>=</span></div><div class="t m0 x3d h4 y22d ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3e hc y22e ffa fs2 fc0 sc0 ls0 ws0">m</div><div class="t m0 x49 he y22f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x49 he y230 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x40 he y231 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x4 h1e y232 ff11 fs7 fc0 sc0 ls0 ws0">x</div><div class="t m0 x40 h22 y233 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 xf0 ha y232 ff12 fs7 fc0 sc0 ls0 ws0">∈<span class="ffd">D</span></div><div class="t m0 x25 h18 y234 ff14 fs9 fc0 sc0 ls0 ws0">+</div><div class="t m0 x5e h4 y22c ff13 fs2 fc0 sc0 ls0 ws0">I<span class="_ _2c"> </span><span class="ffb">(<span class="ffa">f<span class="_ _f"> </span></span>(<span class="ff11">x</span></span></div><div class="t m0 x5f hb y235 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xe3 h4 y22c ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="fff"≯</span>=<span class="_ _2f"> </span><span class="ffa">y</span></div><div class="t m0 x9d hb y235 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x29 h4 y22c ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">×<span class="_ _30"> </span><span class="ff3">cos<span class="_ _2c"> </span><span class="ffa">t</span></span></span></div><div class="t m0 x54 ha y235 ffc fs7 fc0 sc0 ls0 ws0">01</div><div class="t m0 x3d h4 y236 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xf1 he y237 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x49 h1e y238 ff11 fs7 fc0 sc0 ls0 ws0">x</div><div class="t m0 x4a h22 y239 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 xbd ha y238 ff12 fs7 fc0 sc0 ls0 ws0">∈<span class="ffd">D</span></div><div class="t m0 x5b h1b y23a ff15 fs9 fc0 sc0 ls0 ws0">−</div><div class="t m0 x41 h4 y236 ff13 fs2 fc0 sc0 ls0 ws0">I<span class="_ _2c"> </span><span class="ffb">(<span class="ffa">f<span class="_ _f"> </span></span>(<span class="ff11">x</span></span></div><div class="t m0 xcd hb y23b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x42 h4 y236 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="fff"≯</span>=<span class="_ _2f"> </span><span class="ffa">y</span></div><div class="t m0 xef hb y23b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4f h4 y236 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">×<span class="_ _30"> </span><span class="ff3">cos<span class="_ _2c"> </span><span class="ffa">t</span></span></span></div><div class="t m0 xf2 ha y23b ffc fs7 fc0 sc0 ls0 ws0">10</div><div class="t m0 x54 he y23c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x54 he y23d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xba h4 y23e ff3 fs2 fc0 sc0 ls0 ws0">(2.17)</div><div class="t m0 x3 h6 y23f ff1 fs2 fc0 sc0 ls0 ws0">其中，第<span class="_ _9"> </span><span class="ff3">0<span class="_ _9"> </span></span>类作为正类、第<span class="_ _9"> </span><span class="ff3">1<span class="_ _9"> </span></span>类作为反类，<span class="ffa">D</span></div><div class="t m0 x8f ha y240 ffc fs7 fc0 sc0 ls0 ws0">+</div><div class="t m0 xf3 h6 y23f ff1 fs2 fc0 sc0 ls0 ws0">与<span class="_ _9"> </span><span class="ffa">D</span></div><div class="t m0 xc0 ha y240 ff12 fs7 fc0 sc0 ls0 ws0">−</div><div class="t m0 xf4 h6 y23f ff1 fs2 fc0 sc0 ls0 ws0">分别代表样本集<span class="_ _9"> </span><span class="ffa">D<span class="_ _a"> </span></span>的正例集和反例集。</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">16</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf16" class="pf w0 h0" data-page-no="16"><div class="pc pc16 w0 h0"><div class="t m0 x9 h5 y241 ff4 fs3 fc0 sc0 ls0 ws0">第二部分</div><div class="t m0 xa h5 y242 ff4 fs3 fc0 sc0 ls0 ws0">机器学习中阶</div><div class="t m0 x59 h3 y243 ff7 fs1 fc0 sc0 ls0 ws0">传统模型</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">17</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf17" class="pf w0 h0" data-page-no="17"><div class="pc pc17 w0 h0"></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf18" class="pf w0 h0" data-page-no="18"><div class="pc pc18 w0 h0"><img class="bi x3 y17a w2 h23" alt="" src="bg18.png"/><div class="t m0 xc h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第三章 贝叶斯分类器</div><div class="t m0 x1c h9 y4e ff5 fs6 fc0 sc0 ls0 ws0">3.1<span class="_ _1f"> </span><span class="ff9">判别规则</span></div><div class="t m0 x3 h6 y244 ff4 fs2 fc0 sc0 ls0 ws0">定义<span class="ff6">3.1<span class="_ _4"> </span><span class="fc1">Ba<span class="_ _2d"></span>y<span class="_ _2d"></span>esian<span class="_ _12"> </span>decision<span class="_ _a"> </span>theory(<span class="ff4">叶斯决策论</span>)<span class="ff4">：<span class="_ _9"> </span><span class="ff1 fc0">基于概率实施决策的方法。<span class="_ _e"></span>对分类任务来</span></span></span></span></div><div class="t m0 x3 h6 y245 ff1 fs2 fc0 sc0 ls0 ws0">说，<span class="_ _28"></span><span class="ff4">在所有相关概率都己知的理想情形下<span class="ff1">，<span class="_ _27"></span>贝叶斯决策论根据误判代价最小的原则来选择最优的</span></span></div><div class="t m0 x3 h6 y246 ff1 fs2 fc0 sc0 ls0 ws0">分类标记。</div><div class="t m0 x3 h6 y247 ff1 fs2 fc0 sc0 ls0 ws0">以多分类任<span class="_ _1e"></span>务为例来解释<span class="_ _1e"></span>其基本原理：假<span class="_ _1e"></span>设有<span class="_ _a"> </span><span class="ff3">N<span class="_ _9"> </span></span>种可能<span class="_ _1e"></span>的类别<span class="_ _12"> </span><span class="ff6">lab<span class="_ _26"></span>el</span>，即<span class="_ _9"> </span><span class="ffa">y<span class="_ _a"> </span><span class="ffb">=<span class="_ _25"> </span><span class="fff">{</span></span>c</span></div><div class="t m0 x84 ha y248 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xf5 hc y247 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>c</div><div class="t m0 xf6 ha y248 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xf h4 y247 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>c</div><div class="t m0 xf7 hb y249 ffd fs7 fc0 sc0 ls0 ws0">N</div><div class="t m0 xf8 h6 y247 fff fs2 fc0 sc0 ls0 ws0">}<span class="ff1">，</span></div><div class="t m0 x3 hc y24a ffa fs2 fc0 sc0 ls0 ws0">λ</div><div class="t m0 xf9 hb y24b ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xfa h6 y24a ff1 fs2 fc0 sc0 ls0 ws0">是将一个<span class="_ _1e"></span>真实标记<span class="_ _1e"></span>为<span class="_ _a"> </span><span class="ffa">c</span></div><div class="t m0 x70 hb y24b ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xcc h6 y24a ff1 fs2 fc0 sc0 ls0 ws0">的样本误<span class="_ _1e"></span>分类为<span class="_ _a"> </span><span class="ffa">c</span></div><div class="t m0 x24 hb y24b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xfb h6 y24a ff1 fs2 fc0 sc0 ls0 ws0">所产生的<span class="_ _1e"></span>损失。则当<span class="_ _1e"></span>样本为<span class="_ _a"> </span><span class="ffa">x<span class="_ _a"> </span></span>时，分类<span class="_ _1e"></span>为<span class="_ _a"> </span><span class="ffa">c</span></div><div class="t m0 xfc hb y24b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb5 h6 y24a ff1 fs2 fc0 sc0 ls0 ws0">所</div><div class="t m0 x3 h6 y24c ff1 fs2 fc0 sc0 ls0 ws0">产生的期望损失<span class="_ _9"> </span><span class="ff3">(exp<span class="_ _1e"></span>ected<span class="_ _9"> </span>loss)<span class="_ _9"> </span></span>为：</div><div class="t m0 xcb h4 y24d ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>c</div><div class="t m0 x3d hb y24e ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xe2 h4 y24d fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _2f"> </span>=</span></span></div><div class="t m0 xa1 hb y24f ffd fs7 fc0 sc0 ls0 ws0">N</div><div class="t m0 x5b he y250 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x5b ha y251 ffd fs7 fc0 sc0 ls0 ws0">j<span class="_ _1e"></span><span class="ffc">=1</span></div><div class="t m0 x5e hc y24d ffa fs2 fc0 sc0 ls0 ws0">λ</div><div class="t m0 xb4 hb y24e ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xbf h4 y24d ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c</div><div class="t m0 x5f hb y24e ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x66 h4 y24d fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)</span></span></div><div class="t m0 x1e h6 y252 ff1 fs2 fc0 sc0 ls0 ws0">这又称为<span class="ff4">在样本<span class="_ _a"> </span><span class="ffa">x<span class="_ _12"> </span></span>上的条件风险</span>（<span class="ff3">conditional<span class="_ _9"> </span>risk</span>）</div><div class="t m0 x1e h6 y253 ff1 fs2 fc0 sc0 ls0 ws0">注意：<span class="_ _28"></span>这里求的是期望损失，<span class="_ _28"></span>所谓期望，<span class="_ _28"></span>就是所有分类情况的平均<span class="_ _21"></span>（但真实情况只有一个）<span class="_ _32"></span>。</div><div class="t m0 x3 h6 y254 ff1 fs2 fc0 sc0 ls0 ws0">那么，现在要找到一个判定准则：<span class="ffa">x<span class="_ _2f"> </span><span class="fff">→<span class="_ _2f"> </span></span>y<span class="_ _1e"></span></span>，它可以使得总体风险最小：</div><div class="t m0 xfd h4 y255 ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span></span>E</div><div class="t m0 x90 hb y256 ffd fs7 fc0 sc0 ls0 ws0">x</div><div class="t m0 x41 h4 y255 ffb fs2 fc0 sc0 ls0 ws0">[<span class="ffa">R</span>(<span class="ffa">h</span>(<span class="ffa">x</span>)<span class="fff">|<span class="ffa">x</span></span>)]</div><div class="t m0 x1e h6 y257 ff1 fs2 fc0 sc0 ls0 ws0">注意：<span class="_ _21"></span><span class="ffa">R<span class="ffb">(</span>c</span></div><div class="t m0 xfe hb y258 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc3 h6 y257 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _25"> </span><span class="ff1">是一个期望，<span class="_ _21"></span>针对所有<span class="_ _25"> </span><span class="ffa">x<span class="_ _9"> </span></span>的所有分类情况<span class="_ _20"></span>（包括正确的分类情况）<span class="_ _23"></span>；<span class="_ _21"></span><span class="ffa">R<span class="_ _1e"></span><span class="ffb">(</span>h<span class="ffb">)<span class="_ _25"> </span><span class="ff1">是</span></span></span></span></span></span></div><div class="t m0 x1e h4 y259 ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>c</div><div class="t m0 x7a hb y25a ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xff h6 y259 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _9"> </span><span class="ff1">的期望，针对所有<span class="_ _9"> </span></span></span>x<span class="_ _9"> </span><span class="ff1">的期望损失。</span></span></div><div class="t m0 x3 h6 y25b ff1 fs2 fc0 sc0 ls0 ws0">那<span class="_ _1e"></span>么，<span class="_ _1e"></span>如<span class="_ _26"></span>何<span class="_ _1e"></span>使<span class="_ _26"></span>得<span class="_ _0"> </span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _4"> </span></span></span>最小<span class="_ _26"></span>呢？<span class="_ _1e"></span>最<span class="_ _1e"></span>直<span class="_ _26"></span>接<span class="_ _1e"></span>的<span class="_ _1e"></span>想<span class="_ _26"></span>法<span class="_ _1e"></span>时，<span class="_ _26"></span>如<span class="_ _1e"></span>果<span class="_ _1e"></span>对<span class="_ _26"></span>于<span class="_ _1e"></span>每<span class="_ _26"></span>个<span class="_ _0"> </span><span class="ffa">x</span></div><div class="t m0 x8a hb y25c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc8 h6 y25b ff1 fs2 fc0 sc0 ls0 ws0">，<span class="ffa">h<span class="_ _0"> </span></span>都<span class="_ _1e"></span>能<span class="_ _26"></span>最<span class="_ _1e"></span>小<span class="_ _26"></span>化<span class="_ _1e"></span>条<span class="_ _1e"></span>件<span class="_ _26"></span>风<span class="_ _1e"></span>险</div><div class="t m0 x3 h6 y25d ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>h<span class="ffb">(</span>x<span class="ffb">)<span class="fff">|</span></span>x<span class="ffb">)<span class="ff1">，<span class="_ _20"></span>那么总体风险<span class="_ _9"> </span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _25"> </span></span></span>必定也是最小的，<span class="_ _20"></span>这就是<span class="ff4">贝叶斯判别准则</span>。<span class="_ _22"></span>因此，<span class="_ _20"></span>在贝叶斯判定</span></span></div><div class="t m0 x3 h6 y25e ff1 fs2 fc0 sc0 ls0 ws0">准则下，对每个样本都选择能使条件风险<span class="_ _9"> </span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">(</span>x<span class="ffb">)<span class="fff">|</span></span>x<span class="ffb">)<span class="_ _9"> </span></span></span>最小的<span class="_ _9"> </span><span class="ff3">lab<span class="_ _1e"></span>el</span>，即：</div><div class="t m0 x87 hc y25f ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xb3 ha y260 ff12 fs7 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x100 h4 y25f ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span>)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff3">arg<span class="_ _2c"> </span>min</span></div><div class="t m0 x99 ha y261 ffd fs7 fc0 sc0 ls0 ws0">c<span class="ff12">∈</span>y</div><div class="t m0 xb1 h4 y25f ffa fs2 fc0 sc0 ls0 ws0">R<span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></div><div class="t m0 x1e h6 y262 ff3 fs2 fc0 sc0 ls0 ws0">arg<span class="_ _29"> </span>min<span class="_ _2c"> </span><span class="ffa">f<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _25"> </span><span class="ff1">的含义时，当<span class="_ _9"> </span></span></span>f<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _25"> </span><span class="ff1">取最小值时，</span></span>x<span class="_ _9"> </span><span class="ff1">的取值。<span class="_ _1e"></span>上述公式的意义就是：当<span class="_ _9"> </span></span>R<span class="ffb">(</span>c<span class="fff">|</span>x</span></div><div class="t m0 x1e h6 y263 ff1 fs2 fc0 sc0 ls0 ws0">取最小值时，<span class="ffa">c<span class="_ _9"> </span></span>的取值。</div><div class="t m0 x3 h6 y264 ff1 fs2 fc0 sc0 ls0 ws0">此时，<span class="_ _20"></span><span class="ffa">h</span></div><div class="t m0 x101 ha y265 ff12 fs7 fc0 sc0 ls0 ws0">∗</div><div class="t m0 xb h6 y264 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span>)<span class="_ _25"> </span><span class="ff1">称为<span class="ff4">贝叶斯最优分类器<span class="_ _a"> </span><span class="ff6">(Ba<span class="_ _e"></span>y<span class="_ _e"></span>es<span class="_ _a"> </span>optimal<span class="_ _9"> </span>classier)<span class="_ _9"> </span><span class="ff1">，<span class="_ _20"></span>与之对应的总体风险<span class="_ _9"> </span><span class="ffa">R<span class="ffb">(</span>h</span></span></span></span></span></div><div class="t m0 x74 ha y265 ff12 fs7 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x75 h4 y264 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y266 ff1 fs2 fc0 sc0 ls0 ws0">称为贝<span class="_ _1e"></span>叶斯风<span class="_ _1e"></span>险<span class="_ _a"> </span><span class="ff3">(Bay<span class="_ _2d"></span>es<span class="_ _a"> </span>risk)<span class="ff1">。<span class="ffb">1<span class="_ _f"> </span><span class="fff">−<span class="_ _f"> </span><span class="ffa">R</span></span>(<span class="ffa">h</span></span></span></span></div><div class="t m0 x102 ha y267 ff12 fs7 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x59 h6 y266 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _a"> </span><span class="ff1">反映<span class="_ _1e"></span>了分类<span class="_ _1e"></span>器所能<span class="_ _1e"></span>达到的<span class="_ _1e"></span>最好性<span class="_ _1e"></span>能，即通<span class="_ _1e"></span>过机器<span class="_ _1e"></span>学习</span></div><div class="t m0 x3 h6 y268 ff1 fs2 fc0 sc0 ls0 ws0">所能产生的模型精度的理论上限。</div><div class="t m0 x1e h6 y269 ff1 fs2 fc0 sc0 ls0 ws0">换而言之，使得<span class="_ _9"> </span><span class="ffa">R<span class="ffb">(</span>h<span class="ffb">)<span class="_ _9"> </span></span></span>达到理论最小值的贝叶斯分类器才是贝叶斯最优分类器。</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">19</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf19" class="pf w0 h0" data-page-no="19"><div class="pc pc19 w0 h0"><img class="bi x5c y26a wa h24" alt="" src="bg19.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.2<span class="_ _d"> </span><span class="ff8">参数估计</span></div><div class="t m0 x3 h12 yd4 ff5 fs8 fc0 sc0 ls0 ws0">3.1.1<span class="_ _34"> </span><span class="ff9">特殊情形</span></div><div class="t m0 x3 h6 y26b ff1 fs2 fc0 sc0 ls0 ws0">如果在各类上犯错的损失（风险权重）是一样的，同时不犯错就不会有损失，那么：</div><div class="t m0 xc4 hc y26c ffa fs2 fc0 sc0 ls0 ws0">λ</div><div class="t m0 x48 hb y26d ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x102 h4 y26c ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x5a he y26e ffe fs2 fc0 sc0 ls0 ws0">(</div><div class="t m0 x22 h4 y26f ffb fs2 fc0 sc0 ls0 ws0">0<span class="ffa">,<span class="_ _0"> </span>if<span class="_ _0"> </span>i<span class="_ _f"> </span></span>=<span class="_ _2f"> </span><span class="ffa">j</span></div><div class="t m0 x22 h4 y270 ffb fs2 fc0 sc0 ls0 ws0">1<span class="ffa">,<span class="_ _0"> </span>other<span class="_ _26"></span>wise</span></div><div class="t m0 x33 h4 y26c ff3 fs2 fc0 sc0 ls0 ws0">(3.1)</div><div class="t m0 x3 h6 y271 ff1 fs2 fc0 sc0 ls0 ws0">此时，<span class="_ _2d"></span>条件风险为<span class="_ _9"> </span><span class="ffa">R<span class="ffb">(</span>c</span></div><div class="t m0 xc5 hb y272 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x17 h4 y271 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _2f"> </span>=</span></span></div><div class="t m0 xa6 he y273 ffe fs2 fc0 sc0 ls0 ws0">P</div><div class="t m0 x3a hb y274 ffd fs7 fc0 sc0 ls0 ws0">N</div><div class="t m0 x3a ha y275 ffd fs7 fc0 sc0 ls0 ws0">j<span class="_ _1e"></span><span class="ff12"≯<span class="ffc">=</span></span>i</div><div class="t m0 xb8 h4 y271 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c</div><div class="t m0 x100 hb y272 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x102 h4 y271 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span>1<span class="_ _3e"> </span></span></span>−<span class="_ _30"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c</span></div><div class="t m0 x4d hb y272 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc0 h6 y271 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x<span class="ffb">)<span class="ff1">。<span class="_ _2d"></span>于是，<span class="_ _e"></span>最优的贝叶斯分类器就是使得</span></span></span></div><div class="t m0 x3 hc y276 ffa fs2 fc0 sc0 ls0 ws0">c</div><div class="t m0 x103 hb y277 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x104 h6 y276 ff1 fs2 fc0 sc0 ls0 ws0">的后验概率最大的分类器：</div><div class="t m0 xc4 hc y278 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x48 ha y279 ff12 fs7 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x105 h4 y278 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span>)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff3">arg<span class="_ _2c"> </span>max</span></div><div class="t m0 x99 ha y27a ffd fs7 fc0 sc0 ls0 ws0">c<span class="ff12">∈</span>y</div><div class="t m0 x27 h4 y278 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _49"> </span><span class="ff3">(3.2)</span></span></div><div class="t m0 xfd h9 y27b ff5 fs6 fc0 sc0 ls0 ws0">3.2<span class="_ _1f"> </span><span class="ff9">参数估计</span></div><div class="t m0 x3 h6 y27c ff1 fs2 fc0 sc0 ls0 ws0">很显然，在<span class="_ _1e"></span>判定准则中<span class="_ _1e"></span>只有两个<span class="_ _1e"></span>未知量：<span class="ffa">λ</span></div><div class="t m0 x3f hb y27d ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x23 h6 y27c ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _a"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>，<span class="ffa">λ</span></div><div class="t m0 x106 hb y27d ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x28 h6 y27c ff1 fs2 fc0 sc0 ls0 ws0">相对来说<span class="_ _1e"></span>很容易得出。<span class="_ _1e"></span>因此，使用</div><div class="t m0 x3 h6 y27e ff1 fs2 fc0 sc0 ls0 ws0">贝叶斯<span class="_ _1e"></span>分类<span class="_ _1e"></span>最关键<span class="_ _1e"></span>的就<span class="_ _1e"></span>是获得<span class="_ _1e"></span>后验概<span class="_ _1e"></span>率<span class="_ _a"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>。<span class="_ _1e"></span>然而，在<span class="_ _1e"></span>现实任<span class="_ _1e"></span>务中<span class="_ _1e"></span>这通常<span class="_ _1e"></span>难以<span class="_ _1e"></span>直接获<span class="_ _1e"></span>得。我</div><div class="t m0 x3 h6 y27f ff1 fs2 fc0 sc0 ls0 ws0">们要解决的问题是基于有限的训练样本集尽可能准确地估计出后验概率<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>。</div><div class="t m0 x3 h6 y280 ff4 fs2 fc0 sc0 ls0 ws0">主要有两种策略：</div><div class="t m0 x9a h6 y281 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff1">给定<span class="_ _12"> </span><span class="ffa">x</span>，可<span class="_ _1e"></span>通<span class="_ _1e"></span>过直<span class="_ _1e"></span>接<span class="_ _1e"></span>建模<span class="_ _12"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _1c"> </span></span></span>来预<span class="_ _1e"></span>测<span class="_ _12"> </span></span>c<span class="ff1">，<span class="_ _1e"></span>这样<span class="_ _1e"></span>得到<span class="_ _1e"></span>的<span class="_ _1e"></span>是</span>”<span class="_ _12"> </span><span class="ff1">判<span class="_ _1e"></span>别式<span class="_ _1e"></span>模<span class="_ _1e"></span>型</span>”<span class="_ _12"> </span>(discriminativ<span class="_ _e"></span>e</div><div class="t m0 x9b h4 y282 ff3 fs2 fc0 sc0 ls0 ws0">mo<span class="_ _1e"></span>dels)</div><div class="t m0 x9a h6 y283 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff1">也可先对联<span class="_ _1e"></span>合概率<span class="_ _1e"></span>分布<span class="_ _a"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x,<span class="_ _2c"> </span>c<span class="ffb">)<span class="_ _a"> </span></span></span>建<span class="_ _1e"></span>模，然<span class="_ _1e"></span>后再由<span class="_ _1e"></span>此获得<span class="_ _12"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>，这样<span class="_ _1e"></span>得到的<span class="_ _1e"></span>是</span>”<span class="_ _a"> </span><span class="ff1">生成<span class="_ _1e"></span>式模</span></div><div class="t m0 x9b h6 y284 ff1 fs2 fc0 sc0 ls0 ws0">型<span class="ff3">”<span class="_ _9"> </span>(generativ<span class="_ _e"></span>e<span class="_ _9"> </span>mo<span class="_ _1e"></span>dels)</span></div><div class="t m0 x3 h6 y285 ff1 fs2 fc0 sc0 ls0 ws0">对生成式模型来说，必然考虑：</div><div class="t m0 x3d h4 y286 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _f"> </span>=</span></div><div class="t m0 x99 h4 y287 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c,<span class="_ _29"> </span>x<span class="ffb">)</span></div><div class="t m0 x91 h4 y288 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)</span></div><div class="t m0 x3 h6 y289 ff1 fs2 fc0 sc0 ls0 ws0">使用贝叶斯公式，得到：</div><div class="t m0 x1c h4 y28a ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _f"> </span>=</span></div><div class="t m0 x5c h4 y28b ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="ffb">)</span>P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)</span></div><div class="t m0 x91 h4 y28c ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)</span></div><div class="t m0 x3 h6 y28d ff1 fs2 fc0 sc0 ls0 ws0">此时，我们把要估计的<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _9"> </span></span></span>分解为三个概率，也就是要估计以下三个概率：</div><div class="t m0 x3 h6 y28e ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _9"> </span><span class="ff4">类先验概率<span class="_ _12"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="ffb">)</span></span>：<span class="ff1">代表了样本空<span class="_ _1e"></span>间中各类样本所占的比例，根据<span class="_ _1e"></span>大数定律，当训练集包含充</span></span></div><div class="t m0 x3 h6 y1f4 ff1 fs2 fc0 sc0 ls0 ws0">足的独立同分布样本时，<span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="ffb">)<span class="_ _9"> </span></span></span>可通过各类样本出现的频率来进行估计。</div><div class="t m0 x3 h6 y1f5 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _25"> </span><span class="ff4">样本值概率<span class="_ _12"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)</span></span>：<span class="_ _2d"></span><span class="ff1">理论上<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _25"> </span></span></span>也可以通过大数定律，<span class="_ _2d"></span>以频率来估计概率，<span class="_ _2d"></span>但是这很难实现。</span></span></div><div class="t m0 x3 h6 y28f ff1 fs2 fc0 sc0 ls0 ws0">因此，可以尽量避免估计<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _9"> </span></span></span>的值。</div><div class="t m0 x3 h6 y1f7 ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _9"> </span><span class="ff4">类条件概率<span class="_ _a"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)</span></span>：<span class="ff1">由于涉及关于样本<span class="_ _9"> </span><span class="ffa">x<span class="_ _9"> </span></span>所有属性的联合概率，直接根据样本出现的频率来</span></span></div><div class="t m0 x3 h6 y1f8 ff1 fs2 fc0 sc0 ls0 ws0">估计将会遇到严重的困难。估计这个概率是贝叶斯分类方法最重要的任务。</div><div class="t m0 x3 h6 y1f9 ff1 fs2 fc0 sc0 ls0 ws0">例如，<span class="_ _2d"></span>假设样本的<span class="_ _9"> </span><span class="ffa">d<span class="_ _25"> </span></span>个属性都是二值的，<span class="_ _e"></span>则样本空间将有<span class="_ _9"> </span><span class="ffb">2</span></div><div class="t m0 xef hb y290 ffd fs7 fc0 sc0 ls0 ws0">d</div><div class="t m0 x95 h6 y1f9 ff1 fs2 fc0 sc0 ls0 ws0">种可能的取值，<span class="_ _2d"></span>在现实应用中，<span class="_ _2d"></span>这</div><div class="t m0 x3 h6 y110 ff1 fs2 fc0 sc0 ls0 ws0">个值往<span class="_ _1e"></span>往远大<span class="_ _1e"></span>于训练<span class="_ _1e"></span>样本数<span class="_ _12"> </span><span class="ffa">m</span>，也就是<span class="_ _1e"></span>说，很多<span class="_ _1e"></span>样本取<span class="_ _1e"></span>值在训<span class="_ _1e"></span>练集中<span class="_ _1e"></span>根本没<span class="_ _1e"></span>有出现，<span class="_ _1e"></span>直接使<span class="_ _1e"></span>用</div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">频率来估计<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)<span class="_ _9"> </span></span></span>显然不可行，因为<span class="ff3">”<span class="_ _9"> </span></span>未被观测到<span class="ff3">”<span class="_ _9"> </span></span>与<span class="ff3">”<span class="_ _9"> </span></span>出现概率为零<span class="ff3">”<span class="_ _9"> </span></span>通常是不同的。</div><div class="t m0 x3 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">那怎么估计<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _9"> </span></span></span>的值呢？这就需要极大似然估计。</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">20</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1a" class="pf w0 h0" data-page-no="1a"><div class="pc pc1a w0 h0"><img class="bi x3 y291 wb h14" alt="" src="bg1a.png"/><div class="t m0 x72 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.3<span class="_ _d"> </span><span class="ff8">朴素贝叶斯分类器</span></div><div class="t m0 x3 h12 yd4 ff5 fs8 fc0 sc0 ls0 ws0">3.2.1<span class="_ _34"> </span><span class="ff9">极大似然估计</span></div><div class="t m0 x3 h6 y292 ff1 fs2 fc0 sc0 ls0 ws0">估计类条<span class="_ _1e"></span>件概率的一<span class="_ _1e"></span>种常用策略<span class="_ _1e"></span>是先假定<span class="_ _1e"></span>其具有某种<span class="_ _1e"></span>确定的概<span class="_ _1e"></span>率分布形<span class="_ _a"> </span>式（例如：<span class="_ _1e"></span>变量有两个</div><div class="t m0 x3 h6 y293 ff1 fs2 fc0 sc0 ls0 ws0">取值，假定为二项分布；变量有多个取<span class="_ _1e"></span>值，假定为多项分布）<span class="_ _2e"></span>，再使用极大似然估计（或者其它</div><div class="t m0 x3 h6 y294 ff1 fs2 fc0 sc0 ls0 ws0">参数<span class="_ _1e"></span>估计<span class="_ _1e"></span>方法）<span class="_ _1e"></span>估<span class="_ _1e"></span>计出<span class="_ _1e"></span>这种<span class="_ _1e"></span>概率<span class="_ _1e"></span>分布<span class="_ _1e"></span>形<span class="_ _1e"></span>式下<span class="_ _1e"></span>的<span class="ff4">理<span class="_ _1e"></span>论概<span class="_ _1e"></span>率<span class="_ _1e"></span>估计<span class="_ _1e"></span>值</span>（这<span class="_ _1e"></span>个估<span class="_ _1e"></span>计值<span class="_ _1e"></span>就<span class="_ _1e"></span>是分<span class="_ _1e"></span>布参<span class="_ _1e"></span>数的<span class="_ _1e"></span>估</div><div class="t m0 x3 h6 y295 ff1 fs2 fc0 sc0 ls0 ws0">计值）<span class="_ _23"></span>。最后，基于训练样本求出</div><div class="t m0 xed h6 y296 ff4 fs2 fc0 sc0 ls0 ws0">理论概率估计值</div><div class="t m0 xb2 h6 y295 ff1 fs2 fc0 sc0 ls0 ws0">。</div><div class="t m0 x3 h6 y297 ff1 fs2 fc0 sc0 ls0 ws0">事实上，<span class="_ _20"></span>概率模型的训练过程就是参数估计<span class="_ _22"></span>〔<span class="ff3">parameter<span class="_ _9"> </span>estimation)<span class="_ _25"> </span></span>过程。<span class="_ _22"></span>对于参数估计，<span class="_ _20"></span>统计</div><div class="t m0 x3 h6 y298 ff1 fs2 fc0 sc0 ls0 ws0">学界的两个学派分别提供了不同的解决方案：<span class="_ _21"></span>频率学派认为参数未知，<span class="_ _20"></span>但存在客观的固定值，<span class="_ _20"></span>因</div><div class="t m0 x3 h6 y299 ff1 fs2 fc0 sc0 ls0 ws0">此，<span class="_ _21"></span>可通过优化似然函数等准则来确定参数值；<span class="_ _20"></span>贝叶斯学派认为参数是未观察到的随机变量，<span class="_ _20"></span>其</div><div class="t m0 x3 h6 y29a ff1 fs2 fc0 sc0 ls0 ws0">本身也可有分布，<span class="_ _21"></span>因此，<span class="_ _20"></span>可假定参数服从一个先验分布，<span class="_ _20"></span>然后基于观测到的数据来计算参数的后</div><div class="t m0 x3 h6 y29b ff1 fs2 fc0 sc0 ls0 ws0">验分布。</div><div class="t m0 x3 h6 y29c ff1 fs2 fc2 sc0 ls0 ws0">极大<span class="_ _1e"></span>似然<span class="_ _1e"></span>估计<span class="_ _1e"></span>虽然<span class="_ _1e"></span>能<span class="_ _1e"></span>使条<span class="_ _1e"></span>件概<span class="_ _1e"></span>率估<span class="_ _1e"></span>计变<span class="_ _1e"></span>得相<span class="_ _1e"></span>对<span class="_ _1e"></span>简单，<span class="_ _1e"></span>但估<span class="_ _1e"></span>计结<span class="_ _1e"></span>果的<span class="_ _1e"></span>准确<span class="_ _1e"></span>性<span class="_ _1e"></span>严重<span class="_ _1e"></span>依赖<span class="_ _1e"></span>于所<span class="_ _1e"></span>假设<span class="_ _1e"></span>的</div><div class="t m0 x3 h6 y29d ff1 fs2 fc2 sc0 ls0 ws0">概率<span class="_ _1e"></span>分布<span class="_ _1e"></span>形式<span class="_ _1e"></span>是否<span class="_ _1e"></span>符<span class="_ _1e"></span>合潜<span class="_ _1e"></span>在的<span class="_ _1e"></span>真实<span class="_ _1e"></span>数据<span class="_ _1e"></span>分布<span class="_ _1e"></span>（而<span class="_ _1e"></span>贝叶<span class="_ _1e"></span>斯估<span class="_ _1e"></span>计则<span class="_ _1e"></span>会利<span class="_ _1e"></span>用样<span class="_ _1e"></span>本<span class="_ _1e"></span>信息<span class="_ _1e"></span>对假<span class="_ _1e"></span>设的<span class="_ _1e"></span>先验<span class="_ _1e"></span>分</div><div class="t m0 x3 h6 y29e ff1 fs2 fc2 sc0 ls0 ws0">布进行修正）<span class="_ _2e"></span>。<span class="fc0">在现实应用中，欲做出能较好地接近潜在真实分布的假设，<span class="_ _1e"></span>往往需在一定程度上</span></div><div class="t m0 x3 h6 y29f ff1 fs2 fc0 sc0 ls0 ws0">利用关于应用任务本身的经验知讽，否则若仅凭<span class="ff3">”<span class="_ _25"> </span></span>猜测<span class="ff3">”<span class="_ _9"> </span></span>来假设概率分布形式，很可能产生误导</div><div class="t m0 x3 h6 y2a0 ff1 fs2 fc0 sc0 ls0 ws0">性的结果。</div><div class="t m0 x0 h9 y2a1 ff5 fs6 fc0 sc0 ls0 ws0">3.3<span class="_ _1f"> </span><span class="ff9">朴素贝叶斯分类器</span></div><div class="t m0 x3 h6 y2a2 ff1 fs2 fc0 sc0 ls0 ws0">以下<span class="_ _1e"></span>用文<span class="_ _1e"></span>本信<span class="_ _1e"></span>息分<span class="_ _1e"></span>类<span class="_ _1e"></span>作为<span class="_ _1e"></span>例子<span class="_ _1e"></span>来解<span class="_ _1e"></span>释朴<span class="_ _1e"></span>素贝<span class="_ _1e"></span>叶<span class="_ _1e"></span>斯分<span class="_ _1e"></span>类器。<span class="_ _1e"></span>先来<span class="_ _1e"></span>看用<span class="_ _1e"></span>数学<span class="_ _1e"></span>描<span class="_ _1e"></span>述语<span class="_ _1e"></span>言规<span class="_ _1e"></span>律的<span class="_ _1e"></span>普遍<span class="_ _1e"></span>方</div><div class="t m0 x3 h6 y2a3 ff1 fs2 fc0 sc0 ls0 ws0">法。</div><div class="t m0 x3 h12 y2a4 ff5 fs8 fc0 sc0 ls0 ws0">3.3.1<span class="_ _34"> </span><span class="ff9">统计语言模型简述</span></div><div class="t m0 x3 h6 y2a5 ff1 fs2 fc0 sc0 ls0 ws0">假设一个句子的模型为：<span class="ffa">S<span class="_ _9"> </span><span class="ffb">=<span class="_ _2f"> </span></span>w</span></div><div class="t m0 x9f ha y2a6 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x45 hc y2a5 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xbc ha y2a6 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc4 h4 y2a5 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>w</div><div class="t m0 x1 hb y2a6 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 xa0 h6 y2a5 ff1 fs2 fc0 sc0 ls0 ws0">（句子<span class="_ _9"> </span><span class="ffa">S<span class="_ _12"> </span></span>由<span class="_ _9"> </span><span class="ff3">n<span class="_ _9"> </span></span>个词组成）</div><div class="t m0 x3 h6 y2a7 ff1 fs2 fc0 sc0 ls0 ws0">那么<span class="_ _12"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>S<span class="_ _1e"></span><span class="ffb">)<span class="_ _a"> </span>=<span class="_ _a"> </span></span>P<span class="_ _29"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x107 ha y2a8 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x108 hc y2a7 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x109 ha y2a8 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x10a h4 y2a7 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>w</div><div class="t m0 x0 hb y2a8 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x9f h6 y2a7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">。显然<span class="_ _12"> </span><span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">S<span class="_ _26"></span></span>)<span class="_ _a"> </span><span class="ff1">使<span class="_ _1e"></span>句子<span class="_ _a"> </span><span class="ffa">S<span class="_ _0"> </span></span>出现的概率，<span class="_ _1e"></span>在语<span class="_ _1e"></span>言研究<span class="_ _1e"></span>中<span class="_ _a"> </span><span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">S<span class="_ _26"></span></span>)<span class="_ _12"> </span><span class="ff1">越大</span></div><div class="t m0 x3 h6 y2a9 ff1 fs2 fc0 sc0 ls0 ws0">说明<span class="_ _1e"></span>此时<span class="_ _12"> </span><span class="ffa">S<span class="_ _0"> </span></span>越可能<span class="_ _1e"></span>是正<span class="_ _1e"></span>确的<span class="_ _1e"></span>句子，<span class="_ _1e"></span>反之<span class="_ _12"> </span><span class="ffa">S<span class="_ _0"> </span></span>越不可<span class="_ _1e"></span>能<span class="_ _1e"></span>当前<span class="_ _1e"></span>应该<span class="_ _1e"></span>出现<span class="_ _1e"></span>的句<span class="_ _1e"></span>子。利<span class="_ _1e"></span>用条<span class="_ _1e"></span>件概<span class="_ _1e"></span>率<span class="_ _1e"></span>公式，</div><div class="t m0 x3 h4 y2aa ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 xce ha y2ab ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x10b hc y2aa ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x101 ha y2ab ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb h4 y2aa ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>w</div><div class="t m0 x10c hb y2ab ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x10d h6 y2aa ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">可以写为：</span></div><div class="t m0 x10e h4 y2ac ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 xb ha y2ad ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x10f hc y2ac ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x110 ha y2ad ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xc3 h4 y2ac ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>w</div><div class="t m0 x111 hb y2ad ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x109 h4 y2ac ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ffa">P<span class="_ _29"> </span></span>(<span class="ffa">w</span></div><div class="t m0 x97 ha y2ad ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9f h4 y2ac ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff3">·<span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x105 ha y2ad ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x3d h4 y2ac fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xa7 ha y2ad ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xf1 h4 y2ac ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff3">·<span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x5e ha y2ad ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 xb4 h4 y2ac fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x27 ha y2ad ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xcd hc y2ac ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xe3 ha y2ad ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x112 h4 y2ac ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _2c"></span><span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x113 hb y2ad ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 xae h4 y2ac fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x2c ha y2ad ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x53 hc y2ac ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x114 ha y2ad ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x55 h4 y2ac ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>w</div><div class="t m0 x115 ha y2ad ffd fs7 fc0 sc0 ls0 ws0">n<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x116 h4 y2ac ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _38"> </span><span class="ff3">(3.3)</span></div><div class="t m0 x3 h6 y2ae ff1 fs2 fc0 sc0 ls0 ws0">显<span class="_ _1e"></span>然，<span class="_ _1e"></span>词<span class="_ _4"> </span><span class="ffa">w</span></div><div class="t m0 x117 hb y2af ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 xa8 h6 y2ae ff1 fs2 fc0 sc0 ls0 ws0">出<span class="_ _1e"></span>现<span class="_ _1e"></span>的<span class="_ _26"></span>概<span class="_ _1e"></span>率<span class="_ _26"></span>取<span class="_ _1e"></span>决<span class="_ _1e"></span>于<span class="_ _26"></span>它<span class="_ _1e"></span>前<span class="_ _26"></span>面<span class="_ _1e"></span>的<span class="_ _1e"></span>所<span class="_ _26"></span>有<span class="_ _1e"></span>词。<span class="_ _1e"></span>从<span class="_ _26"></span>计<span class="_ _1e"></span>算<span class="_ _26"></span>的<span class="_ _1e"></span>角<span class="_ _1e"></span>度<span class="_ _26"></span>来<span class="_ _1e"></span>看，<span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x77 ha y2af ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x118 h4 y2ae ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x119 h1d y2b0 ff16 fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x11a h6 y2ae ff1 fs2 fc0 sc0 ls0 ws0">很<span class="_ _1e"></span>容<span class="_ _1e"></span>易<span class="_ _26"></span>计<span class="_ _1e"></span>算，</div><div class="t m0 x3 h4 y2b1 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 xce ha y2b2 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x10b h4 y2b1 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x80 ha y2b2 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x6 h6 y2b1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _25"> </span><span class="ff1">也不算太难，<span class="_ _31"></span>但<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>w</span></span></div><div class="t m0 x11b ha y2b2 ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x9c h4 y2b1 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xee ha y2b2 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xcb hc y2b1 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x47 ha y2b2 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x9 h6 y2b1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _25"> </span><span class="ff1">就已经相当有难度，<span class="_ _31"></span>因为它涉及到三个变量，<span class="_ _31"></span>每个变量</span></div><div class="t m0 x3 h6 y2b3 ff1 fs2 fc0 sc0 ls0 ws0">的可<span class="_ _1e"></span>能性<span class="_ _1e"></span>都是<span class="_ _1e"></span>一种<span class="_ _1e"></span>语言<span class="_ _1e"></span>字典<span class="_ _1e"></span>的大<span class="_ _1e"></span>小。到<span class="_ _1e"></span>了<span class="_ _1e"></span>最后<span class="_ _1e"></span>一个<span class="_ _1e"></span>词，条<span class="_ _1e"></span>件概<span class="_ _1e"></span>率<span class="_ _12"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x54 hb y2b4 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x11c h4 y2b3 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x72 ha y2b4 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x11d hc y2b3 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x11e ha y2b4 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x73 h4 y2b3 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>w</div><div class="t m0 x11f ha y2b4 ffd fs7 fc0 sc0 ls0 ws0">n<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x10 h6 y2b3 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _12"> </span><span class="ff1">的可</span></div><div class="t m0 x3 h6 y2b5 ff1 fs2 fc0 sc0 ls0 ws0">能性太多，无法估计。那怎么办？</div><div class="t m0 x3 h6 y2b6 ff3 fs2 fc0 sc0 ls0 ws0">19<span class="_ _9"> </span><span class="ff1">世纪到<span class="_ _a"> </span></span>20<span class="_ _9"> </span><span class="ff1">世<span class="_ _1e"></span>纪初，俄罗斯有个<span class="_ _1e"></span>数学家叫马尔可夫<span class="_ _1e"></span>（</span>Andrey<span class="_ _9"> </span>Marko<span class="_ _2d"></span>v<span class="ff1">）<span class="_ _2e"></span>，<span class="_ _1e"></span>他给了个偷懒但还<span class="_ _1e"></span>颇</span></div><div class="t m0 x3 h6 y2b7 ff1 fs2 fc0 sc0 ls0 ws0">为有效的方法，<span class="_ _2d"></span>也就是每当遇到这种情况时，<span class="_ _2d"></span>就假设任意一个词<span class="_ _9"> </span><span class="ffa">w</span></div><div class="t m0 x120 hb y2b8 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x121 h6 y2b7 ff1 fs2 fc0 sc0 ls0 ws0">出现的概率只同它前面的词</div><div class="t m0 x3 hc y2b9 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x122 ha y2ba ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x10b h6 y2b9 ff1 fs2 fc0 sc0 ls0 ws0">有关，<span class="_ _2d"></span>于是问题就变得很简单了。<span class="_ _2d"></span>这种假设在数学上称为马尔可夫假设</div><div class="t m0 x57 h1d y2bb ff16 fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x58 h6 y2b9 ff1 fs2 fc0 sc0 ls0 ws0">。<span class="_ _2d"></span>现在，<span class="_ _2d"></span><span class="ffa">S<span class="_ _12"> </span><span class="ff1">出现的</span></span></div><div class="t m0 x3 h6 y2bc ff1 fs2 fc0 sc0 ls0 ws0">概率就变得简单了：</div><div class="t m0 x123 h4 y2bd ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 x108 ha y2be ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x124 hc y2bd ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x10a ha y2be ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xde h4 y2bd ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>w</div><div class="t m0 x7 hb y2be ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x8d h4 y2bd ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ffa">P<span class="_ _29"> </span></span>(<span class="ffa">w</span></div><div class="t m0 x59 ha y2be ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x49 h4 y2bd ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff3">·<span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 xf3 ha y2be ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb2 h4 y2bd fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x26 ha y2be ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x27 h4 y2bd ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff3">·<span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x50 ha y2be ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x28 h4 y2bd fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xa3 ha y2be ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x125 h4 y2bd ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _2c"></span><span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x126 hb y2be ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x72 h4 y2bd fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x57 ha y2be ffd fs7 fc0 sc0 ls0 ws0">n<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x127 h4 y2bd ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _4a"> </span><span class="ff3">(3.4)</span></div><div class="t m0 x3 h6 y2bf ff1 fs2 fc0 sc0 ls0 ws0">公式<span class="_ _a"> </span><span class="ff3">3.4<span class="_ _12"> </span></span>对应的<span class="_ _1e"></span>统计<span class="_ _1e"></span>语言模<span class="_ _1e"></span>型是二<span class="_ _1e"></span>元模<span class="_ _1e"></span>型（<span class="ff3">bigram<span class="_ _a"> </span>mo<span class="_ _1e"></span>dule</span>）<span class="_ _3c"></span>。当<span class="_ _1e"></span>然，也<span class="_ _1e"></span>可以假<span class="_ _1e"></span>设一个<span class="_ _1e"></span>词由<span class="_ _1e"></span>前面</div><div class="t m0 x3 h6 y2c0 ffa fs2 fc0 sc0 ls0 ws0">N<span class="_ _9"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffb">1<span class="_ _9"> </span><span class="ff1">个词决定，对应的模型稍微复杂些，被称为<span class="_ _9"> </span></span></span></span>N<span class="_ _1c"> </span><span class="ff1">元模型。</span></div><div class="t m0 x3 h25 y2c1 ff8 fs2 fc0 sc0 ls0 ws0">接下来的内容在这里可以略过。</div><div class="t m0 x104 h26 y2c2 ff18 fs9 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5 h27 y2c3 ff19 fsa fc0 sc0 ls0 ws0">P<span class="_ _2b"> </span><span class="ff1a">(</span>w</div><div class="t m0 x78 h18 y2c4 ff14 fs9 fc0 sc0 ls0 ws0">1</div><div class="t m0 x101 h28 y2c3 ff1a fsa fc0 sc0 ls0 ws0">)<span class="_ _25"> </span><span class="ff1">是第一个<span class="_ _1e"></span>词的条件概率，<span class="_ _1e"></span>实际上更准确<span class="_ _1e"></span>的描述是<span class="_ _25"> </span><span class="ff19">P<span class="_ _29"> </span></span></span>(<span class="ff19">w</span></div><div class="t m0 xc0 h18 y2c4 ff14 fs9 fc0 sc0 ls0 ws0">1</div><div class="t m0 x42 h28 y2c3 ff1b fsa fc0 sc0 ls0 ws0">|<span class="_ _f"> </span><span class="ff19">&lt;<span class="_ _2f"> </span>S<span class="_ _9"> </span>&gt;<span class="ff1a">)<span class="ff1">，即这个<span class="_ _1e"></span>词在句子开头<span class="_ _9"> </span></span></span>&lt;<span class="_ _f"> </span>S<span class="_ _9"> </span>&gt;<span class="_ _25"> </span><span class="ff1">条件下的</span></span></div><div class="t m0 x3 h28 y2c5 ff1 fsa fc0 sc0 ls0 ws0">概率</div><div class="t m0 x104 h26 y2c6 ff18 fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 x5 h28 y2c7 ff1 fsa fc0 sc0 ls0 ws0">马尔可夫在<span class="_ _25"> </span><span class="ff1c">1906<span class="_ _25"> </span></span>年<span class="_ _1e"></span>首先做出了这<span class="_ _1e"></span>类过程。而将此一<span class="_ _1e"></span>般化到可数无<span class="_ _1e"></span>限状态空间是由<span class="_ _1e"></span>柯尔莫果洛夫在<span class="_ _9"> </span><span class="ff1c">1936<span class="_ _2f"> </span></span>年<span class="_ _1e"></span>给出</div><div class="t m0 x3 h28 y1e ff1 fsa fc0 sc0 ls0 ws0">的。</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">21</div><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",87.01,88.66,null]'><div class="d m1" style="border-style:none;position:absolute;left:684.177000px;bottom:437.341500px;width:4.232000px;height:11.293000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1a" data-dest-detail='[26,"XYZ",87.01,64.44,null]'><div class="d m1" style="border-style:none;position:absolute;left:650.293500px;bottom:302.307000px;width:4.232000px;height:11.294000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1b" class="pf w0 h0" data-page-no="1b"><div class="pc pc1b w0 h0"><img class="bi x3 y2c8 wc h29" alt="" src="bg1b.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.3<span class="_ _d"> </span><span class="ff8">朴素贝叶斯分类器</span></div><div class="t m0 x3 h25 y20 ff8 fs2 fc0 sc0 ls0 ws0">现在的问题就是如何估计<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x97 hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x7 h4 y20 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xed ha y2c9 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x87 h25 y20 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff8">的概率，根据它的定义：</span></div><div class="t m0 xa h4 y2ca ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 x3e hb y2cb ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x102 h4 y2ca fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 x5a ha y2cb ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xbe h4 y2ca ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=</div><div class="t m0 x99 h4 y2cc ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 xd6 hb y2cd ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x128 hc y2cc ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x63 ha y2cd ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x50 h4 y2cc ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xb4 h4 y2ce ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 x92 ha y2cf ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x60 h4 y2ce ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h25 y2d0 ff8 fs2 fc0 sc0 ls0 ws0">而估计联合概率<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>w</span></div><div class="t m0 x129 hb y2d1 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x109 hc y2d0 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x12a ha y2d1 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x12b h25 y2d0 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff8">和边缘概率<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span></span></span>(<span class="ffa">w</span></div><div class="t m0 x5b ha y2d1 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x12c h25 y2d0 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff8">现在变得非常简单。因为<span class="_ _9"> </span>有了大量机读文本，</span></div><div class="t m0 x3 h25 y2d2 ff8 fs2 fc0 sc0 ls0 ws0">也就<span class="_ _1e"></span>是语<span class="_ _1e"></span>料<span class="_ _1e"></span>库（<span class="ff3">Corpus</span>）<span class="_ _3d"></span>，只<span class="_ _1e"></span>要数<span class="_ _1e"></span>一数<span class="_ _1c"> </span><span class="ffa">w</span></div><div class="t m0 x49 hb y2d3 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x12d hc y2d2 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xbe ha y2d3 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x12c h25 y2d2 ff8 fs2 fc0 sc0 ls0 ws0">这对<span class="_ _1e"></span>词在<span class="_ _1e"></span>统<span class="_ _1e"></span>计的<span class="_ _1e"></span>文本<span class="_ _1e"></span>中<span class="_ _1e"></span>前后<span class="_ _1e"></span>相邻<span class="_ _1e"></span>出现<span class="_ _1e"></span>了<span class="_ _1e"></span>多少<span class="_ _1e"></span>次</div><div class="t m0 x3 h4 y2d4 ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 x5 hb y2d5 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xce hc y2d4 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x12e ha y2d5 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x12f h25 y2d4 ff8 fs2 fc0 sc0 ls0 ws0">，以及<span class="_ _12"> </span><span class="ffa">w</span></div><div class="t m0 x108 ha y2d5 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x130 h25 y2d4 ff8 fs2 fc0 sc0 ls0 ws0">本身在<span class="_ _1e"></span>同样的<span class="_ _1e"></span>文本中<span class="_ _1e"></span>出现<span class="_ _1e"></span>了多少<span class="_ _1e"></span>次<span class="_ _a"> </span><span class="ff3">#<span class="ffa">w</span></span></div><div class="t m0 x29 ha y2d5 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x131 h25 y2d4 ff8 fs2 fc0 sc0 ls0 ws0">，然后<span class="_ _1e"></span>用两个<span class="_ _1e"></span>数分别<span class="_ _1e"></span>除以<span class="_ _1e"></span>语料</div><div class="t m0 x3 h25 y2d6 ff8 fs2 fc0 sc0 ls0 ws0">库的大小<span class="_ _9"> </span><span class="ff3">#</span>，即可得到这些词或者二元组的相对频度：</div><div class="t m0 x132 h4 y2d7 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>w</div><div class="t m0 x3d ha y2d8 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x12d hc y2d7 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xbe hb y2d8 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa5 h4 y2d7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=</div><div class="t m0 x91 h4 y2d9 ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 xd6 hb y2da ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x128 hc y2d9 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x63 ha y2da ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xcd h4 y2db ff3 fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x100 h4 y2dc ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>w</div><div class="t m0 xf1 ha y2dd ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xa5 h4 y2dc ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=</div><div class="t m0 x91 h4 y2de ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 xd6 ha y2df ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xbf h4 y2e0 ff3 fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x3 h25 y2e1 ff8 fs2 fc0 sc0 ls0 ws0">根据大数定理，只要统计量足够大，相对频率就等于概率，即：</div><div class="t m0 xbc h4 y2e2 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 x102 ha y2e3 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x4a hc y2e2 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x23 hb y2e3 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x5b h4 y2e2 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=</div><div class="t m0 x4b h4 y2e4 ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 xc0 hb y2e5 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x133 hc y2e4 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x66 ha y2e5 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x128 h4 y2e6 ff3 fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x105 h4 y2e7 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>w</div><div class="t m0 x3f ha y2e8 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x5b h4 y2e7 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=</div><div class="t m0 x4b h4 y2e9 ff3 fs2 fc0 sc0 ls0 ws0">#<span class="ffa">w</span></div><div class="t m0 xc0 ha y2ea ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xbf h4 y2eb ff3 fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x3 h25 y2ec ff8 fs2 fc0 sc0 ls0 ws0">最后得到：<span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>w</span></div><div class="t m0 xd2 hb y2ed ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc6 h4 y2ec fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">w</span></div><div class="t m0 xc7 ha y2ed ffd fs7 fc0 sc0 ls0 ws0">i<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x6e h4 y2ec ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="fff">≈</span></div><div class="t m0 xc hb y2ee ff16 fs7 fc0 sc0 ls0 ws0">#<span class="ffd">w</span></div><div class="t m0 x98 h22 y2ef ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa6 hb y2ee ffd fs7 fc0 sc0 ls0 ws0">,w</div><div class="t m0 x11b h18 y2ef ff17 fs9 fc0 sc0 ls0 ws0">i<span class="ff15">−<span class="ff14">1</span></span></div><div class="t m0 x44 hb y2f0 ff16 fs7 fc0 sc0 ls0 ws0">#<span class="ffd">w</span></div><div class="t m0 x0 h18 y2f1 ff17 fs9 fc0 sc0 ls0 ws0">i<span class="ff15">−<span class="ff14">1</span></span></div><div class="t m0 x3 h12 y2f2 ff5 fs8 fc0 sc0 ls0 ws0">3.3.2<span class="_ _34"> </span><span class="ff9">朴素贝叶斯</span></div><div class="t m0 x3 h6 y2f3 ff1 fs2 fc0 sc0 ls0 ws0">通过上一节的叙述，<span class="_ _1e"></span>可以知道如果直接<span class="_ _1e"></span>估计联合概率<span class="_ _a"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)</span></span>，在计算上中会遭遇组合<span class="_ _1e"></span>爆炸问题，</div><div class="t m0 x3 h6 y2f4 ff1 fs2 fc0 sc0 ls0 ws0">在数据上将会遭遇样本稀疏问题（下面会说到）<span class="_ _23"></span>，属性数越多，问题越严重。</div><div class="t m0 x3 h6 y2f5 ff1 fs2 fc0 sc0 ls0 ws0">而我们可以看出如果采用二元模型，<span class="_ _21"></span>计算显然方便很多。<span class="_ _20"></span>但是这还不是最方便的，<span class="_ _20"></span>最方便的就是</div><div class="t m0 x3 h6 y2f6 ff1 fs2 fc0 sc0 ls0 ws0">一元模型（<span class="ff3">uni-gram<span class="_ _9"> </span></span>或<span class="_ _9"> </span><span class="ff3">monogram</span>）<span class="_ _23"></span>，也就是<span class="_ _9"> </span><span class="ffa">w</span></div><div class="t m0 xfb hb y2f7 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x134 h6 y2f6 ff1 fs2 fc0 sc0 ls0 ws0">独立于历史。</div><div class="t m0 x3 h6 y2f8 ff1 fs2 fc0 sc0 ls0 ws0">而朴素贝叶<span class="_ _1e"></span>斯正是相当于<span class="_ _1e"></span>使用了一元<span class="_ _1e"></span>模型，它的<span class="_ _a"> </span><span class="ff3">naiv<span class="_ _e"></span>e<span class="_ _9"> </span><span class="ff1">假<span class="_ _1e"></span>设</span></span></div><div class="t m0 x50 h1d y2f9 ff16 fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x135 h6 y2f8 ff1 fs2 fc0 sc0 ls0 ws0">为：对已知类<span class="_ _1e"></span>别，所有属性相<span class="_ _1e"></span>互独</div><div class="t m0 x3 h6 y2fa ff1 fs2 fc0 sc0 ls0 ws0">立。于是：</div><div class="t m0 x12b h4 y2fb ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="fff">|</span>x<span class="ffb">)<span class="_ _f"> </span>=</span></div><div class="t m0 xe1 h4 y2fc ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="ffb">)</span>P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)</span></div><div class="t m0 x8c h4 y2fd ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)</span></div><div class="t m0 x134 h4 y2fb ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x136 h4 y2fc ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="ffb">)</span></div><div class="t m0 x26 h4 y2fd ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)</span></div><div class="t m0 x106 hb y2fe ffd fs7 fc0 sc0 ls0 ws0">d</div><div class="t m0 x61 he y2ff ffe fs2 fc0 sc0 ls0 ws0">Y</div><div class="t m0 x61 ha y300 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x28 h4 y2fb ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>x</div><div class="t m0 x52 hb y301 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd9 h4 y2fb fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)</span></span></div><div class="t m0 x3 h6 y302 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _9"> </span><span class="ffa">d<span class="_ _a"> </span></span>为属性数目，<span class="ffa">x</span></div><div class="t m0 x16 hb y303 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb0 h6 y302 ff1 fs2 fc0 sc0 ls0 ws0">为<span class="_ _9"> </span><span class="ffa">x<span class="_ _a"> </span></span>在第<span class="_ _9"> </span><span class="ffa">i<span class="_ _a"> </span></span>个属性上的取值。由于对<span class="_ _1e"></span>于所有类别来说，<span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="ffb">)<span class="_ _a"> </span></span></span>的值相同，</div><div class="t m0 x3 h6 y304 ff1 fs2 fc0 sc0 ls0 ws0">因此没有必要计算，它可以被约去。因此，朴素贝叶斯判定准则为：</div><div class="t m0 x11b hc y305 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x45 hb y306 ffd fs7 fc0 sc0 ls0 ws0">nb</div><div class="t m0 xee h4 y305 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span>)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff3">arg<span class="_ _2c"> </span>max</span></div><div class="t m0 xbe ha y307 ffd fs7 fc0 sc0 ls0 ws0">c<span class="ff12">∈</span>y</div><div class="t m0 x12c h4 y305 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="ffb">)</span></div><div class="t m0 xad hb y308 ffd fs7 fc0 sc0 ls0 ws0">d</div><div class="t m0 xc0 he y309 ffe fs2 fc0 sc0 ls0 ws0">Y</div><div class="t m0 xc0 ha y30a ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x66 h4 y305 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>x</div><div class="t m0 x137 hb y30b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x9d h4 y305 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _4b"> </span><span class="ff3">(3.5)</span></span></span></div><div class="t m0 x3 h6 y30c ff1 fs2 fc0 sc0 ls0 ws0">这就是朴素贝叶斯分类器的表达式。</div><div class="t m0 x3 h6 y30d ff1 fs2 fc0 sc0 ls0 ws0">如果假设<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x<span class="fff">|</span>c<span class="ffb">)<span class="_ _9"> </span></span></span>是多项分布，那么根据极大似然估计可以得到，它的概率估计就是频率。</div><div class="t m0 x3 h6 y30e ff1 fs2 fc0 sc0 ls0 ws0">令<span class="_ _9"> </span><span class="ffa">D</span></div><div class="t m0 x138 hb y30f ffd fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x7a h6 y30e ff1 fs2 fc0 sc0 ls0 ws0">表示训练集<span class="_ _9"> </span><span class="ffa">D<span class="_ _a"> </span></span>中第<span class="_ _9"> </span><span class="ffa">c<span class="_ _a"> </span></span>类样本组成的集合，若有充是的独立同分布样本，则<span class="_ _1e"></span>可容易地估计</div><div class="t m0 x3 h6 y310 ff1 fs2 fc0 sc0 ls0 ws0">出类先验概率：</div><div class="t m0 xa7 h4 y311 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="ffb">)<span class="_ _f"> </span>=</span></div><div class="t m0 xb2 h4 y312 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D</span></div><div class="t m0 x136 hb y313 ffd fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x27 h4 y312 fff fs2 fc0 sc0 ls0 ws0">|</div><div class="t m0 x91 h4 y314 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D<span class="_ _1e"></span></span>|</div><div class="t m0 x33 h4 y311 ff3 fs2 fc0 sc0 ls0 ws0">(3.6)</div><div class="t m0 x3 h6 y315 ff1 fs2 fc0 sc0 ls0 ws0">对离散属<span class="_ _1e"></span>性而言，令<span class="_ _a"> </span><span class="ffa">D</span></div><div class="t m0 x17 hb y316 ffd fs7 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x39 h22 y317 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 x139 h6 y315 ff1 fs2 fc0 sc0 ls0 ws0">表示<span class="_ _a"> </span><span class="ffa">D</span></div><div class="t m0 xa hb y316 ffd fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 xab h6 y315 ff1 fs2 fc0 sc0 ls0 ws0">中在第<span class="_ _a"> </span><span class="ff3">i<span class="_ _a"> </span></span>个属性上<span class="_ _1e"></span>取值为<span class="_ _a"> </span><span class="ffa">x</span></div><div class="t m0 x51 hb y316 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x131 h6 y315 ff1 fs2 fc0 sc0 ls0 ws0">的样本组<span class="_ _1e"></span>成的集合，<span class="_ _1e"></span>则条件概</div><div class="t m0 x3 h6 y318 ff1 fs2 fc0 sc0 ls0 ws0">率<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x12e hb y319 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13a h6 y318 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _9"> </span><span class="ff1">可估计为</span></span></span></div><div class="t m0 x88 h4 y31a ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>x</div><div class="t m0 x22 hb y31b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa0 h4 y31a fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _2f"> </span>=</span></span></div><div class="t m0 xa2 hc y31c ffa fs2 fc0 sc0 ls0 ws0">D</div><div class="t m0 xbf hb y31d ffd fs7 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x42 h22 y31e ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13b h4 y31f fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D<span class="_ _1e"></span></span>|</div><div class="t m0 x33 h4 y31a ff3 fs2 fc0 sc0 ls0 ws0">(3.7)</div><div class="t m0 x104 h26 y320 ff18 fs9 fc0 sc0 ls0 ws0">3</div><div class="t m0 x5 h28 y1e ff1 fsa fc0 sc0 ls0 ws0">属性条件独立性假设<span class="_ _2f"> </span><span class="ff1c">attribute<span class="_ _2f"> </span>conditional<span class="_ _2f"> </span>indep<span class="_ _1e"></span>endence<span class="_ _2f"> </span>assumption</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">22</div><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",87.01,53.48,null]'><div class="d m1" style="border-style:none;position:absolute;left:533.101500px;bottom:573.742500px;width:4.233000px;height:11.293000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1c" class="pf w0 h0" data-page-no="1c"><div class="pc pc1c w0 h0"><img class="bi x3 y17a w2 h2a" alt="" src="bg1c.png"/><div class="t m0 x72 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.3<span class="_ _d"> </span><span class="ff8">朴素贝叶斯分类器</span></div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">对连续属性可考虑概率密度函数，假定<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x22 hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa0 h4 y20 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _2f"> </span></span></span>∼<span class="_ _2f"> </span><span class="ffa">N<span class="_ _2b"></span><span class="ffb">(</span>µ</span></div><div class="t m0 x133 hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 xe3 h22 y321 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 x61 hc y20 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>σ</div><div class="t m0 x50 ha y322 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x50 hb y323 ffd fs7 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x96 h22 y324 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6c h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">，其中<span class="_ _9"> </span><span class="ffa">µ</span></div><div class="t m0 x13c hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x13d h22 y321 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 x11d h4 y20 ff3 fs2 fc0 sc0 ls0 ws0">�<span class="ffa">σ</span></div><div class="t m0 x13e ha y322 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x13e hb y323 ffd fs7 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 x118 h22 y324 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 xe9 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">分别是<span class="_ _9"> </span>第<span class="_ _9"> </span><span class="ff3">c<span class="_ _9"> </span></span>类</div><div class="t m0 x3 h6 y1c9 ff1 fs2 fc0 sc0 ls0 ws0">样本在第<span class="_ _9"> </span><span class="ff3">i<span class="_ _9"> </span></span>个属性上取值的均值和方差，则有</div><div class="t m0 xa6 h4 y325 ffa fs2 fc0 sc0 ls0 ws0">p<span class="ffb">(</span>x</div><div class="t m0 x45 hb y326 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xed h4 y325 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _2f"> </span>=</span></span></div><div class="t m0 x4a h4 y327 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3d h4 y328 fff fs2 fc0 sc0 ls0 ws0">√</div><div class="t m0 x21 h4 y329 ffb fs2 fc0 sc0 ls0 ws0">2<span class="ffa">π<span class="_ _1e"></span>σ</span></div><div class="t m0 xbe hb y32a ffd fs7 fc0 sc0 ls0 ws0">c,i</div><div class="t m0 xfb h4 y325 ff3 fs2 fc0 sc0 ls0 ws0">exp<span class="ffb">(<span class="fff">−</span></span></div><div class="t m0 xcd h4 y32b ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">x</span></div><div class="t m0 x13f hb y32c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x61 h4 y32b fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">µ</span></div><div class="t m0 x137 hb y32c ffd fs7 fc0 sc0 ls0 ws0">c,i</div><div class="t m0 xa3 h4 y32b ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x125 ha y32d ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x140 h4 y32e ffb fs2 fc0 sc0 ls0 ws0">2<span class="ffa">σ</span></div><div class="t m0 x50 ha y32f ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x50 hb y330 ffd fs7 fc0 sc0 ls0 ws0">c,i</div><div class="t m0 x131 h4 y325 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _4c"> </span><span class="ff3">(3.8)</span></div><div class="t m0 x3 h12 y331 ff5 fs8 fc0 sc0 ls0 ws0">3.3.3<span class="_ _34"> </span><span class="ff9">修正</span></div><div class="t m0 x3 h6 y332 ff1 fs2 fc0 sc0 ls0 ws0">需注意，<span class="_ _21"></span>若某个属性值在训练集中没有与某个类同时出现过，<span class="_ _20"></span>则直接基于公式<span class="ff3">3.7<span class="_ _25"> </span></span>进行概率估计，</div><div class="t m0 x3 h6 y333 ff1 fs2 fc0 sc0 ls0 ws0">再根据<span class="_ _1e"></span>公式<span class="ff3">3.5</span>进行判<span class="_ _1e"></span>别将出<span class="_ _1e"></span>现问题。<span class="_ _1e"></span>这个问题<span class="_ _1e"></span>就是该<span class="_ _1e"></span>属性值在<span class="_ _1e"></span>没有出<span class="_ _1e"></span>现的那<span class="_ _1e"></span>个类的概<span class="_ _1e"></span>率估计<span class="_ _1e"></span>为</div><div class="t m0 x3 h6 y334 ff3 fs2 fc0 sc0 ls0 ws0">0<span class="ff1">，因为连乘的原因，概率估计值最终为<span class="_ _9"> </span></span>0<span class="ff1">。这显然不合理。</span></div><div class="t m0 x3 h6 y335 ff1 fs2 fc0 sc0 ls0 ws0">为了避免其他属性携带的信息被训练<span class="_ _1e"></span>集中未出现的属性值“抹去”<span class="_ _2e"></span>，在估计概率值时通常要进行</div><div class="t m0 x141 h6 y336 ff1 fs2 fc0 sc0 ls0 ws0">“平滑”<span class="_ _e"></span><span class="ff3">(smo<span class="_ _1e"></span>othing)<span class="ff1">，<span class="_ _2d"></span>常用“拉普拉斯修正”<span class="_ _e"></span><span class="ff3">(Laplaciancorrection)<span class="ff1">。<span class="_ _2d"></span>具体来说，令<span class="_ _25"> </span><span class="ffa">N<span class="_ _1c"> </span></span>表示训练</span></span></span></span></div><div class="t m0 x3 h6 y337 ff1 fs2 fc0 sc0 ls0 ws0">集中可能的类别数，<span class="ffa">N</span></div><div class="t m0 x16 hb y338 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb0 h6 y337 ff1 fs2 fc0 sc0 ls0 ws0">表示第<span class="_ _9"> </span><span class="ff3">i<span class="_ _9"> </span></span>个属性可能的取值数，则上式分别修正为</div><div class="t m0 xe2 h4 y339 ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 x102 h4 y33a ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>c<span class="ffb">)<span class="_ _f"> </span>=</span></div><div class="t m0 x41 h4 y33b fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D</span></div><div class="t m0 x91 hb y33c ffd fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x4c h4 y33b fff fs2 fc0 sc0 ls0 ws0">|<span class="_ _30"> </span><span class="ffb">+<span class="_ _30"> </span>1</span></div><div class="t m0 x41 h4 y33d fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D<span class="_ _1e"></span></span>|<span class="_ _30"> </span><span class="ffb">+<span class="_ _30"> </span><span class="ffa">N</span></span></div><div class="t m0 x33 h4 y33a ff3 fs2 fc0 sc0 ls0 ws0">(3.9)</div><div class="t m0 xb3 h4 y33e ffb fs2 fc0 sc0 ls0 ws0">ˆ</div><div class="t m0 xe1 h4 y33f ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _29"> </span><span class="ffb">(</span>x</div><div class="t m0 x142 hb y340 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x5a h4 y33f fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _2f"> </span>=</span></span></div><div class="t m0 x5d h4 y341 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D</span></div><div class="t m0 xa2 hb y342 ffd fs7 fc0 sc0 ls0 ws0">c,x</div><div class="t m0 xb1 h22 y343 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd6 h4 y341 fff fs2 fc0 sc0 ls0 ws0">|<span class="_ _30"> </span><span class="ffb">+<span class="_ _30"> </span>1</span></div><div class="t m0 x143 h4 y344 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">D</span></div><div class="t m0 xb4 hb y345 ffd fs7 fc0 sc0 ls0 ws0">c</div><div class="t m0 x144 h4 y344 fff fs2 fc0 sc0 ls0 ws0">|<span class="_ _30"> </span><span class="ffb">+<span class="_ _30"> </span><span class="ffa">N</span></span></div><div class="t m0 x63 hb y345 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xba h4 y33f ff3 fs2 fc0 sc0 ls0 ws0">(3.10)</div><div class="t m0 x3 h6 y346 ff1 fs2 fc0 sc0 ls0 ws0">显然，<span class="_ _28"></span>拉普拉斯修正避免了因训练集样本不充分而导致概率估值为零的问题，<span class="_ _27"></span>并且在训练集变大</div><div class="t m0 x3 h6 y347 ff1 fs2 fc0 sc0 ls0 ws0">时，<span class="_ _21"></span>修正过程所引入的先验<span class="_ _9"> </span><span class="ff3">(prior) </span>的影响也会逐渐变得可忽略，<span class="_ _20"></span>使得估值渐趋向于实际概率值。</div><div class="t m0 x3 h6 y348 ff1 fs2 fc0 sc0 ls0 ws0">在现实任务中朴素贝叶斯分类器有多种使用方式。<span class="_ _20"></span>例如，<span class="_ _21"></span>若任务对预测速度要求较高，<span class="_ _20"></span>则对给定</div><div class="t m0 x3 h6 y349 ff1 fs2 fc0 sc0 ls0 ws0">训练集，<span class="_ _28"></span>可将朴素贝叶斯分类器涉及的所有概率估值事先计算好存储起来，<span class="_ _27"></span>这样在进行预测时只</div><div class="t m0 x3 h6 y34a ff1 fs2 fc0 sc0 ls0 ws0">需<span class="ff3">”<span class="_ _9"> </span></span>查表<span class="ff3">”<span class="_ _9"> </span></span>即可进行判别；若任务数据更替频繁，则可采用<span class="ff3">”<span class="_ _9"> </span></span>懒惰学习<span class="ff3">”(lazy<span class="_ _9"> </span>learning)<span class="_ _9"> </span></span>方式，先</div><div class="t m0 x3 h6 y34b ff1 fs2 fc0 sc0 ls0 ws0">不进行任何训练，<span class="_ _21"></span>待收到预测请求时再根据当前数据集进行概率估值；<span class="_ _20"></span>若数据不断增加，<span class="_ _20"></span>则可在</div><div class="t m0 x3 h6 y34c ff1 fs2 fc0 sc0 ls0 ws0">现有估值基础上，仅对新增样本的属性值所涉及的概率估值进行计数修正即可实现增量学习。</div><div class="t m0 x3 h6 y34d ff1 fs2 fc0 sc0 ls0 ws0">尽管朴<span class="_ _1e"></span>素贝叶<span class="_ _1e"></span>斯被认<span class="_ _1e"></span>为是一<span class="_ _1e"></span>种相当<span class="_ _1e"></span>不错的<span class="_ _1e"></span>分类<span class="_ _1e"></span>器，但却<span class="_ _1e"></span>不是好<span class="_ _1e"></span>的估计<span class="_ _1e"></span>器<span class="_ _a"> </span><span class="ff3">(estimator)</span>，所<span class="_ _1e"></span>以不能</div><div class="t m0 x3 h6 y34e ff1 fs2 fc0 sc0 ls0 ws0">太过于重视从<span class="_ _9"> </span><span class="ff3">predict_proba<span class="_ _9"> </span></span>输出的概率。</div><div class="t m0 x1e h6 y34f ff4 fs2 fc0 sc0 ls0 ws0">为什么朴素贝叶斯是较好的分类器，但却是糟糕的估计器？</div><div class="t m0 x1e h6 y350 ff1 fs2 fc0 sc0 ls0 ws0">很显然，其中一个原因是因为它的朴素假设。实际上，只要使用贝叶斯方法，<span class="_ _e"></span>就会带来这</div><div class="t m0 x1e h6 y351 ff1 fs2 fc0 sc0 ls0 ws0">个问题。因为贝叶斯方法验证依赖于先验分布的假设，<span class="_ _e"></span>一旦先验分布假设和真实分布有偏</div><div class="t m0 x1e h6 y352 ff1 fs2 fc0 sc0 ls0 ws0">离，估计出来的概率与真实概率可能就会差距甚大。但是，<span class="_ _e"></span>如果样本真的能反应总体的特</div><div class="t m0 x1e h6 y353 ff1 fs2 fc0 sc0 ls0 ws0">征，那么后验概率一定会对先验概率进行纠正，因此能较好地分类。</div><div class="t m0 x3 h6 y354 ff1 fs2 fc2 sc0 ls0 ws0">还有一点要注意的是：<span class="_ _21"></span>从上面的概率修正的描述中，<span class="_ _20"></span>我们就可以看出来，<span class="_ _20"></span>贝叶斯分类器只能适用</div><div class="t m0 x3 h6 y355 ff1 fs2 fc2 sc0 ls0 ws0">于所有分类估计概率已知的情况下，如果新的样本值在训练样本中没有出现过，则无法分类。</div><div class="t m0 x3 h12 y356 ff5 fs8 fc0 sc0 ls0 ws0">3.3.4<span class="_ _34"> </span><span class="ff9">朴素贝叶斯算法的不同方法</span></div><div class="t m0 x3 h6 y357 ff1 fs2 fc0 sc0 ls0 ws0">在<span class="ff3">3.3.2</span>节中，说了后验概率<span class="_ _a"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x45 hb y358 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x145 h6 y357 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _9"> </span><span class="ff1">的估计。<span class="_ _2e"></span>（朴素）贝叶斯分类器的核心就<span class="_ _1e"></span>是<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></span></span></span></div><div class="t m0 xec hb y358 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xf6 h6 y357 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _9"> </span><span class="ff1">的估计，</span></span></span></div><div class="t m0 x3 h6 y359 ff1 fs2 fc0 sc0 ls0 ws0">根据对<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></div><div class="t m0 xcf hb y35a ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xdc h6 y359 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _9"> </span><span class="ff1">假定的概率分布的不同，朴素贝叶斯会分为三种情况：</span></span></span></div><div class="t m0 x9a h6 y35b ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff1">二分类任务，<span class="ffa">x<span class="_ _25"> </span></span>取值离散且有限：假定<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></span></div><div class="t m0 x134 hb y35c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x91 h6 y35b fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _9"> </span><span class="ff1">服从二项分布</span></span></span></div><div class="t m0 x9a h6 y35d ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff1">多分类任务，<span class="ffa">x<span class="_ _25"> </span></span>取值离散且有限：假定<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></span></div><div class="t m0 x134 hb y35e ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x91 h6 y35d fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _9"> </span><span class="ff1">服从多项分布</span></span></span></div><div class="t m0 x9a h6 y35f ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _4"> </span><span class="ff1">当<span class="_ _25"> </span><span class="ffa">x<span class="_ _9"> </span></span>的取值是连续时</span>:<span class="_ _9"> </span><span class="ff1">假定<span class="_ _9"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></span></div><div class="t m0 xb3 hb y360 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x105 h6 y35f fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)<span class="_ _9"> </span><span class="ff1">服从正态分布</span></span></span></div><div class="t m0 x1e h6 y361 ff1 fs2 fc0 sc0 ls0 ws0">注意，<span class="_ _22"></span>分类的数目永远是有限的，<span class="_ _22"></span><span class="ffa">x<span class="_ _25"> </span><span class="ff1">的分布是<span class="_ _9"> </span></span>x<span class="_ _25"> </span><span class="ff1">取值的概率分布，<span class="_ _22"></span>并不是<span class="_ _9"> </span><span class="ffa">x<span class="_ _25"> </span></span>分类的概率分</span></span></div><div class="t m0 x1e h6 y362 ff1 fs2 fc0 sc0 ls0 ws0">布。<span class="_ _31"></span>例如：<span class="_ _22"></span>在文本分类中，<span class="_ _22"></span><span class="ffa">x</span></div><div class="t m0 x11b hb y363 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x45 h6 y362 ff1 fs2 fc0 sc0 ls0 ws0">一般是<span class="ff4">词的出现次数</span>，<span class="_ _22"></span>如果是二分类，<span class="_ _22"></span><span class="ffa">x</span></div><div class="t m0 x126 hb y363 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13d h6 y362 ff1 fs2 fc0 sc0 ls0 ws0">的取值集合为<span class="_ _25"> </span><span class="ffb">0<span class="ffa">,<span class="_ _2c"> </span></span>1</span>，</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">23</div><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",170.68,101.19,null]'><div class="d m1" style="border-style:none;position:absolute;left:657.966000px;bottom:991.123500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",70.87,284.96,null]'><div class="d m1" style="border-style:none;position:absolute;left:188.643000px;bottom:970.800000px;width:13.941000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf1b" data-dest-detail='[27,"XYZ",70.87,531.57,null]'><div class="d m1" style="border-style:none;position:absolute;left:122.662500px;bottom:250.965000px;width:22.429000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1d" class="pf w0 h0" data-page-no="1d"><div class="pc pc1d w0 h0"><img class="bi x3 y364 w2 h2b" alt="" src="bg1d.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.4<span class="_ _d"> </span>PYTHON<span class="_ _2f"> </span><span class="ff8">示例</span></div><div class="t m0 x1e h6 y365 ff1 fs2 fc0 sc0 ls0 ws0">也就是<span class="ff4">词的出现次数</span>服从二项分布。</div><div class="t m0 x1e h6 y366 ff1 fs2 fc0 sc0 ls0 ws0">伯努<span class="_ _1e"></span>利朴<span class="_ _1e"></span>素贝<span class="_ _1e"></span>叶斯<span class="_ _1e"></span>不是<span class="_ _1e"></span>只能<span class="_ _1e"></span>用在<span class="_ _1e"></span>二分<span class="_ _1e"></span>类的<span class="_ _1e"></span>任务，<span class="_ _1e"></span>多分<span class="_ _1e"></span>类的<span class="_ _1e"></span>任务<span class="_ _1e"></span>也可<span class="_ _1e"></span>以，因<span class="_ _1e"></span>为根<span class="_ _1e"></span>据<span class="_ _12"> </span><span class="ffa">P<span class="_ _29"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x146 hb y367 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x32 h4 y366 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">c<span class="ffb">)</span></span></div><div class="t m0 x1e h6 y368 ff1 fs2 fc0 sc0 ls0 ws0">服从二项分布假定得到的只是一类的后验概率估计。<span class="_ _e"></span>预测分类需要比较各类的后验概率大</div><div class="t m0 x1e h6 y369 ff1 fs2 fc0 sc0 ls0 ws0">小。</div><div class="t m0 x1e h6 y36a ff1 fs2 fc0 sc0 ls0 ws0">多项<span class="_ _1e"></span>式朴<span class="_ _1e"></span>素<span class="_ _1e"></span>贝叶<span class="_ _1e"></span>斯<span class="_ _1e"></span>只适<span class="_ _1e"></span>合用<span class="_ _1e"></span>来<span class="_ _1e"></span>对非<span class="_ _1e"></span>负离<span class="_ _1e"></span>散<span class="_ _1e"></span>数值<span class="_ _1e"></span>特征<span class="_ _1e"></span>进<span class="_ _1e"></span>行分<span class="_ _1e"></span>类，典<span class="_ _1e"></span>型<span class="_ _1e"></span>的例<span class="_ _12"> </span>子<span class="_ _1e"></span>就<span class="_ _1e"></span>是对<span class="_ _1e"></span>转<span class="_ _1e"></span>化为</div><div class="t m0 x1e h6 y36b ff1 fs2 fc0 sc0 ls0 ws0">向量后的文本数据进行分类。</div><div class="t m0 xa h6 y36c ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">3.1:<span class="_ _1c"> </span></span>伯努利朴素贝叶斯</div><div class="t m0 x3 h25 y36d ff8 fs2 fc0 sc0 ls0 ws0">如图：二项分布的概率密度，横轴可以是一个单词的出现次数。</div><div class="t m0 x2 h9 y36e ff5 fs6 fc0 sc0 ls0 ws0">3.4<span class="_ _1f"> </span>p<span class="_ _2d"></span>ython<span class="_ _7"> </span><span class="ff9">示例</span></div><div class="t m0 x3 h12 y36f ff5 fs8 fc0 sc0 ls0 ws0">3.4.1<span class="_ _34"> </span><span class="ff9">伯努利朴素贝叶斯的示例</span></div><div class="t m0 x3 h2c y370 ff1d fs2 fc0 sc0 ls0 ws0">my_string <span class="fc3">= <span class="fc4">&apos;¥ § ß Ğ Ð Ñ Ö þ ø&apos;</span></span></div><div class="t m0 x3 h2d y371 ff1e fs2 fc5 sc0 ls0 ws0">&gt;&gt;&gt; <span class="fc6">import <span class="fc7">numpy </span>as <span class="fc7">np</span></span></div><div class="t m0 x3 h2d y372 ff1e fs2 fc5 sc0 ls0 ws0">&gt;&gt;&gt; <span class="fc6">import <span class="fc7">matplotlib.pyplot </span>as <span class="fc7">plt</span></span></div><div class="t m0 x3 h2c y373 ff1e fs2 fc5 sc0 ls0 ws0">&gt;&gt;&gt; <span class="ff1d fc0">plt<span class="fc3">.</span>figure()</span></div><div class="t m0 x3 h2c y374 ff1d fs2 fc8 sc0 ls0 ws0">&lt;Figure size 640x480 with 0 Axes&gt;</div><div class="t m0 x3 h2c y375 ff1e fs2 fc5 sc0 ls0 ws0">&gt;&gt;&gt; <span class="ff1d fc0">plt<span class="fc3">.</span>plot([<span class="fc3">1</span>,<span class="fc3">2</span>,<span class="fc3">3</span>],[<span class="fc3">1</span>,<span class="fc3">2</span>,<span class="fc3">3</span>])</span></div><div class="t m0 x3 h2c y376 ff1d fs2 fc8 sc0 ls0 ws0">[&lt;matplotlib.lines.Line2D object at 0x0000021511382320&gt;]</div><div class="t m0 x3 h2c y377 ff1e fs2 fc5 sc0 ls0 ws0">&gt;&gt;&gt; <span class="ff1d fc0">plt<span class="fc3">.</span>show()</span></div><div class="t m0 x3 h2c y378 ff1d fs2 fc0 sc0 ls0 ws0">X = np.array([[0,1,0,1],</div><div class="t m0 x3 h2c y379 ff1d fs2 fc0 sc0 ls0 ws0">[1,1,1,0],</div><div class="t m0 x3 h2c y37a ff1d fs2 fc0 sc0 ls0 ws0">[0,1,1,0],</div><div class="t m0 x3 h2c y37b ff1d fs2 fc0 sc0 ls0 ws0">[0,0,0,1],</div><div class="t m0 x3 h2c y37c ff1d fs2 fc0 sc0 ls0 ws0">[0,1,1,0],</div><div class="t m0 x3 h2c y37d ff1d fs2 fc0 sc0 ls0 ws0">[0,1,0,1],</div><div class="t m0 x3 h2c y37e ff1d fs2 fc0 sc0 ls0 ws0">[1,0,0,1]])</div><div class="t m0 x3 h6 y37f ff1d fs2 fc0 sc0 ls0 ws0"># y<span class="_ _1e"></span><span class="ff7">是<span class="_ _26"></span></span>X<span class="_ _26"></span><span class="ff7">的<span class="_ _2b"></span>标<span class="_ _2b"></span>签</span></div><div class="t m0 x3 h2c y380 ff1d fs2 fc0 sc0 ls0 ws0">y = np.array([0,1,1,0,1,0,0])</div><div class="t m0 x3 h2c y1c7 ff1d fs2 fc0 sc0 ls0 ws0">counts={}</div><div class="t m0 x3 h2c y1e ff1d fs2 fc0 sc0 ls0 ws0">for label in np.unique(y):</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">24</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1e" class="pf w0 h0" data-page-no="1e"><div class="pc pc1e w0 h0"><div class="t m0 x147 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.4<span class="_ _d"> </span>PYTHON<span class="_ _2f"> </span><span class="ff8">示例</span></div><div class="t m0 x3 h2c y20 ff1d fs2 fc0 sc0 ls0 ws0">counts[label]=X[y==label].sum(axis=0)</div><div class="t m0 x3 h2c y381 ff1d fs2 fc0 sc0 ls0 ws0">print(&quot;feature counts:\n{}&quot;.format(counts))</div><div class="t m0 x3 h2c y382 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.naive_bayes import BernoulliNB</div><div class="t m0 x3 h2c y383 ff1d fs2 fc0 sc0 ls0 ws0">clf = BernoulliNB()</div><div class="t m0 x3 h2c y384 ff1d fs2 fc0 sc0 ls0 ws0">clf.fit(X,y)</div><div class="t m0 x3 h2c y385 ff1d fs2 fc0 sc0 ls0 ws0">Next_day = [[0,0,1,0]]</div><div class="t m0 x3 h2c y386 ff1d fs2 fc0 sc0 ls0 ws0">pre = clf.predict(Next_day)</div><div class="t m0 x3 h2c y387 ff1d fs2 fc0 sc0 ls0 ws0">clf.predict_proba(Next_day)</div><div class="t m0 x3 h12 y388 ff5 fs8 fc0 sc0 ls0 ws0">3.4.2<span class="_ _34"> </span><span class="ff9">对比</span></div><div class="t m0 x3 h6 y389 ff1 fs2 fc0 sc0 ls0 ws0">先尝试用伯努利贝叶斯进行分类，看看效果。</div><div class="t m0 x3 h2c y38a ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.datasets import make_blobs</div><div class="t m0 x3 h2c y38b ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.model_selection import train_test_split</div><div class="t m0 x3 h2c y38c ff1d fs2 fc0 sc0 ls0 ws0">X,y = make_blobs(n_samples=500,centers = 5, random_state = 2)</div><div class="t m0 x3 h6 y38d ff1d fs2 fc0 sc0 ls0 ws0"># centers=5<span class="_ _4d"> </span><span class="ff7">分<span class="_ _1e"></span></span>5<span class="_ _26"></span><span class="ff7">类</span></div><div class="t m0 x3 h6 y38e ff1d fs2 fc0 sc0 ls0 ws0"># random_state<span class="_ _4d"> </span><span class="ff7">随<span class="_ _2b"></span>机<span class="_ _2b"></span>数<span class="_ _2b"></span>种<span class="_ _2b"></span>子</span></div><div class="t m0 x3 h2c y38f ff1d fs2 fc0 sc0 ls0 ws0">nb = BernoulliNB()</div><div class="t m0 x3 h6 y390 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff7">把<span class="_ _2b"></span>样<span class="_ _2b"></span>本<span class="_ _2b"></span>拆<span class="_ _2b"></span>分<span class="_ _2b"></span>为<span class="_ _2b"></span>训<span class="_ _2b"></span>练<span class="_ _26"></span>集<span class="_ _2b"> </span>和<span class="_ _2b"> </span>测<span class="_ _2b"></span>试<span class="_ _2b"></span>集</span></div><div class="t m0 x3 h2c y391 ff1d fs2 fc0 sc0 ls0 ws0">X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=2)</div><div class="t m0 x3 h2c y392 ff1d fs2 fc0 sc0 ls0 ws0">nb.fit(X_train,y_train)</div><div class="t m0 x3 h6 y393 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff7">模<span class="_ _2b"></span>型<span class="_ _2b"></span>得<span class="_ _2b"></span>分</span></div><div class="t m0 x3 h2c y394 ff1d fs2 fc0 sc0 ls0 ws0">nb.score(X_test,y_test)</div><div class="t m0 x3 h2c y395 ff1d fs2 fc0 sc0 ls0 ws0">nb.predict(X_test)</div><div class="t m0 x3 h6 y396 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">导<span class="_ _2b"> </span>入<span class="_ _2b"> </span>画<span class="_ _2b"></span>图<span class="_ _2b"></span>工<span class="_ _2b"></span>具</span></div><div class="t m0 x3 h2c y397 ff1d fs2 fc0 sc0 ls0 ws0">import matplotlib.pyplot as plt</div><div class="t m0 x3 h6 y398 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">限<span class="_ _2b"> </span>定<span class="_ _2b"> </span>横<span class="_ _2b"></span>轴<span class="_ _2b"></span>与<span class="_ _2b"></span>纵<span class="_ _2b"></span>轴<span class="_ _2b"></span>的<span class="_ _2b"></span>最<span class="_ _2b"></span>大<span class="_ _2b"></span>值</span></div><div class="t m0 x3 h2c y399 ff1d fs2 fc0 sc0 ls0 ws0">x_min, x_max = X[:,0].min()-0.5, X[:,0].max()+0.5</div><div class="t m0 x3 h2c y39a ff1d fs2 fc0 sc0 ls0 ws0">y_min, y_max = X[:,1].min()-0.5, X[:,1].max()+0.5</div><div class="t m0 x3 h6 y39b ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">用<span class="_ _2b"> </span>不<span class="_ _2b"> </span>同<span class="_ _2b"></span>的<span class="_ _2b"></span>背<span class="_ _2b"></span>景<span class="_ _2b"></span>色<span class="_ _2b"></span>表<span class="_ _2b"></span>示<span class="_ _2b"></span>不<span class="_ _2b"></span>同<span class="_ _2b"></span>的<span class="_ _2b"></span>分<span class="_ _2b"></span>类</span></div><div class="t m0 x3 h2c y39c ff1d fs2 fc0 sc0 ls0 ws0">xx,yy = np.meshgrid(np.arange(x_min, x_max,.02),</div><div class="t m0 x3 h2c y39d ff1d fs2 fc0 sc0 ls0 ws0">np.arange(y_min, y_max, .02))</div><div class="t m0 x3 h2c y378 ff1d fs2 fc0 sc0 ls0 ws0">np.arange(x_min, x_max,.02).shape</div><div class="t m0 x3 h2c y37a ff1d fs2 fc0 sc0 ls0 ws0">z = nb.predict(np.c_[(xx.ravel(),yy.ravel())]).reshape(xx.shape)</div><div class="t m0 x3 h2c y37e ff1d fs2 fc0 sc0 ls0 ws0">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</div><div class="t m0 x3 h6 y37f ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">将<span class="_ _2b"> </span>训<span class="_ _2b"> </span>练<span class="_ _2b"></span>集<span class="_ _2b"></span>和<span class="_ _2b"></span>测<span class="_ _2b"></span>试<span class="_ _2b"></span>集<span class="_ _2b"></span>用<span class="_ _2b"></span>散<span class="_ _2b"></span>点<span class="_ _2b"></span>图<span class="_ _2b"></span>表<span class="_ _2b"></span>示</span></div><div class="t m0 x3 h2c y380 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap=plt.cm.cool,edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h2c y39e ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_test[:,0],X_test[:,1],c=y_test,cmap=plt.cm.cool,marker=&apos;*&apos;,</div><div class="t m0 x3 h2c y1c7 ff1d fs2 fc0 sc0 ls0 ws0">edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h2c y1e ff1d fs2 fc0 sc0 ls0 ws0">plt.xlim(xx.min(),xx.max())</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">25</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf1f" class="pf w0 h0" data-page-no="1f"><div class="pc pc1f w0 h0"><img class="bi x17 y39f wd h2e" alt="" src="bg1f.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.4<span class="_ _d"> </span>PYTHON<span class="_ _2f"> </span><span class="ff8">示例</span></div><div class="t m0 x3 h2c y20 ff1d fs2 fc0 sc0 ls0 ws0">plt.ylim(yy.min(),yy.max())</div><div class="t m0 x3 h6 y1c9 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">定<span class="_ _2b"> </span>义<span class="_ _2b"> </span>图<span class="_ _2b"></span>题</span></div><div class="t m0 x3 h2c y381 ff1d fs2 fc0 sc0 ls0 ws0">plt.title(&apos;Classiﬁer: BernoulliNB&apos;)</div><div class="t m0 x3 h6 y3a0 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">现<span class="_ _2b"> </span>实<span class="_ _2b"> </span>图<span class="_ _2b"></span>片</span></div><div class="t m0 x3 h2c y382 ff1d fs2 fc0 sc0 ls0 ws0">plt.show()</div><div class="t m0 x8e h6 y3a1 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">3.2:</span></div><div class="t m0 x3 h6 y3a2 ff1 fs2 fc0 sc0 ls0 ws0">再使用高斯朴素贝叶斯。</div><div class="t m0 x3 h6 y3a3 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">导<span class="_ _2b"> </span>入<span class="_ _2b"> </span>高<span class="_ _2b"></span>斯<span class="_ _2b"></span>贝<span class="_ _2b"></span>叶<span class="_ _2b"></span>斯</span></div><div class="t m0 x3 h2c y3a4 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.naive_bayes import GaussianNB</div><div class="t m0 x3 h6 y3a5 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">使<span class="_ _2b"> </span>用<span class="_ _2b"> </span>高<span class="_ _2b"></span>斯<span class="_ _2b"></span>贝<span class="_ _2b"></span>叶<span class="_ _2b"></span>斯<span class="_ _2b"></span>拟<span class="_ _2b"></span>合<span class="_ _2b"></span>数<span class="_ _2b"></span>据</span></div><div class="t m0 x3 h2c y3a6 ff1d fs2 fc0 sc0 ls0 ws0">gnb = GaussianNB()</div><div class="t m0 x3 h2c y3a7 ff1d fs2 fc0 sc0 ls0 ws0">gnb.ﬁt(X_train, y_train)</div><div class="t m0 x3 h2c y3a8 ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n\n\n&apos;)</div><div class="t m0 x3 h6 y3a9 ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;<span class="_ _1e"></span><span class="ff7">代<span class="_ _2b"> </span>码<span class="_ _2b"> </span>运<span class="_ _2b"></span>行<span class="_ _2b"></span>结<span class="_ _2b"></span>果<span class="_ _2b"></span>：<span class="_ _26"></span></span>&apos;)</div><div class="t m0 x3 h2c y3aa ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;==============================\n&apos;)</div><div class="t m0 x3 h6 y3ab ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">打<span class="_ _2b"> </span>印<span class="_ _2b"> </span>模<span class="_ _2b"></span>型<span class="_ _2b"></span>得<span class="_ _2b"></span>分</span></div><div class="t m0 x3 h6 y3ac ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;<span class="_ _1e"></span><span class="ff7">模<span class="_ _2b"> </span>型<span class="_ _2b"> </span>得<span class="_ _2b"></span>分<span class="_ _2b"></span>：<span class="_ _26"></span></span>{:.3f}&apos;.format(gnb.score(X_test, y_test)))</div><div class="t m0 x3 h2c y3ad ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n==============================&apos;)</div><div class="t m0 x3 h2c y3ae ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n\n\n&apos;)</div><div class="t m0 x3 h6 y3af ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">用<span class="_ _2b"> </span>不<span class="_ _2b"> </span>同<span class="_ _2b"></span>色<span class="_ _2b"></span>块<span class="_ _2b"></span>来<span class="_ _2b"></span>表<span class="_ _2b"></span>示<span class="_ _2b"></span>不<span class="_ _2b"></span>同<span class="_ _2b"></span>的<span class="_ _2b"></span>分<span class="_ _2b"></span>类</span></div><div class="t m0 x3 h2c y3b0 ff1d fs2 fc0 sc0 ls0 ws0">z = gnb.predict(np.c_[(xx.ravel(),yy.ravel())]).reshape(xx.shape)</div><div class="t m0 x3 h2c y3b1 ff1d fs2 fc0 sc0 ls0 ws0">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</div><div class="t m0 x3 h6 y3b2 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">用<span class="_ _2b"> </span>散<span class="_ _2b"> </span>点<span class="_ _2b"></span>图<span class="_ _2b"></span>画<span class="_ _2b"></span>出<span class="_ _2b"></span>训<span class="_ _2b"></span>练<span class="_ _2b"></span>集<span class="_ _2b"></span>和<span class="_ _2b"></span>测<span class="_ _2b"></span>试<span class="_ _2b"></span>集<span class="_ _2b"></span>数<span class="_ _4e"></span>据</span></div><div class="t m0 x3 h2c y3b3 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap=plt.cm.cool,edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h2c y3b4 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_test[:,0],X_test[:,1],c=y_test,cmap=plt.cm.cool,marker=&apos;*&apos;,</div><div class="t m0 x3 h2c y3b5 ff1d fs2 fc0 sc0 ls0 ws0">edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h6 y3b6 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">设<span class="_ _2b"> </span>定<span class="_ _2b"> </span>横<span class="_ _2b"></span>轴<span class="_ _2b"></span>纵<span class="_ _2b"></span>轴<span class="_ _2b"></span>的<span class="_ _2b"></span>范<span class="_ _4e"></span>围</span></div><div class="t m0 x3 h2c y3b7 ff1d fs2 fc0 sc0 ls0 ws0">plt.xlim(xx.min(),xx.max())</div><div class="t m0 x3 h2c y3b8 ff1d fs2 fc0 sc0 ls0 ws0">plt.ylim(yy.min(),yy.max())</div><div class="t m0 x3 h6 y3b9 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">设<span class="_ _2b"> </span>定<span class="_ _2b"> </span>图<span class="_ _2b"></span>题</span></div><div class="t m0 x3 h2c y3ba ff1d fs2 fc0 sc0 ls0 ws0">plt.title(&apos;Classiﬁ er: GaussianNB&apos;)</div><div class="t m0 x3 h6 y3bb ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">画<span class="_ _2b"> </span>出<span class="_ _2b"> </span>图<span class="_ _2b"></span>形</span></div><div class="t m0 x3 h2c y3bc ff1d fs2 fc0 sc0 ls0 ws0">plt.show()</div><div class="t m0 x3 h6 y3bd ff1 fs2 fc0 sc0 ls0 ws0">最后使用多项式朴素贝叶斯</div><div class="t m0 x3 h2c y1e ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">26</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf20" class="pf w0 h0" data-page-no="20"><div class="pc pc20 w0 h0"><img class="bi x17 y3be wd h2e" alt="" src="bg20.png"/><div class="t m0 x147 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.4<span class="_ _d"> </span>PYTHON<span class="_ _2f"> </span><span class="ff8">示例</span></div><div class="t m0 x8e h6 y3bf ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">3.3:</span></div><div class="t m0 x3 h6 y3c0 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff7">下<span class="_ _4e"></span>面<span class="_ _2b"> </span>这<span class="_ _2b"> </span>段<span class="_ _2b"></span>代<span class="_ _2b"></span>码<span class="_ _2b"></span>和<span class="_ _2b"></span>我<span class="_ _2b"></span>们<span class="_ _4e"></span>使<span class="_ _2b"> </span>用<span class="_ _2b"></span>贝<span class="_ _2b"></span>努<span class="_ _2b"></span>利<span class="_ _2b"></span>朴<span class="_ _2b"></span>素<span class="_ _4e"></span>贝<span class="_ _2b"> </span>叶<span class="_ _2b"> </span>斯<span class="_ _2b"></span>或<span class="_ _2b"></span>是<span class="_ _2b"></span>高<span class="_ _2b"></span>斯<span class="_ _2b"></span>朴<span class="_ _4e"></span>素<span class="_ _2b"> </span>贝<span class="_ _2b"></span>叶<span class="_ _2b"></span>斯<span class="_ _2b"></span>看<span class="_ _2b"></span>起<span class="_ _2b"></span>来<span class="_ _4e"></span>没<span class="_ _2b"> </span>有<span class="_ _2b"> </span>什<span class="_ _2b"></span>么<span class="_ _2b"></span>区<span class="_ _2b"></span>别<span class="_ _2b"></span>，</span></div><div class="t m0 x3 h6 y3c1 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff7">但<span class="_ _4e"></span>是<span class="_ _2b"> </span>这<span class="_ _2b"> </span>样<span class="_ _2b"></span>使<span class="_ _2b"></span>用<span class="_ _2b"></span>多<span class="_ _2b"></span>项<span class="_ _2b"></span>式<span class="_ _4e"></span>朴<span class="_ _2b"> </span>素<span class="_ _2b"></span>贝<span class="_ _2b"></span>叶<span class="_ _2b"></span>斯<span class="_ _2b"></span>是<span class="_ _2b"></span>错<span class="_ _4e"></span>误<span class="_ _2b"> </span>的<span class="_ _2b"> </span>。</span></div><div class="t m0 x3 h6 y3c2 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff7">提<span class="_ _4e"></span>示<span class="_ _2b"> </span>信<span class="_ _2b"> </span>息<span class="_ _2b"></span>告<span class="_ _2b"></span>诉<span class="_ _2b"></span>我<span class="_ _2b"></span>们<span class="_ _2b"></span>，<span class="_ _4e"></span>输<span class="_ _2b"> </span>入<span class="_ _2b"></span>的<span class="_ _4d"> </span></span>X<span class="_ _4d"> </span><span class="ff7">值<span class="_ _2b"> </span>必<span class="_ _2b"></span>须<span class="_ _2b"></span>是<span class="_ _2b"></span>非<span class="_ _2b"></span>负<span class="_ _4e"></span>的<span class="_ _2b"> </span>，<span class="_ _2b"> </span>这<span class="_ _2b"></span>样<span class="_ _2b"></span>的<span class="_ _2b"></span>话<span class="_ _2b"></span>，<span class="_ _2b"></span>我<span class="_ _4e"></span>们<span class="_ _2b"> </span>需<span class="_ _2b"></span>要<span class="_ _2b"></span>对<span class="_ _2b"></span>数<span class="_ _2b"></span>据<span class="_ _2b"></span>进<span class="_ _4e"></span>行<span class="_ _2b"> </span>一<span class="_ _2b"> </span>下<span class="_ _2b"></span>预<span class="_ _2b"></span>处<span class="_ _2b"></span>理<span class="_ _2b"></span>才<span class="_ _2b"></span>行<span class="_ _4e"></span>。</span></div><div class="t m0 x3 h2c y38a ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y38b ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">导<span class="_ _2b"> </span>入<span class="_ _2b"> </span>多<span class="_ _2b"></span>项<span class="_ _2b"></span>式<span class="_ _2b"></span>朴<span class="_ _2b"></span>素<span class="_ _2b"></span>贝<span class="_ _4e"></span>叶<span class="_ _2b"> </span>斯</span></div><div class="t m0 x3 h2c y3c3 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.naive_bayes import MultinomialNB</div><div class="t m0 x3 h6 y38c ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">用<span class="_ _2b"> </span>多<span class="_ _2b"> </span>项<span class="_ _2b"></span>式<span class="_ _2b"></span>朴<span class="_ _2b"></span>素<span class="_ _2b"></span>贝<span class="_ _2b"></span>叶<span class="_ _4e"></span>斯<span class="_ _2b"> </span>拟<span class="_ _2b"></span>合<span class="_ _2b"></span>数<span class="_ _2b"></span>据</span></div><div class="t m0 x3 h2c y38d ff1d fs2 fc0 sc0 ls0 ws0">mnb = MultinomialNB()</div><div class="t m0 x3 h2c y38e ff1d fs2 fc0 sc0 ls0 ws0">mnb.ﬁt(X_train, y_train)</div><div class="t m0 x3 h2c y38f ff1d fs2 fc0 sc0 ls0 ws0">mnb.score(X_test, y_test)</div><div class="t m0 x3 h2c y3c4 ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y392 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff7">非<span class="_ _4e"></span>负<span class="_ _2b"> </span>处<span class="_ _2b"> </span>理</span></div><div class="t m0 x3 h2c y3c5 ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y394 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">导<span class="_ _2b"> </span>入<span class="_ _2b"> </span>多<span class="_ _2b"></span>项<span class="_ _2b"></span>式<span class="_ _2b"></span>朴<span class="_ _2b"></span>素<span class="_ _2b"></span>贝<span class="_ _4e"></span>叶<span class="_ _2b"> </span>斯</span></div><div class="t m0 x3 h2c y395 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.naive_bayes import MultinomialNB</div><div class="t m0 x3 h6 y3c6 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">导<span class="_ _2b"> </span>入<span class="_ _2b"> </span>数<span class="_ _2b"></span>据<span class="_ _2b"></span>预<span class="_ _2b"></span>处<span class="_ _2b"></span>理<span class="_ _2b"></span>工<span class="_ _4e"></span>具<span class="_ _26"></span></span>MinMaxScaler</div><div class="t m0 x3 h2c y3c7 ff1d fs2 fc0 sc0 ls0 ws0">from sklearn.preprocessing import MinMaxScaler</div><div class="t m0 x3 h6 y396 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">使<span class="_ _2b"> </span>用<span class="_ _26"></span></span>MinMaxScaler<span class="_ _26"></span><span class="ff7">对<span class="_ _2b"></span>数<span class="_ _2b"></span>据<span class="_ _4e"></span>进<span class="_ _2b"> </span>行<span class="_ _2b"> </span>预<span class="_ _2b"></span>处<span class="_ _2b"></span>理<span class="_ _2b"></span>，<span class="_ _2b"></span>使<span class="_ _4e"></span>数<span class="_ _2b"> </span>据<span class="_ _2b"> </span>全<span class="_ _2b"></span>部<span class="_ _2b"></span>为<span class="_ _2b"></span>非<span class="_ _2b"></span>负<span class="_ _2b"></span>值</span></div><div class="t m0 x3 h2c y397 ff1d fs2 fc0 sc0 ls0 ws0">scaler = MinMaxScaler()</div><div class="t m0 x3 h2c y3c8 ff1d fs2 fc0 sc0 ls0 ws0">scaler.ﬁt(X_train)</div><div class="t m0 x3 h2c y398 ff1d fs2 fc0 sc0 ls0 ws0">X_train_scaled = scaler.transform(X_train)</div><div class="t m0 x3 h2c y399 ff1d fs2 fc0 sc0 ls0 ws0">X_test_scaled = scaler.transform(X_test)</div><div class="t m0 x3 h6 y39a ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">使<span class="_ _2b"> </span>用<span class="_ _2b"> </span>多<span class="_ _2b"></span>项<span class="_ _2b"></span>式<span class="_ _2b"></span>朴<span class="_ _2b"></span>素<span class="_ _2b"></span>贝<span class="_ _4e"></span>叶<span class="_ _2b"> </span>斯<span class="_ _2b"></span>拟<span class="_ _2b"></span>合<span class="_ _2b"></span>经<span class="_ _2b"></span>过<span class="_ _2b"></span>预<span class="_ _4e"></span>处<span class="_ _2b"> </span>理<span class="_ _2b"> </span>之<span class="_ _2b"></span>后<span class="_ _2b"></span>的<span class="_ _2b"></span>数<span class="_ _2b"></span>据</span></div><div class="t m0 x3 h2c y39b ff1d fs2 fc0 sc0 ls0 ws0">mnb = MultinomialNB()</div><div class="t m0 x3 h2c y39c ff1d fs2 fc0 sc0 ls0 ws0">mnb.ﬁt(X_train_scaled, y_train)</div><div class="t m0 x3 h2c y39d ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n\n\n&apos;)</div><div class="t m0 x3 h6 y378 ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;<span class="_ _1e"></span><span class="ff7">代<span class="_ _2b"> </span>码<span class="_ _2b"> </span>运<span class="_ _2b"></span>行<span class="_ _2b"></span>结<span class="_ _2b"></span>果<span class="_ _2b"></span>：<span class="_ _26"></span></span>&apos;)</div><div class="t m0 x3 h2c y379 ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;==============================\n&apos;)</div><div class="t m0 x3 h6 y37a ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">打<span class="_ _2b"> </span>印<span class="_ _2b"> </span>模<span class="_ _2b"></span>型<span class="_ _2b"></span>得<span class="_ _2b"></span>分</span></div><div class="t m0 x3 h6 y37b ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;<span class="_ _1e"></span><span class="ff7">模<span class="_ _2b"> </span>型<span class="_ _2b"> </span>得<span class="_ _2b"></span>分<span class="_ _2b"></span>：<span class="_ _26"></span></span>{:.3f}&apos;.format(mnb.score(X_test_scaled, y_test)))</div><div class="t m0 x3 h2c y37c ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n==============================&apos;)</div><div class="t m0 x3 h2c y37d ff1d fs2 fc0 sc0 ls0 ws0">print(&apos;\n\n\n&apos;)</div><div class="t m0 x3 h2c y380 ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 x3 h6 y39e ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _4d"> </span><span class="ff7">如<span class="_ _4e"></span>果<span class="_ _2b"> </span>我<span class="_ _2b"> </span>们<span class="_ _2b"></span>用<span class="_ _2b"></span>图<span class="_ _2b"></span>形<span class="_ _2b"></span>来<span class="_ _2b"></span>表<span class="_ _4e"></span>示<span class="_ _2b"> </span>的<span class="_ _2b"></span>话<span class="_ _2b"></span>，<span class="_ _2b"></span>也<span class="_ _2b"></span>可<span class="_ _2b"></span>以<span class="_ _4e"></span>直<span class="_ _2b"> </span>观<span class="_ _2b"> </span>地<span class="_ _2b"></span>看<span class="_ _2b"></span>出<span class="_ _2b"></span>多<span class="_ _2b"></span>项<span class="_ _2b"></span>式<span class="_ _4e"></span>朴<span class="_ _2b"> </span>素<span class="_ _2b"></span>贝<span class="_ _2b"></span>叶<span class="_ _2b"></span>斯<span class="_ _2b"></span>并<span class="_ _2b"></span>不<span class="_ _4e"></span>适<span class="_ _2b"> </span>合<span class="_ _2b"> </span>用<span class="_ _2b"></span>来<span class="_ _2b"></span>拟<span class="_ _2b"></span>合<span class="_ _2b"></span>这<span class="_ _4e"></span>个<span class="_ _2b"> </span>数<span class="_ _2b"> </span>据<span class="_ _2b"></span>集</span></div><div class="t m0 x3 h2c y1c7 ff1d fs2 fc0 sc0 ls0 ws0"># =============================================================================</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">27</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf21" class="pf w0 h0" data-page-no="21"><div class="pc pc21 w0 h0"><img class="bi x17 y3c9 wd h2e" alt="" src="bg21.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">3.4<span class="_ _d"> </span>PYTHON<span class="_ _2f"> </span><span class="ff8">示例</span></div><div class="t m0 x3 h6 y20 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">用<span class="_ _2b"> </span>不<span class="_ _2b"> </span>同<span class="_ _2b"></span>颜<span class="_ _2b"></span>色<span class="_ _2b"></span>区<span class="_ _2b"></span>分<span class="_ _2b"></span>不<span class="_ _4e"></span>同<span class="_ _2b"> </span>的<span class="_ _2b"></span>分<span class="_ _2b"></span>类</span></div><div class="t m0 x3 h2c y1c9 ff1d fs2 fc0 sc0 ls0 ws0">z = mnb.predict(np.c_[(xx.ravel(),yy.ravel())]).reshape(xx.shape)</div><div class="t m0 x3 h2c y381 ff1d fs2 fc0 sc0 ls0 ws0">plt.pcolormesh(xx,yy,z,cmap=plt.cm.Pastel1)</div><div class="t m0 x3 h6 y3a0 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">用<span class="_ _2b"> </span>散<span class="_ _2b"> </span>点<span class="_ _2b"></span>图<span class="_ _2b"></span>表<span class="_ _2b"></span>示<span class="_ _2b"></span>训<span class="_ _2b"></span>练<span class="_ _4e"></span>集<span class="_ _2b"> </span>和<span class="_ _2b"></span>测<span class="_ _2b"></span>试<span class="_ _2b"></span>集</span></div><div class="t m0 x3 h2c y382 ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_train[:,0],X_train[:,1],c=y_train,cmap=plt.cm.cool,edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h2c y3ca ff1d fs2 fc0 sc0 ls0 ws0">plt.scatter(X_test[:,0],X_test[:,1],c=y_test,cmap=plt.cm.cool,marker=&apos;*&apos;,</div><div class="t m0 x3 h2c y383 ff1d fs2 fc0 sc0 ls0 ws0">edgecolor=&apos;k&apos;)</div><div class="t m0 x3 h6 y384 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">设<span class="_ _2b"> </span>定<span class="_ _2b"> </span>横<span class="_ _2b"></span>纵<span class="_ _2b"></span>轴<span class="_ _2b"></span>范<span class="_ _2b"></span>围</span></div><div class="t m0 x3 h2c y385 ff1d fs2 fc0 sc0 ls0 ws0">plt.xlim(xx.min(),xx.max())</div><div class="t m0 x3 h2c y386 ff1d fs2 fc0 sc0 ls0 ws0">plt.ylim(yy.min(),yy.max())</div><div class="t m0 x3 h6 y387 ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">设<span class="_ _2b"> </span>定<span class="_ _2b"> </span>图<span class="_ _2b"></span>题</span></div><div class="t m0 x3 h2c y3cb ff1d fs2 fc0 sc0 ls0 ws0">plt.title(&apos;Classiﬁ er: MultinomialNB&apos;)</div><div class="t m0 x3 h6 y3cc ff1d fs2 fc0 sc0 ls0 ws0">#<span class="_ _1e"></span><span class="ff7">显<span class="_ _2b"> </span>示<span class="_ _2b"> </span>图<span class="_ _2b"></span>片</span></div><div class="t m0 x3 h2c y3cd ff1d fs2 fc0 sc0 ls0 ws0">plt.show()</div><div class="t m0 x8e h6 y3ce ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">3.4:</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">28</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf22" class="pf w0 h0" data-page-no="22"><div class="pc pc22 w0 h0"><div class="t m0 x45 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第四章 决策树</div><div class="t m0 x46 h4 y3cf ff3 fs2 fc0 sc0 ls0 ws0">Ent<span class="ffb">(<span class="ffa">D<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="fff">−</span></span></div><div class="t m0 x143 ha y3d0 ff12 fs7 fc0 sc0 ls0 ws0">|Y<span class="_ _26"></span>|</div><div class="t m0 xfb he y3d1 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xfb ha y3d2 ffd fs7 fc0 sc0 ls0 ws0">k<span class="ffc">=1</span></div><div class="t m0 x13b hc y3cf ffa fs2 fc0 sc0 ls0 ws0">p</div><div class="t m0 xb1 hb y3d3 ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 xcd h4 y3cf ff3 fs2 fc0 sc0 ls0 ws0">log</div><div class="t m0 x63 ha y3d4 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x64 hc y3cf ffa fs2 fc0 sc0 ls0 ws0">p</div><div class="t m0 xef hb y3d3 ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">29</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf23" class="pf w0 h0" data-page-no="23"><div class="pc pc23 w0 h0"><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">30</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf24" class="pf w0 h0" data-page-no="24"><div class="pc pc24 w0 h0"><div class="t m0 x9 h5 y241 ff4 fs3 fc0 sc0 ls0 ws0">第三部分</div><div class="t m0 xa h5 y242 ff4 fs3 fc0 sc0 ls0 ws0">机器学习高阶</div><div class="t m0 x59 h3 y243 ff7 fs1 fc0 sc0 ls0 ws0">优化方法</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">31</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf25" class="pf w0 h0" data-page-no="25"><div class="pc pc25 w0 h0"></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf26" class="pf w0 h0" data-page-no="26"><div class="pc pc26 w0 h0"><img class="bi xc3 y3d5 w8 h2f" alt="" src="bg26.png"/><div class="t m0 x97 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第五章 梯度下降</div><div class="t m0 x1d h9 y4e ff5 fs6 fc0 sc0 ls0 ws0">5.1<span class="_ _1f"> </span><span class="ff9">梯度下降原理</span></div><div class="t m0 x7 h4 y3d6 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="_ _2f"> </span><span class="fff">≈<span class="_ _2f"> </span></span></span>f<span class="_ _2b"></span><span class="ffb">(</span>θ</div><div class="t m0 xa7 ha y3d7 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xf1 h4 y3d6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span>+<span class="_ _30"> </span>(<span class="ff11">θ<span class="_ _f"> </span><span class="fff">−<span class="_ _30"> </span></span>θ</span></div><div class="t m0 xb1 ha y3d7 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xc0 h4 y3d6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">·<span class="_ _30"> </span><span class="ff20">∇<span class="ff11">f<span class="_ _2b"></span><span class="ff21">(</span>θ</span></span></span></div><div class="t m0 x29 ha y3d7 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x148 h4 y3d6 ff21 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h4 y3d8 ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _f"> </span><span class="fff">−<span class="_ _3e"></span></span>θ</div><div class="t m0 x10b ha y3d9 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xff h6 y3d8 ff1 fs2 fc0 sc0 ls0 ws0">是微小向量，它的大小就是步进长度，<span class="_ _2d"></span>即学习率<span class="_ _9"> </span><span class="ffa">α</span>，<span class="ffa">α<span class="_ _9"> </span></span>是一个标量，而<span class="_ _25"> </span><span class="ff11">θ<span class="_ _f"> </span><span class="fff">−<span class="_ _30"> </span></span>θ</span></div><div class="t m0 xe ha y3d9 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x149 h6 y3d8 ff1 fs2 fc0 sc0 ls0 ws0">的单位向</div><div class="t m0 x3 h6 y3da ff1 fs2 fc0 sc0 ls0 ws0">量用<span class="_ _9"> </span><span class="ff11">v<span class="_ _a"> </span></span>表示，因此<span class="_ _9"> </span><span class="ff11">θ<span class="_ _f"> </span><span class="fff">−<span class="_ _30"> </span></span>θ</span></div><div class="t m0 xdf ha y3db ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xa9 h6 y3da ff1 fs2 fc0 sc0 ls0 ws0">可表示为：</div><div class="t m0 x49 h4 y3dc ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _f"> </span><span class="fff">−<span class="_ _30"> </span></span>θ</div><div class="t m0 x5c ha y3dd ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xf3 h4 y3dc ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">α<span class="ff11">v</span></span></div><div class="t m0 x3 h6 y3de ff1 fs2 fc0 sc0 ls0 ws0">特别需要注意的是，<span class="_ _20"></span><span class="ff11">θ<span class="_ _3e"> </span><span class="fff">−<span class="_ _2c"></span></span>θ</span></div><div class="t m0 x39 ha y3df ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x139 h6 y3de ff1 fs2 fc0 sc0 ls0 ws0">不能太大，<span class="_ _20"></span>因为太大的话，<span class="_ _20"></span>线性近似就不够准确，<span class="_ _20"></span>一阶泰勒近似也不</div><div class="t m0 x3 h6 y3e0 ff1 fs2 fc0 sc0 ls0 ws0">成立了，替换之后，<span class="ffa">f<span class="_ _2b"></span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="_ _9"> </span></span></span>的表达式为：</div><div class="t m0 x1d h4 y3e1 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="_ _2f"> </span><span class="fff">≈<span class="_ _2f"> </span></span></span>f<span class="_ _2b"></span><span class="ffb">(</span>θ</div><div class="t m0 xa0 ha y3e2 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xf0 h4 y3e1 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span>+<span class="_ _30"> </span><span class="ffa">α<span class="ff11">v<span class="_ _f"> </span><span class="fff">·<span class="_ _30"> </span><span class="ff20">∇</span></span>f<span class="_ _2b"> </span><span class="ff21">(</span>θ</span></span></div><div class="t m0 xef ha y3e2 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x28 h4 y3e1 ff21 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y3e3 ff1 fs2 fc0 sc0 ls0 ws0">局部<span class="_ _1e"></span>下<span class="_ _1e"></span>降的<span class="_ _1e"></span>目<span class="_ _1e"></span>的<span class="_ _1e"></span>是希<span class="_ _1e"></span>望<span class="_ _1e"></span>每次<span class="_ _1c"> </span><span class="ffa">θ<span class="_ _1c"> </span></span>更新，<span class="_ _1e"></span>都<span class="_ _1e"></span>能<span class="_ _1e"></span>让函<span class="_ _1e"></span>数<span class="_ _1e"></span>值<span class="_ _12"> </span><span class="ffa">f<span class="_ _2b"> </span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="_ _1c"> </span></span></span>变小。<span class="_ _1e"></span>也<span class="_ _1e"></span>就是<span class="_ _1e"></span>说，<span class="_ _1e"></span>上<span class="_ _1e"></span>式中，<span class="_ _1e"></span>我<span class="_ _1e"></span>们希<span class="_ _1e"></span>望</div><div class="t m0 x3 h4 y3e4 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="_ _2f"> </span><span class="fff">≤<span class="_ _2f"> </span></span></span>f<span class="_ _2b"></span><span class="ffb">(</span>θ</div><div class="t m0 x68 ha y3e5 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xcf h6 y3e4 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">。则有：</span></div><div class="t m0 x3a h4 y3e6 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span></span></span>f<span class="_ _2b"></span><span class="ffb">(</span>θ</div><div class="t m0 x14a ha y3e7 ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xbd h4 y3e6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="fff">≈<span class="_ _2f"> </span><span class="ffa">α<span class="ff11">v<span class="_ _f"> </span></span></span>·<span class="_ _30"> </span>∇<span class="ff11">f<span class="_ _2b"> </span><span class="ff21">(</span>θ</span></span></div><div class="t m0 x140 ha y3e7 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x106 h4 y3e6 ff21 fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="fff">≤<span class="_ _2f"> </span><span class="ffb">0</span></span></div><div class="t m0 x3 h6 y3e8 ff1 fs2 fc0 sc0 ls0 ws0">因为<span class="_ _9"> </span><span class="ffa">α<span class="_ _9"> </span></span>为标量，且一般设定为正值，所以可以忽略，不等式变成了：</div><div class="t m0 x59 h4 y3e9 ff11 fs2 fc0 sc0 ls0 ws0">v<span class="_ _f"> </span><span class="fff">·<span class="_ _30"> </span>∇<span class="ffa">f<span class="_ _2b"></span><span class="ffb">(</span>θ</span></span></div><div class="t m0 x12c ha y3ea ffc fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x91 h4 y3e9 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="fff">≤<span class="_ _2f"> </span></span>0</div><div class="t m0 x3 h6 y3eb ff1 fs2 fc0 sc0 ls0 ws0">上面这个不等式非常重要！<span class="_ _22"></span><span class="ff11">v<span class="_ _a"> </span><span class="ff1">和<span class="_ _25"> </span><span class="ff20">∇</span></span>f<span class="_ _2b"> </span><span class="ff21">(</span>θ</span></div><div class="t m0 x105 ha y3ec ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xaa h6 y3eb ff21 fs2 fc0 sc0 ls0 ws0">)<span class="_ _25"> </span><span class="ff1">都是向量，<span class="_ _20"></span><span class="ff20">∇<span class="ff11">f<span class="_ _2b"> </span><span class="ff21">(</span>θ</span></span></span></div><div class="t m0 x14b ha y3ec ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x50 h6 y3eb ff21 fs2 fc0 sc0 ls0 ws0">)<span class="_ _25"> </span><span class="ff1">是当前位置的梯度方向，<span class="_ _20"></span><span class="ff11">v<span class="_ _a"> </span><span class="ff1">表示下</span></span></span></div><div class="t m0 x3 h6 y3ed ff1 fs2 fc0 sc0 ls0 ws0">一步前进的单位向量，是需要我们求解的，有了它，就能根据<span class="_ _9"> </span><span class="ff11">θ<span class="_ _f"> </span><span class="fff">−<span class="_ _30"> </span></span>θ</span></div><div class="t m0 x14c ha y3ee ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x2c h6 y3ed ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">α<span class="ff11">v<span class="_ _a"> </span><span class="ff1">来确定<span class="_ _9"> </span></span>θ<span class="_ _a"> </span><span class="ff1">的值了。</span></span></span></div><div class="t m0 x3 h6 y3ef ff1 fs2 fc0 sc0 ls0 ws0">想要两个向量的乘积小于零，我们先来看一下两个向量乘积包含哪几种情况：</div><div class="t m0 x3 h6 y3f0 ff1 fs2 fc0 sc0 ls0 ws0">上图中，<span class="ff11">A<span class="_ _9"> </span></span>和<span class="_ _9"> </span><span class="ff11">B<span class="_ _a"> </span></span>均为向量，<span class="ffa">α<span class="_ _9"> </span></span>为两个向量之间的夹角。<span class="ff11">A<span class="_ _9"> </span></span>和<span class="_ _9"> </span><span class="ff11">B<span class="_ _12"> </span></span>的乘积为：</div><div class="t m0 x2 h4 y3f1 ff11 fs2 fc0 sc0 ls0 ws0">A<span class="_ _30"> </span><span class="fff">·<span class="_ _30"> </span></span>B<span class="_ _9"> </span><span class="ffb">=<span class="_ _f"> </span><span class="fff">||</span></span>A<span class="fff">||<span class="_ _30"> </span>·<span class="_ _30"> </span>||</span>B<span class="_ _26"></span><span class="fff">||<span class="_ _30"> </span>·<span class="_ _30"> </span><span class="ffa">cos<span class="ffb">(</span>α<span class="ffb">)</span></span></span></div><div class="t m0 x3 h6 y3f2 fff fs2 fc0 sc0 ls0 ws0">||<span class="ff11">A</span>||<span class="_ _9"> </span><span class="ff1">和<span class="_ _a"> </span></span>||<span class="ff11">B<span class="_ _26"></span></span>||<span class="_ _9"> </span><span class="ff1">均<span class="_ _1e"></span>为标量，在<span class="_ _a"> </span></span>||<span class="ff11">A</span>||<span class="_ _9"> </span><span class="ff1">和<span class="_ _a"> </span></span>||<span class="ff11">B<span class="_ _26"></span></span>||<span class="_ _9"> </span><span class="ff1">确<span class="_ _1e"></span>定的情况下，只<span class="_ _1e"></span>要<span class="_ _9"> </span><span class="ffa">cos<span class="ffb">(</span>α <span class="ffb">)<span class="_ _9"> </span>=<span class="_ _25"> </span></span></span></span>−<span class="ffb">1<span class="ff1">，即<span class="_ _a"> </span><span class="ff11">A<span class="_ _9"> </span></span>和<span class="_ _a"> </span><span class="ff11">B<span class="_ _12"> </span></span>完全</span></span></div><div class="t m0 x3 h6 y3f3 ff1 fs2 fc0 sc0 ls0 ws0">相反，就能让<span class="_ _9"> </span><span class="ff11">A<span class="_ _9"> </span></span>和<span class="_ _9"> </span><span class="ff11">B<span class="_ _a"> </span></span>的向量乘积最小（负最大值）<span class="_ _23"></span>。</div><div class="t m0 x3 h6 y3f4 ff1 fs2 fc0 sc0 ls0 ws0">顾名思义，<span class="_ _3d"></span>当<span class="_ _f"> </span><span class="ff11">v<span class="_ _9"> </span></span>和<span class="_ _2f"> </span><span class="ff20">∇<span class="ff11">f<span class="_ _2b"> </span><span class="ff21">(</span>θ</span></span></div><div class="t m0 x18 ha y3f5 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xc h6 y3f4 ff21 fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="ff1">互为反向，<span class="_ _3d"></span>即当<span class="_ _2f"> </span><span class="ff11">v<span class="_ _25"> </span></span>为当前梯度方向的负方向的时候，<span class="_ _3d"></span>能让<span class="_ _2f"> </span><span class="ff11">v<span class="_ _2c"> </span><span class="fff">·<span class="_ _2b"></span><span class="ff20">∇</span></span>f<span class="_ _2b"> </span><span class="ff21">(</span>θ</span></span></div><div class="t m0 xb5 ha y3f5 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x79 h4 y3f4 ff21 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y3f6 ff1 fs2 fc0 sc0 ls0 ws0">最大程度地小，也就保证了<span class="_ _9"> </span><span class="ff11">v<span class="_ _a"> </span></span>的方向是局部下降最快的方向。</div><div class="t m0 x3 h6 y3f7 ff1 fs2 fc0 sc0 ls0 ws0">知道了<span class="_ _9"> </span><span class="ff11">v<span class="_ _a"> </span></span>是<span class="_ _9"> </span><span class="ff20">∇<span class="ff11">f<span class="_ _2b"> </span><span class="ff21">(</span>θ</span></span></div><div class="t m0 xc7 ha y3f8 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xeb h6 y3f7 ff21 fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">的反方向后，可直接得到：</span></div><div class="t m0 x9 h4 y3f9 ff11 fs2 fc0 sc0 ls0 ws0">v<span class="_ _25"> </span><span class="ffb">=<span class="_ _2f"> </span><span class="fff">−</span></span></div><div class="t m0 xa1 h4 y3fa ff20 fs2 fc0 sc0 ls0 ws0">∇<span class="ff11">f<span class="_ _2b"></span><span class="ff21">(</span>θ</span></div><div class="t m0 x27 ha y3fb ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xcd h4 y3fa ff21 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xa5 h4 y3fc fff fs2 fc0 sc0 ls0 ws0">||<span class="ff20">∇<span class="ff11">f<span class="_ _2b"></span><span class="ff21">(</span>θ</span></span></div><div class="t m0 x27 ha y13c ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xcd h4 y3fc ff21 fs2 fc0 sc0 ls0 ws0">)<span class="fff">||</span></div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">33</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf27" class="pf w0 h0" data-page-no="27"><div class="pc pc27 w0 h0"><img class="bi x5d y3fd we h30" alt="" src="bg27.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">5.1<span class="_ _d"> </span><span class="ff8">梯度下降原理</span></div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">之所以要除以<span class="_ _9"> </span><span class="ff20">∇<span class="ff11">f<span class="_ _2b"></span><span class="ff21">(</span>θ</span></span></div><div class="t m0 xc2 ha y2c9 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x6e h6 y20 ff21 fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">的模<span class="_ _9"> </span><span class="fff">||<span class="ff20">∇<span class="ff11">f<span class="_ _2b"></span></span></span></span></span>(<span class="ff11">θ</span></div><div class="t m0 x87 ha y2c9 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x48 h6 y20 ff21 fs2 fc0 sc0 ls0 ws0">)<span class="fff">||<span class="ff1">，是因为<span class="_ _9"> </span><span class="ff11">v<span class="_ _a"> </span></span>是单位向量。</span></span></div><div class="t m0 x3 h6 y3c ff1 fs2 fc0 sc0 ls0 ws0">求出最优解<span class="_ _9"> </span><span class="ff11">v<span class="_ _a"> </span></span>之后，带入到<span class="_ _9"> </span><span class="ff11">θ<span class="_ _f"> </span><span class="fff">−<span class="_ _30"> </span></span>θ</span></div><div class="t m0 xee ha y3fe ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x87 h6 y3c ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">α<span class="ff11">v<span class="_ _a"> </span><span class="ff1">中，得：</span></span></span></div><div class="t m0 xab h4 y3ff ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _25"> </span><span class="ffb">=<span class="_ _2f"> </span></span>θ</div><div class="t m0 x14a ha y400 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x22 h4 y3ff fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">α</span></div><div class="t m0 x134 h4 y401 ff20 fs2 fc0 sc0 ls0 ws0">∇<span class="ff11">f<span class="_ _2b"></span><span class="ff21">(</span>θ</span></div><div class="t m0 xc1 ha y402 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x14d h4 y401 ff21 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x25 h4 y26e fff fs2 fc0 sc0 ls0 ws0">||<span class="ff20">∇<span class="ff11">f<span class="_ _2b"></span><span class="ff21">(</span>θ</span></span></div><div class="t m0 xc1 ha y403 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x14d h4 y26e ff21 fs2 fc0 sc0 ls0 ws0">)<span class="fff">||</span></div><div class="t m0 x3 h6 y404 ff1 fs2 fc0 sc0 ls0 ws0">一般的，因为<span class="_ _9"> </span><span class="fff">||<span class="ff20">∇<span class="ff11">f<span class="_ _2b"></span><span class="ff21">(</span>θ</span></span></span></div><div class="t m0 x109 ha y405 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x10a h6 y404 ff21 fs2 fc0 sc0 ls0 ws0">)<span class="fff">||<span class="_ _9"> </span><span class="ff1">是标量，可以并入到学习率<span class="_ _9"> </span><span class="ffa">α<span class="_ _9"> </span></span>中，即简化为：</span></span></div><div class="t m0 x47 h4 y406 ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _25"> </span><span class="ffb">=<span class="_ _2f"> </span></span>θ</div><div class="t m0 x22 ha y407 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xa5 h4 y406 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">α<span class="ff20">∇<span class="ff11">f<span class="_ _2b"> </span><span class="ff21">(</span>θ</span></span></span></div><div class="t m0 xc1 ha y407 ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x14d h4 y406 ff21 fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y408 ff1 fs2 fc0 sc0 ls0 ws0">把<span class="_ _9"> </span><span class="ffa">f<span class="_ _2b"></span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="_ _9"> </span></span></span>换为目标函数<span class="_ _9"> </span><span class="ffa">J<span class="_ _2b"></span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)</span></span>，就是我们上面的梯度下降公式了：</div><div class="t m0 x14e h4 y409 ff11 fs2 fc0 sc0 ls0 ws0">θ<span class="_ _25"> </span><span class="ffb">=<span class="_ _2f"> </span></span>θ</div><div class="t m0 x46 ha y40a ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xab h4 y409 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">α<span class="ff20">∇<span class="ff11">J<span class="_ _2b"></span><span class="ff21">(</span>θ</span></span></span></div><div class="t m0 x90 ha y40a ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 xfb h4 y409 ff21 fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span><span class="ff11">θ</span></span></div><div class="t m0 x27 ha y40a ff1f fs7 fc0 sc0 ls0 ws0">0</div><div class="t m0 x42 h4 y409 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">α<span class="_ _30"> </span></span>·</div><div class="t m0 x4f h4 y40b ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>J<span class="_ _4e"></span><span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)</span></div><div class="t m0 x9d hc y40c ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>θ</div><div class="t m0 x3 h6 y40d ff1 fs2 fc9 sc0 ls0 ws0">梯度下降算法总结</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">34</div><a class="l" href="https://lumingdong.cn/summary-of-gradient-descent-algorithm.html"><div class="d m1" style="border-style:none;position:absolute;left:106.299000px;bottom:899.832000px;width:87.273000px;height:10.909000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf28" class="pf w0 h0" data-page-no="28"><div class="pc pc28 w0 h0"><div class="t m0 x111 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第六章 <span class="ff5">Bac<span class="_ _31"></span>kpropagation</span></div><div class="t m0 xfd h9 y4e ff5 fs6 fc0 sc0 ls0 ws0">6.1<span class="_ _1f"> </span><span class="ff9">神经网络</span></div><div class="t m0 x3 h6 y40e ff1 fs2 fc0 sc0 ls0 ws0">神经网络是按照一定规则连接起来的多个神经元。神经网络按照层级来布局神经元。</div><div class="t m0 x9a h6 y40f ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">最左边的层叫做输入层（</span>input<span class="_ _25"> </span>lay<span class="_ _2d"></span>er<span class="ff1">）<span class="_ _23"></span>，主要负责接收输入数据。</span></div><div class="t m0 x9a h6 y410 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">最右边的层叫输出层（</span>output<span class="_ _25"> </span>lay<span class="_ _2d"></span>er<span class="ff1">）<span class="_ _23"></span>，可以从这一层获取神经网络输出数据。</span></div><div class="t m0 x9a h6 y411 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">输入层与输出层之间的层叫做隐藏层，可以包含多个<span class="_ _1e"></span>隐藏层，之所以叫做隐藏层，是因<span class="_ _1e"></span>为</span></div><div class="t m0 x9b h6 y412 ff1 fs2 fc0 sc0 ls0 ws0">它们对于外部来说是不可见的。</div><div class="t m0 x3 h6 y413 ff1 fs2 fc0 sc0 ls0 ws0">全连接神经网络的特征如下：</div><div class="t m0 x9a h6 y414 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _4"> </span><span class="ff1">位于同一层的各个神经元没有任何连接。</span></div><div class="t m0 x9a h6 y415 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _4"> </span><span class="ff1">位于第<span class="_ _2f"> </span></span>N<span class="_ _9"> </span><span class="ff1">层的每个神经元都与第<span class="_ _9"> </span></span>N-1<span class="_ _25"> </span><span class="ff1">层的所有神经元相连，<span class="_ _2d"></span>也就是全连接<span class="_ _e"></span>（<span class="ff3">F<span class="_ _22"></span>ull<span class="_ _9"> </span>Connec-</span></span></div><div class="t m0 x9b h6 y416 ff3 fs2 fc0 sc0 ls0 ws0">tion<span class="ff1">）<span class="_ _23"></span>，第<span class="_ _9"> </span><span class="ff3">N-1<span class="_ _9"> </span></span>层神经元的输出就是第<span class="_ _9"> </span><span class="ff3">N<span class="_ _9"> </span></span>层神经元的输入。</span></div><div class="t m0 x9a h6 y417 ff3 fs2 fc0 sc0 ls0 ws0">3.<span class="_ _4"> </span><span class="ff1">全连接的每个连接都有一个权值。</span></div><div class="t m0 x3 h6 y418 ff1 fs2 fc0 sc0 ls0 ws0">事实上还存在很多其它结构的神经网络，<span class="_ _2d"></span>比如卷积神经网络<span class="_ _9"> </span><span class="ff3">(CNN)</span>、循环神经网络<span class="_ _25"> </span><span class="ff3">(RNN)</span>，他</div><div class="t m0 x3 h6 y419 ff1 fs2 fc0 sc0 ls0 ws0">们都具有不同的连接规则。</div><div class="t m0 xfd h9 y41a ff5 fs6 fc0 sc0 ls0 ws0">6.2<span class="_ _1f"> </span><span class="ff9">基本函数</span></div><div class="t m0 x3 h6 y41b ff1 fs2 fc0 sc0 ls0 ws0">推导<span class="_ _9"> </span><span class="ff3">BP<span class="_ _9"> </span></span>算法的过程中需要注意几个要点：</div><div class="t m0 x9a h6 y41c ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">网络函数</span></div><div class="t m0 x9a h6 y41d ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">激活函数：</span>sigmoid</div><div class="t m0 x9a h6 y41e ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">误差函数：平方误差</span></div><div class="t m0 x9a h6 y41f ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">优化方法：梯度下降，降低误差大的网络的权值，增加误差小的网络的权值。</span></div><div class="t m0 x3 h6 y420 ff1 fs2 fc0 sc0 ls0 ws0">下面先来介绍几个在神经网络反向传播算法的推导<span class="_ _9"> </span>过程中用到的几个函数：</div><div class="t m0 x3 h6 y421 ff6 fs2 fc0 sc0 ls0 ws0">1.Net<span class="_ _2d"></span>work<span class="_ _a"> </span>function(<span class="ff4">网络函数</span>)</div><div class="t m0 x3 h4 y422 ff3 fs2 fc0 sc0 ls0 ws0">The netw<span class="_ _2d"></span>ork is a<span class="_ _25"> </span>particular implementation of a comp<span class="_ _1e"></span>osite<span class="_ _25"> </span>function from<span class="_ _25"> </span>input to output<span class="_ _25"> </span>space,</div><div class="t m0 x3 h4 y423 ff3 fs2 fc0 sc0 ls0 ws0">whic<span class="_ _e"></span>h<span class="_ _9"> </span>w<span class="_ _e"></span>e<span class="_ _9"> </span>call<span class="_ _9"> </span>the<span class="_ _9"> </span>net<span class="_ _e"></span>w<span class="_ _e"></span>ork<span class="_ _9"> </span>function.</div><div class="t m0 x87 h4 y424 ffa fs2 fc0 sc0 ls0 ws0">h<span class="ffb">(</span>x<span class="ffb">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span></span>w</div><div class="t m0 xa5 hb y425 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 xa1 h4 y424 ffa fs2 fc0 sc0 ls0 ws0">x<span class="_ _2f"> </span><span class="ffb">=</span></div><div class="t m0 xbf hb y426 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x4c he y427 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x13b ha y428 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 xad hc y424 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x14d hb y429 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x140 hc y424 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x106 hb y429 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x3 h6 y111 ff6 fs2 fc0 sc0 ls0 ws0">2.A<span class="_ _2d"></span>ctiv<span class="_ _2d"></span>ation<span class="_ _12"> </span>function(<span class="ff4">激活函数</span>)</div><div class="t m0 x3 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">这里使用的激活函数是<span class="_ _9"> </span><span class="ff3">Sigmoid<span class="_ _9"> </span></span>函数：</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">35</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf29" class="pf w0 h0" data-page-no="29"><div class="pc pc29 w0 h0"><img class="bi x3 y42a w2 h31" alt="" src="bg29.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">6.3<span class="_ _d"> </span><span class="ff8">前向传播</span></div><div class="t m0 x47 h4 y42b ffa fs2 fc0 sc0 ls0 ws0">y<span class="_ _25"> </span><span class="ffb">=<span class="_ _2f"> </span></span>f<span class="_ _2b"> </span><span class="ffb">(</span>z<span class="_ _26"></span><span class="ffb">)<span class="_ _2f"> </span>=</span></div><div class="t m0 x4d h4 y42c ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x91 h4 y42d ffb fs2 fc0 sc0 ls0 ws0">1<span class="_ _30"> </span>+<span class="_ _30"> </span><span class="ffa">e</span></div><div class="t m0 xad ha y42e ff12 fs7 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 x3 h4 y42f ff6 fs2 fc0 sc0 ls0 ws0">3.Error<span class="_ _a"> </span>function</div><div class="t m0 x76 h6 y430 ff4 fs2 fc0 sc0 ls0 ws0">（误差函数）</div><div class="t m0 x3 h6 y431 ff1 fs2 fc0 sc0 ls0 ws0">采用平方误差作为目标函数<span class="ff3">:</span></div><div class="t m0 x20 h4 y432 ffa fs2 fc0 sc0 ls0 ws0">E<span class="_ _9"> </span><span class="ffb">=</span></div><div class="t m0 x1 h4 y433 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x1 h4 y434 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8f hb y435 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x23 he y436 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xf0 ha y437 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">=1</span></div><div class="t m0 x12c h4 y432 ffb fs2 fc0 sc0 ls0 ws0">[<span class="ffa">t</span></div><div class="t m0 xa2 hb y438 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xac h4 y432 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 xad hb y438 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x43 h4 y432 ffb fs2 fc0 sc0 ls0 ws0">]</div><div class="t m0 x13f ha y439 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x3 h6 y43a ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _9"> </span><span class="ffa">t</span></div><div class="t m0 x14f hb y43b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x80 h6 y43a ff1 fs2 fc0 sc0 ls0 ws0">为真实值，<span class="ffa">y</span></div><div class="t m0 x124 hb y43b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6e h6 y43a ff1 fs2 fc0 sc0 ls0 ws0">为计算值，等于<span class="_ _9"> </span><span class="ffa">y</span></div><div class="t m0 xaa hb y43b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x21 h4 y43a ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f<span class="_ _2b"></span></span>(<span class="ffa">h</span>(<span class="ffa">x</span></div><div class="t m0 x134 hb y43b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x91 h6 y43a ffb fs2 fc0 sc0 ls0 ws0">))<span class="ff1">。下面对<span class="_ _9"> </span><span class="ff3">BP<span class="_ _9"> </span></span>算法的计算过程进行推导。</span></div><div class="t m0 xfd h9 y43c ff5 fs6 fc0 sc0 ls0 ws0">6.3<span class="_ _1f"> </span><span class="ff9">前向传播</span></div><div class="t m0 x1f h6 y43d ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">6.1:<span class="_ _1c"> </span></span>神经网络示意图</div><div class="t m0 x3 h6 y43e ff1 fs2 fc0 sc0 ls0 ws0">上图展示的是一个经典的三层神经网络，<span class="_ _22"></span>包括输入层、<span class="_ _31"></span>隐藏层、<span class="_ _31"></span>输出层。<span class="_ _31"></span>为了体现一般性，<span class="_ _22"></span>现在</div><div class="t m0 x3 h6 y43f ff1 fs2 fc0 sc0 ls0 ws0">用数学语言进行描述：</div><div class="t m0 x3 h6 y440 ff1 fs2 fc0 sc0 ls0 ws0">给定一个训练集<span class="_ _a"> </span><span class="fff">{<span class="ffb">(<span class="ffa">x</span></span></span></div><div class="t m0 x124 ha y441 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x129 hc y440 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>t</div><div class="t m0 x10a ha y441 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xb0 h4 y440 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="ffa">,<span class="_ _29"> </span></span>(<span class="ffa">x</span></div><div class="t m0 xd ha y441 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x1a hc y440 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>t</div><div class="t m0 x9f ha y441 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8d h4 y440 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="ffa">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span></span>(<span class="ffa">x</span></div><div class="t m0 x21 hb y441 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x14a hc y440 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>t</div><div class="t m0 x8e hb y441 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x23 h6 y440 ffb fs2 fc0 sc0 ls0 ws0">)<span class="fff">}<span class="ff1">，目标变量<span class="_ _a"> </span><span class="ffa">t</span></span></span></div><div class="t m0 x4f hb y441 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x9d h6 y440 ff1 fs2 fc0 sc0 ls0 ws0">的取值可以有多个，<span class="_ _1e"></span>其中<span class="_ _9"> </span><span class="ffa">x</span></div><div class="t m0 x146 hb y441 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x33 h6 y440 ff1 fs2 fc0 sc0 ls0 ws0">是一</div><div class="t m0 x3 h6 y442 ff1 fs2 fc0 sc0 ls0 ws0">个<span class="_ _9"> </span><span class="ffa">m<span class="_ _a"> </span></span>维向量<span class="_ _1e"></span>（对应输入层<span class="_ _1e"></span>的<span class="_ _a"> </span><span class="ffa">m<span class="_ _9"> </span></span>个神<span class="_ _1e"></span>经元）<span class="_ _24"></span>，表达式为<span class="_ _a"> </span><span class="ffa">x</span></div><div class="t m0 x63 hb y443 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x64 h4 y442 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _25"> </span>(<span class="ffa">x</span></div><div class="t m0 x150 ha y443 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">1</span></div><div class="t m0 xe4 hc y442 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>x</div><div class="t m0 x151 ha y443 ffd fs7 fc0 sc0 ls0 ws0">i<span class="ffc">2</span></div><div class="t m0 x8a h4 y442 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="fff">·<span class="_ _29"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>x</div><div class="t m0 x56 hb y443 ffd fs7 fc0 sc0 ls0 ws0">im</div><div class="t m0 x152 h6 y442 ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">。我们将输<span class="_ _1e"></span>入层、</span></div><div class="t m0 x3 h6 y444 ff1 fs2 fc0 sc0 ls0 ws0">隐藏层、<span class="_ _31"></span>输出层合并在一起，<span class="_ _2d"></span>就形成了一个<span class="_ _25"> </span><span class="ff3">netw<span class="_ _2d"></span>ork<span class="ff1">。<span class="_ _2d"></span>在这个<span class="_ _9"> </span><span class="ff3">net<span class="_ _e"></span>w<span class="_ _e"></span>ork<span class="_ _25"> </span><span class="ff1">里，<span class="_ _2d"></span>除输入层外，<span class="_ _31"></span>其他层</span></span></span></span></div><div class="t m0 x3 h6 y445 ff1 fs2 fc0 sc0 ls0 ws0">上的每个神经元都是上一层神经元的全连接，<span class="_ _21"></span>不同的是全连接的权值不一样。<span class="_ _20"></span>现在，<span class="_ _20"></span>我们需要通</div><div class="t m0 x3 h6 y446 ff1 fs2 fc0 sc0 ls0 ws0">过训练，来求出各个神经元的权重值，也就是<span class="_ _9"> </span><span class="ffa">w<span class="_ _1e"></span></span>。</div><div class="t m0 x3 h6 y447 ff1 fs2 fc0 sc0 ls0 ws0">那么现在的问题是，这些权值应该如何计算呢？</div><div class="t m0 x3 h6 y448 ff1 fs2 fc0 sc0 ls0 ws0">刚刚说到，<span class="_ _20"></span>除输入层外，<span class="_ _22"></span>其他层上的每个神经元都是上一层神经元的全连接<span class="ff3">,<span class="_ _9"> </span></span>比如隐藏层<span class="_ _25"> </span><span class="ffa">h</span></div><div class="t m0 x11 ha y449 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x153 h6 y448 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _20"></span>是</div><div class="t m0 x3 h6 y44a ff1 fs2 fc0 sc0 ls0 ws0">隐藏层的第一个神经元，它的输出值是输入层的全连接，即：</div><div class="t m0 xe2 hc y44b ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x142 ha y44c ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xbd h4 y44b ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 x8 he y44d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x143 h20 y44b ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y44e ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y44f ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x144 h4 y44b fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _30"> </span><span class="ff11">x</span></div><div class="t m0 x133 he y44d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y44b ff3 fs2 fc0 sc0 ls0 ws0">(6.1)</div><div class="t m0 x0 hc y450 ffa fs2 fc0 sc0 ls0 ws0">net</div><div class="t m0 xed ha y451 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xed ha y452 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xb8 h4 y450 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">w</span></div><div class="t m0 x9 ha y451 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9 ha y452 ffc fs7 fc0 sc0 ls0 ws0">11</div><div class="t m0 xb9 hc y450 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x12d ha y453 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x22 h4 y450 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x5d ha y451 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xfb ha y454 ffc fs7 fc0 sc0 ls0 ws0">12</div><div class="t m0 x5e hc y450 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x154 ha y453 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x155 h4 y450 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x14d ha y451 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13f ha y454 ffc fs7 fc0 sc0 ls0 ws0">13</div><div class="t m0 x64 hc y450 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xef ha y453 ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x137 h4 y450 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x2b ha y451 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2b ha y454 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x33 h4 y450 ff3 fs2 fc0 sc0 ls0 ws0">(6.2)</div><div class="t m0 x1e h6 y455 ff1 fs2 fc0 sc0 ls0 ws0">行标表示当前层的第几个节点，列标表示上一层的第几个节点，<span class="_ _e"></span>上标表示当前是第几个隐</div><div class="t m0 x1e h6 y456 ff1 fs2 fc0 sc0 ls0 ws0">藏层</div><div class="t m0 x3 h6 y457 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _9"> </span><span class="ffa">f<span class="_ _0"> </span></span>为<span class="_ _9"> </span><span class="ff3">sigmoid<span class="_ _9"> </span></span>函数，<span class="ff11">w</span></div><div class="t m0 xe0 ha y458 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe0 hb y459 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x0 h6 y457 ff1 fs2 fc0 sc0 ls0 ws0">表示隐藏层的第<span class="_ _9"> </span><span class="ffa">i<span class="_ _a"> </span></span>个节点与输入层的第<span class="_ _a"> </span><span class="ffa">j<span class="_ _12"> </span></span>个节点的权重值，<span class="ffa">b</span></div><div class="t m0 x156 ha y458 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x156 hb y459 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb5 h6 y457 ff1 fs2 fc0 sc0 ls0 ws0">表</div><div class="t m0 x3 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">示第<span class="_ _9"> </span><span class="ffa">i<span class="_ _9"> </span></span>个隐藏层全连接中的偏置，<span class="ffa">x</span></div><div class="t m0 x1f hb y9d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xe1 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">为输入层的值，即样本的输入值。</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">36</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2a" class="pf w0 h0" data-page-no="2a"><div class="pc pc2a w0 h0"><img class="bi xb y45a w1 h32" alt="" src="bg2a.png"/><div class="t m0 x83 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">6.3<span class="_ _d"> </span><span class="ff8">前向传播</span></div><div class="t m0 x3d h6 y45b ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">6.2:<span class="_ _1c"> </span></span>前向传播</div><div class="t m0 x3 h6 y45c ff1 fs2 fc0 sc0 ls0 ws0">类似的，可以计算出<span class="_ _9"> </span><span class="ffa">h</span></div><div class="t m0 xc5 ha y45d ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x65 h6 y45c ff1 fs2 fc0 sc0 ls0 ws0">、<span class="ffa">h</span></div><div class="t m0 x139 ha y45d ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x82 h6 y45c ff1 fs2 fc0 sc0 ls0 ws0">、<span class="ffa">h</span></div><div class="t m0 x9c ha y45d ffc fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 x157 h6 y45c ff1 fs2 fc0 sc0 ls0 ws0">：</div><div class="t m0 x14e hc y45e ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1b ha y45f ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9c h4 y45e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 x87 he y460 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x158 hc y45e ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x9 ha y461 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9 ha y462 ffc fs7 fc0 sc0 ls0 ws0">11</div><div class="t m0 xb9 hc y45e ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x14a ha y45f ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x86 h4 y45e ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 xfb ha y461 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xfb ha y462 ffc fs7 fc0 sc0 ls0 ws0">12</div><div class="t m0 xb2 hc y45e ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb4 ha y45f ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbf h4 y45e ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x13f ha y461 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13f ha y462 ffc fs7 fc0 sc0 ls0 ws0">13</div><div class="t m0 x64 hc y45e ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xef ha y45f ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x135 h4 y45e ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x2b ha y461 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2b ha y462 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x131 he y460 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x14e hc y463 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1b ha y464 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x9c h4 y463 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 x87 he y465 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x158 hc y463 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x9 ha y466 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9 ha y467 ffc fs7 fc0 sc0 ls0 ws0">21</div><div class="t m0 xb9 hc y463 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x14a ha y464 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x86 h4 y463 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 xfb ha y466 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xfb ha y467 ffc fs7 fc0 sc0 ls0 ws0">22</div><div class="t m0 xb2 hc y463 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb4 ha y464 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbf h4 y463 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x13f ha y466 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13f ha y467 ffc fs7 fc0 sc0 ls0 ws0">23</div><div class="t m0 x64 hc y463 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xef ha y464 ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x135 h4 y463 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x2b ha y466 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2b ha y467 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x131 he y465 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x14e hc y468 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1b ha y469 ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x9c h4 y468 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 x87 he y46a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x158 hc y468 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x9 ha y46b ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9 ha y46c ffc fs7 fc0 sc0 ls0 ws0">31</div><div class="t m0 xb9 hc y468 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x14a ha y469 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x86 h4 y468 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 xfb ha y46b ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xfb ha y46c ffc fs7 fc0 sc0 ls0 ws0">32</div><div class="t m0 xb2 hc y468 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb4 ha y469 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbf h4 y468 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x13f ha y46b ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13f ha y46c ffc fs7 fc0 sc0 ls0 ws0">33</div><div class="t m0 x64 hc y468 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xef ha y469 ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x135 h4 y468 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x2b ha y46b ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2b ha y46c ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x131 he y46a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x14e hc y46d ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x1b ha y46e ffc fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 x9c h4 y46d ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 x87 he y46f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x158 hc y46d ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x9 ha y470 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x9 ha y471 ffc fs7 fc0 sc0 ls0 ws0">41</div><div class="t m0 xb9 hc y46d ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x14a ha y46e ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x86 h4 y46d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 xfb ha y470 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xfb ha y471 ffc fs7 fc0 sc0 ls0 ws0">42</div><div class="t m0 xb2 hc y46d ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb4 ha y46e ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbf h4 y46d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x13f ha y470 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x13f ha y471 ffc fs7 fc0 sc0 ls0 ws0">43</div><div class="t m0 x64 hc y46d ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xef ha y46e ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x135 h4 y46d ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x2b ha y470 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2b ha y471 ffc fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 x131 he y46f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y472 ff3 fs2 fc0 sc0 ls0 ws0">(6.3)</div><div class="t m0 x3 h6 y473 ff1 fs2 fc0 sc0 ls0 ws0">因此，我们可以将隐藏层表示为如下通式：</div><div class="t m0 x46 h4 y474 ff11 fs2 fc0 sc0 ls0 ws0">h<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span><span class="ffa">f<span class="_ _2b"></span></span>(</span>net</div><div class="t m0 xa5 ha y475 ff1f fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa1 h4 y474 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 xbf he y476 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xd6 h20 y474 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x43 ha y475 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xc1 ha y477 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x63 h4 y474 fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _30"> </span><span class="ff11">x</span></div><div class="t m0 xef he y476 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y474 ff3 fs2 fc0 sc0 ls0 ws0">(6.4)</div><div class="t m0 x98 h20 y478 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x159 ha y479 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x8d h4 y478 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xa he y47a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa he y47b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa he y47c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa he y47d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa he y47e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa he y47f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe1 h20 y480 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3d ha y481 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3d ha y482 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe1 h20 y483 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3d ha y484 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3d ha y485 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xe1 h20 y486 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3d ha y487 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3d ha y488 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xe1 h20 y489 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3d ha y48a ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3d ha y48b ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 xe1 h20 y48c ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3d ha y48d ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3d ha y48e ffc fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 x142 he y47a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x142 he y47b ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x142 he y47c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x142 he y47d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x142 he y47e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x142 he y47f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4 h4 y478 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x5b he y48f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5b he y47c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5b he y47d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5b he y490 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf3 hc y491 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y492 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y493 ffc fs7 fc0 sc0 ls0 ws0">11</div><div class="t m0 x136 hc y491 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xad ha y492 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xad ha y493 ffc fs7 fc0 sc0 ls0 ws0">12</div><div class="t m0 xe3 hc y491 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xd7 ha y492 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd7 ha y493 ffc fs7 fc0 sc0 ls0 ws0">13</div><div class="t m0 x137 hc y491 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>b</div><div class="t m0 xa3 ha y492 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa3 ha y493 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xf3 hc y494 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y495 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y496 ffc fs7 fc0 sc0 ls0 ws0">21</div><div class="t m0 x136 hc y494 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xad ha y495 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xad ha y496 ffc fs7 fc0 sc0 ls0 ws0">22</div><div class="t m0 xe3 hc y494 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xd7 ha y495 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd7 ha y496 ffc fs7 fc0 sc0 ls0 ws0">23</div><div class="t m0 x137 hc y494 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>b</div><div class="t m0 xa3 ha y495 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa3 ha y496 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xf3 hc y497 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y498 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y499 ffc fs7 fc0 sc0 ls0 ws0">31</div><div class="t m0 x136 hc y497 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xad ha y498 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xad ha y499 ffc fs7 fc0 sc0 ls0 ws0">32</div><div class="t m0 xe3 hc y497 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xd7 ha y498 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd7 ha y499 ffc fs7 fc0 sc0 ls0 ws0">33</div><div class="t m0 x137 hc y497 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>b</div><div class="t m0 xa3 ha y498 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa3 ha y499 ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 xf3 hc y49a ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b ha y49b ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4b ha y49c ffc fs7 fc0 sc0 ls0 ws0">41</div><div class="t m0 x136 hc y49a ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xad ha y49b ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xad ha y49c ffc fs7 fc0 sc0 ls0 ws0">42</div><div class="t m0 xe3 hc y49a ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xd7 ha y49b ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd7 ha y49c ffc fs7 fc0 sc0 ls0 ws0">43</div><div class="t m0 x137 hc y49a ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>b</div><div class="t m0 xa3 ha y49b ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa3 ha y49c ffc fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 x15a he y48f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x15a he y47c ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x15a he y47d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x15a he y490 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y478 ff3 fs2 fc0 sc0 ls0 ws0">(6.5)</div><div class="t m0 x3 h6 y49d ff1 fs2 fc0 sc0 ls0 ws0">对于输出层，<span class="_ _22"></span>也是同样的计算方式，<span class="_ _22"></span>只不过对于输出层而言，<span class="_ _22"></span>它们的输入为隐藏层的输出，<span class="_ _22"></span>即<span class="_ _9"> </span><span class="ff11">h</span></div><div class="t m0 x3 h6 y49e ff1 fs2 fc0 sc0 ls0 ws0">，输出层的表达式为：</div><div class="t m0 x88 h4 y49f ff11 fs2 fc0 sc0 ls0 ws0">y<span class="_ _25"> </span><span class="ffb">=<span class="_ _2f"> </span><span class="ffa">f</span></span></div><div class="t m0 x24 he y4a0 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x8 h20 y49f ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x99 ha y4a1 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x26 h4 y49f fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _30"> </span><span class="ff11">h</span></div><div class="t m0 x42 he y4a0 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x17 h20 y4a2 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x36 ha y4a3 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xd h4 y4a2 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x7 he y4a4 ffe fs2 fc0 sc0 ls0 ws0">&quot;</div><div class="t m0 x145 h20 y4a5 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xbc ha y4a6 ff1f fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xbc ha y4a7 ff1f fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x145 h20 y4a8 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xbc ha y4a9 ff1f fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xbc ha y4aa ff1f fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x9 he y4a4 ffe fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 x21 h4 y4a2 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x4 he y4a4 ffe fs2 fc0 sc0 ls0 ws0">&quot;</div><div class="t m0 x5b hc y4a5 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x41 ha y4ab ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x41 ha y4a7 ffc fs7 fc0 sc0 ls0 ws0">11</div><div class="t m0 x91 hc y4a5 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xb1 ha y4ab ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x155 ha y4a7 ffc fs7 fc0 sc0 ls0 ws0">12</div><div class="t m0 x92 hc y4a5 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x112 ha y4ab ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x112 ha y4a7 ffc fs7 fc0 sc0 ls0 ws0">13</div><div class="t m0 x15b hc y4a5 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x6c ha y4ab ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x6c ha y4a7 ffc fs7 fc0 sc0 ls0 ws0">14</div><div class="t m0 x15a hc y4a5 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>b</div><div class="t m0 x89 ha y4ab ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x89 ha y4a7 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5b hc y4a8 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x41 ha y4a9 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x41 ha y4aa ffc fs7 fc0 sc0 ls0 ws0">21</div><div class="t m0 x91 hc y4a8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 xb1 ha y4a9 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x155 ha y4aa ffc fs7 fc0 sc0 ls0 ws0">22</div><div class="t m0 x92 hc y4a8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x112 ha y4a9 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x112 ha y4aa ffc fs7 fc0 sc0 ls0 ws0">23</div><div class="t m0 x15b hc y4a8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>w</div><div class="t m0 x6c ha y4a9 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x6c ha y4aa ffc fs7 fc0 sc0 ls0 ws0">24</div><div class="t m0 x15a hc y4a8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>b</div><div class="t m0 x89 ha y4a9 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x89 ha y4aa ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x15c he y4a4 ffe fs2 fc0 sc0 ls0 ws0">#</div><div class="t m0 xc5 hc y4ac ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 xde ha y4ad ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x36 h4 y4ac ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 xd3 he y4ae ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x11b hc y4ac ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3b ha y4af ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x3b ha y4b0 ffc fs7 fc0 sc0 ls0 ws0">11</div><div class="t m0 xbc hc y4ac ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xab ha y4ad ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x47 h4 y4ac ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x5a ha y4af ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x5a ha y4b0 ffc fs7 fc0 sc0 ls0 ws0">12</div><div class="t m0 xa0 hc y4ac ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x15d ha y4ad ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8 h4 y4ac ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x4c ha y4af ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4c ha y4b0 ffc fs7 fc0 sc0 ls0 ws0">13</div><div class="t m0 xc0 hc y4ac ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xad ha y4ad ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x14d h4 y4ac ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x4f ha y4af ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4f ha y4b0 ffc fs7 fc0 sc0 ls0 ws0">13</div><div class="t m0 x6c hc y4ac ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x125 ha y4ad ffc fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 xd9 h4 y4ac ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x15e ha y4af ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x15e ha y4b0 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x15f he y4ae ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xc5 hc y4b1 ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 xde ha y4b2 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x36 h4 y4b1 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 xd3 he y4b3 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x11b hc y4b1 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3b ha y4b4 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x3b ha y4b5 ffc fs7 fc0 sc0 ls0 ws0">21</div><div class="t m0 xbc hc y4b1 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xab ha y4b2 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x47 h4 y4b1 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x5a ha y4b4 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x5a ha y4b5 ffc fs7 fc0 sc0 ls0 ws0">22</div><div class="t m0 xa0 hc y4b1 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x15d ha y4b2 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8 h4 y4b1 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x4c ha y4b4 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4c ha y4b5 ffc fs7 fc0 sc0 ls0 ws0">23</div><div class="t m0 xc0 hc y4b1 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xad ha y4b2 ffc fs7 fc0 sc0 ls0 ws0">3</div><div class="t m0 x14d h4 y4b1 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x4f ha y4b4 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4f ha y4b5 ffc fs7 fc0 sc0 ls0 ws0">13</div><div class="t m0 x6c hc y4b1 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x125 ha y4b2 ffc fs7 fc0 sc0 ls0 ws0">4</div><div class="t m0 xd9 h4 y4b1 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x15e ha y4b4 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x15e ha y4b5 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x15f he y4b3 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3 h6 y4b6 ff1 fs2 fc0 sc0 ls0 ws0">即：</div><div class="t m0 x12b h20 y4b7 ff11 fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 xa4 hb y4b8 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x97 h4 y4b7 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 x160 he y4b9 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x1f hc y4b7 ffa fs2 fc0 sc0 ls0 ws0">net</div><div class="t m0 x9 ha y4ba ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x9 hb y4bb ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x49 he y4b9 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4 h4 y4b7 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 xfb he y4bc ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xfb he y4bd ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5e he y4be ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x161 ha y4bf ffd fs7 fc0 sc0 ls0 ws0">j<span class="_ _1e"></span><span class="ffc">=1</span></div><div class="t m0 xd6 hc y4b7 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x92 ha y4ba ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x92 hb y4bb ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x61 hc y4b7 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x14b hb y4b8 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x15b h4 y4b7 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x148 ha y4ba ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x148 hb y4bb ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x162 he y4bc ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x162 he y4bd ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y4b7 ff3 fs2 fc0 sc0 ls0 ws0">(6.6)</div><div class="t m0 x3 h6 y1c7 ff1 fs2 fc0 sc0 ls0 ws0">上述部分属于<span class="_ _25"> </span><span class="ff3">feed-forward </span>部分，<span class="_ _22"></span>从前往后依次计算出各个输出层，<span class="_ _22"></span>最后求得<span class="_ _25"> </span><span class="ffa">y<span class="_ _26"></span></span>。<span class="_ _22"></span>但此时这些权</div><div class="t m0 x3 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">值还未知。</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">37</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2b" class="pf w0 h0" data-page-no="2b"><div class="pc pc2b w0 h0"><img class="bi x163 y4c0 wf h33" alt="" src="bg2b.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">6.4<span class="_ _d"> </span><span class="ff8">反向传播</span></div><div class="t m0 xfd h9 yaf ff5 fs6 fc0 sc0 ls0 ws0">6.4<span class="_ _1f"> </span><span class="ff9">反向传播</span></div><div class="t m0 x3 h6 y4c1 ff1 fs2 fc0 sc0 ls0 ws0">首先，<span class="_ _27"></span>对所有的权值<span class="_ _25"> </span><span class="ffa">w<span class="_ _9"> </span></span>给定一个初始值，<span class="_ _27"></span>然后根据前向传播的方式来计算出输出值<span class="_ _25"> </span><span class="ffa">y<span class="_ _1e"></span></span>，<span class="_ _21"></span>为了评估</div><div class="t m0 x3 h6 y4c2 ff1 fs2 fc0 sc0 ls0 ws0">此次训<span class="_ _1e"></span>练模<span class="_ _1e"></span>型是否<span class="_ _1e"></span>合理，我<span class="_ _1e"></span>们取网<span class="_ _1e"></span>络所<span class="_ _1e"></span>有输出<span class="_ _1e"></span>层节点<span class="_ _1e"></span>的误<span class="_ _1e"></span>差平方<span class="_ _1e"></span>和作为<span class="_ _1e"></span>目标<span class="_ _1e"></span>函数，对<span class="_ _1e"></span>于样本<span class="_ _12"> </span><span class="ffa">k<span class="_ _1e"></span></span>，</div><div class="t m0 x3 h6 y4c3 ff1 fs2 fc0 sc0 ls0 ws0">其误差表达式为：</div><div class="t m0 x87 hc y4c4 ffa fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x47 hb y4c5 ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 xaa h4 y4c4 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x12d h4 y4c6 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x12d h4 y4c7 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8e h1d y4c8 ff16 fs7 fc0 sc0 ls0 ws0">output</div><div class="t m0 xf0 he y4c9 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xa5 ha y4ca ffd fs7 fc0 sc0 ls0 ws0">j<span class="_ _1e"></span><span class="ffc">=1</span></div><div class="t m0 xa2 h4 y4c4 ffb fs2 fc0 sc0 ls0 ws0">[<span class="ffa">t</span></div><div class="t m0 x26 hb y4cb ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x164 h4 y4c4 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 xe3 hb y4cb ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x61 h4 y4c4 ffb fs2 fc0 sc0 ls0 ws0">]</div><div class="t m0 x64 ha y4cc ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x33 h4 y4c4 ff3 fs2 fc0 sc0 ls0 ws0">(6.7)</div><div class="t m0 x3 h6 y4cd ff1 fs2 fc0 sc0 ls0 ws0">有了目标函数之后，现在我们采用梯度下降来寻找最优解。</div><div class="t m0 x3 h12 y4ce ff5 fs8 fc0 sc0 ls0 ws0">6.4.1<span class="_ _34"> </span><span class="ff9">输出层</span></div><div class="t m0 x3 h6 y4cf ff1 fs2 fc0 sc0 ls0 ws0">对于输出层节点，第<span class="_ _9"> </span><span class="ffa">i<span class="_ _9"> </span></span>个输出节点与第<span class="_ _9"> </span><span class="ffa">j<span class="_ _12"> </span></span>个隐藏节点的权值更新规则为：</div><div class="t m0 xfd hc y4d0 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x100 ha y4d1 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x105 hb y4d2 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xa7 h4 y4d0 fff fs2 fc0 sc0 ls0 ws0">←<span class="_ _2f"> </span><span class="ffa">w</span></div><div class="t m0 x8f ha y4d1 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x8f hb y4d2 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x134 h4 y4d0 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">η</span></div><div class="t m0 x165 hc y4d3 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>E</div><div class="t m0 xe3 hb y4d4 ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 x27 hc y4d5 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 xf4 ha y4d6 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xf4 hb y4d7 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x33 h4 y4d0 ff3 fs2 fc0 sc0 ls0 ws0">(6.8)</div><div class="t m0 x3 h6 y4d8 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _9"> </span><span class="ffa">η<span class="_ _a"> </span></span>为学习率，由于<span class="_ _25"> </span><span class="ffa">E</span></div><div class="t m0 x166 hb y4d9 ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 x12b h6 y4d8 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _9"> </span><span class="ffa">y</span></div><div class="t m0 xbb hb y4da ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x145 h6 y4d8 ff1 fs2 fc0 sc0 ls0 ws0">的函数，<span class="ffa">y</span></div><div class="t m0 x86 hb y4da ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xbe h6 y4d8 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _9"> </span><span class="ffa">net</span></div><div class="t m0 xac ha y4db ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x42 h6 y4d8 ff1 fs2 fc0 sc0 ls0 ws0">的函数，<span class="ffa">net</span></div><div class="t m0 x151 ha y4db ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x167 h6 y4d8 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _9"> </span><span class="ffa">w</span></div><div class="t m0 x11d hb y4da ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xe7 h6 y4d8 ff1 fs2 fc0 sc0 ls0 ws0">的函数，根据链式</div><div class="t m0 x3 h6 y4dc ff1 fs2 fc0 sc0 ls0 ws0">求导法则，有：</div><div class="t m0 xee hc y4dd ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>E</div><div class="t m0 x158 hb y4de ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 x2 hc y4df ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 xfd ha y4e0 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xfd hb y4e1 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xe2 h4 y4e2 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xf1 hc y4dd ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>E</div><div class="t m0 x15d hb y4de ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 xbd hc y4e3 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 xa5 hb y4e4 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x134 hc y4dd ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 x144 hb y4e5 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x8 hc y4df ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x26 ha y4e0 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x26 hb y4e1 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xad hc y4e6 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 xef ha y4e7 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xef hb y4e8 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x43 hc y4df ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 x106 ha y4e0 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x106 hb y4e1 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x33 h4 y4e2 ff3 fs2 fc0 sc0 ls0 ws0">(6.9)</div><div class="t m0 x3 h6 y4e9 ff1 fs2 fc0 sc0 ls0 ws0">根据上述公式，可以分别求出偏导数：</div><div class="t m0 x168 hc y4ea ffa fs2 fc2 sc0 ls0 ws0">∂<span class="_ _26"></span>E</div><div class="t m0 x169 hb y4eb ffd fs7 fc2 sc0 ls0 ws0">k</div><div class="t m0 xeb hc y4ec ffa fs2 fc2 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 x16 hb y4ed ffd fs7 fc2 sc0 ls0 ws0">i</div><div class="t m0 x12a h4 y4ee ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x82 hc y4ea ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x44 hc y4ec ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 xd3 hb y4ed ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x7 he y4ef ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x7 he y4f0 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3b h4 y4ea ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3b h4 y4ec ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 xa h1d y4f1 ff16 fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x87 he y4f2 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x48 hb y4f3 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x49 h4 y4ee ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">t</span></div><div class="t m0 x1 hb y4f4 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x40 h4 y4ee fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 x25 hb y4f4 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x99 h4 y4ee ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x91 ha y4f5 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x154 he y4ef ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x154 he y4f0 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x12a h4 y4f6 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x82 hc y4f7 ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x44 hc y4f8 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 xd3 hb y4f9 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x7 he y4fa ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x45 h4 y4f7 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x45 h4 y4f8 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 xee h4 y4f6 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">t</span></div><div class="t m0 xc4 hb y4fb ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x158 h4 y4f6 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 xb9 hb y4fb ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x5a h4 y4f6 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xf1 ha y4fc ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x86 he y4fa ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xbe ha y4fd ffd fs7 fc0 sc0 ls0 ws0">j<span class="_ _1e"></span><span class="ffc">=</span>i</div><div class="t m0 x16a h4 y4f6 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x26 hc y4f7 ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 xb4 hc y4f8 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 x164 hb y4f9 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xad he y4fe ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xad he y4ff ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x14d h4 y4f7 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x14d h4 y4f8 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x64 h1d y500 ff16 fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x50 he y501 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x137 hb y502 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x15a h4 y4f6 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">t</span></div><div class="t m0 x151 hb y4fb ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x14c h4 y4f6 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 x13c hb y4fb ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x126 h4 y4f6 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x16b ha y4fc ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xe6 he y4fe ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xe6 he y4ff ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x57 ha y503 ffd fs7 fc0 sc0 ls0 ws0">j<span class="_ _1e"></span><span class="ff12"≯<span class="ffc">=</span></span>i</div><div class="t m0 x12a h4 y504 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x82 hc y505 ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x44 hc y506 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 xd3 hb y507 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x7 he y508 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x45 h4 y505 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x45 h4 y506 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 xee h4 y504 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">t</span></div><div class="t m0 xc4 hb y509 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xe1 h4 y504 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 x16c hb y509 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x49 h4 y504 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x12d ha y50a ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x1 he y508 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xbe h4 y504 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span>0</div><div class="t m0 x12a h4 y50b ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="fff">−<span class="_ _2c"></span></span>(<span class="ffa">t</span></div><div class="t m0 x7 hb y50c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x9c h4 y50b fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 x132 hb y50c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x87 h4 y50b ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xb6 hc y50d ffa fs2 fc2 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 x111 hb y50e ffd fs7 fc2 sc0 ls0 ws0">i</div><div class="t m0 xc6 hc y50f ffa fs2 fc2 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x129 ha y510 ffc fs7 fc2 sc0 ls0 ws0">(2)</div><div class="t m0 x129 hb y511 ffd fs7 fc2 sc0 ls0 ws0">i</div><div class="t m0 x12a h4 y512 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">y</span></div><div class="t m0 xcc hb y513 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x14e h4 y512 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">y</span></span></div><div class="t m0 xbc hb y513 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1f h4 y512 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xc6 hc y514 ffa fs2 fc2 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x129 ha y515 ffc fs7 fc2 sc0 ls0 ws0">(2)</div><div class="t m0 x129 hb y516 ffd fs7 fc2 sc0 ls0 ws0">i</div><div class="t m0 x16d hc y517 ffa fs2 fc2 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 xc2 ha y518 ffc fs7 fc2 sc0 ls0 ws0">(2)</div><div class="t m0 x16e hb y519 ffd fs7 fc2 sc0 ls0 ws0">ij</div><div class="t m0 x12a h4 y51a ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">h</span></div><div class="t m0 x82 hb y51b ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xba h4 y51c ff3 fs2 fc0 sc0 ls0 ws0">(6.10)</div><div class="t m0 x16f hb y51d ffd fs7 fc0 sc0 ls0 ws0">∂<span class="_ _1e"></span>y</div><div class="t m0 xfa h22 y51e ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 x163 hb y51f ffd fs7 fc0 sc0 ls0 ws0">∂<span class="_ _1e"></span>net</div><div class="t m0 x170 h18 y520 ff14 fs9 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x170 h22 y521 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 x12e h6 y522 ff1 fs2 fc0 sc0 ls0 ws0">就是激活函数求导：</div><div class="t m0 x97 h4 y523 ffa fs2 fc0 sc0 ls0 ws0">y<span class="_ _25"> </span><span class="ffb">=<span class="_ _2f"> </span></span>f<span class="_ _2b"> </span><span class="ffb">(</span>z<span class="_ _26"></span><span class="ffb">)<span class="_ _2f"> </span>=</span></div><div class="t m0 xa5 h4 y524 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x12d h4 y525 ffb fs2 fc0 sc0 ls0 ws0">1<span class="_ _30"> </span>+<span class="_ _30"> </span><span class="ffa">e</span></div><div class="t m0 x41 ha y526 ff12 fs7 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 xca hc y527 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 x132 ha y528 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 xc4 h4 y527 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">z<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=</div><div class="t m0 xa5 hc y529 ffa fs2 fc0 sc0 ls0 ws0">e</div><div class="t m0 xa1 ha y52a ff12 fs7 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 x12d h4 y52b ffb fs2 fc0 sc0 ls0 ws0">(<span class="ffa">e</span></div><div class="t m0 x171 ha y52c ff12 fs7 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 x8 h4 y52b ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span>1)</div><div class="t m0 xac ha y52d ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xaa h4 y52e ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xa5 h4 y52f ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x12d h4 y530 ffb fs2 fc0 sc0 ls0 ws0">1<span class="_ _30"> </span>+<span class="_ _30"> </span><span class="ffa">e</span></div><div class="t m0 x41 ha y531 ff12 fs7 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 xa2 h4 y52e fff fs2 fc0 sc0 ls0 ws0">−</div><div class="t m0 x27 he y532 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x60 h4 y52f ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xad h4 y530 ffb fs2 fc0 sc0 ls0 ws0">1<span class="_ _30"> </span>+<span class="_ _30"> </span><span class="ffa">e</span></div><div class="t m0 x172 ha y531 ff12 fs7 fc0 sc0 ls0 ws0">−<span class="ffd">z</span></div><div class="t m0 x29 he y532 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x125 ha y533 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xaa h4 y534 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">y<span class="_ _f"> </span><span class="fff">−<span class="_ _30"> </span></span>y</span></div><div class="t m0 x8 ha y535 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xba h4 y536 ff3 fs2 fc0 sc0 ls0 ws0">(6.11)</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">38</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2c" class="pf w0 h0" data-page-no="2c"><div class="pc pc2c w0 h0"><img class="bi x101 y537 w10 h34" alt="" src="bg2c.png"/><div class="t m0 x77 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">6.5<span class="_ _d"> </span><span class="ff8">权值更新归纳</span></div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">由此可得，</div><div class="t m0 x9f hc y538 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>E</div><div class="t m0 xee hb y539 ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 x159 hc y53a ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 x2 ha y53b ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x2 hb y53c ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x1c h4 y53d ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="fff">−<span class="_ _2c"></span></span>(<span class="ffa">t</span></div><div class="t m0 x4 hb y53e ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x40 h4 y53d fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 x25 hb y53e ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xf3 h4 y53d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">·<span class="_ _30"> </span><span class="ffa">y</span></span></div><div class="t m0 xbf hb y53e ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd6 h4 y53d ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">y</span></span></div><div class="t m0 xef hb y53e ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x15b h4 y53d ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">·<span class="_ _30"> </span><span class="ffa">h</span></span></div><div class="t m0 x125 hb y53e ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xba h4 y53d ff3 fs2 fc0 sc0 ls0 ws0">(6.12)</div><div class="t m0 x3 h12 y53f ff5 fs8 fc0 sc0 ls0 ws0">6.4.2<span class="_ _34"> </span><span class="ff9">隐藏层</span></div><div class="t m0 x3 h6 y540 ff1 fs2 fc0 sc0 ls0 ws0">首先，<span class="_ _22"></span>对于隐藏层的任意一个神经元，<span class="_ _20"></span>输出层的每个神经单元的误差对其都有影响。<span class="_ _31"></span>因此，<span class="_ _22"></span>对于</div><div class="t m0 x3 h6 y541 ff1 fs2 fc0 sc0 ls0 ws0">隐藏层第<span class="_ _9"> </span><span class="ffa">i<span class="_ _9"> </span></span>个神经元，它与输入层的第<span class="_ _9"> </span><span class="ffa">j<span class="_ _12"> </span></span>个神经元的权值更新规则为：</div><div class="t m0 xe1 hc y542 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x9 ha y543 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x9 hb y544 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x14a h4 y542 fff fs2 fc0 sc0 ls0 ws0">←<span class="_ _2f"> </span><span class="ffa">w</span></div><div class="t m0 xa1 ha y543 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xa1 hb y544 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x5e h4 y542 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">η</span></div><div class="t m0 x165 hc y545 ffa fs2 fc2 sc0 ls0 ws0">∂<span class="_ _26"></span>E</div><div class="t m0 xe3 hb y546 ffd fs7 fc2 sc0 ls0 ws0">k</div><div class="t m0 x164 hc y547 ffa fs2 fc2 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 x13f hb y548 ffd fs7 fc2 sc0 ls0 ws0">ij</div><div class="t m0 xba h4 y542 ff3 fs2 fc0 sc0 ls0 ws0">(6.13)</div><div class="t m0 x3 h6 y549 ff1 fs2 fc0 sc0 ls0 ws0">接着由链式法则，我们对上面红色部分进行展开：</div><div class="t m0 x65 hc y54a ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>E</div><div class="t m0 xb7 hb y54b ffd fs7 fc0 sc0 ls0 ws0">k</div><div class="t m0 x10a hc y54c ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 xc ha y54d ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xc hb y54e ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xa6 h4 y54f ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xca hc y54a ffa fs2 fc0 sc0 ls0 ws0">∂</div><div class="t m0 x9c hc y54c ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 xb8 ha y54d ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xb8 hb y54e ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x20 he y550 ffe fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 xe2 hb y551 ffd fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x142 he y552 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x4a hb y553 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x8f hc y54f ffa fs2 fc0 sc0 ls0 ws0">E</div><div class="t m0 x25 hb y554 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x99 he y550 ffe fs2 fc0 sc0 ls0 ws0">!</div><div class="t m0 xa6 h4 y555 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xbb hb y556 ffd fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x145 he y557 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xee hb y558 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x105 hc y559 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>E</div><div class="t m0 x49 hb y55a ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x100 hc y55b ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>y</div><div class="t m0 x21 hb y55c ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 xf0 hc y559 ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 x90 hb y55a ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x3f hc y55d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x41 ha y55e ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x41 hb y55f ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 xa2 hc y559 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x92 ha y560 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x92 hb y561 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x136 hc y55b ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>h</div><div class="t m0 xad hb y55c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x172 hc y559 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>h</div><div class="t m0 x29 hb y55a ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x60 hc y55d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x29 ha y55e ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x29 hb y562 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x131 hc y563 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x2c ha y564 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x2c hb y565 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x173 hc y55b ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 x174 hb y55c ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xa6 h4 y566 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xbb hb y567 ffd fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x145 he y568 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xee hb y569 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x20 he y56a ffe fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 xe2 h4 y566 fff fs2 fc0 sc0 ls0 ws0">−<span class="ffa">δ</span></div><div class="t m0 x3f hb y56b ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x171 h4 y566 fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 xa5 hc y56c ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x4b ha y56d ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x4b hb y56e ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x41 hc y56f ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>h</div><div class="t m0 x91 hb y570 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xad hc y571 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>h</div><div class="t m0 x61 hb y572 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4d hc y573 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x112 ha y574 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x112 hb y575 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x94 hc y56c ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x15a ha y56d ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x15a hb y56e ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x62 hc y573 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 x175 ha y574 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x2b hb y575 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x121 he y56a ffe fs2 fc0 sc0 ls0 ws0">!</div><div class="t m0 xa6 h4 y576 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xbb hb y577 ffd fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x145 he y578 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xee hb y579 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x20 he y57a ffe fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 xe2 h4 y576 fff fs2 fc0 sc0 ls0 ws0">−<span class="ffa">δ</span></div><div class="t m0 x3f hb y57b ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x171 h4 y576 fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x8 ha y57c ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x5c hb y57d ffd fs7 fc0 sc0 ls0 ws0">si</div><div class="t m0 x91 h4 y576 fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 x4d hc y57e ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>h</div><div class="t m0 x93 hb y57f ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13b hc y580 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 xf4 ha y581 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xf4 hb y582 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4e hc y583 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x2a ha y584 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x2a hb y585 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xef hc y580 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 xd8 ha y581 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xd8 hb y582 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xd5 he y57a ffe fs2 fc0 sc0 ls0 ws0">!</div><div class="t m0 xa6 h4 y586 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xbb h1d y587 ff16 fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x145 he y588 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xee hb y589 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x20 he y58a ffe fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 xe2 h4 y586 fff fs2 fc0 sc0 ls0 ws0">−<span class="ffa">δ</span></div><div class="t m0 x3f hb y58b ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x171 h4 y586 fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _30"> </span><span class="ffa">w</span></div><div class="t m0 x8 ha y58c ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 x176 hb y58d ffd fs7 fc0 sc0 ls0 ws0">si</div><div class="t m0 x91 h4 y586 fff fs2 fc0 sc0 ls0 ws0">·<span class="_ _30"> </span><span class="ffa">h</span></div><div class="t m0 x155 hb y58b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd6 h4 y586 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">h</span></span></div><div class="t m0 x172 hb y58b ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4f h4 y586 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">·</span></div><div class="t m0 xa3 hc y58e ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>net</div><div class="t m0 x121 ha y58f ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x121 hb y590 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x51 hc y591 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>w</div><div class="t m0 x151 ha y592 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x151 hb y593 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x54 he y58a ffe fs2 fc0 sc0 ls0 ws0">!</div><div class="t m0 xa6 h4 y594 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xbb h1d y595 ff16 fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x145 he y596 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xee hb y597 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x20 he y598 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x102 h4 y594 fff fs2 fc0 sc0 ls0 ws0">−<span class="ffa">δ</span></div><div class="t m0 x12d hb y599 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x1 hc y594 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xbe ha y59a ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xbe hb y59b ffd fs7 fc0 sc0 ls0 ws0">si</div><div class="t m0 x41 hc y594 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xf3 hb y599 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x5e h4 y594 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">h</span></span></div><div class="t m0 xf4 hb y599 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xe3 h4 y594 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2c"> </span><span class="ffa">x</span></div><div class="t m0 xd7 hb y599 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x15b he y598 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa6 h4 y59c ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="fff">−<span class="ffa">h</span></span></div><div class="t m0 x46 hb y59d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc4 h4 y59c ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">h</span></span></div><div class="t m0 x14a hb y59d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x3f h4 y59c ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x171 he y59e ffe fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x5b h1d y59f ff16 fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 x41 he y5a0 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xf3 hb y5a1 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 xbf hc y59c ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x164 hb y59d ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x133 hc y59c ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xf4 ha y5a2 ffc fs7 fc0 sc0 ls0 ws0">(2)</div><div class="t m0 xf4 hb y5a3 ffd fs7 fc0 sc0 ls0 ws0">si</div><div class="t m0 x64 he y59e ffe fs2 fc0 sc0 ls0 ws0">!</div><div class="t m0 x94 hc y59c ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x9d hb y59d ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xba h4 y5a4 ff3 fs2 fc0 sc0 ls0 ws0">(6.14)</div><div class="t m0 x3 h6 y5a5 ff1 fs2 fc0 sc0 ls0 ws0">代入到上式，得到隐藏层的权值更新公式：</div><div class="t m0 x166 hc y5a6 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x12b ha y5a7 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x12b hb y5a8 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x159 h4 y5a6 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">w</span></div><div class="t m0 xa ha y5a7 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xa hb y5a8 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xb3 h4 y5a6 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">η<span class="_ _1e"></span>h</span></div><div class="t m0 x4a hb y5a9 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x86 h4 y5a6 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">h</span></span></div><div class="t m0 x161 hb y5a9 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x177 h4 y5a6 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x26 he y5aa ffe fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x165 hb y5ab ffd fs7 fc0 sc0 ls0 ws0">outputs</div><div class="t m0 xad he y5ac ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x5f hb y5ad ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x50 hc y5a6 ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x135 hb y5a9 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x9d hc y5a6 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x148 hb y5a9 ffd fs7 fc0 sc0 ls0 ws0">si</div><div class="t m0 x178 he y5aa ffe fs2 fc0 sc0 ls0 ws0">!</div><div class="t m0 x89 hc y5a6 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x8a hb y5a9 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xba h4 y5a6 ff3 fs2 fc0 sc0 ls0 ws0">(6.15)</div><div class="t m0 x3 h6 y5ae ff1 fs2 fc0 sc0 ls0 ws0">令<span class="_ _9"> </span><span class="ffa">δ</span></div><div class="t m0 x179 hb y5af ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x10b h4 y5ae ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x17a hb y5b0 ffd fs7 fc0 sc0 ls0 ws0">∂<span class="_ _1e"></span>E</div><div class="t m0 x17b h22 y5b1 ff17 fs9 fc0 sc0 ls0 ws0">k</div><div class="t m0 x35 hb y5b2 ffd fs7 fc0 sc0 ls0 ws0">∂<span class="_ _1e"></span>net</div><div class="t m0 xcf h22 y5b3 ff17 fs9 fc0 sc0 ls0 ws0">i</div><div class="t m0 xfe h4 y5ae ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="fff">−<span class="ffa">h</span></span></div><div class="t m0 x76 hb y5af ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x168 h4 y5ae ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">h</span></span></div><div class="t m0 x39 hb y5af ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x70 h4 y5ae ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _29"> </span>(</div><div class="t m0 xd he y5b4 ffe fs2 fc0 sc0 ls0 ws0">P</div><div class="t m0 x7 hb y5b5 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x8d hc y5ae ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x145 hb y5af ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x3c hc y5ae ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x1f hb y5af ffd fs7 fc0 sc0 ls0 ws0">si</div><div class="t m0 x158 h6 y5ae ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">，则公式简化为：</span></div><div class="t m0 x47 hc y5b6 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x88 ha y5b7 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 xaa hb y5b8 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x3f h4 y5b6 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">w</span></div><div class="t m0 x5c ha y5b7 ffc fs7 fc0 sc0 ls0 ws0">(1)</div><div class="t m0 x5c hb y5b8 ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x161 h4 y5b6 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">η<span class="_ _1e"></span>δ</span></div><div class="t m0 x133 hb y5b9 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x92 hc y5b6 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x14d hb y5b9 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xba h4 y5b6 ff3 fs2 fc0 sc0 ls0 ws0">(6.16)</div><div class="t m0 x1d h9 y5ba ff5 fs6 fc0 sc0 ls0 ws0">6.5<span class="_ _1f"> </span><span class="ff9">权值更新归纳</span></div><div class="t m0 x3 h6 y5bb ff1 fs2 fc0 sc0 ls0 ws0">通过<span class="_ _9"> </span><span class="ff3">BP<span class="_ _a"> </span></span>推导，现在我们知道<span class="_ _1e"></span>如何更新权值了，<span class="_ _1e"></span>下面来总结一下。假<span class="_ _1e"></span>定每个节点的误差<span class="_ _1e"></span>项为<span class="_ _9"> </span><span class="ffa">δ</span></div><div class="t m0 x17c hb y5bc ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x17d h6 y5bb ff1 fs2 fc0 sc0 ls0 ws0">，</div><div class="t m0 x3 h6 y5bd ff1 fs2 fc0 sc0 ls0 ws0">不管是隐藏节点还是输出节点，其输出值统一使用<span class="_ _9"> </span><span class="ffa">x</span></div><div class="t m0 xb1 hb y5be ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x133 h6 y5bd ff1 fs2 fc0 sc0 ls0 ws0">来表示，那么权值更新规则为：</div><div class="t m0 x100 hc y1f9 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x59 hb y5bf ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 xf1 h4 y1f9 fff fs2 fc0 sc0 ls0 ws0">←<span class="_ _2f"> </span><span class="ffa">w</span></div><div class="t m0 x8 hb y5bf ffd fs7 fc0 sc0 ls0 ws0">ij</div><div class="t m0 x134 h4 y1f9 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">η<span class="_ _1e"></span>δ</span></div><div class="t m0 xc0 hb y5bf ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x133 hc y1f9 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x93 hb y5bf ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xba h4 y1f9 ff3 fs2 fc0 sc0 ls0 ws0">(6.17)</div><div class="t m0 x3 h6 y5c0 ff1 fs2 fc0 sc0 ls0 ws0">当节点为输出层神经元时，</div><div class="t m0 x1f hc y1e ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 xfd hb y9d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x20 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="fff">−<span class="ffa">y</span></span></div><div class="t m0 x4 hb y9d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x8e h4 y1e ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">y</span></span></div><div class="t m0 x4b hb y9d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb4 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">)(<span class="ffa">t</span></div><div class="t m0 xd6 hb y9d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xad h4 y1e fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 x17e hb y9d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4e h4 y1e ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _4f"> </span><span class="ff3">(6.18)</span></div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">39</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2d" class="pf w0 h0" data-page-no="2d"><div class="pc pc2d w0 h0"><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">6.5<span class="_ _d"> </span><span class="ff8">权值更新归纳</span></div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">当节点为隐藏层神经元时，</div><div class="t m0 x157 hc y5c1 ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 xca hb y5c2 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x132 h4 y5c1 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="fff">−<span class="ffa">h</span></span></div><div class="t m0 x21 hb y5c2 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xa7 h4 y5c1 ffb fs2 fc0 sc0 ls0 ws0">(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">h</span></span></div><div class="t m0 x25 hb y5c2 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xf3 h4 y5c1 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x161 he y5c3 ffe fs2 fc0 sc0 ls0 ws0"> </div><div class="t m0 x144 he y5c4 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x27 hb y5c5 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x43 hc y5c1 ffa fs2 fc0 sc0 ls0 ws0">δ</div><div class="t m0 x14d hb y5c2 ffd fs7 fc0 sc0 ls0 ws0">s</div><div class="t m0 x140 hc y5c1 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x17f hb y5c2 ffd fs7 fc0 sc0 ls0 ws0">si</div><div class="t m0 x4f he y5c3 ffe fs2 fc0 sc0 ls0 ws0">!</div><div class="t m0 xba h4 y5c1 ff3 fs2 fc0 sc0 ls0 ws0">(6.19)</div><div class="t m0 x3 h6 y5c6 ff1 fs2 fc0 sc0 ls0 ws0">其中，<span class="ffa">δ</span></div><div class="t m0 x101 hb y5c7 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x81 h6 y5c6 ff1 fs2 fc0 sc0 ls0 ws0">是节点的误差项，<span class="ffa">y</span></div><div class="t m0 xa4 hb y5c7 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1b h6 y5c6 ff1 fs2 fc0 sc0 ls0 ws0">是输出节点的输出值，<span class="ffa">t</span></div><div class="t m0 x133 hb y5c7 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x93 h6 y5c6 ff1 fs2 fc0 sc0 ls0 ws0">是样本<span class="_ _9"> </span><span class="ffa">i<span class="_ _a"> </span></span>对应的目标值，<span class="ffa">h</span></div><div class="t m0 x180 hb y5c7 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x30 h6 y5c6 ff1 fs2 fc0 sc0 ls0 ws0">为隐藏节点</div><div class="t m0 x3 h6 y5c8 ff1 fs2 fc0 sc0 ls0 ws0">的输出值。权值更新归纳</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">40</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2e" class="pf w0 h0" data-page-no="2e"><div class="pc pc2e w0 h0"><div class="t m0 x9 h5 y4b ff4 fs3 fc0 sc0 ls0 ws0">第四部分</div><div class="t m0 x9 h5 y4c ff4 fs3 fc0 sc0 ls0 ws0">神经网络</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">41</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf2f" class="pf w0 h0" data-page-no="2f"><div class="pc pc2f w0 h0"></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf30" class="pf w0 h0" data-page-no="30"><div class="pc pc30 w0 h0"><img class="bi x3 y5c9 w2 h35" alt="" src="bg30.png"/><div class="t m0 x44 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第七章 <span class="ff5">P<span class="_ _31"></span>erceptron</span></div><div class="t m0 x3 h6 yf1 ff3 fs2 fc0 sc0 ls0 ws0">P<span class="_ _e"></span>erceptron<span class="_ _a"> </span><span class="ff1">由<span class="_ _a"> </span></span>Rosenblatt<span class="_ _a"> </span><span class="ff1">于<span class="_ _a"> </span></span>1957<span class="_ _a"> </span><span class="ff1">年<span class="_ _1e"></span>提出，是<span class="_ _1e"></span>一种<span class="_ _1e"></span>简单的<span class="_ _1e"></span>线性二<span class="_ _1e"></span>分类<span class="_ _1e"></span>模型。可<span class="_ _1e"></span>以认为，<span class="_ _1e"></span>感知机</span></div><div class="t m0 x3 h6 yf2 ff1 fs2 fc0 sc0 ls0 ws0">是最简单的神经网络。<span class="_ _22"></span>感知机可以在输入空间划出一条直线，<span class="_ _22"></span>或者一个平面、<span class="_ _22"></span>超平面，<span class="_ _22"></span>如果训练</div><div class="t m0 x3 h6 yf3 ff1 fs2 fc0 sc0 ls0 ws0">集是线性可分的，那么两类样本则分别位于超平面的两侧。</div><div class="t m0 x3 h6 yf4 ff1 fs2 fc0 sc0 ls0 ws0">以下图的感知机为例子：</div><div class="t m0 x122 h6 y5ca ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">7.1:<span class="_ _1c"> </span></span>两个输入神经元的感知机结构示意图</div><div class="t m0 x71 h6 y5cb ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">7.2:<span class="_ _1c"> </span>sgn<span class="_ _9"> </span></span>激活函数</div><div class="t m0 x3 h6 y5cc ff1 fs2 fc0 sc0 ls0 ws0">假设输入空间<span class="_ _a"> </span><span class="ff3">(</span>特征向量<span class="ff3">)<span class="_ _9"> </span></span>为<span class="_ _a"> </span><span class="ff11">X<span class="_ _a"> </span><span class="fff">⊆<span class="_ _25"> </span><span class="ffa">R</span></span></span></div><div class="t m0 xfd ha y5cd ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb3 h6 y5cc ff1 fs2 fc0 sc0 ls0 ws0">，输出空间为<span class="_ _a"> </span><span class="ffa">Y<span class="_ _4"> </span><span class="ffb">=<span class="_ _2f"> </span><span class="fff">{−</span>1</span>,<span class="_ _2c"> </span><span class="ffb">+1<span class="fff">}</span></span></span>。输入<span class="_ _a"> </span><span class="ff11">x</span></div><div class="t m0 x181 ha y5cd ff1f fs7 fc0 sc0 ls0 ws0">(<span class="ff11">i</span>)</div><div class="t m0 x8b h6 y5cc fff fs2 fc0 sc0 ls0 ws0">∈<span class="_ _2f"> </span><span class="ffa">X<span class="_ _1c"> </span><span class="ff1">表示第<span class="_ _a"> </span></span>i<span class="_ _9"> </span><span class="ff1">个</span></span></div><div class="t m0 x3 h6 y5ce ff1 fs2 fc0 sc0 ls0 ws0">样本的特征向量。输出<span class="_ _9"> </span><span class="ffa">y</span></div><div class="t m0 x37 ha y5cf ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">i</span>)</div><div class="t m0 x12b h6 y5ce fff fs2 fc0 sc0 ls0 ws0">∈<span class="_ _2f"> </span><span class="ffa">Y<span class="_ _7"> </span><span class="ff1">表示第<span class="_ _9"> </span></span>i<span class="_ _9"> </span><span class="ff1">个样本的类别。显然这个感知机要寻找的直线为：</span></span></div><div class="t m0 x158 hc y5d0 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x9 ha y5d1 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xe2 hc y5d0 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x142 ha y5d1 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3f h4 y5d0 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x23 hc y5d2 ffa fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xa1 ha y5d1 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x5d hc y5d0 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x99 ha y5d1 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x177 h4 y5d0 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x27 hc y5d2 ffa fs2 fc0 sc0 ls0 ws0">b</div><div class="t m0 x42 h4 y5d0 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>0</div><div class="t m0 x1e h6 y5d3 ff1 fs2 fc0 sc0 ls0 ws0">这里的<span class="_ _9"> </span><span class="ffa">x</span></div><div class="t m0 xdb ha y5d4 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x182 h6 y5d3 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _9"> </span><span class="ffa">x</span></div><div class="t m0 xdd ha y5d4 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x183 h6 y5d3 ff1 fs2 fc0 sc0 ls0 ws0">并不来自输入空间。</div><div class="t m0 x3 h6 y5d5 ff1 fs2 fc0 sc0 ls0 ws0">而输入空间到输出空间的决策函数为：</div><div class="t m0 x3a h4 y5d6 ffb fs2 fc0 sc0 ls0 ws0">ˆ<span class="_ _50"></span><span class="ffa">y<span class="_ _25"> </span><span class="ffb">=<span class="_ _2f"> </span><span class="ff3">sgn<span class="_ _2c"> </span></span>(</span>f<span class="_ _2b"> </span><span class="ffb">(<span class="ff11">x</span>))<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff3">sgn</span></span></span></div><div class="t m0 xb1 he y5d7 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xcd h20 y5d6 ff11 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xf4 ha y5d8 ff12 fs7 fc0 sc0 ls0 ws0">⊤</div><div class="t m0 x140 h4 y5d6 ff11 fs2 fc0 sc0 ls0 ws0">x<span class="_ _30"> </span><span class="ffb">+<span class="_ _30"> </span><span class="ffa">b</span></span></div><div class="t m0 xd8 he y5d7 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3 h6 y5d9 ff1 fs2 fc0 sc0 ls0 ws0">可以看到，一个感知机主要由如下两部分组成：</div><div class="t m0 x9a h6 y5da ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">输入权值和偏置：<span class="ff11">w<span class="_ _9"> </span></span>和<span class="_ _9"> </span><span class="ffa">b</span></span></div><div class="t m0 x9a h6 y5db ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">激活函数：<span class="_ _2a"></span>感知器的激活函数可以有很多选择，<span class="_ _27"></span>比如这里选择的激活函数是<span class="_ _2f"> </span><span class="ffa">sig<span class="_ _26"></span>n<span class="_ _2f"> </span></span>符号函数</span></div><div class="t m0 x3 h6 y5dc ff1 fs2 fc0 sc0 ls0 ws0">因为感<span class="_ _1e"></span>知机只有<span class="_ _1e"></span>一个输<span class="_ _1e"></span>出层神<span class="_ _1e"></span>经元，其学<span class="_ _1e"></span>习能力<span class="_ _1e"></span>是非常有<span class="_ _1e"></span>限的，只<span class="_ _1e"></span>能处理<span class="_ _1e"></span>线性可分<span class="_ _1e"></span>问题。因<span class="_ _1e"></span>此，</div><div class="t m0 x3 h6 y5dd ff1 fs2 fc0 sc0 ls0 ws0">感知机被诟病最多的就是其不能处理非线性可分问题。</div><div class="t m0 x3 h6 y5de ff1 fs2 fc0 sc0 ls0 ws0">如图<span class="ff3">7.3</span>所示，<span class="_ _23"></span>“与、或、非”都是线性问题，而“异或”是非线性可分问题，感知机无法处理。</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">43</div><a class="l" href="#pf31" data-dest-detail='[49,"XYZ",435.52,618.78,null]'><div class="d m1" style="border-style:none;position:absolute;left:139.026000px;bottom:225.685500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf31" class="pf w0 h0" data-page-no="31"><div class="pc pc31 w0 h0"><img class="bi x76 y5df w3 h36" alt="" src="bg31.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">7.1<span class="_ _d"> </span><span class="ff8">参数学习</span></div><div class="t m0 x184 h6 y5e0 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">7.3:<span class="_ _1c"> </span></span>线性可分的“与”<span class="_ _23"></span>“或”<span class="_ _23"></span>“非”问题与非线性可分的“异或”问题</div><div class="t m0 xfd h9 y5e1 ff5 fs6 fc0 sc0 ls0 ws0">7.1<span class="_ _1f"> </span><span class="ff9">参数学习</span></div><div class="t m0 x3 h6 y5e2 ff1 fs2 fc0 sc0 ls0 ws0">感知<span class="_ _1e"></span>机的<span class="_ _1e"></span>学习<span class="_ _1e"></span>策<span class="_ _1e"></span>略是<span class="_ _1e"></span>最小<span class="_ _1e"></span>化损<span class="_ _1e"></span>失函<span class="_ _1e"></span>数。<span class="_ _1e"></span>损失<span class="_ _1e"></span>函数<span class="_ _1e"></span>的选<span class="_ _1e"></span>择<span class="_ _1e"></span>有多<span class="_ _1e"></span>种，这<span class="_ _1e"></span>里我<span class="_ _1e"></span>们采<span class="_ _1e"></span>用<span class="_ _1e"></span>的是<span class="_ _1e"></span>误分<span class="_ _1e"></span>类点<span class="_ _1e"></span>到</div><div class="t m0 x3 h6 y5e3 ff1 fs2 fc0 sc0 ls0 ws0">超平面的距离，如下：</div><div class="t m0 x3f h4 y5e4 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x16c h4 y5e5 fff fs2 fc0 sc0 ls0 ws0">∥<span class="_ _2f"> </span><span class="ff11">w<span class="_ _25"> </span></span>∥</div><div class="t m0 x90 h4 y5e6 fff fs2 fc0 sc0 ls0 ws0">|</div><div class="t m0 x176 h20 y5e7 ff11 fs2 fc0 sc0 ls0 ws0">w<span class="_ _1e"></span>x</div><div class="t m0 x4c h4 y5e6 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xd6 hc y5e7 ffa fs2 fc0 sc0 ls0 ws0">b</div><div class="t m0 x133 h4 y5e6 fff fs2 fc0 sc0 ls0 ws0">|</div><div class="t m0 x3 h6 y5e8 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _9"> </span><span class="fff">||<span class="ff11">w<span class="_ _1e"></span></span>||<span class="_ _9"> </span></span>是<span class="_ _9"> </span><span class="ffa">L</span></div><div class="t m0 x6a ha y5e9 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x38 h6 y5e8 ff1 fs2 fc0 sc0 ls0 ws0">范数，即是<span class="_ _9"> </span><span class="ff11">w<span class="_ _a"> </span></span>向量的模。</div><div class="t m0 x3 h6 y5ea ff1 fs2 fc0 sc0 ls0 ws0">对于正确分类的样本点<span class="_ _9"> </span><span class="ffb">(<span class="ff11">x</span></span></div><div class="t m0 x19 ha y5eb ff1f fs7 fc0 sc0 ls0 ws0">(<span class="ff11">i</span>)</div><div class="t m0 xd hc y5ea ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x159 ha y5eb ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">i</span>)</div><div class="t m0 x3b h6 y5ea ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">而言：</span></div><div class="t m0 x20 hc y5ec ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 x102 ha y5ed ffc fs7 fc0 sc0 ls0 ws0">(</div><div class="t m0 x8c hb y5ee ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x16c ha y5ed ffc fs7 fc0 sc0 ls0 ws0">)</div><div class="t m0 x49 h4 y5ec ffb fs2 fc0 sc0 ls0 ws0">(<span class="ff11">w<span class="_ _1e"></span>x</span></div><div class="t m0 x5b ha y5ed ff1f fs7 fc0 sc0 ls0 ws0">(</div><div class="t m0 xa1 h1e y5ee ff11 fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x41 ha y5ed ff1f fs7 fc0 sc0 ls0 ws0">)</div><div class="t m0 x12c h4 y5ec ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span>)<span class="_ _2f"> </span><span class="ffa">&gt;<span class="_ _2f"> </span></span>0</div><div class="t m0 x3 h6 y5ef ff1 fs2 fc0 sc0 ls0 ws0">所以，对于误分类点<span class="_ _9"> </span><span class="ffb">(<span class="ffa">x</span></span></div><div class="t m0 x65 hb y5f0 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x6b hc y5ef ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x185 hb y5f0 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x44 h6 y5ef ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">来说：</span></div><div class="t m0 x20 hc y5f1 ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 x102 ha y5f2 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">i</span>)</div><div class="t m0 x49 h4 y5f1 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ff11">w<span class="_ _1e"></span>x</span></div><div class="t m0 x5b ha y5f2 ff1f fs7 fc0 sc0 ls0 ws0">(<span class="ff11">i</span>)</div><div class="t m0 x12c h4 y5f1 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span>)<span class="_ _2f"> </span><span class="ffa">&lt;<span class="_ _2f"> </span></span>0</div><div class="t m0 x3 h6 y5f3 ff1 fs2 fc0 sc0 ls0 ws0">误分类点<span class="_ _9"> </span><span class="ff11">x</span></div><div class="t m0 x186 ha y5f4 ff1f fs7 fc0 sc0 ls0 ws0">(<span class="ff11">i</span>)</div><div class="t m0 xa8 h6 y5f3 ff1 fs2 fc0 sc0 ls0 ws0">到超平面的距离为：</div><div class="t m0 x187 h4 y5f5 fff fs2 fc0 sc0 ls0 ws0">−</div><div class="t m0 x16c h4 y5f6 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x100 h4 y5f7 fff fs2 fc0 sc0 ls0 ws0">∥<span class="_ _2f"> </span><span class="ffa">w<span class="_ _25"> </span></span>∥</div><div class="t m0 x8e hc y5f5 ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 xf0 ha y5f8 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">i</span>)</div><div class="t m0 x41 h4 y5f5 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ff11">w<span class="_ _1e"></span>x</span></div><div class="t m0 x26 ha y5f8 ff1f fs7 fc0 sc0 ls0 ws0">(<span class="ff11">i</span>)</div><div class="t m0 xad h4 y5f5 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span>)</div><div class="t m0 x3 h6 y5f9 ff1 fs2 fc0 sc0 ls0 ws0">那么，所有误分类的点到超平面的总距离为：</div><div class="t m0 x145 h4 y5fa fff fs2 fc0 sc0 ls0 ws0">−</div><div class="t m0 x158 h4 y5fb ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xbc h4 y5fc fff fs2 fc0 sc0 ls0 ws0">∥<span class="_ _2f"> </span><span class="ff11">w<span class="_ _25"> </span></span>∥</div><div class="t m0 xf1 he y5fd ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x142 h1e y5fe ff11 fs7 fc0 sc0 ls0 ws0">x</div><div class="t m0 x4a h18 y5ff ff22 fs9 fc0 sc0 ls0 ws0">(<span class="ff23">i</span>)</div><div class="t m0 xa0 hb y5fe ffd fs7 fc0 sc0 ls0 ws0">ϵM</div><div class="t m0 x41 hc y5fa ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 x12c ha y600 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">i</span>)</div><div class="t m0 xb4 h4 y5fa ffb fs2 fc0 sc0 ls0 ws0">(<span class="ff11">w<span class="_ _1e"></span>x</span></div><div class="t m0 xc1 ha y600 ff1f fs7 fc0 sc0 ls0 ws0">(<span class="ff11">i</span>)</div><div class="t m0 x17e h4 y5fa ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span>)</div><div class="t m0 x3 h6 y601 ff1 fs2 fc0 sc0 ls0 ws0">由于极值计算不受常量的影响，因此不考虑</div><div class="t m0 x15d ha y602 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x40 ha y603 ff12 fs7 fc0 sc0 ls0 ws0">||<span class="ffd">w</span>||</div><div class="t m0 x143 h6 y601 ff1 fs2 fc0 sc0 ls0 ws0">，由此得到感知机的损失函数如下：</div><div class="t m0 x11b h4 y604 ffa fs2 fc0 sc0 ls0 ws0">L<span class="ffb">(</span>w<span class="_ _1e"></span>,<span class="_ _29"> </span>b <span class="ffb">)<span class="_ _2f"> </span>=<span class="_ _25"> </span><span class="fff">−</span></span></div><div class="t m0 x40 he y605 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x4 h1e y606 ff11 fs7 fc0 sc0 ls0 ws0">x</div><div class="t m0 xa0 h18 y607 ff22 fs9 fc0 sc0 ls0 ws0">(<span class="ff23">i</span>)</div><div class="t m0 x90 hb y606 ffd fs7 fc0 sc0 ls0 ws0">ϵM</div><div class="t m0 x5e hc y604 ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 xb4 ha y608 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">i</span>)</div><div class="t m0 x27 h4 y604 ffb fs2 fc0 sc0 ls0 ws0">(<span class="ff11">w<span class="_ _1e"></span>x</span></div><div class="t m0 x140 ha y608 ff1f fs7 fc0 sc0 ls0 ws0">(<span class="ff11">i</span>)</div><div class="t m0 x15b h4 y604 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span>)</div><div class="t m0 x3 h6 y1f8 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _9"> </span><span class="ffa">M<span class="_ _1c"> </span></span>为误分类的集合。</div><div class="t m0 x3 h6 y1f9 ff1 fs2 fc0 sc0 ls0 ws0">可以看出，<span class="_ _e"></span>随时函数<span class="_ _9"> </span><span class="ffa">L<span class="ffb">(</span>w,<span class="_ _2c"> </span>b<span class="ffb">)<span class="_ _9"> </span></span></span>是非负的。<span class="ff4">如果没有误分类点，<span class="_ _2d"></span>则损失函数的值为<span class="_ _12"> </span><span class="ff6">0</span>，<span class="_ _2d"></span>而且误分类</span></div><div class="t m0 x3 h6 y110 ff4 fs2 fc0 sc0 ls0 ws0">点越少，<span class="_ _2d"></span>误分类点距离超平面就越近，<span class="_ _e"></span>损失函数值就越小。<span class="_ _e"></span><span class="ff1">同时，<span class="_ _2d"></span>损失函数<span class="_ _9"> </span><span class="ffa">L<span class="ffb">(</span>w<span class="_ _1e"></span>,<span class="_ _2c"> </span>b<span class="ffb">)<span class="_ _9"> </span></span></span>是连续可导</span></div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">函数<span class="_ _9"> </span><span class="ff3">s</span>。</div><div class="t m0 x3 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">感知<span class="_ _1e"></span>器的学<span class="_ _1e"></span>习算<span class="_ _1e"></span>法是<span class="_ _1e"></span>一种<span class="_ _1e"></span><span class="ff4">错误<span class="_ _1e"></span>驱动<span class="_ _1e"></span></span>的<span class="ff4">在线<span class="_ _1e"></span>学习<span class="_ _1e"></span></span>算法<span class="_ _12"> </span><span class="ff3">[Rosen<span class="_ _e"></span>blatt,<span class="_ _12"> </span>1958].<span class="_ _4d"> </span><span class="ff1">先初<span class="_ _1e"></span>始化<span class="_ _1e"></span>一个<span class="_ _1e"></span>权重向<span class="_ _1e"></span>量</span></span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">44</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf32" class="pf w0 h0" data-page-no="32"><div class="pc pc32 w0 h0"><img class="bi xa9 y609 w11 h37" alt="" src="bg32.png"/><div class="t m0 x83 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">7.1<span class="_ _d"> </span><span class="ff8">参数学习</span></div><div class="t m0 x3 h6 y20 ff11 fs2 fc0 sc0 ls0 ws0">w<span class="_ _25"> </span><span class="fff">←<span class="_ _2f"> </span><span class="ffb">0<span class="_ _25"> </span><span class="ff3">(<span class="ff1">通常是全零向量</span>)<span class="ff1">，<span class="_ _31"></span>然后每次分错一个样本<span class="_ _25"> </span><span class="ffb">(<span class="ff11">x<span class="ffa">,<span class="_ _2c"> </span>y<span class="_ _1e"></span></span></span>)<span class="_ _9"> </span></span>时，<span class="_ _22"></span>即<span class="_ _25"> </span><span class="ffa">y<span class="_ _1e"></span><span class="ff11">w</span></span></span></span></span></span></div><div class="t m0 x121 ha y322 ff12 fs7 fc0 sc0 ls0 ws0">⊤</div><div class="t m0 xc8 h6 y20 ff11 fs2 fc0 sc0 ls0 ws0">x<span class="_ _2f"> </span><span class="ffa">&lt;<span class="_ _2f"> </span><span class="ffb">0<span class="ff1">，<span class="_ _22"></span>就用这个样本来更</span></span></span></div><div class="t m0 x3 h6 y1c9 ff1 fs2 fc0 sc0 ls0 ws0">新权重。</div><div class="t m0 x142 h4 y60a ff11 fs2 fc0 sc0 ls0 ws0">w<span class="_ _25"> </span><span class="fff">←<span class="_ _2f"> </span></span>w<span class="_ _f"> </span><span class="ffb">+<span class="_ _30"> </span><span class="ffa">y<span class="_ _1e"></span></span></span>x</div><div class="t m0 x3 h6 y60b ff1 fs2 fc0 sc0 ls0 ws0">因此，采用随机梯度下降，其每次更新的梯度为</div><div class="t m0 x139 h4 y60c ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span><span class="fff">L<span class="ffb">(<span class="ff11">w<span class="_ _1e"></span></span>;<span class="_ _2c"> </span><span class="ff11">x</span></span></span>,<span class="_ _29"> </span>y<span class="_ _26"></span><span class="ffb">)</span></div><div class="t m0 x9f hc y60d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span><span class="ff11">w</span></div><div class="t m0 xaa h4 y60e ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 x14a he y60f ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xbe h4 y610 ffb fs2 fc0 sc0 ls0 ws0">0<span class="_ _47"> </span><span class="ff3">if<span class="_ _51"> </span><span class="ffa">y<span class="_ _1e"></span><span class="ff11">w</span></span></span></div><div class="t m0 x172 ha y611 ff12 fs7 fc0 sc0 ls0 ws0">⊤</div><div class="t m0 x95 h4 y610 ff11 fs2 fc0 sc0 ls0 ws0">x<span class="_ _2f"> </span><span class="ffa">&gt;<span class="_ _2f"> </span><span class="ffb">0</span></span></div><div class="t m0 xbe h4 y612 fff fs2 fc0 sc0 ls0 ws0">−<span class="ffa">y<span class="_ _1e"></span><span class="ff11">x<span class="_ _52"> </span><span class="ff3">if<span class="_ _51"> </span></span></span>y<span class="_ _26"></span><span class="ff11">w</span></span></div><div class="t m0 x172 ha y613 ff12 fs7 fc0 sc0 ls0 ws0">⊤</div><div class="t m0 x95 h4 y612 ff11 fs2 fc0 sc0 ls0 ws0">x<span class="_ _2f"> </span><span class="ffa">&lt;<span class="_ _2f"> </span><span class="ffb">0</span></span></div><div class="t m0 x3 h6 y614 ff1 fs2 fc0 sc0 ls0 ws0">极小<span class="_ _1e"></span>化过<span class="_ _1e"></span>程不<span class="_ _1e"></span>是<span class="_ _1e"></span>一次<span class="_ _1e"></span>所有<span class="_ _1e"></span>误分<span class="_ _1e"></span>类点<span class="_ _1e"></span>的<span class="_ _1e"></span>梯度<span class="_ _1e"></span>下降，<span class="_ _1e"></span>选取<span class="_ _1e"></span>当<span class="_ _1e"></span>前误<span class="_ _1e"></span>分类<span class="_ _1e"></span>点使<span class="_ _1e"></span>其梯<span class="_ _1e"></span>度<span class="_ _1e"></span>下降。<span class="_ _1e"></span>使用<span class="_ _1e"></span>的规<span class="_ _1e"></span>则</div><div class="t m0 x3 h6 y615 ff1 fs2 fc0 sc0 ls0 ws0">为<span class="_ _25"> </span><span class="ffa">θ<span class="_ _25"> </span><span class="ffb">:=<span class="_ _2f"> </span></span>θ<span class="_ _3e"> </span><span class="fff">−<span class="_ _3e"></span></span>η<span class="_ _1e"></span><span class="fff">∇</span></span></div><div class="t m0 xd1 hb y616 ffd fs7 fc0 sc0 ls0 ws0">θ</div><div class="t m0 xd2 h6 y615 ffa fs2 fc0 sc0 ls0 ws0">ℓ<span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="ff1">，<span class="_ _20"></span>其中<span class="_ _25"> </span><span class="ffa">η<span class="_ _a"> </span></span>是步长，<span class="_ _21"></span>即学习率，<span class="_ _22"></span><span class="fff">∇</span></span></span></div><div class="t m0 xb4 hb y616 ffd fs7 fc0 sc0 ls0 ws0">θ</div><div class="t m0 x188 h6 y615 ffa fs2 fc0 sc0 ls0 ws0">ℓ<span class="ffb">(</span>θ<span class="_ _1e"></span><span class="ffb">)<span class="_ _25"> </span><span class="ff1">是梯度。<span class="_ _22"></span>因此，<span class="_ _20"></span>每次更新权重的公式为：</span></span></div><div class="t m0 x59 h4 y617 ff11 fs2 fc0 sc0 ls0 ws0">w<span class="_ _25"> </span><span class="fff">←<span class="_ _2f"> </span></span>w<span class="_ _f"> </span><span class="ffb">+<span class="_ _30"> </span><span class="ffa">η<span class="_ _1e"></span>y<span class="_ _1e"></span></span></span>x</div><div class="t m0 x12d h4 y618 ffa fs2 fc0 sc0 ls0 ws0">b<span class="_ _2f"> </span><span class="fff">←<span class="_ _2f"> </span></span>b<span class="_ _30"> </span><span class="ffb">+<span class="_ _30"> </span></span>η<span class="_ _1e"></span>y</div><div class="t m0 x3 h6 y619 ff1 fs2 fc0 sc0 ls0 ws0">每次更新参数之后，<span class="_ _20"></span>感知机的划分直线<span class="_ _31"></span>（平面）<span class="_ _22"></span>与对应的误分类点会变得更小，<span class="_ _22"></span>划分直线甚至会</div><div class="t m0 x3 h6 y61a ff1 fs2 fc0 sc0 ls0 ws0">越过误分类点，<span class="_ _21"></span>此时该误分类点可以被正确分类。<span class="_ _20"></span>这是感知机参数更新的性质，<span class="_ _20"></span>具体证明过程如</div><div class="t m0 x3 h6 y61b ff1 fs2 fc0 sc0 ls0 ws0">下：</div><div class="t m0 x3 h6 y61c ff1 fs2 fc0 sc0 ls0 ws0">对于某个误分类点</div><div class="t m0 x15 he y61d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xeb h4 y61e fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 xc2 h4 y61c ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x16 hb y61f ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x130 h4 y61c ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _30"> </span><span class="ffb">˜<span class="_ _50"></span><span class="ffa">y</span></span></div><div class="t m0 x6f hb y61f ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc he y61d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x139 h6 y61c ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _9"> </span><span class="ff1">假设它被选中用于更新参数。</span></div><div class="t m0 x3 h6 y620 ff3 fs2 fc0 sc0 ls0 ws0">1.<span class="_ _1c"> </span><span class="ff1">假设迭代之前，分类超平面为<span class="_ _9"> </span><span class="ffa">S<span class="_ _26"></span></span></span>,<span class="_ _9"> </span><span class="ff1">该误分类点距超平面的距离为<span class="_ _9"> </span><span class="ffa">d</span></span></div><div class="t m0 x3 h6 y621 ff3 fs2 fc0 sc0 ls0 ws0">2.<span class="_ _1c"> </span><span class="ff1">假设迭代之后，分类超平面为<span class="_ _9"> </span><span class="ffa">S</span></span></div><div class="t m0 x46 ha y622 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 xcb h6 y621 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _9"> </span><span class="ff1">该误分类点距超平面的距离为<span class="_ _9"> </span></span>d</div><div class="t m0 xe5 ha y622 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x3 h6 y623 ff1 fs2 fc0 sc0 ls0 ws0">则：</div><div class="t m0 x108 h4 y624 ffb fs2 fc0 sc0 ls0 ws0">∆<span class="ffa">d<span class="_ _2f"> </span></span>=<span class="_ _2f"> </span><span class="ffa">d</span></div><div class="t m0 xb7 ha y625 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 xe0 h4 y624 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">d<span class="_ _2f"> </span><span class="ffb">=</span></span></div><div class="t m0 x187 h4 y626 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xca he y627 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xca he y628 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xbc h4 y629 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x132 h4 y62a ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x48 ha y62b ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x20 he y627 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x20 he y628 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3d ha y62c ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x21 he y62d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x21 he y62e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x5a h4 y62f fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x5a h4 y624 ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x8e ha y625 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x23 h4 y624 fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 x8f h4 y62f fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x5c h4 y624 ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf3 hb y630 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x161 h4 y624 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x4d ha y625 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 xc0 he y62d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xc0 he y62e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x92 h4 y624 fff fs2 fc0 sc0 ls0 ws0">−</div><div class="t m0 x172 h4 y626 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x61 h4 y631 fff fs2 fc0 sc0 ls0 ws0">∥</div><div class="t m0 x14b h4 y632 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x4e h4 y631 ff6 fs2 fc0 sc0 ls0 ws0">w<span class="_ _4e"></span><span class="fff">∥</span></div><div class="t m0 x96 ha y633 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xd4 he y62d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xd4 he y62e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x175 h4 y62f fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x52 h4 y624 ff6 fs2 fc0 sc0 ls0 ws0">w<span class="_ _25"> </span><span class="fff">·</span></div><div class="t m0 x8a h4 y62f fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x15e h4 y624 ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x53 hb y630 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x189 h4 y624 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x56 he y62d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x56 he y62e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x169 h4 y634 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="fff">−</span></div><div class="t m0 xd3 h4 y635 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa9 he y636 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa9 he y637 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x82 h4 y638 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 xd h4 y639 ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x1b ha y63a ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x11b he y636 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x11b he y637 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x45 ha y63b ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xca h4 y634 ffb fs2 fc0 sc0 ls0 ws0">˜<span class="_ _50"></span><span class="ffa">y</span></div><div class="t m0 x46 hb y63c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1f he y63d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x1c h4 y63e fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 xe1 h4 y634 ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x3d ha y63f ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x59 h4 y634 fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 x49 h4 y63e fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x5a h4 y634 ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x22 hb y63c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xbe h4 y634 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x16a ha y63f ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x99 he y63d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x177 h4 y634 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 xc1 h4 y635 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x4d h4 y640 fff fs2 fc0 sc0 ls0 ws0">∥</div><div class="t m0 x128 h4 y641 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x133 h4 y640 ff6 fs2 fc0 sc0 ls0 ws0">w<span class="_ _4e"></span><span class="fff">∥</span></div><div class="t m0 x112 ha y642 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x17f h4 y634 ffb fs2 fc0 sc0 ls0 ws0">˜<span class="_ _50"></span><span class="ffa">y</span></div><div class="t m0 x50 hb y63c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x137 he y63d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x96 h4 y63e fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x29 h4 y634 ff6 fs2 fc0 sc0 ls0 ws0">w<span class="_ _25"> </span><span class="fff">·</span></div><div class="t m0 xd5 h4 y63e fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x120 h4 y634 ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xf2 hb y63c ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x174 h4 y634 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x18a he y63d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x1a h4 y643 fff fs2 fc0 sc0 ls0 ws0">≃<span class="_ _2f"> </span>−</div><div class="t m0 xc4 h4 y644 ffb fs2 fc0 sc0 ls0 ws0">˜<span class="_ _50"></span><span class="ffa">y</span></div><div class="t m0 x1c hb y645 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xca h4 y646 fff fs2 fc0 sc0 ls0 ws0">∥</div><div class="t m0 xbc h4 y647 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 xbc h4 y646 ff6 fs2 fc0 sc0 ls0 ws0">w<span class="_ _4e"></span><span class="fff">∥</span></div><div class="t m0 x100 ha y648 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 x8c he y649 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x14a h4 y64a fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x4a h4 y643 ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xa0 ha y64b ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 xa5 h4 y643 fff fs2 fc0 sc0 ls0 ws0">−</div><div class="t m0 x25 h4 y64c fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x25 h4 y643 ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x4b he y649 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x188 h4 y643 fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 x27 h4 y64c fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 xd6 h4 y643 ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xc1 hb y64d ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x14d h4 y643 ffb fs2 fc0 sc0 ls0 ws0">+</div><div class="t m0 x14b he y649 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x172 hc y643 ffa fs2 fc0 sc0 ls0 ws0">b</div><div class="t m0 x28 ha y64b ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x9d h4 y643 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x178 he y649 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xee h4 y64e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="fff">−</span></div><div class="t m0 x8c h4 y64f ffb fs2 fc0 sc0 ls0 ws0">˜<span class="_ _50"></span><span class="ffa">y</span></div><div class="t m0 x142 hb y650 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x3e h4 y651 fff fs2 fc0 sc0 ls0 ws0">∥</div><div class="t m0 xe2 h4 y652 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x8c h4 y651 ff6 fs2 fc0 sc0 ls0 ws0">w<span class="_ _4e"></span><span class="fff">∥</span></div><div class="t m0 x8e he y653 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xbe h4 y64e ffa fs2 fc0 sc0 ls0 ws0">η<span class="_ _2b"></span><span class="ffb">˜<span class="_ _50"></span><span class="ffa">y</span></span></div><div class="t m0 x41 hb y654 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x25 h4 y655 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 xf3 h4 y64e ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xa2 hb y654 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x144 h4 y64e fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 x27 h4 y655 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x4d h4 y64e ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x92 hb y654 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x13f h4 y64e ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">η<span class="_ _2b"></span></span>˜<span class="_ _50"></span><span class="ffa">y</span></div><div class="t m0 x135 hb y654 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x71 he y653 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x9c h4 y656 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _30"> </span><span class="fff">−</span></div><div class="t m0 x100 h4 y657 ffb fs2 fc0 sc0 ls0 ws0">˜<span class="_ _50"></span><span class="ffa">y</span></div><div class="t m0 xaa ha y658 ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xaa hb y659 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xfd h4 y65a fff fs2 fc0 sc0 ls0 ws0">∥</div><div class="t m0 x47 h4 y65b fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x20 h4 y65a ff6 fs2 fc0 sc0 ls0 ws0">w<span class="_ _4e"></span><span class="fff">∥</span></div><div class="t m0 x49 ha y65c ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbd he y65d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x8e hc y656 ffa fs2 fc0 sc0 ls0 ws0">η</div><div class="t m0 xf0 h4 y65e fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x15d h4 y656 ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xfb hb y65f ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x12c h4 y656 fff fs2 fc0 sc0 ls0 ws0">·</div><div class="t m0 x91 h4 y65e fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 xa2 h4 y656 ff6 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xbf hb y65f ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xd6 h4 y656 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span>1</div><div class="t m0 x66 he y65d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x106 h4 y656 ffa fs2 fc0 sc0 ls0 ws0">&lt;<span class="_ _2f"> </span><span class="ffb">0</span></div><div class="t m0 x3 h6 y660 ff1 fs2 fc0 sc0 ls0 ws0">因此有<span class="_ _9"> </span><span class="ffa">d</span></div><div class="t m0 x6 ha y661 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x10f h6 y660 ffa fs2 fc0 sc0 ls0 ws0">&lt;<span class="_ _2f"> </span>d<span class="_ _9"> </span><span class="ff1">这里要求</span></div><div class="t m0 x12a h4 y662 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x12a h4 y660 ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 xb7 ha y661 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 xe0 h4 y660 fff fs2 fc0 sc0 ls0 ws0">≃</div><div class="t m0 x97 h4 y662 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _53"></span>→</div><div class="t m0 x1b h6 y660 ff6 fs2 fc0 sc0 ls0 ws0">w<span class="_ _4e"></span><span class="ffa">,<span class="_ _9"> </span><span class="ff1">因此步长<span class="_ _9"> </span></span>η<span class="_ _a"> </span><span class="ff1">要相当小。</span></span></div><div class="t m0 x3 h6 y663 ff1 fs2 fc0 sc0 ls0 ws0">具体的感知器参数学习策略如下图所示（摘自邱锡鹏的《神经网络与深度学习》<span class="_ _23"></span>）<span class="_ _23"></span>：</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">45</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf33" class="pf w0 h0" data-page-no="33"><div class="pc pc33 w0 h0"><img class="bi x3 y17a w2 h17" alt="" src="bg33.png"/><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">7.2<span class="_ _d"> </span><span class="ff8">感知器收敛性</span></div><div class="t m0 xa4 h6 y664 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">7.4:<span class="_ _1c"> </span></span>二分类感知器的参数学习算法</div><div class="t m0 x3 h6 y665 ff1 fs2 fc0 sc0 ls0 ws0">在有的文章中（例如周志华的《机器学习》<span class="_ _23"></span>）<span class="_ _23"></span>，最后得到的更新公式为：</div><div class="t m0 x88 h4 y666 ff11 fs2 fc0 sc0 ls0 ws0">w<span class="_ _25"> </span><span class="fff">←<span class="_ _2f"> </span></span>w<span class="_ _f"> </span><span class="ffb">+<span class="_ _30"> </span><span class="ffa">α</span>∆</span>w</div><div class="t m0 x14a h4 y667 ffa fs2 fc0 sc0 ls0 ws0">b<span class="_ _2f"> </span><span class="fff">←<span class="_ _2f"> </span></span>b<span class="_ _30"> </span><span class="ffb">+<span class="_ _30"> </span>∆</span>b</div><div class="t m0 x3 h6 y668 ff1 fs2 fc0 sc0 ls0 ws0">其中，<span class="ffb">∆<span class="ff11">w<span class="_ _25"> </span></span>=<span class="_ _2f"> </span><span class="ffa">α</span>(<span class="ffa">y<span class="_ _f"> </span><span class="fff">−<span class="_ _25"> </span></span></span>ˆ<span class="_ _50"></span><span class="ffa">y<span class="_ _1e"></span><span class="ffb">)<span class="ff11">x<span class="ff1">，</span></span>∆</span>b<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span></span>α<span class="ffb">(</span>y<span class="_ _2f"> </span><span class="fff">−<span class="_ _2f"> </span><span class="ffb">ˆ<span class="_ _50"></span><span class="ffa">y<span class="_ _26"></span><span class="ffb">)<span class="ff1">。</span></span></span></span></span></span></span></div><div class="t m0 x3 h6 y669 ff1 fs2 fc0 sc0 ls0 ws0">这是<span class="_ _1e"></span>因为它<span class="_ _1e"></span>将样<span class="_ _1e"></span>本的<span class="_ _1e"></span>类别<span class="_ _1e"></span>映射<span class="_ _1e"></span>为<span class="_ _a"> </span><span class="ff3">0<span class="_ _12"> </span></span>和<span class="_ _a"> </span><span class="ff3">1</span>，<span class="_ _1e"></span>同时<span class="_ _1e"></span>采取<span class="_ _1e"></span>平方<span class="_ _1e"></span>和损失<span class="_ _1e"></span>函数，<span class="_ _1e"></span>所以<span class="_ _1e"></span>权值<span class="_ _1e"></span>更新的<span class="_ _1e"></span>公式<span class="_ _1e"></span>不一</div><div class="t m0 x3 h6 y66a ff1 fs2 fc0 sc0 ls0 ws0">样，<span class="_ _22"></span>不过思想都是一样的。<span class="_ _31"></span>这种情况下的更新公式推导可以参考这篇文章<span class="_ _31"></span><span class="fc9">《机器学习<span class="_ _9"> </span><span class="ff3">_<span class="_ _25"> </span></span>感知机》</span></div><div class="t m0 x3 h6 y66b ff1 fs2 fc0 sc0 ls0 ws0">。</div><div class="t m0 x1d h9 y66c ff5 fs6 fc0 sc0 ls0 ws0">7.2<span class="_ _1f"> </span><span class="ff9">感知器收敛性</span></div><div class="t m0 x3 h6 y66d ff1 fs2 fc0 sc0 ls0 ws0">感知机的可行<span class="_ _1e"></span>性是由<span class="_ _a"> </span><span class="ff3">No<span class="_ _2d"></span>viko<span class="_ _9"> </span><span class="ff1">证明的，</span>[Novik<span class="_ _2d"></span>o,<span class="_ _a"> </span>1963]<span class="_ _a"> </span><span class="ff1">证明对于两类问<span class="_ _1e"></span>题，如果训练集<span class="_ _1e"></span>是线性</span></span></div><div class="t m0 x3 h6 y66e ff1 fs2 fc0 sc0 ls0 ws0">可分的，<span class="_ _22"></span>那么感知器算法可以在有限次迭代后收敛。<span class="_ _22"></span>然而，<span class="_ _22"></span>如果训练集不是线性可分的，<span class="_ _22"></span>那么这</div><div class="t m0 x3 h6 y66f ff1 fs2 fc0 sc0 ls0 ws0">个算法则不能确保会收敛。</div><div class="t m0 x3 h6 y670 ff1 fs2 fc0 sc0 ls0 ws0">当数据<span class="_ _1e"></span>集是两类<span class="_ _1e"></span>线性可<span class="_ _1e"></span>分时<span class="ff3">,<span class="_ _a"> </span></span>对于<span class="_ _1e"></span>训练集<span class="_ _a"> </span><span class="fff">D<span class="_ _a"> </span><span class="ffb">=</span></span></div><div class="t m0 xa1 he y671 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x134 h20 y670 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xb4 ha y672 ffc fs7 fc0 sc0 ls0 ws0">(</div><div class="t m0 x13b hb y673 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x155 ha y672 ffc fs7 fc0 sc0 ls0 ws0">)</div><div class="t m0 x164 hc y670 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x43 ha y672 ffc fs7 fc0 sc0 ls0 ws0">(</div><div class="t m0 x5f hb y673 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x140 ha y672 ffc fs7 fc0 sc0 ls0 ws0">)</div><div class="t m0 x60 he y671 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4f hb y674 ffd fs7 fc0 sc0 ls0 ws0">N</div><div class="t m0 x4f ha y44d ffd fs7 fc0 sc0 ls0 ws0">n<span class="ffc">=1</span></div><div class="t m0 x2b h6 y670 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _a"> </span><span class="ff1">其中<span class="_ _a"> </span><span class="ff11">x</span></span></div><div class="t m0 x126 ha y673 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">n</span>)</div><div class="t m0 x57 h6 y670 ff1 fs2 fc0 sc0 ls0 ws0">为<span class="_ _a"> </span>样本的<span class="_ _1e"></span>增广特征</div><div class="t m0 x3 h6 y675 ff1 fs2 fc0 sc0 ls0 ws0">向量<span class="ff3">,<span class="_ _9"> </span><span class="ffa">y</span></span></div><div class="t m0 x78 ha y676 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">n</span>)</div><div class="t m0 x18b h6 y675 fff fs2 fc0 sc0 ls0 ws0">∈<span class="_ _2f"> </span>{−<span class="ffb">1<span class="ffa">,<span class="_ _2c"> </span></span>1</span>}<span class="ff3">,<span class="_ _9"> </span><span class="ff1">那么存<span class="_ _1e"></span>在一个正的常数<span class="_ _9"> </span><span class="ffa">γ<span class="_ _26"></span><span class="ffb">(</span>γ<span class="_ _a"> </span>&gt;<span class="_ _2f"> </span><span class="ffb">0)<span class="_ _a"> </span></span></span>和权重向<span class="_ _9"> </span>量<span class="_ _9"> </span><span class="ff11">w</span></span></span></div><div class="t m0 x2c ha y676 ff12 fs7 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x15c h6 y675 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _9"> </span><span class="ff1">并且<span class="_ _9"> </span><span class="fff">∥<span class="ff11">w</span></span></span></div><div class="t m0 xe9 ha y676 ff12 fs7 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x84 h6 y675 fff fs2 fc0 sc0 ls0 ws0">∥<span class="_ _2f"> </span><span class="ffb">=<span class="_ _25"> </span>1<span class="ffa">,<span class="_ _9"> </span><span class="ff1">对所有</span></span></span></div><div class="t m0 x3 h6 y677 ffa fs2 fc0 sc0 ls0 ws0">n<span class="_ _9"> </span><span class="ff1">都满足<span class="_ _9"> </span><span class="ffb">(<span class="ff11">w</span></span></span></div><div class="t m0 xd0 ha y678 ff12 fs7 fc0 sc0 ls0 ws0">∗</div><div class="t m0 x182 h4 y677 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 xa8 ha y679 ff12 fs7 fc0 sc0 ls0 ws0">⊤</div><div class="t m0 x13 he y67a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x16d hc y677 ffa fs2 fc0 sc0 ls0 ws0">y</div><div class="t m0 x76 ha y678 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">n</span>)</div><div class="t m0 x129 h20 y677 ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 xc5 ha y678 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">n</span>)</div><div class="t m0 x6f he y67a ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa9 h6 y677 fff fs2 fc0 sc0 ls0 ws0">≥<span class="_ _2f"> </span><span class="ffa">γ<span class="_ _26"></span>.<span class="_ _9"> </span><span class="ff1">我们可以证明如下<span class="_ _9"> </span>定理<span class="ff3">.</span></span></span></div><div class="t m0 x138 h38 y67b ff24 fs2 fca sc0 ls0 ws0">定理<span class="_ _a"> </span><span class="ff25">7.1.<span class="_ _a"> </span></span>感知器收敛性</div><div class="t m0 x18c h6 y67c ff1 fs2 fc0 sc0 ls0 ws0">给定训练集<span class="_ _9"> </span><span class="fff">D<span class="_ _25"> </span><span class="ffb">=</span></span></div><div class="t m0 x16e he y67d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xc5 h20 y67c ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x6b ha y67e ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">n</span>)</div><div class="t m0 xa9 hc y67c ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x14e ha y67e ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">n</span>)</div><div class="t m0 x3a he y67d ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xca hb y67f ffd fs7 fc0 sc0 ls0 ws0">N</div><div class="t m0 xca ha y680 ffd fs7 fc0 sc0 ls0 ws0">n<span class="ffc">=1</span></div><div class="t m0 x47 h6 y67c ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _9"> </span><span class="ff1">令<span class="_ _9"> </span></span>R<span class="_ _9"> </span><span class="ff1">是训练集<span class="_ _9"> </span>中最大的特征向量的模<span class="ff3">,<span class="_ _9"> </span></span>即</span></div><div class="t m0 x88 h4 y681 ffa fs2 fc0 sc0 ls0 ws0">R<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span><span class="ff3">max</span></span></div><div class="t m0 x8f hb y682 ffd fs7 fc0 sc0 ls0 ws0">n</div><div class="t m0 x134 he y683 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x134 he y684 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x134 he y685 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x177 hc y681 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x188 ha y686 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">n</span>)</div><div class="t m0 x133 he y683 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x133 he y684 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x133 he y685 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x18c h6 y687 ff1 fs2 fc0 sc0 ls0 ws0">如果训练集<span class="_ _9"> </span><span class="ff3">D<span class="_ _9"> </span></span>线性可分，两类感知器的参数学习算法<span class="_ _9"> </span><span class="ff3">3.1<span class="_ _9"> </span></span>的权重更新次数不超过</div><div class="t m0 x11f hb y688 ffd fs7 fc0 sc0 ls0 ws0">R</div><div class="t m0 x18d h18 y689 ff14 fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 x11f hb y68a ffd fs7 fc0 sc0 ls0 ws0">γ</div><div class="t m0 x18e h18 y68b ff14 fs9 fc0 sc0 ls0 ws0">2</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">46</div><a class="l" href="https://ff120.github.io/2017/05/19/机器学习专题/机器学习_感知机/"><div class="d m1" style="border-style:none;position:absolute;left:625.855500px;bottom:488.520000px;width:113.240000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf34" class="pf w0 h0" data-page-no="34"><div class="pc pc34 w0 h0"><div class="t m0 x77 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">7.3<span class="_ _d"> </span><span class="ff8">感知机的缺陷</span></div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">详细的证明过程参考邱锡鹏的《神经网络与深度学习》第<span class="_ _9"> </span><span class="ff3">3.4.2<span class="_ _9"> </span></span>节（感知器的收敛性）<span class="_ _23"></span>。</div><div class="t m0 x1d h9 y68c ff5 fs6 fc0 sc0 ls0 ws0">7.3<span class="_ _1f"> </span><span class="ff9">感知机的缺陷</span></div><div class="t m0 x3 h6 y68d ff1 fs2 fc0 sc0 ls0 ws0">虽然感知器在线性可分的数据上可以保证收敛，但其存在以下不足：</div><div class="t m0 x7f h6 y68e ff1 fs2 fc0 sc0 ls0 ws0">（<span class="ff3">1</span>）在数<span class="_ _1e"></span>据集线性<span class="_ _1e"></span>可分时，感<span class="_ _1e"></span>知器虽<span class="_ _1e"></span>然可以找<span class="_ _1e"></span>到一个<span class="_ _1e"></span>超平面把<span class="_ _1e"></span>两类数<span class="_ _1e"></span>据分<span class="_ _a"> </span>开，但并<span class="_ _1e"></span>不能保<span class="_ _1e"></span>证其</div><div class="t m0 x3 h6 y68f ff1 fs2 fc0 sc0 ls0 ws0">泛化能力。</div><div class="t m0 x7f h6 y690 ff1 fs2 fc0 sc0 ls0 ws0">（<span class="ff3">2</span>）感知器对样本顺序比较敏感．<span class="_ _e"></span>每次迭代的顺序不一致时，找到的分割<span class="_ _25"> </span>超平面也往往不一致。</div><div class="t m0 x7f h6 y691 ff1 fs2 fc0 sc0 ls0 ws0">（<span class="ff3">3</span>）如果训练集不是线性可分的，就永远不会收敛。</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">47</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf35" class="pf w0 h0" data-page-no="35"><div class="pc pc35 w0 h0"><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">7.3<span class="_ _d"> </span><span class="ff8">感知机的缺陷</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">48</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf36" class="pf w0 h0" data-page-no="36"><div class="pc pc36 w0 h0"><img class="bi xc3 y692 w12 h39" alt="" src="bg36.png"/><div class="t m0 x18f h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第八章 <span class="ff5">Recurren<span class="_ _31"></span>t<span class="_ _54"> </span>Neural<span class="_ _54"> </span>Net<span class="_ _31"></span>w<span class="_ _2d"></span>orks</span></div><div class="t m0 x190 h3a y693 ff5 fs6 fc0 sc0 ls0 ws0">8.1<span class="_ _1f"> </span>Simple<span class="_ _7"> </span>Recurren<span class="_ _31"></span>t<span class="_ _7"> </span>Net<span class="_ _2d"></span>w<span class="_ _2d"></span>ork</div><div class="t m0 x3 h12 y694 ff5 fs8 fc0 sc0 ls0 ws0">8.1.1<span class="_ _34"> </span><span class="ff9">前向传播</span></div><div class="t m0 x3 h6 y695 ff1 fs2 fc0 sc0 ls0 ws0">我们熟悉的神经网络可能是这样的：</div><div class="c xc3 y696 w13 h3b"><div class="t m0 x191 h3c y697 ff26 fsb fc0 sc0 ls0 ws0">input</div><div class="t m0 x191 h3c y698 ff26 fsb fc0 sc0 ls0 ws0">layer</div></div><div class="c xcd y699 w14 h3d"><div class="t m0 x192 h3e y69a ff27 fsc fc0 sc0 ls0 ws0">input→hidden</div></div><div class="c xc3 y696 w13 h3b"><div class="t m0 x193 h3c y697 ff26 fsb fc0 sc0 ls0 ws0">hidden</div><div class="t m0 x9a h3c y698 ff26 fsb fc0 sc0 ls0 ws0">layer</div><div class="t m0 x194 h3c y697 ff26 fsb fc0 sc0 ls0 ws0">output</div><div class="t m0 x38 h3c y698 ff26 fsb fc0 sc0 ls0 ws0">layer</div></div><div class="c xcd y69b w15 h3f"><div class="t m0 x192 h3e y69c ff27 fsc fc0 sc0 ls0 ws0">hidden→output</div></div><div class="c xcd y69d w16 h40"><div class="t m0 x192 h41 y69e ff28 fsd fc0 sc0 ls0 ws0">Description</div><div class="t m0 x192 h42 y69f ff29 fse fc0 sc0 ls0 ws0">Uistheweightmatrixfromthe</div><div class="t m0 x192 h42 y6a0 ff29 fse fc0 sc0 ls0 ws0">inputlayertothehiddenlayer</div><div class="t m0 x192 h42 y6a1 ff29 fse fc0 sc0 ls0 ws0">Vistheweightmatrixfromthe</div><div class="t m0 x192 h42 y6a2 ff29 fse fc0 sc0 ls0 ws0">hiddenlayertotheoutputlayer</div></div><div class="t m0 x1d h6 y6a3 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">8.1:<span class="_ _1c"> </span></span>三层神经网络示意图</div><div class="t m0 x3 h6 y6a4 ff1 fs2 fc0 sc0 ls0 ws0">这是一个简单的多层神经网络。它的<span class="_ _1e"></span>输入维度是<span class="_ _9"> </span><span class="ff3">5</span>，输出维度是<span class="_ _a"> </span><span class="ff3">2</span>，隐藏层的维度是<span class="_ _9"> </span><span class="ff3">3</span>。用数学</div><div class="t m0 x3 h6 y6a5 ff1 fs2 fc0 sc0 ls0 ws0">公式表示：</div><div class="t m0 x45 h4 y6a6 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(<span class="ff11">U</span></span></div><div class="t m0 x187 ha y6a7 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>5</div><div class="t m0 x88 h20 y6a6 ff11 fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x14a ha y6a7 ffc fs7 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>1</div><div class="t m0 x5b h4 y6a6 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff11">B</span></div><div class="t m0 x4b ha y6a7 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 xd6 h4 y6a6 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff11">H</span></div><div class="t m0 xef ha y6a7 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x74 h4 y6a6 ff3 fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3 h6 y6a8 ff1 fs2 fc0 sc0 ls0 ws0">其中，<span class="ffa">f<span class="_ _0"> </span></span>是隐藏层的激活函数，<span class="ff11">U<span class="_ _0"> </span></span>是隐藏层的权重矩<span class="_ _1e"></span>阵，<span class="ff11">B<span class="_ _12"> </span></span>是隐藏层的偏置向<span class="_ _1e"></span>量，当然以下两</div><div class="t m0 x3 h6 y6a9 ff1 fs2 fc0 sc0 ls0 ws0">种写法在数学上也是等价的：</div><div class="t m0 x45 h4 y6aa ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(<span class="ff11">U</span></span></div><div class="t m0 xfd hb y6ab ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x187 ha y6ac ffc fs7 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>3</div><div class="t m0 x88 h20 y6aa ff11 fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x14a ha y6ad ffc fs7 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>1</div><div class="t m0 x5b h4 y6aa ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff11">B</span></div><div class="t m0 x4b ha y6ad ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 xd6 h4 y6aa ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff11">H</span></div><div class="t m0 xef ha y6ad ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x74 h4 y6aa ff3 fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 x45 h4 y6ae ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(<span class="ff11">X</span></span></div><div class="t m0 x1c ha y6af ffc fs7 fc0 sc0 ls0 ws0">1<span class="ff12">×</span>5</div><div class="t m0 x8c h20 y6ae ff11 fs2 fc0 sc0 ls0 ws0">U</div><div class="t m0 x14a ha y6af ffc fs7 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>3</div><div class="t m0 x5b h4 y6ae ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff11">B</span></div><div class="t m0 x4b ha y6af ffc fs7 fc0 sc0 ls0 ws0">1<span class="ff12">×</span>3</div><div class="t m0 xd6 h4 y6ae ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff11">H</span></div><div class="t m0 xef ha y6af ffc fs7 fc0 sc0 ls0 ws0">1<span class="ff12">×</span>3</div><div class="t m0 x74 h4 y6b0 ff3 fs2 fc0 sc0 ls0 ws0">3</div><div class="t m0 x3 h6 y6b1 ff1 fs2 fc0 sc0 ls0 ws0">一般在<span class="_ _1e"></span>机器学<span class="_ _1e"></span>习的<span class="_ _1e"></span>书籍中<span class="_ _1e"></span>惯用的<span class="_ _1e"></span>写法<span class="_ _1e"></span>是<span class="_ _25"> </span><span class="ff3">2<span class="_ _25"> </span></span>。<span class="_ _1e"></span>在这里<span class="_ _1e"></span>遵循<span class="_ _1e"></span>惯例，沿<span class="_ _1e"></span>用<span class="_ _25"> </span><span class="ff3">2<span class="_ _9"> </span></span>的写法。那<span class="_ _1e"></span>么，从<span class="_ _1e"></span>隐藏层</div><div class="t m0 x3 h6 y6b2 ff1 fs2 fc0 sc0 ls0 ws0">到输出层则表示为：</div><div class="t m0 x157 h4 y6b3 ffa fs2 fc0 sc0 ls0 ws0">g<span class="_ _1e"></span><span class="ffb">(<span class="ff11">V</span></span></div><div class="t m0 xe1 hb y6b4 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x187 ha y6b5 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>2</div><div class="t m0 x88 h20 y6b3 ff11 fs2 fc0 sc0 ls0 ws0">H</div><div class="t m0 x14a ha y6b6 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x5b h4 y6b3 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff11">C</span></div><div class="t m0 x91 ha y6b6 ffc fs7 fc0 sc0 ls0 ws0">2<span class="ff12">×</span>1</div><div class="t m0 x164 h4 y6b3 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff11">O</span></div><div class="t m0 xd7 ha y6b6 ffc fs7 fc0 sc0 ls0 ws0">2<span class="ff12">×</span>1</div><div class="t m0 x3 h6 y6b7 ff1 fs2 fc0 sc0 ls0 ws0">数据在这样的网络中流动<span class="_ _20"></span>（向前传播）<span class="_ _20"></span>的过程是很容易理解和想象的，<span class="_ _21"></span>如果将每一层用一个单元</div><div class="t m0 x3 h6 y6b8 ff1 fs2 fc0 sc0 ls0 ws0">来表示，可以有更简洁的图例：</div><div class="c x76 y6b9 w17 h43"><div class="t m0 x195 h44 y6ba ff2a fsf fc0 sc0 ls0 ws0">X<span class="_ _55"> </span>H<span class="_ _56"> </span>O</div><div class="t m0 x196 h45 y6bb ff2b fs10 fc0 sc0 ls0 ws0">U<span class="_ _57"> </span>V</div><div class="t m0 x36 h44 y6ba ff2a fsf fc0 sc0 ls0 ws0">L<span class="_ _58"> </span>Y</div></div><div class="t m0 x183 h6 y6bc ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">8.2:<span class="_ _1c"> </span></span>三层神经网络简要示意图（包括反向传播过程）</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">49</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf37" class="pf w0 h0" data-page-no="37"><div class="pc pc37 w0 h0"><img class="bi xb y6bd w18 h46" alt="" src="bg37.png"/><div class="t m0 x3 h47 y1f ff3 fs5 fc0 sc0 ls0 ws0">8.1<span class="_ _d"> </span>SIMPLE<span class="_ _2f"> </span>RECURRENT<span class="_ _9"> </span>NETW<span class="_ _2d"></span>ORK</div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">如果加上<span class="_ _9"> </span><span class="ff3">batc<span class="_ _e"></span>h<span class="_ _9"> </span>size<span class="_ _9"> </span><span class="ff1">的话，是这个样子的：</span></span></div><div class="c xb y6be w19 h48"><div class="t m0 x197 h49 y6bf ff2c fs11 fcb sc0 ls0 ws0">X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x141 h4a y6c0 ff2d fs12 fcb sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 xbf h49 y6bf ff2c fs11 fcb sc0 ls0 ws0">Y<span class="_ _5c"></span>X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x141 h4a y6c0 ff2d fs12 fcb sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 xbf h49 y6bf ff2c fs11 fcb sc0 ls0 ws0">Y</div><div class="t m0 x198 h49 y6c1 ff2c fs11 fcb sc0 ls0 ws0">X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x3 h4a y6c2 ff2d fs12 fcb sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 x164 h49 y6c1 ff2c fs11 fcb sc0 ls0 ws0">Y<span class="_ _5c"></span>X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x3 h4a y6c2 ff2d fs12 fcb sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 x164 h49 y6c1 ff2c fs11 fcb sc0 ls0 ws0">Y</div><div class="t m0 x199 h49 y6c3 ff2c fs11 fcb sc0 ls0 ws0">X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x103 h4a y6c4 ff2d fs12 fcb sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 x133 h49 y6c3 ff2c fs11 fcb sc0 ls0 ws0">Y<span class="_ _5c"></span>X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x103 h4a y6c4 ff2d fs12 fcb sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 x133 h49 y6c3 ff2c fs11 fcb sc0 ls0 ws0">Y</div><div class="t m0 x196 h49 y6c5 ff2c fs11 fcb sc0 ls0 ws0">X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x16f h4a y6c6 ff2d fs12 fcb sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 xc1 h49 y6c5 ff2c fs11 fcb sc0 ls0 ws0">Y<span class="_ _5c"></span>X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x16f h4a y6c6 ff2d fs12 fcb sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 xc1 h49 y6c5 ff2c fs11 fcb sc0 ls0 ws0">Y</div><div class="t m0 x19a h49 y6c7 ff2c fs11 fc0 sc0 ls0 ws0">X<span class="_ _59"> </span>H<span class="_ _5a"> </span>O</div><div class="t m0 x9a h4a y6c8 ff2d fs12 fc0 sc0 ls0 ws0">U<span class="_ _5b"> </span>V</div><div class="t m0 x5f h49 y6c7 ff2c fs11 fc0 sc0 ls0 ws0">Y</div><div class="t m0 x3d h49 y6c3 ff2c fs11 fc0 sc0 ls0 ws0">L</div><div class="t m2 x191 h4b y6c9 ff2e fs13 fc0 sc0 ls0 ws0">batchsize=5</div></div><div class="t m0 x37 h6 y6ca ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">8.3:<span class="_ _1c"> </span></span>三层神经网络简要示意图<span class="_ _9"> </span><span class="ff3">(batch<span class="_ _25"> </span>size)</span></div><div class="t m0 x3 h6 y6cb ff1 fs2 fc0 sc0 ls0 ws0">与<span class="_ _f"> </span><span class="ff3">DNN </span>不同，<span class="_ _33"></span><span class="ff3">Simple<span class="_ _f"> </span>RNN <span class="ff1">是包含循环结构的网络，<span class="_ _3c"></span>几乎没有平面图能很好地展示<span class="_ _2f"> </span><span class="ff3">Simple RNN</span></span></span></div><div class="t m0 x3 h6 y6cc ff1 fs2 fc0 sc0 ls0 ws0">的循环过程，但我尝试画了一张示意图：</div><div class="t m0 x9f h6 y6cd ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">8.4:<span class="_ _1c"> </span>Simple<span class="_ _9"> </span>RNN<span class="_ _9"> </span></span>展开示意图</div><div class="t m0 x3 h6 y6ce ff1 fs2 fc0 sc0 ls0 ws0">图中，<span class="_ _1e"></span>正方<span class="_ _1e"></span>形<span class="_ _1e"></span>单元<span class="_ _1e"></span>存在<span class="_ _1e"></span>激<span class="_ _1e"></span>活函<span class="_ _1e"></span>数，而<span class="_ _1e"></span>圆<span class="_ _1e"></span>形单<span class="_ _1e"></span>元则<span class="_ _1e"></span>没有<span class="_ _1e"></span>激<span class="_ _1e"></span>活函<span class="_ _1e"></span>数，因<span class="_ _1e"></span>此，<span class="_ _1e"></span>圆形<span class="_ _1e"></span>单元<span class="_ _1e"></span>会<span class="_ _1e"></span>将输<span class="_ _1e"></span>入值<span class="_ _1e"></span>直</div><div class="t m0 x3 h6 y6cf ff1 fs2 fc0 sc0 ls0 ws0">接输出，<span class="_ _1e"></span>不会对输<span class="_ _1e"></span>入的数<span class="_ _1e"></span>值作改<span class="_ _1e"></span>动。在同<span class="_ _1e"></span>一层中，实<span class="_ _1e"></span>线和虚<span class="_ _1e"></span>线代表<span class="_ _1e"></span>着不同<span class="_ _1e"></span>的权重矩<span class="_ _1e"></span>阵。实际<span class="_ _1e"></span>上，</div><div class="t m0 x3 h6 y6d0 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="ff3">8.4</span>的输入数据<span class="_ _1e"></span>只有一个时<span class="_ _1e"></span>间步（<span class="ff3">time<span class="_ _a"> </span>step</span>）<span class="_ _2e"></span>，<span class="_ _1e"></span>这并没有发挥<span class="_ _a"> </span><span class="ff3">RNN<span class="_ _a"> </span></span>的长处。<span class="ff3">RNN<span class="_ _a"> </span></span>处理的数据</div><div class="t m0 x3 h6 y6d1 ff1 fs2 fc0 sc0 ls0 ws0">应该是序列数据，并且具有多个时间步，如图</div><div class="t m0 x5b h6 y6d2 ff3 fs2 fc0 sc0 ls0 ws0">8.5<span class="ff1">：</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">50</div><div class="c x10c y6d3 w1a h4c"><div class="t m0 x70 h4d y6d4 ff2f fs14 fc0 sc0 ls0 ws0">A</div></div><div class="c x38 y6d5 w1b h4e"><div class="t m0 x192 h4f y6d6 ff30 fs15 fc0 sc0 ls0 ws0">Description</div><div class="t m0 x192 h50 y6d7 ff31 fs16 fc0 sc0 ls0 ws0">Round units have no activation</div><div class="t m0 x192 h50 y6d8 ff31 fs16 fc0 sc0 ls0 ws0">functions.</div><div class="t m0 x192 h50 y6d9 ff31 fs16 fc0 sc0 ls0 ws0">Square units have activation</div><div class="t m0 x192 h50 y6da ff31 fs16 fc0 sc0 ls0 ws0">function.</div><div class="t m0 x192 h51 y6db ff32 fs16 fc0 sc0 ls0 ws0">Wistherecurrentweightmatrixof</div><div class="t m0 x192 h51 y6dc ff32 fs16 fc0 sc0 ls0 ws0">thehiddenlayer<span class="_ _2d"></span>.</div></div><div class="c x95 y6dd w1c h52"><div class="t m0 x192 h53 y6de ff33 fs17 fc0 sc0 ls0 ws0">a sample</div><div class="t m0 x192 h53 y6df ff33 fs17 fc0 sc0 ls0 ws0">input <span class="ff34">→</span> hidden</div><div class="t m0 x192 h53 y6e0 ff33 fs17 fc0 sc0 ls0 ws0">hidden <span class="ff34">→</span> output</div></div><div class="c x10c y6d3 w1a h4c"><div class="t m0 x19b h54 y6e1 ff35 fs18 fc0 sc0 ls0 ws0">3timesteps</div></div><div class="t m0 xbc h6 y6e2 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">8.5:<span class="_ _1c"> </span>Simple<span class="_ _9"> </span>RNN<span class="_ _9"> </span></span>展开示意图</div><a class="l" href="#pf37" data-dest-detail='[55,"XYZ",390.16,420.34,null]'><div class="d m1" style="border-style:none;position:absolute;left:122.662500px;bottom:489.750000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf37" data-dest-detail='[55,"XYZ",485.48,93.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:433.572000px;bottom:469.426500px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf38" class="pf w0 h0" data-page-no="38"><div class="pc pc38 w0 h0"><img class="bi x3 y6e3 w2 h55" alt="" src="bg38.png"/><div class="t m0 x5f h47 y1f ff3 fs5 fc0 sc0 ls0 ws0">8.1<span class="_ _d"> </span>SIMPLE<span class="_ _2f"> </span>RECURRENT<span class="_ _9"> </span>NETW<span class="_ _2d"></span>ORK</div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="ff3">8.5</span>中展示的样本数据有<span class="_ _9"> </span><span class="ff3">3<span class="_ _9"> </span></span>个时间步，每一个时间步的数据都是<span class="_ _25"> </span><span class="ff3">5<span class="_ _9"> </span></span>维的，也就是说这个样本是</div><div class="t m0 x3 h6 y1c9 ff1 fs2 fc0 sc0 ls0 ws0">这样的：</div><div class="c xed y6e4 w1d h56"><div class="t m0 x14f h57 y6e5 ff36 fs19 fc0 sc0 ls0 ws0">3 time steps</div><div class="t m0 x19c h57 y6e6 ff36 fs19 fc0 sc0 ls0 ws0">dimensions per time step</div></div><div class="t m0 x3 h6 y6e7 ff1 fs2 fc0 sc0 ls0 ws0">各个样本时间步数可能不一样，<span class="_ _21"></span>一般而言，<span class="_ _20"></span>在数据预处理时，<span class="_ _20"></span>我们会将所有样本的时间步处理成</div><div class="t m0 x3 h6 y6e8 ff1 fs2 fc0 sc0 ls0 ws0">等长的。<span class="_ _2d"></span>从图<span class="ff3">8.5</span>可以看出隐藏层<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 xcb h1e y6e9 ff11 fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xe1 h6 y6e8 ff1 fs2 fc0 sc0 ls0 ws0">不仅由<span class="_ _9"> </span><span class="ff11">x</span></div><div class="t m0 x8f h1e y6e9 ff11 fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x25 h6 y6e8 ff1 fs2 fc0 sc0 ls0 ws0">决定，<span class="_ _2d"></span>也受到<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 xe4 ha y6e9 ff11 fs7 fc0 sc0 ls0 ws0">t<span class="ff20">−<span class="ff1f">1</span></span></div><div class="t m0 xe5 h6 y6e8 ff1 fs2 fc0 sc0 ls0 ws0">的影响<span class="_ _2d"></span>（<span class="ffa">t<span class="_ _9"> </span></span>代表第<span class="_ _9"> </span><span class="ffa">t<span class="_ _9"> </span></span>个时间</div><div class="t m0 x3 h6 y6ea ff1 fs2 fc0 sc0 ls0 ws0">步）<span class="_ _23"></span>，<span class="_ _22"></span>这是<span class="_ _9"> </span><span class="ff3">RNN<span class="_ _25"> </span></span>和<span class="_ _9"> </span><span class="ff3">DNN<span class="_ _25"> </span></span>的不同点，<span class="_ _31"></span>也正是<span class="_ _25"> </span><span class="ff3">RNN<span class="_ _9"> </span></span>循环思想的体现。<span class="_ _31"></span>而<span class="_ _9"> </span><span class="ff3">RNN<span class="_ _25"> </span></span>的输出层<span class="_ _9"> </span><span class="ff11">O</span></div><div class="t m0 x146 h1e y6eb ff11 fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x33 h6 y6ea ff1 fs2 fc0 sc0 ls0 ws0">只由</div><div class="t m0 x3 h6 y6ec ff1 fs2 fc0 sc0 ls0 ws0">当前时间步的隐藏层<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 x65 h1e y6ed ff11 fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xdf h6 y6ec ff1 fs2 fc0 sc0 ls0 ws0">决定，这点和<span class="_ _9"> </span><span class="ff3">DNN<span class="_ _9"> </span></span>是一样的。</div><div class="t m0 x3 h6 y6ee ff1 fs2 fc0 sc0 ls0 ws0">对于任意<span class="_ _9"> </span><span class="ffa">t<span class="_ _9"> </span></span>时刻，从输入层到隐藏层，用数学公式表示如下：</div><div class="t m0 xa h4 y6ef ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(<span class="ff11">U</span></span></div><div class="t m0 x9 hb y6f0 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x8c h4 y6ef ff11 fs2 fc0 sc0 ls0 ws0">X<span class="_ _25"> </span><span class="ffb">+<span class="_ _30"> </span></span>W<span class="_ _29"> </span>H</div><div class="t m0 xb4 ha y6f1 ff11 fs7 fc0 sc0 ls0 ws0">t<span class="ff20">−<span class="ff1f">1</span></span></div><div class="t m0 x42 h4 y6ef ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff11">B<span class="_ _1e"></span></span>)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff11">H</span></div><div class="t m0 x178 hb y6f1 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb7 h4 y6f2 ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _2b"></span><span class="ffb">(<span class="ff37">□</span></span></div><div class="t m0 x159 hb y6f3 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x159 ha y6f4 ffc fs7 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>3</div><div class="t m0 xca h58 y6f2 ff37 fs2 fc0 sc0 ls0 ws0">□</div><div class="t m0 x1f ha y6f5 ffc fs7 fc0 sc0 ls0 ws0">5<span class="ff12">×</span>1</div><div class="t m0 x102 h4 y6f2 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff37">□</span></div><div class="t m0 x86 ha y6f5 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>3</div><div class="t m0 x5c h58 y6f2 ff37 fs2 fc0 sc0 ls0 ws0">□</div><div class="t m0 xf3 ha y6f5 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x155 h4 y6f2 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff37">□</span></div><div class="t m0 xe3 ha y6f5 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x4f h4 y6f2 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ff37">□</span></div><div class="t m0 xe4 ha y6f5 ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x121 h4 y6f2 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h6 y6f6 ff1 fs2 fc0 sc0 ls0 ws0">其中，<span class="_ _31"></span><span class="ff11">U<span class="_ _1c"> </span><span class="ff1">是输入层到隐藏层的权重矩阵，<span class="_ _31"></span><span class="ff11">W<span class="_ _0"> </span><span class="ff1">是隐藏层的循环权重矩阵。<span class="_ _31"></span>隐藏层到输出层的公式</span></span></span></span></div><div class="t m0 x3 h6 y6f7 ff1 fs2 fc0 sc0 ls0 ws0">为：</div><div class="t m0 xaa h4 y6f8 ffa fs2 fc0 sc0 ls0 ws0">g<span class="_ _1e"></span><span class="ffb">(<span class="ff11">V</span></span></div><div class="t m0 x8e hb y6f9 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 xf0 h20 y6f8 ff11 fs2 fc0 sc0 ls0 ws0">H</div><div class="t m0 xfb h1e y6fa ff11 fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x99 h4 y6f8 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff11">C<span class="_ _26"></span></span>)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff11">O</span></div><div class="t m0 x17f h1e y6fa ff11 fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x145 h4 y6fb ffa fs2 fc0 sc0 ls0 ws0">g<span class="_ _1e"></span><span class="ffb">(<span class="ff37">□</span></span></div><div class="t m0 x1c hb y6fc ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x1c ha y6fd ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>2</div><div class="t m0 x8c h58 y6fb ff37 fs2 fc0 sc0 ls0 ws0">□</div><div class="t m0 x14a ha y6fe ffc fs7 fc0 sc0 ls0 ws0">3<span class="ff12">×</span>1</div><div class="t m0 x5b h4 y6fb ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ff37">□</span></div><div class="t m0 x91 ha y6fe ffc fs7 fc0 sc0 ls0 ws0">2<span class="ff12">×</span>1</div><div class="t m0 x164 h4 y6fb ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=<span class="_ _2f"> </span><span class="ff37">□</span></div><div class="t m0 x17f ha y6fe ffc fs7 fc0 sc0 ls0 ws0">2<span class="ff12">×</span>1</div><div class="t m0 x3 h6 y6ff ff11 fs2 fc0 sc0 ls0 ws0">U<span class="_ _2b"> </span><span class="ff1">、</span>W<span class="_ _4"> </span><span class="ff1">和<span class="_ _25"> </span></span>V<span class="_ _4d"> </span><span class="ff1">三个权重矩阵和传播过程中是权值共享的。</span></div><div class="t m0 x1e h6 y700 ff1 fs2 fc0 sc0 ls0 ws0">权值共享是指<span class="_ _25"> </span><span class="ff11">U<span class="_ _2b"> </span></span>、<span class="_ _21"></span><span class="ff11">W<span class="_ _0"> </span><span class="ff1">和<span class="_ _25"> </span></span>V<span class="_ _7"> </span><span class="ff1">三个权重矩阵在前向传播的过程中不会改变，<span class="_ _21"></span>不同时间步所使</span></span></div><div class="t m0 x1e h6 y701 ff1 fs2 fc0 sc0 ls0 ws0">用的权重矩阵都是一样的。</div><div class="t m0 x3 h6 y702 ff1 fs2 fc0 sc0 ls0 ws0">将<span class="_ _9"> </span><span class="ff3">RNN<span class="_ _9"> </span></span>每一层用一个单元表示，并加上<span class="_ _9"> </span><span class="ff3">batc<span class="_ _e"></span>h<span class="_ _9"> </span>size<span class="ff1">，可以得到以下图示：</span></span></div><div class="c x81 y703 w1e h59"><div class="t m0 xbe h5a y704 ff38 fs1a fc0 sc0 ls0 ws0">L</div><div class="t m0 x18c h5a y705 ff38 fs1a fcc sc0 ls0 ws0">X</div><div class="t m0 xda h5b y706 ff39 fs1b fcc sc0 ls0 ws0">U<span class="_ _5d"> </span>V</div><div class="t m0 x4d h5a y705 ff38 fs1a fcc sc0 ls0 ws0">Y<span class="_ _5e"></span>H<span class="_ _41"> </span>O<span class="_ _5f"></span>X<span class="_ _60"></span>X</div><div class="t m0 xd2 h5b y707 ff39 fs1b fcc sc0 ls0 ws0">W</div><div class="t m0 x179 h5a y708 ff38 fs1a fcc sc0 ls0 ws0">X</div><div class="t m0 x18b h5b y709 ff39 fs1b fcc sc0 ls0 ws0">U<span class="_ _5d"> </span>V</div><div class="t m0 xcd h5a y708 ff38 fs1a fcc sc0 ls0 ws0">Y<span class="_ _5e"></span>H<span class="_ _41"> </span>O<span class="_ _5f"></span>X<span class="_ _60"></span>X</div><div class="t m0 x13 h5b y70a ff39 fs1b fcc sc0 ls0 ws0">W</div><div class="t m0 x10e h5a y70b ff38 fs1a fcc sc0 ls0 ws0">X</div><div class="t m0 x186 h5b y70c ff39 fs1b fcc sc0 ls0 ws0">U<span class="_ _5d"> </span>V</div><div class="t m0 xad h5a y70b ff38 fs1a fcc sc0 ls0 ws0">Y<span class="_ _5e"></span>H<span class="_ _41"> </span>O<span class="_ _5f"></span>X<span class="_ _60"></span>X</div><div class="t m0 x38 h5b y70d ff39 fs1b fcc sc0 ls0 ws0">W</div><div class="t m0 x9b h5a y70e ff38 fs1a fcc sc0 ls0 ws0">X</div><div class="t m0 x117 h5b y70f ff39 fs1b fcc sc0 ls0 ws0">U<span class="_ _5d"> </span>V</div><div class="t m0 x43 h5a y70e ff38 fs1a fcc sc0 ls0 ws0">Y<span class="_ _5e"></span>H<span class="_ _41"> </span>O<span class="_ _5f"></span>X<span class="_ _60"></span>X</div><div class="t m0 xdd h5b y710 ff39 fs1b fcc sc0 ls0 ws0">W</div><div class="t m0 x34 h5a y711 ff38 fs1a fcc sc0 ls0 ws0">X</div><div class="t m0 x110 h5b y712 ff39 fs1b fcc sc0 ls0 ws0">U<span class="_ _5d"> </span>V</div><div class="t m0 x13f h5a y711 ff38 fs1a fcc sc0 ls0 ws0">Y<span class="_ _5e"></span>H<span class="_ _41"> </span>O<span class="_ _5f"></span>X<span class="_ _60"></span>X</div><div class="t m0 x76 h5b y713 ff39 fs1b fcc sc0 ls0 ws0">W</div><div class="t m0 xff h5a y704 ff38 fs1a fc0 sc0 ls0 ws0">X</div><div class="t m0 x182 h5b y714 ff39 fs1b fc0 sc0 ls0 ws0">U<span class="_ _5d"> </span>V</div><div class="t m0 x66 h5a y704 ff38 fs1a fc0 sc0 ls0 ws0">Y<span class="_ _5e"></span>H<span class="_ _41"> </span>O<span class="_ _61"></span>X<span class="_ _60"></span>X</div><div class="t m0 x168 h5b y715 ff39 fs1b fc0 sc0 ls0 ws0">W</div><div class="t m0 x196 h5c y716 ff3a fs1c fc0 sc0 ls0 ws0">batchsize=5</div></div><div class="t m0 x3 h12 y717 ff5 fs8 fc0 sc0 ls0 ws0">8.1.2<span class="_ _34"> </span><span class="ff9">反向传播</span></div><div class="t m0 x3 h6 y718 ff1 fs2 fc0 sc0 ls0 ws0">与<span class="_ _9"> </span><span class="ff3">DNN<span class="_ _9"> </span></span>一致，<span class="_ _2d"></span><span class="ff3">RNN<span class="_ _9"> </span><span class="ff1">也是通过梯度下降的方法来寻找<span class="_ _9"> </span></span>U<span class="ff1">、</span>V<span class="ff1">、<span class="_ _2d"></span><span class="ff3">W<span class="_ _9"> </span><span class="ff1">这三个参数的最优解，此处我</span></span></span></span></div><div class="t m0 x3 h6 y719 ff1 fs2 fc0 sc0 ls0 ws0">们考虑较复杂的<span class="_ _25"> </span><span class="ff3">Many to<span class="_ _25"> </span>Many </span>形式，<span class="_ _20"></span>损失函数暂定为<span class="_ _9"> </span><span class="ff3">MSE </span>损失函数，<span class="_ _22"></span>由于序列的每个位置都</div><div class="t m0 x3 h6 y71a ff1 fs2 fc0 sc0 ls0 ws0">有损失函数，因此最终损失为：</div><div class="t m0 x12d h4 y71b ffa fs2 fc0 sc0 ls0 ws0">L<span class="_ _2f"> </span><span class="ffb">=</span></div><div class="t m0 x143 hb y71c ffd fs7 fc0 sc0 ls0 ws0">τ</div><div class="t m0 x176 he y71d ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 x143 ha y71e ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xb4 hc y71b ffa fs2 fc0 sc0 ls0 ws0">L</div><div class="t m0 xbf hb y71f ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x33 h4 y71b ff3 fs2 fc0 sc0 ls0 ws0">(8.1)</div><div class="t m0 x3 h6 y720 ff1 fs2 fc0 sc0 ls0 ws0">假定我们最终的损失函数为<span class="_ _9"> </span><span class="ffa">L</span>，这里假设为<span class="_ _9"> </span><span class="ffa">M<span class="_ _2b"></span>S<span class="_ _26"></span>E<span class="_ _26"></span></span>，即：</div><div class="t m0 xab h4 y721 ffa fs2 fc0 sc0 ls0 ws0">L<span class="_ _2f"> </span><span class="ffb">=</span></div><div class="t m0 x142 h4 y722 ffb fs2 fc0 sc0 ls0 ws0">1</div><div class="t m0 x142 h4 y723 ffb fs2 fc0 sc0 ls0 ws0">2</div><div class="t m0 xbd h1d y724 ff16 fs7 fc0 sc0 ls0 ws0">output</div><div class="t m0 x171 he y725 ffe fs2 fc0 sc0 ls0 ws0">X</div><div class="t m0 xa0 ha y726 ffd fs7 fc0 sc0 ls0 ws0">j<span class="_ _1e"></span><span class="ffc">=1</span></div><div class="t m0 x134 he y727 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xa2 h4 y721 ffb fs2 fc0 sc0 ls0 ws0">ˆ<span class="_ _50"></span><span class="ffa">y</span></div><div class="t m0 xac hb y728 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x13b hb y729 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x27 h4 y721 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 x13f hb y728 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x5f hb y729 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x66 he y727 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x60 ha y72a ffc fs7 fc0 sc0 ls0 ws0">2</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">51</div><a class="l" href="#pf37" data-dest-detail='[55,"XYZ",485.48,93.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:122.662500px;bottom:1177.872000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a><a class="l" href="#pf37" data-dest-detail='[55,"XYZ",485.48,93.4,null]'><div class="d m1" style="border-style:none;position:absolute;left:203.844000px;bottom:964.323000px;width:13.941000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf39" class="pf w0 h0" data-page-no="39"><div class="pc pc39 w0 h0"><img class="bi xc3 y72b w8 h5d" alt="" src="bg39.png"/><div class="t m0 x3 h47 y1f ff3 fs5 fc0 sc0 ls0 ws0">8.2<span class="_ _d"> </span>LSTM</div><div class="t m0 x3 h5e y72c ff9 fs1d fc0 sc0 ls0 ws0">输出层</div><div class="t m0 xa6 hc y72d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>L</div><div class="t m0 x14e h4 y72e ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _2b"> </span><span class="ffb">ˆ<span class="_ _50"></span><span class="ffa">y</span></span></div><div class="t m0 xbb hb y72f ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xed h4 y730 ffb fs2 fc0 sc0 ls0 ws0">=</div><div class="t m0 xab hc y72d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>L</div><div class="t m0 xc4 hc y72e ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>L</div><div class="t m0 x9 hb y72f ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x8c hc y72d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>L</div><div class="t m0 xbd hb y731 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x59 h4 y72e ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _2b"> </span><span class="ffb">ˆ<span class="_ _50"></span><span class="ffa">y</span></span></div><div class="t m0 xbd hb y72f ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x40 h4 y730 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>1<span class="_ _30"> </span><span class="fff">×</span></div><div class="t m0 xac hc y72d ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>L</div><div class="t m0 x133 ha y731 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">t</span>)</div><div class="t m0 x144 hc y732 ffa fs2 fc0 sc0 ls0 ws0">∂<span class="_ _26"></span>o</div><div class="t m0 x128 ha y733 ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">t</span>)</div><div class="t m0 x140 h4 y730 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _9"> </span>ˆ<span class="_ _50"></span><span class="ffa">y</span></div><div class="t m0 x135 hb y734 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x96 h4 y730 fff fs2 fc0 sc0 ls0 ws0">−<span class="_ _30"> </span><span class="ffa">y</span></div><div class="t m0 xd9 hb y734 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x33 h4 y730 ff3 fs2 fc0 sc0 ls0 ws0">(8.2)</div><div class="t m0 x3 h6 y735 ff1 fs2 fc0 sc0 ls0 ws0">关于<span class="_ _9"> </span><span class="ff11">W</span></div><div class="t m0 x13a h1e y736 ff11 fs7 fc0 sc0 ls0 ws0">O</div><div class="t m0 x10f h6 y735 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _9"> </span><span class="ff11">B</span></div><div class="t m0 x6a h1e y736 ff11 fs7 fc0 sc0 ls0 ws0">O</div><div class="t m0 x16d h6 y735 ff1 fs2 fc0 sc0 ls0 ws0">的梯度计算如下：</div><div class="t m0 x3 h5f y737 ff5 fs8 fc0 sc0 ls0 ws0">8.1.3<span class="_ _34"> </span>title</div><div class="t m0 xb3 h3a y738 ff5 fs6 fc0 sc0 ls0 ws0">8.2<span class="_ _1f"> </span>LSTM</div><div class="t m0 x3 h12 y739 ff5 fs8 fc0 sc0 ls0 ws0">8.2.1<span class="_ _34"> </span>LSTM<span class="_ _4"> </span><span class="ff9">概述</span></div><div class="t m0 x3 h6 y73a ff1 fs2 fc0 sc0 ls0 ws0">传统<span class="_ _25"> </span><span class="ff3">RNN<span class="_ _9"> </span></span>模型容易产生梯度消失的问题，<span class="_ _22"></span>难以处理长序列的数据。<span class="_ _22"></span>而造成梯度消失的原因，<span class="_ _22"></span>本</div><div class="t m0 x3 h6 y73b ff1 fs2 fc0 sc0 ls0 ws0">质<span class="_ _1e"></span>上<span class="_ _1e"></span>是<span class="_ _1e"></span>因<span class="_ _1e"></span>为<span class="_ _1e"></span>隐<span class="_ _1e"></span>藏<span class="_ _1e"></span>层<span class="_ _1e"></span>状<span class="_ _1e"></span>态<span class="_ _0"> </span><span class="ffa">H</span></div><div class="t m0 x185 hb y73c ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x82 h6 y73b ff1 fs2 fc0 sc0 ls0 ws0">的<span class="_ _1e"></span>计<span class="_ _1e"></span>算<span class="_ _1e"></span>方<span class="_ _1e"></span>式<span class="_ _1e"></span>导<span class="_ _1e"></span>致<span class="_ _1e"></span>梯<span class="_ _1e"></span>度<span class="_ _1e"></span>被<span class="_ _1e"></span>表<span class="_ _1e"></span>示<span class="_ _1e"></span>为<span class="_ _1e"></span>连<span class="_ _1e"></span>乘<span class="_ _1e"></span>积<span class="_ _1e"></span>的<span class="_ _1e"></span>形<span class="_ _1e"></span>式，<span class="_ _1e"></span>因<span class="_ _1e"></span>此<span class="_ _0"> </span><span class="ff3">Hochreater<span class="_ _1c"> </span></span>和</div><div class="t m0 x3 h6 y73d ff3 fs2 fc0 sc0 ls0 ws0">Sc<span class="_ _e"></span>hmidh<span class="_ _e"></span>ub<span class="_ _1e"></span>er<span class="_ _25"> </span><span class="ff1">在<span class="_ _25"> </span></span>1997<span class="_ _25"> </span><span class="ff1">年提出了长短期记忆网络<span class="_ _25"> </span></span>LSTM<span class="ff1">，<span class="_ _21"></span>通过精心设计的隐藏层神经元缓解了传</span></div><div class="t m0 x3 h6 y73e ff1 fs2 fc0 sc0 ls0 ws0">统<span class="_ _9"> </span><span class="ff3">RNN<span class="_ _9"> </span></span>的梯度消失问题。</div><div class="t m0 x3 h12 y73f ff5 fs8 fc0 sc0 ls0 ws0">8.2.2<span class="_ _34"> </span>LSTM<span class="_ _4"> </span><span class="ff9">与<span class="_ _4"> </span></span>RNN<span class="_ _4"> </span><span class="ff9">的区别</span></div><div class="t m0 x3 h6 y740 ff1 fs2 fc0 sc0 ls0 ws0">如果我们略去<span class="_ _30"> </span><span class="ff3">RNN<span class="_ _f"> </span></span>网络的输出层和损失函数，<span class="_ _32"></span>那么模型可以简化为如图<span class="ff3">8.6</span>的形式<span class="_ _3c"></span>（只保留<span class="_ _30"> </span><span class="ff3">RNN</span></div><div class="t m0 x3 h6 y741 ff1 fs2 fc0 sc0 ls0 ws0">的隐藏层）<span class="_ _23"></span>，<span class="_ _2d"></span>通过线条指示的路径可以清晰地看出隐藏状态<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 x62 hb y742 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x150 h6 y741 ff1 fs2 fc0 sc0 ls0 ws0">由<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 x14c ha y742 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x13c h6 y741 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _9"> </span><span class="ff11">x</span></div><div class="t m0 x147 hb y742 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x77 h6 y741 ff1 fs2 fc0 sc0 ls0 ws0">共同决定。<span class="_ _2d"></span><span class="ff11">H</span></div><div class="t m0 xfc hb y742 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb5 h6 y741 ff1 fs2 fc0 sc0 ls0 ws0">一</div><div class="t m0 x3 h6 y743 ff1 fs2 fc0 sc0 ls0 ws0">方面是<span class="_ _9"> </span><span class="ff3">RNN<span class="_ _9"> </span></span>层当前的输出，另一方面用于计算<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 x154 ha y744 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ffc">+1</span></div><div class="t m0 x48 h6 y745 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">8.6:<span class="_ _1c"> </span>RNN<span class="_ _9"> </span></span>隐藏层</div><div class="t m0 x3 h6 y746 ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _1c"> </span><span class="ff1">和<span class="_ _12"> </span></span>RNN<span class="_ _1c"> </span><span class="ff1">区<span class="_ _1e"></span>别<span class="_ _1e"></span>在<span class="_ _1e"></span>于隐<span class="_ _1e"></span>藏<span class="_ _1e"></span>层<span class="_ _1e"></span>的<span class="_ _1e"></span>不<span class="_ _1e"></span>同。虽<span class="_ _1e"></span>然<span class="_ _1c"> </span></span>LSTM<span class="_ _1c"> </span><span class="ff1">也<span class="_ _1e"></span>有这<span class="_ _1e"></span>种<span class="_ _1e"></span>链<span class="_ _1e"></span>状<span class="_ _1e"></span>结<span class="_ _1e"></span>构，不<span class="_ _1e"></span>过<span class="_ _1e"></span>其<span class="_ _1e"></span>循<span class="_ _1e"></span>环结<span class="_ _1e"></span>构<span class="_ _1e"></span>和</span></div><div class="t m0 x3 h6 y747 ff3 fs2 fc0 sc0 ls0 ws0">RNN<span class="_ _9"> </span><span class="ff1">不同。</span>LSTM<span class="_ _9"> </span><span class="ff1">的循环结构中有<span class="_ _9"> </span></span>4<span class="_ _9"> </span><span class="ff1">个神经网络层，并且他们之间的交互非常特别。</span></div><div class="t m0 xfd h6 y748 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">8.7:<span class="_ _1c"> </span>LSTM<span class="_ _9"> </span></span>隐藏层</div><div class="t m0 x3 h6 y1c7 ff1 fs2 fc0 sc0 ls0 ws0">可以发现，<span class="_ _e"></span><span class="ff3">LSTM<span class="_ _9"> </span><span class="ff1">和<span class="_ _9"> </span></span>RNN<span class="_ _9"> </span><span class="ff1">的隐藏层都只有一个输出，<span class="_ _2d"></span>就是<span class="_ _9"> </span><span class="ff11">H</span></span></span></div><div class="t m0 xd8 hb y749 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x2a h6 y1c7 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _e"></span>并且<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 x7b hb y749 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x11d h6 y1c7 ff1 fs2 fc0 sc0 ls0 ws0">都参与了下一时刻的</div><div class="t m0 x3 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">前向传播。<span class="_ _31"></span>但除了<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 x129 hb y9d ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x109 h6 y1e ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _31"></span><span class="ff3">LSTM<span class="_ _9"> </span><span class="ff1">还有一个隐藏状态也参与了前向传播，<span class="_ _31"></span>但这个隐藏状态没有被输</span></span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">52</div><a class="l" href="#pf39" data-dest-detail='[57,"XYZ",458.19,312.33,null]'><div class="d m1" style="border-style:none;position:absolute;left:616.666500px;bottom:683.982000px;width:13.942000px;height:15.458000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3a" class="pf w0 h0" data-page-no="3a"><div class="pc pc3a w0 h0"><img class="bi x76 y74a w3 h60" alt="" src="bg3a.png"/><div class="t m0 x30 h47 y1f ff3 fs5 fc0 sc0 ls0 ws0">8.2<span class="_ _d"> </span>LSTM</div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">出。我们称这个隐藏状态<span class="_ _1e"></span>为细胞状态<span class="_ _9"> </span><span class="ff11">C</span></div><div class="t m0 x102 hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x8c h6 y20 ff3 fs2 fc0 sc0 ls0 ws0">(Cell<span class="_ _9"> </span>State)<span class="ff1">。<span class="ff11">C</span></span></div><div class="t m0 x5f hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x112 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">在<span class="_ _9"> </span><span class="ff3">LSTM<span class="_ _9"> </span></span>中实<span class="_ _1e"></span>质上起到了<span class="_ _9"> </span><span class="ff3">RNN<span class="_ _a"> </span></span>中隐</div><div class="t m0 x3 h6 y1c9 ff1 fs2 fc0 sc0 ls0 ws0">藏状态<span class="_ _9"> </span><span class="ff11">H</span></div><div class="t m0 x12f hb y74b ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x186 h6 y1c9 ff1 fs2 fc0 sc0 ls0 ws0">的作用。</div><div class="t m0 x3 h6 y74c ff1 fs2 fc0 sc0 ls0 ws0">除了<span class="_ _25"> </span><span class="ff11">H</span></div><div class="t m0 x80 hb y74d ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb h6 y74c ff1 fs2 fc0 sc0 ls0 ws0">和细胞状态<span class="_ _25"> </span><span class="ff11">C</span></div><div class="t m0 x130 hb y74d ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xde h6 y74c ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _31"></span>图中还有三个结构，<span class="_ _31"></span>这些结构一般称之为门控结构<span class="_ _9"> </span><span class="ff3">(Gate)</span>。<span class="_ _2d"></span><span class="ff3">LSTM<span class="_ _9"> </span><span class="ff1">的</span></span></div><div class="t m0 x3 h6 y74e ff1 fs2 fc0 sc0 ls0 ws0">门控结构一般包括遗忘门，输入门和输出门三种，这三个门结构都是用来控制<span class="_ _9"> </span><span class="ff11">C</span></div><div class="t m0 xe9 hb y74f ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x2e h6 y74e ff1 fs2 fc0 sc0 ls0 ws0">的状态。</div><div class="t m0 x3d h6 y750 ff1 fs2 fc0 sc0 ls0 ws0">图<span class="_ _9"> </span><span class="ff3">8.8:<span class="_ _1c"> </span>cell<span class="_ _9"> </span>state</span></div><div class="t m0 x3 h6 y751 ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _25"> </span><span class="ff1">的关键是细胞状态<span class="_ _9"> </span><span class="ff11">C</span></span></div><div class="t m0 x82 hb y752 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xa4 h6 y751 ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _31"></span><span class="ff11">C</span></div><div class="t m0 x157 hb y752 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x160 h6 y751 ff1 fs2 fc0 sc0 ls0 ws0">横穿整个<span class="_ _25"> </span><span class="ff3">LSTM<span class="_ _9"> </span></span>单元顶部的水平线。<span class="_ _2d"></span><span class="ff3">LSTM<span class="_ _9"> </span><span class="ff1">通过门结构对细</span></span></div><div class="t m0 x3 h6 y753 ff1 fs2 fc0 sc0 ls0 ws0">胞状态<span class="_ _1e"></span>添加或<span class="_ _1e"></span>者删<span class="_ _1e"></span>除信息。<span class="_ _1e"></span>门是一<span class="_ _1e"></span>种选<span class="_ _1e"></span>择性让<span class="_ _1e"></span>信息通<span class="_ _1e"></span>过的方<span class="_ _1e"></span>法。它<span class="_ _1e"></span>们由一<span class="_ _1e"></span>个<span class="_ _a"> </span><span class="ff3">Sigmoid<span class="_ _a"> </span></span>神<span class="_ _1e"></span>经网络</div><div class="t m0 x3 h6 y754 ff1 fs2 fc0 sc0 ls0 ws0">层和一个元素级相乘操作组成。</div><div class="t m0 x3 h6 y755 ff1 fs2 fc0 sc0 ls0 ws0">在开始之介绍<span class="_ _9"> </span><span class="ff3">LSTM<span class="_ _9"> </span></span>各个门结构前，我们先介绍一下将用到的标记。</div><div class="t m0 x3 h6 y756 ff1 fs2 fc0 sc0 ls0 ws0">在上图中，<span class="_ _21"></span>每条线表示向量的传递，<span class="_ _20"></span>从一个结点的输出传递到另外结点的输入。<span class="_ _20"></span>粉红圆表示向量</div><div class="t m0 x3 h6 yf ff1 fs2 fc0 sc0 ls0 ws0">的元素级操作，<span class="_ _20"></span>比如相加或者相乘。<span class="_ _31"></span>黄色方框表示神经网络的层。<span class="_ _22"></span>线合并表示向量的连接，<span class="_ _22"></span>线分</div><div class="t m0 x3 h6 y757 ff1 fs2 fc0 sc0 ls0 ws0">叉表示向量复制。接下来按运算顺序介绍<span class="_ _9"> </span><span class="ff3">LSTM<span class="_ _9"> </span></span>的三个门结构。</div><div class="t m0 x3 h12 y758 ff5 fs8 fc0 sc0 ls0 ws0">8.2.3<span class="_ _34"> </span><span class="ff9">遗忘门</span></div><div class="t m0 x3 h6 y759 ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _9"> </span><span class="ff1">的第一步是决定我们将要从细胞状态中扔掉哪些信息。<span class="_ _2d"></span>该决定由一个叫做<span class="_ _2d"></span>“遗忘门<span class="_ _9"> </span><span class="ff3">(F<span class="_ _31"></span>or-</span></span></div><div class="t m0 x3 h4 y75a ff3 fs2 fc0 sc0 ls0 ws0">get<span class="_ _9"> </span>Gate)</div><div class="t m0 x81 h6 y75b ff1 fs2 fc0 sc0 ls0 ws0">”<span class="_ _e"></span>的</div><div class="t m0 xd1 h4 y75a ff3 fs2 fc0 sc0 ls0 ws0">Sigmoid</div><div class="t m0 x65 h6 y75b ff1 fs2 fc0 sc0 ls0 ws0">层控制。</div><div class="t m0 x3b h20 y75a ff11 fs2 fc0 sc0 ls0 ws0">H</div><div class="t m0 xb8 ha y75c ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x100 h6 y75b ff1 fs2 fc0 sc0 ls0 ws0">和</div><div class="t m0 x5a h20 y75a ff11 fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x1 hb y75c ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x19d h6 y75b ff1 fs2 fc0 sc0 ls0 ws0">被输入遗忘门，<span class="_ _2d"></span>经过</div><div class="t m0 xd5 h4 y75a ff3 fs2 fc0 sc0 ls0 ws0">Sigmoid</div><div class="t m0 x11d h6 y75b ff1 fs2 fc0 sc0 ls0 ws0">激活函数，<span class="_ _2d"></span>输出一个</div><div class="t m0 x3 h6 y75d ff1 fs2 fc0 sc0 ls0 ws0">向量<span class="_ _9"> </span><span class="ffa">f</span></div><div class="t m0 x34 hb y75e ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x78 h6 y75d ff1 fs2 fc0 sc0 ls0 ws0">，<span class="ffa">f</span></div><div class="t m0 x68 hb y75e ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x117 h6 y75d ff1 fs2 fc0 sc0 ls0 ws0">的元素与<span class="_ _9"> </span><span class="ff11">C</span></div><div class="t m0 xb0 ha y75e ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xe0 h6 y75d ff1 fs2 fc0 sc0 ls0 ws0">的元素一一对应，并且<span class="_ _a"> </span><span class="ffa">f</span></div><div class="t m0 x27 hb y75e ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x133 h6 y75d ff1 fs2 fc0 sc0 ls0 ws0">的元素都是<span class="_ _9"> </span><span class="ffb">0<span class="_ _25"> </span><span class="fff">∼<span class="_ _25"> </span></span>1<span class="_ _9"> </span></span>之间的数，<span class="ff3">1<span class="_ _a"> </span></span>表示“完</div><div class="t m0 x3 h6 y75f ff1 fs2 fc0 sc0 ls0 ws0">全保留该信息”<span class="_ _23"></span>，<span class="_ _22"></span><span class="ff3">0<span class="_ _25"> </span><span class="ff1">表示<span class="_ _2d"></span>“完全丢弃该信息”<span class="_ _23"></span>。<span class="_ _31"></span>即遗忘门以一定的概率控制是否遗忘上一个时刻的</span></span></div><div class="t m0 x3 h6 y760 ff1 fs2 fc0 sc0 ls0 ws0">细胞状态。</div><div class="t m0 xed hc y761 ffa fs2 fc0 sc0 ls0 ws0">f</div><div class="t m0 x160 hb y762 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x1f h4 y761 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">σ<span class="_ _3e"> </span></span>(<span class="ffa">W</span></div><div class="t m0 xbd hb y763 ffd fs7 fc0 sc0 ls0 ws0">f</div><div class="t m0 x171 hc y761 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa5 ha y762 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x134 h4 y761 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y763 ffd fs7 fc0 sc0 ls0 ws0">f</div><div class="t m0 x128 hc y761 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x43 hb y762 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x63 h4 y761 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x50 hb y763 ffd fs7 fc0 sc0 ls0 ws0">f</div><div class="t m0 x137 h4 y761 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _62"> </span><span class="ff3">(8.3)</span></div><div class="t m0 x3 h12 y764 ff5 fs8 fc0 sc0 ls0 ws0">8.2.4<span class="_ _34"> </span><span class="ff9">输入门</span></div><div class="t m0 x3 h6 y111 ff1 fs2 fc0 sc0 ls0 ws0">第二步是决定我们将会把哪些新信息存储到元胞状态中。这步分为两部分：</div><div class="t m0 x9a h6 y1e ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">首先，有一个叫做“输入门<span class="_ _25"> </span></span>(Input<span class="_ _9"> </span>Gate)<span class="ff1">”的<span class="_ _9"> </span></span>Sigmoid<span class="_ _9"> </span><span class="ff1">层决定我们要更新哪些信息。</span></div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">53</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3b" class="pf w0 h0" data-page-no="3b"><div class="pc pc3b w0 h0"><div class="t m0 x3 h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">8.3<span class="_ _d"> </span><span class="ff8">带窥孔的<span class="_ _2f"> </span></span>LSTM</div><div class="t m0 x9a h6 y20 ff3 fs2 fc0 sc0 ls0 ws0">•<span class="_ _4"> </span><span class="ff1">接下来，一个<span class="_ _25"> </span></span>tanh<span class="_ _9"> </span><span class="ff1">层创造了一个新的候选值</span></div><div class="t m0 x136 h4 y765 ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x144 hc y20 ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 x164 hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x128 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">，该值可能被加入到元胞状态中。</div><div class="t m0 x3 h6 y3c ff1 fs2 fc0 sc0 ls0 ws0">在第三步中，<span class="ff3">LSTM<span class="_ _9"> </span></span>把这两个值组合起来用于更新元胞状态。</div><div class="t m0 x3c hc y766 ffa fs2 fc0 sc0 ls0 ws0">i</div><div class="t m0 xb8 hb y767 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xab h4 y766 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">σ<span class="_ _3e"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x86 hb y767 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x171 hc y766 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x15d ha y767 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x134 h4 y766 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y767 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 xc0 hc y766 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x92 hb y767 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x13f h4 y766 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 xef hb y767 ffd fs7 fc0 sc0 ls0 ws0">i</div><div class="t m0 x4f h4 y766 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _63"> </span><span class="ff3">(8.4)</span></div><div class="t m0 x3a h4 y768 ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x7 hc y769 ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 x45 hb y76a ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xca h4 y769 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ff3">tanh<span class="_ _2c"> </span></span>(<span class="ffa">W</span></div><div class="t m0 xa0 hb y76b ffd fs7 fc0 sc0 ls0 ws0">C</div><div class="t m0 x5b hc y769 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x41 ha y76a ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xb4 h4 y769 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">U</span></div><div class="t m0 xad hb y76b ffd fs7 fc0 sc0 ls0 ws0">C</div><div class="t m0 x5f hc y769 ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x61 hb y76a ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x14b h4 y769 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x96 hb y76b ffd fs7 fc0 sc0 ls0 ws0">C</div><div class="t m0 x148 h4 y769 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _64"> </span><span class="ff3">(8.5)</span></div><div class="t m0 x3 h12 y76c ff5 fs8 fc0 sc0 ls0 ws0">8.2.5<span class="_ _34"> </span><span class="ff9">细胞状态更新</span></div><div class="t m0 x3 h6 y76d ff1 fs2 fc0 sc0 ls0 ws0">现在我们该将旧细胞状态<span class="_ _9"> </span><span class="ff11">C</span></div><div class="t m0 xe0 ha y76e ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x3a h6 y76d ff1 fs2 fc0 sc0 ls0 ws0">更新到新状态<span class="_ _9"> </span><span class="ff11">C</span></div><div class="t m0 x25 hb y76e ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x5e h6 y76d ff1 fs2 fc0 sc0 ls0 ws0">了。上面的步骤中已经决定了该怎么做，<span class="_ _e"></span>这一</div><div class="t m0 x3 h6 y76f ff1 fs2 fc0 sc0 ls0 ws0">步我们只需要实际执行即可。</div><div class="t m0 xcb hc y770 ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 xe1 hb y771 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x100 h4 y770 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">C</span></div><div class="t m0 xf1 ha y771 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x8f h4 y770 fff fs2 fc0 sc0 ls0 ws0">⊙<span class="_ _30"> </span><span class="ffa">f</span></div><div class="t m0 x5e hb y771 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb4 h4 y770 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">i</span></div><div class="t m0 xcd hb y771 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xc1 h4 y770 fff fs2 fc0 sc0 ls0 ws0">⊙</div><div class="t m0 x60 h4 y772 ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x61 hc y770 ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 xd7 hb y771 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x33 h4 y770 ff3 fs2 fc0 sc0 ls0 ws0">(8.6)</div><div class="t m0 x3 h6 y773 fff fs2 fc0 sc0 ls0 ws0">⊙<span class="_ _9"> </span><span class="ff1">是矩阵的<span class="_ _a"> </span><span class="ff3">Hadamard<span class="_ _9"> </span></span>积<span class="_ _9"> </span><span class="ff3">(</span>两个矩阵相同位<span class="_ _1e"></span>置元素的乘积<span class="ff3">)</span>。新状态即为旧<span class="_ _1e"></span>状态乘以需要忘记的</span></div><div class="t m0 x3 h6 y774 ff1 fs2 fc0 sc0 ls0 ws0">概率，加上新的候选值乘以需要更新的比率。</div><div class="t m0 x3 h12 y775 ff5 fs8 fc0 sc0 ls0 ws0">8.2.6<span class="_ _34"> </span><span class="ff9">输出门</span></div><div class="t m0 x3 h6 y776 ff1 fs2 fc0 sc0 ls0 ws0">最后，<span class="_ _20"></span>我们需要决定最终的输出。<span class="_ _31"></span>输出将会基于目前的细胞状态，<span class="_ _20"></span>并且会加入一些过滤。<span class="_ _31"></span>首先我</div><div class="t m0 x3 h6 y777 ff1 fs2 fc0 sc0 ls0 ws0">们建立一个<span class="_ _25"> </span><span class="ff3">Sigmoid<span class="_ _25"> </span></span>层的输出门<span class="_ _25"> </span><span class="ff3">(Output<span class="_ _9"> </span>Gate)</span>，<span class="_ _21"></span>来决定我们将输出元胞的哪些部分。<span class="_ _20"></span>然后我们</div><div class="t m0 x3 h6 y778 ff1 fs2 fc0 sc0 ls0 ws0">将元胞状态通过<span class="_ _9"> </span><span class="ff3">tanh<span class="_ _9"> </span></span>之后（使得输<span class="_ _1e"></span>出值在<span class="ff3">-1<span class="_ _9"> </span></span>到<span class="_ _9"> </span><span class="ff3">1<span class="_ _9"> </span></span>之间）<span class="_ _2e"></span>，与输出门相乘，这样我们只会输出我</div><div class="t m0 x3 h6 y779 ff1 fs2 fc0 sc0 ls0 ws0">们想输出的部分。</div><div class="t m0 x2 hc y77a ffa fs2 fc0 sc0 ls0 ws0">o</div><div class="t m0 xa hb y77b ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x87 h4 y77a ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">σ<span class="_ _3e"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x4 hb y77b ffd fs7 fc0 sc0 ls0 ws0">o</div><div class="t m0 x171 hc y77a ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x15d ha y77b ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x134 h4 y77a ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y77b ffd fs7 fc0 sc0 ls0 ws0">o</div><div class="t m0 x128 hc y77a ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x43 hb y77b ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xe3 h4 y77a ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x50 hb y77b ffd fs7 fc0 sc0 ls0 ws0">o</div><div class="t m0 x135 h4 y77a ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _65"> </span><span class="ff3">(8.7)</span></div><div class="t m0 x19e hc y77c ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x9 hb y77d ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x59 h4 y77c ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">o</span></div><div class="t m0 x8e hb y77d ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xf0 h4 y77c fff fs2 fc0 sc0 ls0 ws0">⊙<span class="_ _30"> </span><span class="ff3">tanh</span></div><div class="t m0 x155 he y77e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x133 h4 y77f ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 xcd hc y77c ffa fs2 fc0 sc0 ls0 ws0">C</div><div class="t m0 x43 hb y77d ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x13f he y77e ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y77c ff3 fs2 fc0 sc0 ls0 ws0">(8.8)</div><div class="t m0 x7 h9 y780 ff5 fs6 fc0 sc0 ls0 ws0">8.3<span class="_ _1f"> </span><span class="ff9">带窥孔的<span class="_ _7"> </span></span>LSTM</div><div class="t m0 x3 h6 y781 ff1 fs2 fc0 sc0 ls0 ws0">本文前<span class="_ _1e"></span>面所介<span class="_ _1e"></span>绍的<span class="_ _a"> </span><span class="ff3">LSTM<span class="_ _12"> </span></span>是最普<span class="_ _1e"></span>通的<span class="_ _a"> </span><span class="ff3">LSTM</span>，<span class="_ _1e"></span>但并非<span class="_ _1e"></span>所有的<span class="_ _12"> </span><span class="ff3">LSTM<span class="_ _a"> </span></span>模型<span class="_ _1e"></span>都与前<span class="_ _1e"></span>面相同。<span class="_ _1e"></span>事实</div><div class="t m0 x3 h6 y782 ff1 fs2 fc0 sc0 ls0 ws0">上，似乎每一篇<span class="_ _25"> </span><span class="ff3">pap<span class="_ _1e"></span>er<span class="_ _9"> </span></span>中所用到的<span class="_ _9"> </span><span class="ff3">LSTM<span class="_ _9"> </span></span>都是稍微不一样的版本。不同之处很微小，不过其中</div><div class="t m0 x3 h6 y783 ff1 fs2 fc0 sc0 ls0 ws0">一些值得介绍。</div><div class="t m0 x3 h6 y784 ff1 fs2 fc0 sc0 ls0 ws0">一个流行的<span class="_ _25"> </span><span class="ff3">LSTM<span class="_ _9"> </span></span>变种，<span class="_ _22"></span>由<span class="_ _9"> </span><span class="ff3">Gers<span class="_ _25"> </span>&amp;<span class="_ _9"> </span>Sc<span class="_ _2d"></span>hmidhuber<span class="_ _9"> </span>(2000)<span class="_ _25"> </span><span class="ff1">提出，<span class="_ _31"></span>加入了<span class="_ _2d"></span>“窥视孔连接<span class="_ _25"> </span><span class="ff3">(p<span class="_ _1e"></span>eephole</span></span></span></div><div class="t m0 x3 h6 y785 ff3 fs2 fc0 sc0 ls0 ws0">connection)<span class="ff1">”<span class="_ _23"></span>。也就是说我们让各种门可以观察到元胞状态。</span></div><div class="t m0 x3d h3a y786 ff5 fs6 fc0 sc0 ls0 ws0">8.4<span class="_ _1f"> </span>GR<span class="_ _2d"></span>U</div><div class="t m0 x3 h6 y787 ff1 fs2 fc0 sc0 ls0 ws0">另一个变化更大一些的<span class="_ _f"> </span><span class="ff3">LSTM<span class="_ _f"> </span></span>变种叫做<span class="_ _f"> </span><span class="ff3">Gated<span class="_ _30"> </span>Recurrent<span class="_ _f"> </span>Unit</span>，<span class="_ _2e"></span>或者<span class="_ _f"> </span><span class="ff3">GRU</span>，<span class="_ _2e"></span>由<span class="_ _f"> </span><span class="ff3">Cho, et<span class="_ _30"> </span>al.<span class="_ _1c"> </span>(2014)</span></div><div class="t m0 x3 h6 y788 ff1 fs2 fc0 sc0 ls0 ws0">提出。<span class="ff3">GR<span class="_ _e"></span>U<span class="_ _9"> </span><span class="ff1">将遗忘门<span class="_ _1e"></span>和输入门合并成为单一<span class="_ _1e"></span>的“更新门<span class="_ _9"> </span></span>(Up<span class="_ _1e"></span>date<span class="_ _a"> </span>Gate)<span class="ff1">”<span class="_ _2e"></span>。<span class="ff3">GR<span class="_ _2d"></span>U<span class="_ _a"> </span><span class="ff1">同时也将元胞</span></span></span></span></div><div class="t m0 x3 h6 y5bb ff1 fs2 fc0 sc0 ls0 ws0">状态<span class="_ _12"> </span><span class="ff3">(Cell<span class="_ _a"> </span>State)<span class="_ _12"> </span></span>和<span class="_ _1e"></span>隐状态<span class="_ _12"> </span><span class="ff3">(Hidden<span class="_ _12"> </span>State)<span class="_ _a"> </span></span>合<span class="_ _1e"></span>并，同<span class="_ _1e"></span>时引<span class="_ _1e"></span>入其<span class="_ _1e"></span>他的<span class="_ _1e"></span>一些<span class="_ _1e"></span>变化。<span class="_ _1e"></span>该模型<span class="_ _1e"></span>比标<span class="_ _1e"></span>准的</div><div class="t m0 x3 h6 y5bd ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _9"> </span><span class="ff1">模型更加简化，同时现在也变得越来越流行。</span></div><div class="t m0 x3 h6 y789 ff1 fs2 fc0 sc0 ls0 ws0">图中，<span class="ffa">r</span></div><div class="t m0 x101 hb y78a ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x18f h6 y789 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _9"> </span><span class="ff3">GR<span class="_ _e"></span>U<span class="_ _9"> </span><span class="ff1">模型的重置门部分，用于控制前一时刻隐藏状态<span class="_ _9"> </span><span class="ffa">h</span></span></span></div><div class="t m0 xe5 ha y78a ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xc9 h6 y789 ff1 fs2 fc0 sc0 ls0 ws0">对当前状态的影响。若</div><div class="t m0 x3 hc y78b ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xf9 ha y78c ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x138 h6 y78b ff1 fs2 fc0 sc0 ls0 ws0">不重要，<span class="_ _20"></span>从语言模型角度看，<span class="_ _20"></span>即从当前开始表达新的意思，<span class="_ _20"></span>与上文无关，<span class="_ _22"></span>则重置门关闭，<span class="_ _20"></span>数</div><div class="t m0 x3 h6 y78d ff1 fs2 fc0 sc0 ls0 ws0">学表达式为：</div><div class="t m0 x2 hc y1e ffa fs2 fc0 sc0 ls0 ws0">r</div><div class="t m0 xa hb y9d ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xc4 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">σ<span class="_ _3e"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x4 hb y9d ffd fs7 fc0 sc0 ls0 ws0">r</div><div class="t m0 x171 hc y1e ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa5 ha y9d ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x134 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y9d ffd fs7 fc0 sc0 ls0 ws0">r</div><div class="t m0 x128 hc y1e ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x19f hb y9d ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xe3 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x50 hb y9d ffd fs7 fc0 sc0 ls0 ws0">r</div><div class="t m0 x28 h4 y1e ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _65"> </span><span class="ff3">(8.9)</span></div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">54</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3c" class="pf w0 h0" data-page-no="3c"><div class="pc pc3c w0 h0"><div class="t m0 x1a0 h47 y1f ff3 fs5 fc0 sc0 ls0 ws0">8.4<span class="_ _d"> </span>GR<span class="_ _2d"></span>U</div><div class="t m0 x3 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">图中<span class="_ _a"> </span><span class="ffa">z</span></div><div class="t m0 x7a hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x35 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">是<span class="_ _a"> </span><span class="ff3">GRU<span class="_ _9"> </span></span>模型<span class="_ _1e"></span>的更新<span class="_ _1e"></span>门部分，<span class="_ _1e"></span>用于决<span class="_ _1e"></span>定是否<span class="_ _1e"></span>忽略当<span class="_ _1e"></span>前输入<span class="_ _12"> </span><span class="ffa">x</span></div><div class="t m0 x121 hb y2c9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xe5 h6 y20 ff1 fs2 fc0 sc0 ls0 ws0">，类似<span class="_ _12"> </span><span class="ff3">LSTM<span class="_ _a"> </span></span>中的输<span class="_ _1e"></span>入门</div><div class="t m0 x3 hc y1c9 ffa fs2 fc0 sc0 ls0 ws0">i</div><div class="t m0 x1a1 hb y74b ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x122 h6 y1c9 ff1 fs2 fc0 sc0 ls0 ws0">。从语言模型角度看，即判断当前词<span class="_ _9"> </span><span class="ffa">x</span></div><div class="t m0 x8c hb y74b ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x5a h6 y1c9 ff1 fs2 fc0 sc0 ls0 ws0">对整体意思的表达是否重要，数学表达式为：</div><div class="t m0 x1d hc y60a ffa fs2 fc0 sc0 ls0 ws0">z</div><div class="t m0 xa hb y78e ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xc4 h4 y60a ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">σ<span class="_ _3e"> </span></span>(<span class="ffa">W</span></div><div class="t m0 x4 hb y78e ffd fs7 fc0 sc0 ls0 ws0">z</div><div class="t m0 x171 hc y60a ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa5 ha y78e ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x134 h4 y60a ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">U</span></div><div class="t m0 x4d hb y78e ffd fs7 fc0 sc0 ls0 ws0">z</div><div class="t m0 x128 hc y60a ffa fs2 fc0 sc0 ls0 ws0">x</div><div class="t m0 x19f hb y78e ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xe3 h4 y60a ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 x50 hb y78e ffd fs7 fc0 sc0 ls0 ws0">z</div><div class="t m0 x135 h4 y60a ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _66"> </span><span class="ff3">(8.10)</span></div><div class="t m0 x3 h6 y60b ff1 fs2 fc0 sc0 ls0 ws0">定义完<span class="_ _12"> </span><span class="ff3">GR<span class="_ _e"></span>U<span class="_ _a"> </span><span class="ff1">的<span class="_ _1e"></span>重置门<span class="_ _1e"></span>和更<span class="_ _1e"></span>新门<span class="_ _1e"></span>之后，我<span class="_ _1e"></span>们再<span class="_ _1e"></span>来看<span class="_ _a"> </span></span>GRU<span class="_ _a"> </span><span class="ff1">的细<span class="_ _1e"></span>胞更<span class="_ _1e"></span>新。当更<span class="_ _1e"></span>新门<span class="_ _1e"></span>打开时，<span class="ffa">h</span></span></span></div><div class="t m0 xfc hb y78f ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xb5 h6 y60b ff1 fs2 fc0 sc0 ls0 ws0">由</div><div class="t m0 x3 hc y790 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xf9 ha y791 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x138 h6 y790 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _25"> </span><span class="ffa">x</span></div><div class="t m0 x18f hb y791 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x17b h6 y790 ff1 fs2 fc0 sc0 ls0 ws0">决定；<span class="_ _22"></span>当更新门被关闭时，<span class="_ _31"></span><span class="ffa">h</span></div><div class="t m0 x3d ha y791 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xbd h6 y790 ff1 fs2 fc0 sc0 ls0 ws0">将仅由<span class="_ _25"> </span><span class="ffa">h</span></div><div class="t m0 x26 ha y791 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x93 h6 y790 ff1 fs2 fc0 sc0 ls0 ws0">决定，<span class="_ _22"></span>帮助梯度反向传播，<span class="_ _31"></span>与<span class="_ _25"> </span><span class="ff3">LSTM<span class="_ _9"> </span></span>相</div><div class="t m0 x3 h6 y792 ff1 fs2 fc0 sc0 ls0 ws0">同，这种机制有效地缓解了梯度消失现象。数学表达式为：</div><div class="t m0 x97 h4 y793 ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x97 hc y794 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x3a hb y795 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x157 h4 y794 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ff3">tanh<span class="_ _2c"> </span></span>(<span class="ffa">W<span class="_ _29"> </span>r</span></div><div class="t m0 x40 hb y795 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x24 h4 y794 fff fs2 fc0 sc0 ls0 ws0">⊙<span class="_ _30"> </span><span class="ffa">h</span></div><div class="t m0 x5e ha y795 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x4d h4 y794 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">U<span class="_ _2b"></span>x</span></div><div class="t m0 x106 hb y795 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x50 h4 y794 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">b</span></div><div class="t m0 xa3 hb y796 ffd fs7 fc0 sc0 ls0 ws0">f</div><div class="t m0 x2b h4 y794 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _67"> </span><span class="ff3">(8.11)</span></div><div class="t m0 x157 hc y797 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xee hb y798 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x1f h4 y797 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>(1<span class="_ _30"> </span><span class="fff">−<span class="_ _30"> </span><span class="ffa">z</span></span></div><div class="t m0 x8e hb y798 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x19d h4 y797 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="fff">⊙<span class="_ _30"> </span><span class="ffa">h</span></span></div><div class="t m0 x161 ha y798 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 xd6 h4 y797 ffb fs2 fc0 sc0 ls0 ws0">+<span class="_ _30"> </span><span class="ffa">z</span></div><div class="t m0 x63 hb y798 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x60 h4 y797 fff fs2 fc0 sc0 ls0 ws0">⊙</div><div class="t m0 x4f h4 y799 ffb fs2 fc0 sc0 ls0 ws0">˜</div><div class="t m0 x4f hc y797 ffa fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x71 hb y798 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xba h4 y797 ff3 fs2 fc0 sc0 ls0 ws0">(8.12)</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">55</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3d" class="pf w0 h0" data-page-no="3d"><div class="pc pc3d w0 h0"><div class="t m0 x3 h47 y1f ff3 fs5 fc0 sc0 ls0 ws0">8.4<span class="_ _d"> </span>GR<span class="_ _2d"></span>U</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">56</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3e" class="pf w0 h0" data-page-no="3e"><div class="pc pc3e w0 h0"><img class="bi x3 y2c8 w1f h61" alt="" src="bg3e.png"/><div class="t m0 x97 h5 y4 ff4 fs3 fc0 sc0 ls0 ws0">第九章 <span class="ff5">Seq2Seq</span></div><div class="t m0 xa6 h3a y4e ff5 fs6 fc0 sc0 ls0 ws0">9.1<span class="_ _1f"> </span>Enco<span class="_ _1e"></span>der-Deco<span class="_ _26"></span>der</div><div class="t m0 x3 h6 y79a ff3 fs2 fc0 sc0 ls0 ws0">Kyungh<span class="_ _e"></span>yun Cho<span class="_ _25"> </span><span class="ff1">等人在<span class="_ _25"> </span></span>2014<span class="_ _25"> </span><span class="ff1">年<span class="_ _25"> </span></span>6<span class="_ _25"> </span><span class="ff1">月<span class="_ _25"> </span></span>3 <span class="ff1">日将论文<span class="_ _20"></span>《<span class="ff3">Learning<span class="_ _25"> </span>Phrase<span class="_ _25"> </span>Representations using RNN</span></span></div><div class="t m0 x3 h6 y79b ff3 fs2 fc0 sc0 ls0 ws0">Enco<span class="_ _1e"></span>der<span class="_ _2a"></span><span class="ff1">–<span class="_ _2a"></span><span class="ff3">Deco<span class="_ _1e"></span>der<span class="_ _25"> </span>for<span class="_ _25"> </span>Statistical<span class="_ _25"> </span>Machine T<span class="_ _31"></span>ranslation<span class="ff1">》<span class="_ _20"></span>发布于<span class="_ _9"> </span><span class="ff3">Arxiv</span>，<span class="_ _21"></span>提出了<span class="_ _2f"> </span><span class="ff3">Enco<span class="_ _1e"></span>der<span class="_ _2a"></span><span class="ff1">–<span class="_ _2a"></span><span class="ff3">Deco<span class="_ _1e"></span>der</span></span></span></span></span></span></div><div class="t m0 x3 h6 y79c ff1 fs2 fc0 sc0 ls0 ws0">模型结构。论文提出的<span class="_ _9"> </span><span class="ff3">RNN<span class="_ _9"> </span>Enco<span class="_ _1e"></span>der-Deco<span class="_ _1e"></span>der<span class="_ _9"> </span></span>模型由两个<span class="_ _9"> </span><span class="ff3">RNN<span class="_ _9"> </span></span>组成：</div><div class="t m0 x3 h6 y79d ff4 fs2 fc0 sc0 ls0 ws0">简要地回顾<span class="_ _a"> </span><span class="ff6">RNN<span class="_ _12"> </span></span>的知识：</div><div class="t m0 x3 h6 y79e ff3 fs2 fc0 sc0 ls0 ws0">RNN <span class="ff1">是一个包含隐藏状态<span class="_ _25"> </span><span class="ff11">h<span class="_ _25"> </span></span>和可选输出<span class="_ _25"> </span><span class="ff11">y<span class="_ _9"> </span></span>的神经网络，<span class="_ _27"></span>它接受可变长序列<span class="_ _25"> </span><span class="ff11">x<span class="_ _2f"> </span><span class="ffb">=<span class="_ _2f"> </span>(<span class="ffa">x</span></span></span></span></div><div class="t m0 xf5 ha y79f ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xec hc y79e ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x1a2 hb y7a0 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 xfc h6 y79e ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span><span class="ff1">的</span></div><div class="t m0 x3 h6 y7a1 ff1 fs2 fc0 sc0 ls0 ws0">输入。在每个时间步，隐藏状态<span class="_ _9"> </span><span class="ff11">h</span></div><div class="t m0 xee ha y7a2 ff12 fs7 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 x158 h6 y7a1 ff1 fs2 fc0 sc0 ls0 ws0">按照如下公式更新：</div><div class="t m0 x47 h4 y7a3 ff6 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x102 ha y7a4 ff12 fs7 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 x14a h4 y7a3 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 x90 he y7a5 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x41 h4 y7a3 ff6 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x99 ha y7a4 ff12 fs7 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>−<span class="ffc">1</span>⟩</div><div class="t m0 x164 hc y7a3 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>x</div><div class="t m0 x93 hb y7a6 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x14d he y7a5 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x3 h6 y7a7 ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _25"> </span><span class="ffa">f<span class="_ _12"> </span></span>是非线性激活函数。<span class="_ _20"></span><span class="ffa">f<span class="_ _1c"> </span><span class="ff1">可以像<span class="_ _25"> </span><span class="ff3">logistic</span>、<span class="_ _20"></span><span class="ff3">sigmoid function<span class="_ _25"> </span><span class="ff1">一样简单，<span class="_ _20"></span>也可以像<span class="_ _25"> </span><span class="ff3">long<span class="_ _25"> </span>short-</span></span></span></span></span></div><div class="t m0 x3 h6 y7a8 ff3 fs2 fc0 sc0 ls0 ws0">term<span class="_ _9"> </span>memory<span class="ff1">（</span>LSTM<span class="ff1">）一样复杂。</span></div><div class="t m0 x3 h6 y7a9 ff1 fs2 fc0 sc0 ls0 ws0">以输入序列的下一个字符作为预测目标来训练，<span class="_ _28"></span><span class="ff3">RNN<span class="_ _25"> </span><span class="ff1">可以学习序列上的概率分布</span></span></div><div class="t m0 x119 h1d y7aa ff16 fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x2e h6 y7a9 ff1 fs2 fc0 sc0 ls0 ws0">。<span class="_ _21"></span>在这种情况</div><div class="t m0 x3 h6 y7ab ff1 fs2 fc0 sc0 ls0 ws0">下，<span class="_ _22"></span>每个时间步长<span class="_ _25"> </span><span class="ff3">t<span class="_ _25"> </span></span>的输出是条件分布<span class="_ _9"> </span><span class="ffa">p<span class="_ _2c"> </span><span class="ffb">(</span>x</span></div><div class="t m0 x1 hb y7ac ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x8e h4 y7ab fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 x5b ha y7ac ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x99 hc y7ab ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x19f ha y7ac ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x14d h6 y7ab ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">。<span class="_ _22"></span>例如，<span class="_ _22"></span>对于所有<span class="_ _25"> </span><span class="ffa">j<span class="_ _a"> </span><span class="ffb">=<span class="_ _f"> </span>1</span>,<span class="_ _2c"> </span><span class="fff">·<span class="_ _2c"></span>·<span class="_ _2c"></span>·<span class="_ _9"> </span></span>,<span class="_ _2c"> </span>K<span class="_ _26"></span></span>，<span class="_ _22"></span>可以</span></div><div class="t m0 x3 h6 y7ad ff1 fs2 fc0 sc0 ls0 ws0">使用<span class="_ _9"> </span><span class="ff3">softmax<span class="_ _9"> </span></span>激活函数输出多项式分布（<span class="ff3">1-K<span class="_ _9"> </span></span>编码）</div><div class="t m0 x12a h4 y7ae ffa fs2 fc0 sc0 ls0 ws0">p<span class="_ _2c"> </span><span class="ffb">(</span>x</div><div class="t m0 x82 hb y7af ffd fs7 fc0 sc0 ls0 ws0">t,j</div><div class="t m0 x7 h4 y7ae ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span>1<span class="fff">|<span class="ffa">x</span></span></div><div class="t m0 xab ha y7af ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x102 hc y7ae ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x5b ha y7af ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x5c h4 y7ae ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=</div><div class="t m0 xad h4 y7b0 ff3 fs2 fc0 sc0 ls0 ws0">exp</div><div class="t m0 x106 he y7b1 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xef h4 y7b0 ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x62 hb y7b2 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x29 h4 y7b0 ff6 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x51 ha y7b3 ff12 fs7 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 xd5 he y7b1 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x4c he y7b4 ffe fs2 fc0 sc0 ls0 ws0">P</div><div class="t m0 xd6 hb y7b5 ffd fs7 fc0 sc0 ls0 ws0">K</div><div class="t m0 xd6 hb y7b6 ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x133 h1b y7b7 ff15 fs9 fc0 sc0 ls0 ws0">′</div><div class="t m0 xad ha y7b6 ffc fs7 fc0 sc0 ls0 ws0">=1</div><div class="t m0 x112 h4 y7b8 ff3 fs2 fc0 sc0 ls0 ws0">exp</div><div class="t m0 x71 he y7b9 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xd8 h4 y7b8 ff6 fs2 fc0 sc0 ls0 ws0">w</div><div class="t m0 x175 hb y7ba ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 x131 h1b y7bb ff15 fs9 fc0 sc0 ls0 ws0">′</div><div class="t m0 xd5 h4 y7b8 ff6 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xae ha y7bc ff12 fs7 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 x174 he y7b9 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y7ae ff3 fs2 fc0 sc0 ls0 ws0">(9.1)</div><div class="t m0 x3 h6 y7bd ff1 fs2 fc0 sc0 ls0 ws0">其中<span class="_ _9"> </span><span class="ff11">w</span></div><div class="t m0 x78 hb y7be ffd fs7 fc0 sc0 ls0 ws0">j</div><div class="t m0 xb h6 y7bd ff1 fs2 fc0 sc0 ls0 ws0">是权重矩阵<span class="_ _9"> </span><span class="ff11">W<span class="_ _0"> </span></span>的行。通过组合这些概率，我们可以用如下公式计算序列<span class="_ _9"> </span><span class="ff11">x<span class="_ _9"> </span></span>的概率<span class="ff3">:</span></div><div class="t m0 xed h4 y7bf ffa fs2 fc0 sc0 ls0 ws0">p<span class="ffb">(<span class="ff6">x</span>)<span class="_ _2f"> </span>=</span></div><div class="t m0 xa7 hb y7c0 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 xb9 he y7c1 ffe fs2 fc0 sc0 ls0 ws0">Y</div><div class="t m0 xb9 ha y7c2 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ffc">=1</span></div><div class="t m0 x171 h4 y7bf ffa fs2 fc0 sc0 ls0 ws0">p<span class="_ _2c"> </span><span class="ffb">(</span>x</div><div class="t m0 x25 hb y7c3 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 xf3 h4 y7bf fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 x177 ha y7c3 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x165 hc y7bf ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x15b ha y7c3 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x137 h4 y7bf ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _68"> </span><span class="ff3">(9.2)</span></div><div class="t m0 x3 h6 y7c4 ff1 fs2 fc0 sc0 ls0 ws0">从这个学习的分布中，通过在每个时间步长迭代采样符号来直接抽样新序列。</div><div class="t m0 x104 h26 y320 ff18 fs9 fc0 sc0 ls0 ws0">1</div><div class="t m0 x18c h28 y1e ff1 fsa fc0 sc0 ls0 ws0">此时，<span class="ff1c">RNN<span class="_ _2f"> </span></span>的拟合目标就是这个概率分布。</div><div class="t m0 x90 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">57</div><a class="l" href="#pf3e" data-dest-detail='[62,"XYZ",87.01,53.48,null]'><div class="d m1" style="border-style:none;position:absolute;left:684.250500px;bottom:340.692000px;width:4.232000px;height:11.294000px;background-color:rgba(255,255,255,0.000001);"></div></a></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf3f" class="pf w0 h0" data-page-no="3f"><div class="pc pc3f w0 h0"><img class="bi x69 y7c5 w8 h62" alt="" src="bg3f.png"/><div class="t m0 x3 h47 y1f ff3 fs5 fc0 sc0 ls0 ws0">9.2<span class="_ _d"> </span>SEQ2SEQ</div><div class="t m0 x3 h6 y20 ff6 fs2 fc0 sc0 ls0 ws0">RNN<span class="_ _a"> </span>Enco<span class="_ _26"></span>der-Deco<span class="_ _1e"></span>der<span class="_ _a"> </span><span class="ff4">模型：</span></div><div class="t m0 x3 h6 y3c ff3 fs2 fc2 sc0 ls0 ws0">Enco<span class="_ _1e"></span>der<span class="_ _9"> </span><span class="ff1">将输入序列<span class="_ _a"> </span><span class="ffa">X<span class="_ _1c"> </span></span>编码为一个<span class="ff4">固定长度</span>的向量<span class="_ _a"> </span><span class="ff11">c</span>，</span>Deco<span class="_ _1e"></span>der<span class="_ _9"> </span><span class="ff1">将输入的<span class="ff4">固定<span class="_ _1e"></span>长度</span>向量<span class="_ _9"> </span><span class="ff11">c<span class="_ _a"> </span></span>解码</span></div><div class="t m0 x3 h6 y74c ff1 fs2 fc2 sc0 ls0 ws0">成输出<span class="_ _1e"></span>序列<span class="_ _12"> </span><span class="ffa">Y<span class="_ _30"> </span></span>。<span class="fc0">从概<span class="_ _1e"></span>率的角<span class="_ _1e"></span>度来<span class="_ _1e"></span>看，这种<span class="_ _1e"></span>结构<span class="_ _1e"></span>是一<span class="_ _1e"></span>种通用<span class="_ _1e"></span>方法，<span class="_ _1e"></span>可学习<span class="_ _1e"></span>一个<span class="_ _1e"></span>可变长<span class="_ _1e"></span>序列<span class="_ _1e"></span>在另<span class="_ _1e"></span>一</span></div><div class="t m0 x3 h6 y74e ff1 fs2 fc0 sc0 ls0 ws0">个可变长序列下的条件分布：<span class="_ _2d"></span><span class="ffa">p<span class="_ _2c"> </span><span class="ffb">(</span>y</span></div><div class="t m0 x145 ha y74f ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x3c hc y74e ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>y</div><div class="t m0 x59 hb y7c6 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x5a h1b y7c7 ff15 fs9 fc0 sc0 ls0 ws0">′</div><div class="t m0 x4a h4 y74e fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 xa0 ha y74f ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xa5 hc y74e ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x188 hb y7c8 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x164 h6 y74e ffb fs2 fc0 sc0 ls0 ws0">)<span class="ff1">，<span class="_ _2d"></span>值得注意的是代表了输入序列长度的<span class="_ _9"> </span><span class="ffa">T</span></span></div><div class="t m0 x3 h6 y60b ff1 fs2 fc0 sc0 ls0 ws0">和输出序列长度<span class="_ _9"> </span><span class="ffa">T</span></div><div class="t m0 xb6 ha y7c9 ff12 fs7 fc0 sc0 ls0 ws0">′</div><div class="t m0 x183 h6 y60b ff1 fs2 fc0 sc0 ls0 ws0">可以不一样。</div><div class="t m0 x3 h6 y7ca ff1 fs2 fc0 sc0 ls0 ws0">编码器是一个<span class="_ _9"> </span><span class="ff3">RNN</span>，<span class="_ _1e"></span>依次读取输入序列<span class="_ _a"> </span><span class="ff11">x<span class="_ _9"> </span></span>的每个字符。当它读取<span class="_ _1e"></span>每个字符时，<span class="ff3">RNN<span class="_ _9"> </span></span>的隐层<span class="_ _1e"></span>状</div><div class="t m0 x3 h6 y7cb ff1 fs2 fc0 sc0 ls0 ws0">态会根据公式（<span class="ff3">1</span>）改变。当读到序列的结尾（由<span class="_ _9"> </span><span class="ff3">end-of-sequence<span class="_ _9"> </span></span>符号标记）后，<span class="ff3">RNN<span class="_ _9"> </span></span>隐层状</div><div class="t m0 x3 h6 y7cc ff1 fs2 fc0 sc0 ls0 ws0">态<span class="_ _9"> </span><span class="ff11">c<span class="_ _9"> </span></span>包含了整个输入序列的信息。</div><div class="t m0 x3 h6 y7cd ff1 fs2 fc0 sc0 ls0 ws0">模型的解码器是另一个<span class="_ _25"> </span><span class="ff3">RNN</span>，<span class="_ _21"></span>通过给定隐藏状态<span class="_ _9"> </span><span class="ff11">h</span></div><div class="t m0 x13b ha y7ce ff12 fs7 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 x128 h6 y7cd ff1 fs2 fc0 sc0 ls0 ws0">和下一个输出字符<span class="_ _25"> </span><span class="ffa">y</span></div><div class="t m0 x55 hb y7cf ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x1a3 h6 y7cd ff1 fs2 fc0 sc0 ls0 ws0">，<span class="_ _21"></span>解码器被训练输出</div><div class="t m0 x3 h6 y7d0 ff1 fs2 fc0 sc0 ls0 ws0">序列。<span class="_ _2d"></span>然而，与上述的<span class="_ _25"> </span><span class="ff3">RNN<span class="_ _9"> </span></span>不同，<span class="_ _2d"></span><span class="ffa">y</span></div><div class="t m0 x158 hb y7d1 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x3e h6 y7d0 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _9"> </span><span class="ffa">h</span></div><div class="t m0 x1 hb y7d1 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x40 h6 y7d0 ff1 fs2 fc0 sc0 ls0 ws0">都受制于<span class="_ _9"> </span><span class="ffa">y</span></div><div class="t m0 x93 ha y7d1 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff16">−<span class="ffc">1</span></span></div><div class="t m0 xef h6 y7d0 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _9"> </span><span class="ff3">Encoder<span class="_ _9"> </span></span>隐藏状态<span class="_ _9"> </span><span class="ffa">c</span>。<span class="_ _e"></span>因此，<span class="_ _2d"></span>在<span class="_ _9"> </span><span class="ff3">t</span></div><div class="t m0 x3 h6 y7d2 ff1 fs2 fc0 sc0 ls0 ws0">时刻解码器的隐藏状态是由下述公式计算：</div><div class="t m0 x1f h4 y7d3 ff6 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xe1 ha y7d4 ff12 fs7 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>⟩</div><div class="t m0 xe2 h4 y7d3 ffb fs2 fc0 sc0 ls0 ws0">=<span class="_ _2f"> </span><span class="ffa">f</span></div><div class="t m0 x171 he y7d5 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 xf0 h4 y7d3 ff6 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 xa1 ha y7d4 ff12 fs7 fc0 sc0 ls0 ws0">⟨<span class="ffd">t</span>−<span class="ffc">1</span>⟩</div><div class="t m0 x4c hc y7d3 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x164 ha y7d6 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x13f h4 y7d3 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="ff6">c</span></div><div class="t m0 x106 he y7d5 ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y7d3 ff3 fs2 fc0 sc0 ls0 ws0">(9.3)</div><div class="t m0 x3 h6 y7d7 ff1 fs2 fc0 sc0 ls0 ws0">类似的，下一个<span class="_ _9"> </span><span class="ff3">sym<span class="_ _e"></span>b<span class="_ _1e"></span>ol<span class="_ _9"> </span><span class="ff1">的条件分布为：</span></span></div><div class="t m0 x70 h4 y7d8 ffa fs2 fc0 sc0 ls0 ws0">P<span class="_ _25"> </span><span class="ffb">(</span>y</div><div class="t m0 x1b hb y7d9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x11b h4 y7d8 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">y</span></div><div class="t m0 x157 ha y7d9 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x1f hc y7d8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x20 ha y7d9 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">2</span></span></div><div class="t m0 x21 hc y7d8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>y</div><div class="t m0 x41 ha y7d9 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x16a h4 y7d8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="ff6">c<span class="ffb">)<span class="_ _f"> </span>=<span class="_ _2f"> </span></span></span>g</div><div class="t m0 x5f he y7da ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x66 h4 y7d8 ff6 fs2 fc0 sc0 ls0 ws0">h</div><div class="t m0 x106 ha y7db ffc fs7 fc0 sc0 ls0 ws0">(<span class="ffd">t</span>)</div><div class="t m0 x28 hc y7d8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>y</div><div class="t m0 x150 ha y7d9 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x162 h4 y7d8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _2c"> </span><span class="ff6">c</span></div><div class="t m0 x14c he y7da ffe fs2 fc0 sc0 ls0 ws0"></div><div class="t m0 x33 h4 y7d8 ff3 fs2 fc0 sc0 ls0 ws0">(9.4)</div><div class="t m0 x3 h6 y7dc ffa fs2 fc0 sc0 ls0 ws0">f<span class="_ _1c"> </span><span class="ff1">与<span class="_ _9"> </span></span>g<span class="_ _a"> </span><span class="ff1">为激活函数，</span>g<span class="_ _a"> </span><span class="ff1">必须能生成有效的概率，比如利用<span class="_ _9"> </span><span class="ff3">softmax</span>。</span></div><div class="t m0 xfd h3a y7dd ff5 fs6 fc0 sc0 ls0 ws0">9.2<span class="_ _1f"> </span>Seq2Seq</div><div class="t m0 x3 h6 y7de ff1 fs2 fc0 sc0 ls0 ws0">正式<span class="_ _1e"></span>提<span class="_ _1e"></span>出<span class="_ _1c"> </span><span class="ff3">Sequence<span class="_ _12"> </span>to<span class="_ _1c"> </span>Sequence<span class="_ _12"> </span></span>的<span class="_ _1e"></span>文章<span class="_ _1e"></span>是<span class="_ _1e"></span>《<span class="ff3">Sequence<span class="_ _12"> </span>to<span class="_ _1c"> </span>Sequence<span class="_ _1c"> </span>Learning<span class="_ _12"> </span>with<span class="_ _1c"> </span>Neural<span class="_ _12"> </span>Net-</span></div><div class="t m0 x3 h6 y7df ff3 fs2 fc0 sc0 ls0 ws0">w<span class="_ _e"></span>orks<span class="ff1">》<span class="_ _24"></span>。<span class="ff6">Sequence<span class="_ _12"> </span>to<span class="_ _1c"> </span>Sequence<span class="_ _12"> </span><span class="ff4">的意思<span class="_ _1e"></span>是：输入一个<span class="_ _1e"></span>序列，输出<span class="_ _1e"></span>另一个序列。<span class="ff3">Seq2Seq<span class="_ _a"> </span></span></span></span>一词</span></div><div class="t m0 x3 h6 y7e0 ff1 fs2 fc0 sc0 ls0 ws0">带有<span class="_ _1e"></span>歧<span class="_ _1e"></span>义，在<span class="_ _1e"></span>原<span class="_ _1e"></span>论<span class="_ _1e"></span>文中，<span class="ff3">Seq2Seq<span class="_ _1c"> </span></span>指代<span class="_ _1e"></span>输<span class="_ _1e"></span>入和<span class="_ _1e"></span>输<span class="_ _1e"></span>出都<span class="_ _1e"></span>是<span class="_ _1e"></span>序<span class="_ _1e"></span>列的<span class="_ _1e"></span>机<span class="_ _1e"></span>器学<span class="_ _1e"></span>习<span class="_ _1e"></span>任务，<span class="_ _1e"></span>但<span class="_ _1e"></span>现<span class="_ _1e"></span>在很<span class="_ _1e"></span>多<span class="_ _1e"></span>人都</div><div class="t m0 x3 h6 y7e1 ff1 fs2 fc0 sc0 ls0 ws0">将<span class="_ _a"> </span><span class="ff3">Seq2Seq<span class="_ _12"> </span></span>视作<span class="_ _1e"></span>一种模<span class="_ _1e"></span>型，或<span class="_ _1e"></span>者特<span class="_ _1e"></span>指原<span class="_ _1e"></span>文论中<span class="_ _1e"></span>的模<span class="_ _1e"></span>型。在<span class="_ _1e"></span>我看来，<span class="ff3">Seq2Seq<span class="_ _12"> </span></span>更准<span class="_ _1e"></span>确的<span class="_ _1e"></span>含义<span class="_ _1e"></span>是序</div><div class="t m0 x3 h6 y7e2 ff1 fs2 fc0 sc0 ls0 ws0">列学习<span class="_ _1e"></span>任务，而<span class="_ _1e"></span>不是作<span class="_ _1e"></span>为模型<span class="_ _1e"></span>的概念。<span class="_ _1e"></span>即使<span class="_ _a"> </span><span class="ff3">Seq2Seq<span class="_ _a"> </span></span>指<span class="_ _1e"></span>代模型，<span class="_ _1e"></span>也应该<span class="_ _1e"></span>是一类<span class="_ _1e"></span>模型（输<span class="_ _1e"></span>入和输</div><div class="t m0 x3 h6 y7e3 ff1 fs2 fc0 sc0 ls0 ws0">出都<span class="_ _1e"></span>是序列<span class="_ _1e"></span>的模<span class="_ _1e"></span>型）<span class="_ _3c"></span>，而<span class="_ _1e"></span>不是一<span class="_ _1e"></span>种模<span class="_ _1e"></span>型。之<span class="_ _1e"></span>所以强<span class="_ _1e"></span>调<span class="_ _a"> </span><span class="ff3">Seq2Seq<span class="_ _12"> </span></span>的含<span class="_ _1e"></span>义，是<span class="_ _1e"></span>因为<span class="_ _12"> </span><span class="ff3">Seq2Seq<span class="_ _a"> </span></span>往往<span class="_ _1e"></span>和</div><div class="t m0 x3 h6 y7e4 ff3 fs2 fc0 sc0 ls0 ws0">Enco<span class="_ _1e"></span>der-Deco<span class="_ _1e"></span>der <span class="ff1">有关，<span class="_ _21"></span>如果模糊<span class="_ _25"> </span><span class="ff3">Seq2Seq<span class="_ _25"> </span></span>的含义，<span class="_ _21"></span><span class="ff3">Seq2Seq <span class="ff1">和<span class="_ _25"> </span></span>Enco<span class="_ _1e"></span>der-Deco<span class="_ _1e"></span>der<span class="_ _25"> </span><span class="ff1">两者同时出现</span></span></span></div><div class="t m0 x3 h6 y7e5 ff1 fs2 fc0 sc0 ls0 ws0">容易让人感到混乱。</div><div class="t m0 x3 h6 y7e6 ff1 fs2 fc0 sc0 ls0 ws0">这篇论文提出了如下图结构的模型（<span class="ff3">&lt;EOS&gt;<span class="_ _9"> </span></span>是句子结束的标识符）<span class="_ _23"></span>：</div><div class="t m0 x3 h6 y7e7 ff1 fs2 fc0 sc0 ls0 ws0">实际<span class="_ _1e"></span>上，<span class="_ _1e"></span>这就<span class="_ _1e"></span>是<span class="_ _1e"></span>一个<span class="_ _1c"> </span><span class="ff3">Encoder-Deco<span class="_ _1e"></span>der<span class="_ _1c"> </span></span>结构<span class="_ _1e"></span>的模<span class="_ _1e"></span>型，<span class="_ _1e"></span>但是<span class="_ _1e"></span>它<span class="_ _1e"></span>比<span class="_ _12"> </span><span class="ff3">RNN<span class="_ _12"> </span>Enco<span class="_ _1e"></span>der-Deco<span class="_ _1e"></span>der<span class="_ _1c"> </span></span>模型<span class="_ _1e"></span>简</div><div class="t m0 x3 h6 y7e8 ff1 fs2 fc0 sc0 ls0 ws0">单一<span class="_ _1e"></span>些。因<span class="_ _1e"></span>为<span class="_ _12"> </span><span class="ff3">Deco<span class="_ _1e"></span>der<span class="_ _1c"> </span></span>在<span class="_ _12"> </span><span class="ffa">t<span class="_ _12"> </span></span>时刻<span class="_ _1e"></span>是由<span class="_ _1c"> </span><span class="ffa">h</span></div><div class="t m0 x59 hb y7e9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x14a h6 y7e8 ff1 fs2 fc0 sc0 ls0 ws0">和<span class="_ _12"> </span><span class="ffa">y</span></div><div class="t m0 x90 ha y7e9 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff16">−<span class="ffc">1</span></span></div><div class="t m0 xa2 h6 y7e8 ff1 fs2 fc0 sc0 ls0 ws0">计算<span class="_ _1e"></span>出<span class="_ _12"> </span><span class="ffa">y</span></div><div class="t m0 xef hb y7e9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x15b h6 y7e8 ff1 fs2 fc0 sc0 ls0 ws0">，而<span class="_ _1e"></span>没有<span class="_ _1c"> </span><span class="ffa">c</span>。论<span class="_ _1e"></span>文中<span class="_ _1e"></span>的<span class="_ _12"> </span><span class="ff3">Enco<span class="_ _1e"></span>der<span class="_ _12"> </span></span>和</div><div class="t m0 x3 h6 y7ea ff3 fs2 fc0 sc0 ls0 ws0">Deco<span class="_ _1e"></span>der<span class="_ _9"> </span><span class="ff1">都是用<span class="_ _9"> </span></span>4<span class="_ _9"> </span><span class="ff1">层<span class="_ _9"> </span></span>LSTM<span class="ff1">。</span></div><div class="t m0 x3 h6 y7eb ff3 fs2 fc0 sc0 ls0 ws0">LSTM<span class="_ _30"> </span><span class="ff1">的目标是估计条件概率<span class="_ _30"> </span><span class="ffa">p<span class="_ _29"> </span><span class="ffb">(</span>y</span></span></div><div class="t m0 xca ha y7ec ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xb8 hc y7eb ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>y</div><div class="t m0 x142 hb y7ed ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x4a h1b y7ee ff15 fs9 fc0 sc0 ls0 ws0">′</div><div class="t m0 x1 h4 y7eb fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 x23 ha y7ec ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x24 hc y7eb ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x155 hb y7ef ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 xcd h6 y7eb ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="ff1">，<span class="_ _3b"></span>其中<span class="_ _30"> </span><span class="ffb">(<span class="ffa">x</span></span></span></div><div class="t m0 x148 ha y7ec ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x175 hc y7eb ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x53 hb y7ef ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 xc9 h6 y7eb ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _30"> </span><span class="ff1">是输入序列，<span class="_ _3b"></span><span class="ffa">y</span></span></div><div class="t m0 x1a4 ha y7ec ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x1a5 hc y7eb ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>y</div><div class="t m0 x75 hb y7ed ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x1a6 h1b y7ee ff15 fs9 fc0 sc0 ls0 ws0">′</div><div class="t m0 x3 h6 y7f0 ff1 fs2 fc0 sc0 ls0 ws0">是对应的输出序列。模型先获得<span class="_ _1e"></span>输入序列<span class="_ _9"> </span><span class="ffb">(<span class="ffa">x</span></span></div><div class="t m0 x171 ha y7f1 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xf0 hc y7f0 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x188 hb y7f2 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x4d h6 y7f0 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _9"> </span><span class="ff1">的固定维度的向量表<span class="_ _1e"></span>示<span class="_ _9"> </span><span class="ffa">v<span class="_ _1e"></span></span>，<span class="ffa">v<span class="_ _12"> </span></span>是<span class="_ _9"> </span><span class="ff3">Enco<span class="_ _1e"></span>der</span></span></div><div class="t m0 x3 h6 y7f3 ff1 fs2 fc0 sc0 ls0 ws0">的最后一个隐藏状态，<span class="_ _31"></span>同时也是<span class="_ _9"> </span><span class="ff3">Deco<span class="_ _1e"></span>der<span class="_ _9"> </span></span>的初始隐藏状态。<span class="_ _2d"></span>然后模型通过标准的<span class="_ _9"> </span><span class="ff3">LSTM<span class="_ _25"> </span></span>计算公</div><div class="t m0 x3 h6 y7f4 ff1 fs2 fc0 sc0 ls0 ws0">式计算出<span class="_ _9"> </span><span class="ffa">y</span></div><div class="t m0 x67 ha y7f5 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x117 hc y7f4 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>y</div><div class="t m0 x107 hb y7f6 ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x168 h1b y7f7 ff15 fs9 fc0 sc0 ls0 ws0">′</div><div class="t m0 x111 h6 y7f4 ff1 fs2 fc0 sc0 ls0 ws0">的条件概率：</div><div class="t m0 x169 h4 y7f8 ffa fs2 fc0 sc0 ls0 ws0">p<span class="_ _2c"> </span><span class="ffb">(</span>y</div><div class="t m0 x19 ha y7f9 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x44 hc y7f8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>y</div><div class="t m0 xed hb y7fa ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 xa h1b y7fb ff15 fs9 fc0 sc0 ls0 ws0">′</div><div class="t m0 xbc h4 y7f8 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">x</span></div><div class="t m0 xe1 ha y7f9 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 x105 hc y7f8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>x</div><div class="t m0 x40 hb y7fc ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x24 h4 y7f8 ffb fs2 fc0 sc0 ls0 ws0">)<span class="_ _2f"> </span>=</div><div class="t m0 x177 hb y7fd ffd fs7 fc0 sc0 ls0 ws0">T</div><div class="t m0 x188 h1b y7fe ff15 fs9 fc0 sc0 ls0 ws0">′</div><div class="t m0 x91 he y7ff ffe fs2 fc0 sc0 ls0 ws0">Y</div><div class="t m0 x91 ha y13c ffd fs7 fc0 sc0 ls0 ws0">t<span class="ffc">=1</span></div><div class="t m0 xd6 h4 y7f8 ffa fs2 fc0 sc0 ls0 ws0">p<span class="_ _2c"> </span><span class="ffb">(</span>y</div><div class="t m0 x66 hb y7f9 ffd fs7 fc0 sc0 ls0 ws0">t</div><div class="t m0 x112 h4 y7f8 fff fs2 fc0 sc0 ls0 ws0">|<span class="ffa">v<span class="_ _1e"></span>,<span class="_ _2c"> </span>y</span></div><div class="t m0 x71 ha y7f9 ffc fs7 fc0 sc0 ls0 ws0">1</div><div class="t m0 xd8 hc y7f8 ffa fs2 fc0 sc0 ls0 ws0">,<span class="_ _29"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>.<span class="_ _2c"> </span>,<span class="_ _2c"> </span>y</div><div class="t m0 x15e ha y7f9 ffd fs7 fc0 sc0 ls0 ws0">t<span class="ff12">−<span class="ffc">1</span></span></div><div class="t m0 x13c h4 y7f8 ffb fs2 fc0 sc0 ls0 ws0">)</div><div class="t m0 x3 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">58</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
<div id="pf40" class="pf w0 h0" data-page-no="40"><div class="pc pc40 w0 h0"><div class="t m0 x18a h7 y1f ff3 fs5 fc0 sc0 ls0 ws0">9.3<span class="_ _d"> </span>A<span class="_ _22"></span>TTENTION<span class="_ _9"> </span><span class="ff8">机制</span></div><div class="t m0 x3a h9 yaf ff5 fs6 fc0 sc0 ls0 ws0">9.3<span class="_ _1f"> </span>A<span class="_ _2d"></span>tten<span class="_ _2d"></span>tion<span class="_ _7"> </span><span class="ff9">机制</span></div><div class="t m0 x3 h6 yb0 ff3 fs2 fc0 sc0 ls0 ws0">A<span class="_ _e"></span>tten<span class="_ _e"></span>tion<span class="_ _25"> </span><span class="ff1">机制由视觉图像领域提出来，<span class="_ _21"></span>在<span class="_ _25"> </span><span class="ff3">2014<span class="_ _25"> </span></span>年，<span class="_ _21"></span><span class="ff3">Bahdanau<span class="_ _25"> </span><span class="ff1">在<span class="_ _22"></span>《<span class="ff3">Neural<span class="_ _25"> </span>Machine T<span class="_ _22"></span>ranslation</span></span></span></span></div><div class="t m0 x3 h6 yb1 ff3 fs2 fc0 sc0 ls0 ws0">b<span class="_ _e"></span>y<span class="_ _25"> </span>Jointly Learning<span class="_ _9"> </span>to<span class="_ _25"> </span>Align<span class="_ _9"> </span>and<span class="_ _25"> </span>T<span class="_ _31"></span>ranslate<span class="ff1">》<span class="_ _31"></span>上将其应用到机器翻译任务上，<span class="_ _22"></span>这是第一个应用到</span></div><div class="t m0 x3 h6 yb2 ff3 fs2 fc0 sc0 ls0 ws0">NLP <span class="ff1">领域的论文。<span class="_ _3d"></span>之后，<span class="_ _33"></span><span class="ff3">15<span class="ff1">、<span class="_ _33"></span><span class="ff3">16<span class="ff1">、<span class="_ _33"></span><span class="ff3">17 <span class="ff1">乃至今年，<span class="_ _33"></span>都有各式各样的<span class="_ _f"> </span><span class="ff3">attention<span class="_ _f"> </span></span>机制结合深度学习网络</span></span></span></span></span></span></span></div><div class="t m0 x3 h6 yb3 ff1 fs2 fc0 sc0 ls0 ws0">模型被用于处理各种</div><div class="t m0 x129 h4 yb4 ff3 fs2 fc0 sc0 ls0 ws0">NLP</div><div class="t m0 x185 h6 yb3 ff1 fs2 fc0 sc0 ls0 ws0">的任务。<span class="_ _3d"></span>在</div><div class="t m0 x47 h4 yb4 ff3 fs2 fc0 sc0 ls0 ws0">2017</div><div class="t m0 x1 h6 yb3 ff1 fs2 fc0 sc0 ls0 ws0">年，</div><div class="t m0 x176 h4 yb4 ff3 fs2 fc0 sc0 ls0 ws0">go<span class="_ _1e"></span>ogle</div><div class="t m0 x128 h6 yb3 ff1 fs2 fc0 sc0 ls0 ws0">机器翻译团队发表的<span class="_ _2a"></span>《</div><div class="t m0 x147 h4 yb4 ff3 fs2 fc0 sc0 ls0 ws0">A<span class="_ _e"></span>tten<span class="_ _e"></span>tion is all<span class="_ _f"> </span>y<span class="_ _e"></span>ou</div><div class="t m0 x3 h6 yb5 ff3 fs2 fc0 sc0 ls0 ws0">need<span class="ff1">》中大<span class="_ _1e"></span>量使用<span class="_ _1e"></span>了自注<span class="_ _1e"></span>意力<span class="_ _1e"></span>机制（</span>self-attention<span class="ff1">）来学习<span class="_ _1e"></span>文本表<span class="_ _1e"></span>示，脱离<span class="_ _1e"></span>传统的<span class="_ _12"> </span></span>RNN/CNN<span class="ff1">，</span></div><div class="t m0 x3 h6 yb6 ff1 fs2 fc0 sc0 ls0 ws0">同时也使用<span class="_ _1e"></span>了新颖的<span class="_ _a"> </span><span class="ff3">multi-head<span class="_ _9"> </span></span>机制。自注意<span class="_ _1e"></span>力机制也成<span class="_ _1e"></span>为了大家近<span class="_ _1e"></span>期研究的热<span class="_ _1e"></span>点，可以应用</div><div class="t m0 x3 h6 yb7 ff1 fs2 fc0 sc0 ls0 ws0">到各种<span class="_ _9"> </span><span class="ff3">NLP<span class="_ _9"> </span></span>任务上。</div><div class="t m0 x3 h6 y800 ff3 fs2 fc0 sc0 ls0 ws0">A<span class="_ _e"></span>tten<span class="_ _e"></span>tion<span class="_ _9"> </span><span class="ff1">机制经过长时间的发展，虽然不同论<span class="_ _1e"></span>文里的实现方法可能各不一样，但是基本上都遵</span></div><div class="t m0 x3 h6 y801 ff1 fs2 fc0 sc0 ls0 ws0">循着同一个范式。其中包含三个成分<span class="ff3">:</span></div><div class="t m0 x3 h6 y802 ff3 fs2 fc0 sc0 ls0 ws0">Key(<span class="ff1">键</span>)<span class="_ _9"> </span><span class="ff1">与值相对应同时又用来与查询计算相似度作为<span class="_ _9"> </span></span>A<span class="_ _e"></span>tten<span class="_ _e"></span>tion<span class="_ _9"> </span><span class="ff1">选取的依据</span></div><div class="t m0 x3 h6 y803 ff3 fs2 fc0 sc0 ls0 ws0">Query(<span class="ff1">查询</span>)<span class="_ _9"> </span><span class="ff1">一次执行<span class="_ _9"> </span></span>A<span class="_ _e"></span>tten<span class="_ _e"></span>tion<span class="_ _9"> </span><span class="ff1">时的查询</span></div><div class="t m0 x3 h6 y804 ff3 fs2 fc0 sc0 ls0 ws0">V<span class="_ _31"></span>alue(<span class="ff1">值</span>)<span class="_ _9"> </span><span class="ff1">被注意并选取的数据</span></div><div class="t m0 x3 h6 y805 ff1 fs2 fc0 sc0 ls0 ws0">对应的公式为：</div><div class="t m0 x6d h4 y806 ff3 fs2 fc0 sc0 ls0 ws0">A<span class="_ _e"></span>tten<span class="_ _e"></span>tion<span class="_ _9"> </span><span class="ffb">(<span class="ffa">K,<span class="_ _2c"> </span>Q,<span class="_ _2c"> </span>V<span class="_ _30"> </span></span>)<span class="_ _2f"> </span>=<span class="_ _2f"> </span></span>softmax<span class="ffb">(</span>Similarity<span class="ffb">(<span class="ffa">K,<span class="_ _2c"> </span>Q</span>))<span class="ffa">V<span class="_ _69"> </span></span></span>(9.5)</div><div class="t m0 x3 h6 y807 ff1 fs2 fc0 sc0 ls0 ws0">可以看出<span class="_ _9"> </span><span class="ff3">atten<span class="_ _e"></span>tion<span class="_ _9"> </span><span class="ff1">的计算分为三步：</span></span></div><div class="t m0 x3 h6 y808 ff1 fs2 fc0 sc0 ls0 ws0">计算<span class="_ _9"> </span><span class="ff3">K</span>、<span class="ff3">Q<span class="_ _9"> </span></span>的相似矩阵</div><div class="t m0 x3 h6 y809 ff1 fs2 fc0 sc0 ls0 ws0">对相似矩阵作归一化处理</div><div class="t m0 x3 h6 y80a ff1 fs2 fc0 sc0 ls0 ws0">其中，相似矩阵的计算有很多种方式：</div><div class="t m0 xb5 h4 y3 ff3 fs2 fc0 sc0 ls0 ws0">59</div></div><div class="pi" data-data='{"ctm":[1.500000,0.000000,0.000000,1.500000,0.000000,0.000000]}'></div></div>
</div>
<div class="loading-indicator">
<img alt="" src="pdf2htmlEX-64x64.png"/>
</div>
</body>
</html>
