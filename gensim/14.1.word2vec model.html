
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-6.1.4">
    
    
      
        <title>14.1.word2vec model - Python笔记</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.358818c7.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.f0267088.min.css">
        
      
    
    
    
      
        
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
      
    
    
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
      
  
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#word2vec" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

  

<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid" aria-label="Header">
    <a href="../index.html" title="Python笔记" class="md-header-nav__button md-logo" aria-label="Python笔记">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header-nav__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header-nav__title" data-md-component="header-title">
      
        <div class="md-header-nav__ellipsis">
          <span class="md-header-nav__topic md-ellipsis">
            Python笔记
          </span>
          <span class="md-header-nav__topic md-ellipsis">
            
              14.1.word2vec model
            
          </span>
        </div>
      
    </div>
    
      <label class="md-header-nav__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" data-md-component="search-reset" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header-nav__source">
        
<a href="https://github.com/siwing/siwing.github.io/" title="前往 GitHub 仓库" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  

<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../index.html" title="Python笔记" class="md-nav__button md-logo" aria-label="Python笔记">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 003-3 3 3 0 00-3-3 3 3 0 00-3 3 3 3 0 003 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    Python笔记
  </label>
  
    <div class="md-nav__source">
      
<a href="https://github.com/siwing/siwing.github.io/" title="前往 GitHub 仓库" class="md-source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M439.55 236.05L244 40.45a28.87 28.87 0 00-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 01-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 000 40.81l195.61 195.6a28.86 28.86 0 0040.8 0l194.69-194.69a28.86 28.86 0 000-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../index.html" class="md-nav__link">
      Home
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" type="checkbox" id="nav-2">
    
    <label class="md-nav__link" for="nav-2">
      计算机基础
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="计算机基础" data-md-level="1">
      <label class="md-nav__title" for="nav-2">
        <span class="md-nav__icon md-icon"></span>
        计算机基础
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1.1.CPU.html" class="md-nav__link">
      1.1.CPU
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1.2.Memory.html" class="md-nav__link">
      1.2.Memory
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1.3.%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html" class="md-nav__link">
      1.3.基本概念
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1.4.%E7%BC%96%E8%AF%91%E5%9E%8B%E8%AF%AD%E8%A8%80%E5%92%8C%E8%A7%A3%E9%87%8A%E5%9E%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E5%AF%B9%E6%AF%94.html" class="md-nav__link">
      1.4.编译型语言 vs 解释型语言
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1.5.%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81.html" class="md-nav__link">
      1.5.字符编码
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" type="checkbox" id="nav-3">
    
    <label class="md-nav__link" for="nav-3">
      Python基础
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Python基础" data-md-level="1">
      <label class="md-nav__title" for="nav-3">
        <span class="md-nav__icon md-icon"></span>
        Python基础
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.1.Python%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95.html" class="md-nav__link">
      2.1.Python基本语法
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.2.%E8%AF%AD%E5%8F%A5.html" class="md-nav__link">
      2.2.语句
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.3.%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B.html" class="md-nav__link">
      2.3.数据类型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.4.Number.html" class="md-nav__link">
      2.4.Number
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.5.String.html" class="md-nav__link">
      2.5.String
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.6.List.html" class="md-nav__link">
      2.6.List
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.7.Tuple.html" class="md-nav__link">
      2.7.Tuple
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.8.Dict.html" class="md-nav__link">
      2.8.Dict
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.9.%E7%AE%80%E6%B4%81%E7%9A%84Python.html" class="md-nav__link">
      2.9.简洁的Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.10.%E8%B5%8B%E5%80%BC%E3%80%81immutable%E3%80%81%E6%B7%B1%E6%8B%B7%E8%B4%9D.html" class="md-nav__link">
      2.10.赋值、immutable、深拷贝
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.11.%E5%87%BD%E6%95%B0.html" class="md-nav__link">
      2.11.函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.12.%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0.html" class="md-nav__link">
      2.12.内置函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/2.13.%E7%AE%80%E6%B4%81%E7%9A%84Python.html" class="md-nav__link">
      2.13.简洁的Python
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/3.1.%E5%BC%82%E5%B8%B8.html" class="md-nav__link">
      3.1.异常
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/3.2.%E5%91%BD%E5%90%8D%E7%A9%BA%E9%97%B4%E5%92%8C%E4%BD%9C%E7%94%A8%E5%9F%9F.html" class="md-nav__link">
      3.2.命名空间和作用域
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/3.3.%E9%97%AD%E5%8C%85.html" class="md-nav__link">
      3.3.闭包
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/3.4.%E8%A3%85%E9%A5%B0%E5%99%A8.html" class="md-nav__link">
      3.4.装饰器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/4.1.%E7%B1%BB.html" class="md-nav__link">
      4.1.类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/4.2.%E5%A4%9A%E9%87%8D%E7%BB%A7%E6%89%BF%E5%92%8CMRO.html" class="md-nav__link">
      4.2.多重继承和MRO
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/4.3.%E6%A8%A1%E5%9D%97.html" class="md-nav__link">
      4.3.模块
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Python%E5%9F%BA%E7%A1%80/4.4.%E9%AD%94%E6%9C%AF%E6%96%B9%E6%B3%95.html" class="md-nav__link">
      4.4.魔术方法
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" type="checkbox" id="nav-4">
    
    <label class="md-nav__link" for="nav-4">
      开发环境管理
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="开发环境管理" data-md-level="1">
      <label class="md-nav__title" for="nav-4">
        <span class="md-nav__icon md-icon"></span>
        开发环境管理
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/5.1.conda%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
      5.1.conda笔记
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/5.2.pip%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
      5.2.pip笔记
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/5.3.pip%E5%AF%B9%E6%AF%94conda.html" class="md-nav__link">
      5.3.pip对比conda
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/5.4.anaconda.html" class="md-nav__link">
      5.4.anaconda
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86/5.5.jupyter%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0.html" class="md-nav__link">
      5.5.jupyter使用笔记
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      标准库
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="标准库" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        <span class="md-nav__icon md-icon"></span>
        标准库
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.1.string.html" class="md-nav__link">
      6.1.string
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.2.textwrap.html" class="md-nav__link">
      6.2.textwrap
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.3.time.html" class="md-nav__link">
      6.3.time
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.4.datetime.html" class="md-nav__link">
      6.4.datetime
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.5.calendar.html" class="md-nav__link">
      6.5.calendar
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.7.urllib.html" class="md-nav__link">
      6.7.urllib
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.8.requests.html" class="md-nav__link">
      6.8.requests
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.9.re.html" class="md-nav__link">
      6.9.re
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.10.os_path.html" class="md-nav__link">
      6.10.os.path
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.11.traceback.html" class="md-nav__link">
      6.11.traceback
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.12.enum.html" class="md-nav__link">
      6.12.enum
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.13.difflib%E2%80%94%E2%80%94%E5%AD%97%E7%AC%A6%E6%AF%94%E8%BE%83.html" class="md-nav__link">
      6.13.difflib——字符比较
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.14.logging.html" class="md-nav__link">
      6.14.logging
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.15.Compression%26Archiving.html" class="md-nav__link">
      6.15.Compression&Archiving
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.16.shutil.html" class="md-nav__link">
      6.16.shutil
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%A0%87%E5%87%86%E5%BA%93/6.17.test.html" class="md-nav__link">
      6.17.test
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      设计模式
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="设计模式" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        <span class="md-nav__icon md-icon"></span>
        设计模式
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/7.1.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E5%9F%BA%E7%A1%80.html" class="md-nav__link">
      7.1.面向对象程序设计基础
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/7.2.%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E5%8E%9F%E5%88%99.html" class="md-nav__link">
      7.2.面向对象软件设计原则
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/7.3.%E5%88%9B%E5%BB%BA%E5%9E%8B%E6%A8%A1%E5%BC%8F.html" class="md-nav__link">
      7.3.创建型模式
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../设计模式/7.4.结构型模式.md" class="md-nav__link">
      7.4.结构型模式
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      numpy笔记
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="numpy笔记" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        <span class="md-nav__icon md-icon"></span>
        numpy笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.1.%E5%88%9B%E5%BB%BA%E6%95%B0%E7%BB%84.html" class="md-nav__link">
      8.1.创建数组
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.2.%E7%B4%A2%E5%BC%95.html" class="md-nav__link">
      8.2.索引
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.3.%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80.html" class="md-nav__link">
      8.3.内存布局
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.4.%E5%B9%BF%E6%92%AD.html" class="md-nav__link">
      8.4.广播
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.5.%E5%B8%B8%E9%87%8F.html" class="md-nav__link">
      8.5.常量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.6.%E6%89%93%E5%8D%B0%E6%95%B0%E7%BB%84.html" class="md-nav__link">
      8.6.打印数组
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.7.%E6%B7%BB%E5%8A%A0%E5%92%8C%E5%88%A0%E9%99%A4.html" class="md-nav__link">
      8.7.添加和删除
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.8.%E5%BD%A2%E7%8A%B6%E6%93%8D%E7%BA%B5.html" class="md-nav__link">
      8.8.形状操纵
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.9.ufunc%E5%87%BD%E6%95%B0.html" class="md-nav__link">
      8.9.ufunc函数
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.10.%E5%87%BD%E6%95%B0%E5%BA%93.html" class="md-nav__link">
      8.10.函数库
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.11.%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD.html" class="md-nav__link">
      8.11.保存和加载
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.12.%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E7%BB%84.html" class="md-nav__link">
      8.12.结构化数组
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../numpy%E7%AC%94%E8%AE%B0/8.13.%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86.html" class="md-nav__link">
      8.13.数据处理
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8">
    
    <label class="md-nav__link" for="nav-8">
      pandas笔记
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="pandas笔记" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        <span class="md-nav__icon md-icon"></span>
        pandas笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.1.Series.html" class="md-nav__link">
      9.1.Series
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.2.DataFrame.html" class="md-nav__link">
      9.2.DataFrame
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.3.%E7%B4%A2%E5%BC%95.html" class="md-nav__link">
      9.3.索引
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.4.%E7%B4%A2%E5%BC%95%E5%AF%B9%E8%B1%A1.html" class="md-nav__link">
      9.4.索引对象
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.5.%E7%B4%A2%E5%BC%95%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C.html" class="md-nav__link">
      9.5.索引的基本操作
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.6.%E6%8B%BC%E6%8E%A5.html" class="md-nav__link">
      9.6.拼接
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.7.%E5%8F%98%E6%8D%A2%E7%B4%A2%E5%BC%95.html" class="md-nav__link">
      9.7.变换索引
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.8.%E5%88%86%E7%BB%84%E4%B8%8E%E8%81%9A%E5%90%88.html" class="md-nav__link">
      9.8.分组与聚合
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.9.%E7%BB%98%E5%9B%BE.html" class="md-nav__link">
      9.9.绘图
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../pandas%E7%AC%94%E8%AE%B0/9.11.%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86.html" class="md-nav__link">
      9.11.数据处理
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-9" type="checkbox" id="nav-9">
    
    <label class="md-nav__link" for="nav-9">
      Matplotlib
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Matplotlib" data-md-level="1">
      <label class="md-nav__title" for="nav-9">
        <span class="md-nav__icon md-icon"></span>
        Matplotlib
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Matplotlib/10.1.%E6%9E%B6%E6%9E%84.html" class="md-nav__link">
      10.1.架构
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-10" type="checkbox" id="nav-10">
    
    <label class="md-nav__link" for="nav-10">
      scikit-learn
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="scikit-learn" data-md-level="1">
      <label class="md-nav__title" for="nav-10">
        <span class="md-nav__icon md-icon"></span>
        scikit-learn
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.1.%E6%95%B0%E6%8D%AE%E9%9B%86.html" class="md-nav__link">
      11.1.数据集
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.2.%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87.html" class="md-nav__link">
      11.2.评价指标-分类
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.5.%E6%8B%86%E5%88%86%E6%95%B0%E6%8D%AE.html" class="md-nav__link">
      11.5.拆分数据
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.6.%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81.html" class="md-nav__link">
      11.6.交叉验证
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.7.%E8%B6%85%E5%8F%82%E6%95%B0%E5%AF%BB%E4%BC%98.html" class="md-nav__link">
      11.7.超参数寻优
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.8.%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%9E%8B.html" class="md-nav__link">
      11.8.保存模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.9.%E7%89%B9%E5%BE%81%E5%A4%84%E7%90%86.html" class="md-nav__link">
      11.9.特征处理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.10.%E8%BD%AC%E6%8D%A2%E9%A2%84%E6%B5%8B%E7%9B%AE%E6%A0%87y.html" class="md-nav__link">
      11.10.转换预测目标y
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.11.%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9.html" class="md-nav__link">
      11.11.特征选择
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.12.%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96.html" class="md-nav__link">
      11.12.特征提取
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.13.%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86.html" class="md-nav__link">
      11.13.缺失值处理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.14.%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92.html" class="md-nav__link">
      11.14.线性回归
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../scikit-learn/11.15.%E5%86%B3%E7%AD%96%E6%A0%91.html" class="md-nav__link">
      11.15.决策树
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-11" type="checkbox" id="nav-11">
    
    <label class="md-nav__link" for="nav-11">
      tensorflow笔记
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="tensorflow笔记" data-md-level="1">
      <label class="md-nav__title" for="nav-11">
        <span class="md-nav__icon md-icon"></span>
        tensorflow笔记
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../tensorflow%E7%AC%94%E8%AE%B0/12.1.keras%E6%95%B0%E6%8D%AE%E9%9B%86.html" class="md-nav__link">
      12.1.keras数据集
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tensorflow%E7%AC%94%E8%AE%B0/12.2.%E5%88%9B%E5%BB%BA%E5%BC%A0%E9%87%8F.html" class="md-nav__link">
      12.2.创建张量
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tensorflow%E7%AC%94%E8%AE%B0/12.3.%E5%BC%A0%E9%87%8F%E8%BF%9B%E9%98%B6%E6%93%8D%E4%BD%9C.html" class="md-nav__link">
      12.3.张量进阶操作
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tensorflow%E7%AC%94%E8%AE%B0/12.4.%E6%B1%82%E5%AF%BC.html" class="md-nav__link">
      12.4.求导
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tensorflow%E7%AC%94%E8%AE%B0/12.5.%E5%8F%AF%E7%94%A8%E6%80%A7%E6%B5%8B%E8%AF%95.html" class="md-nav__link">
      12.5.可用性测试
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tensorflow%E7%AC%94%E8%AE%B0/12.6.Perceptron.html" class="md-nav__link">
      12.6.Perceptron
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tensorflow%E7%AC%94%E8%AE%B0/12.7.keras%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B.html" class="md-nav__link">
      12.7.keras快速开始
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-12" type="checkbox" id="nav-12">
    
    <label class="md-nav__link" for="nav-12">
      爬虫
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="爬虫" data-md-level="1">
      <label class="md-nav__title" for="nav-12">
        <span class="md-nav__icon md-icon"></span>
        爬虫
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../%E7%88%AC%E8%99%AB/13.1.lxml.html" class="md-nav__link">
      13.1.lxml
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E7%88%AC%E8%99%AB/13.3.pyquery.html" class="md-nav__link">
      13.3.pyquery
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-13" type="checkbox" id="nav-13" checked>
    
    <label class="md-nav__link" for="nav-13">
      gensim
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="gensim" data-md-level="1">
      <label class="md-nav__title" for="nav-13">
        <span class="md-nav__icon md-icon"></span>
        gensim
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        14.1.word2vec model
        <span class="md-nav__icon md-icon"></span>
      </label>
    
    <a href="14.1.word2vec%20model.html" class="md-nav__link md-nav__link--active">
      14.1.word2vec model
    </a>
    
      
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bag-of-words" class="md-nav__link">
    回顾Bag-of-words模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#word2vec_1" class="md-nav__link">
    Word2Vec模型简介
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#word2vec_2" class="md-nav__link">
    Word2Vec 演示
  </a>
  
    <nav class="md-nav" aria-label="Word2Vec 演示">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    获取词库
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    获取词向量
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    相似性任务
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    获取余弦距离
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    获取余弦相似度
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    获取距离排名
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    训练自己的模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    存储和加载模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gzippedbz2" class="md-nav__link">
    也可以输入gzipped/bz2文件，无需解压缩
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    训练参数
  </a>
  
    <nav class="md-nav" aria-label="训练参数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#min_count" class="md-nav__link">
    min_count
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#workers" class="md-nav__link">
    workers
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#memory" class="md-nav__link">
    Memory
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluating" class="md-nav__link">
    Evaluating
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    在线训练/增量训练
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loss-computation" class="md-nav__link">
    Training Loss Computation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#benchmarks" class="md-nav__link">
    Benchmarks
  </a>
  
</li>
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="14.2.word2vec%E5%8F%82%E6%95%B0.html" class="md-nav__link">
      14.2.word2vec参数
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-14" type="checkbox" id="nav-14">
    
    <label class="md-nav__link" for="nav-14">
      数据库
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="数据库" data-md-level="1">
      <label class="md-nav__title" for="nav-14">
        <span class="md-nav__icon md-icon"></span>
        数据库
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%95%B0%E6%8D%AE%E5%BA%93/15.1.DBAPI.html" class="md-nav__link">
      15.1.DBAPI
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%95%B0%E6%8D%AE%E5%BA%93/15.2.PostgreSQL.html" class="md-nav__link">
      15.2.PostgreSQL
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%95%B0%E6%8D%AE%E5%BA%93/15.3.MSSQL.html" class="md-nav__link">
      15.3.MSSQL
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%95%B0%E6%8D%AE%E5%BA%93/15.4.SQLAlchemy.html" class="md-nav__link">
      15.4.SQLAlchemy
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-15" type="checkbox" id="nav-15">
    
    <label class="md-nav__link" for="nav-15">
      文件操作
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="文件操作" data-md-level="1">
      <label class="md-nav__title" for="nav-15">
        <span class="md-nav__icon md-icon"></span>
        文件操作
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/16.2.PDF.html" class="md-nav__link">
      16.2.PDF
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/16.3.docx.html" class="md-nav__link">
      16.3.docx
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/16.4.OCR.html" class="md-nav__link">
      16.4.OCR
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-nav__toggle md-toggle" data-md-toggle="nav-16" type="checkbox" id="nav-16">
    
    <label class="md-nav__link" for="nav-16">
      Docker
      <span class="md-nav__icon md-icon"></span>
    </label>
    <nav class="md-nav" aria-label="Docker" data-md-level="1">
      <label class="md-nav__title" for="nav-16">
        <span class="md-nav__icon md-icon"></span>
        Docker
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../Docker/17.2.Dockerfile.html" class="md-nav__link">
      17.2.Dockerfile
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../Docker/17.3.Image.html" class="md-nav__link">
      17.3.Image
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#bag-of-words" class="md-nav__link">
    回顾Bag-of-words模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#word2vec_1" class="md-nav__link">
    Word2Vec模型简介
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#word2vec_2" class="md-nav__link">
    Word2Vec 演示
  </a>
  
    <nav class="md-nav" aria-label="Word2Vec 演示">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    获取词库
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    获取词向量
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    相似性任务
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    获取余弦距离
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    获取余弦相似度
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    获取距离排名
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    训练自己的模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    存储和加载模型
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gzippedbz2" class="md-nav__link">
    也可以输入gzipped/bz2文件，无需解压缩
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    训练参数
  </a>
  
    <nav class="md-nav" aria-label="训练参数">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#min_count" class="md-nav__link">
    min_count
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#size" class="md-nav__link">
    size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#workers" class="md-nav__link">
    workers
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#memory" class="md-nav__link">
    Memory
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluating" class="md-nav__link">
    Evaluating
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    在线训练/增量训练
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loss-computation" class="md-nav__link">
    Training Loss Computation
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#benchmarks" class="md-nav__link">
    Benchmarks
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/siwing/siwing.github.io/edit/master/docs/gensim/14.1.word2vec model.md" title="编辑此页" class="md-content__button md-icon">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"/></svg>
                  </a>
                
                
                <div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pprint</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div>

<h1 id="word2vec">Word2Vec 模型</h1>
<p>本文介绍Gensim的Word2Vec模型，并在Lee Corpus上演示其用法。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">basicConfig</span><span class="p">(</span><span class="nb">format</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%(asctime)s</span><span class="s1"> : </span><span class="si">%(levelname)s</span><span class="s1"> : </span><span class="si">%(message)s</span><span class="s1">&#39;</span><span class="p">,</span> 
                    <span class="n">level</span><span class="o">=</span><span class="n">logging</span><span class="o">.</span><span class="n">INFO</span><span class="p">)</span>
</code></pre></div>

<p>如果你之前错过了令人振奋的算法，那么word2vec现在是深度学习算法的新星之一，因此受到广泛的推荐，尽管它本身的网络层很浅。word2vec可以从大量未注释的纯文本中自动学习单词之间的关系。</p>
<p>word2vec的输出是具有显著线性关系的向量（每个单词就是一个向量），因此我们可以执行以下操作：</p>
<ul>
<li>vec("king") - vec("man") + vec("woman") =~ vec("queen")</li>
<li>vec("Montreal Canadiens") – vec("Montreal") + vec("Toronto") =~ vec("Toronto Maple Leafs")</li>
</ul>
<p>Word2vec在<a href="https://github.com/RaRe-Technologies/movie-plots-by-genre">自动文本标记</a>、推荐系统和机器翻译中非常有用。</p>
<p>本教程将:</p>
<ol>
<li>引入“ Word2Vec”作为对传统 bag-of-words 模型的改进</li>
<li>使用预先训练的模型展示“ Word2Vec”的功能</li>
<li>演示根据您自己的数据训练新模型</li>
<li>演示加载和保存模型</li>
<li>介绍几个训练参数并演示其效果</li>
<li>讨论内存需求</li>
<li>通过应用降维来可视化Word2Vec嵌入</li>
</ol>
<h2 id="bag-of-words">回顾Bag-of-words模型</h2>
<p><strong>注意：</strong>如果您已经熟悉模型，可以跳过模型回顾。 </p>
<p>您可能从 core_concepts_vector 部分熟悉了词袋模型<a href="https://en.wikipedia.org/wiki/Bag-of-words_model">https://en.wikipedia.org/wiki/Bag-of-words_model</a> 。该模型将每个文档转换为固定长度的整数矢量。 例如，给定句子：</p>
<ul>
<li><code>John likes to watch movies. Mary likes movies too.</code></li>
<li><code>John also likes to watch football games. Mary hates football.</code></li>
</ul>
<p>模型输出向量：</p>
<ul>
<li><code>[1, 2, 1, 1, 2, 1, 1, 0, 0, 0, 0]</code></li>
<li><code>[1, 1, 1, 1, 0, 1, 0, 1, 2, 1, 1]</code></li>
</ul>
<p>每个向量有10个元素，其中每个元素计算文档中特定单词出现的次数。元素的顺序是任意的。</p>
<p>在上面的示例中，元素的顺序对应于以下单词：</p>
<p><code>["John", "likes", "to", "watch", "movies", "Mary", "too", "also", "football", "games", "hates"]</code>.</p>
<p>词袋模型出奇地有效，但有几个缺点。</p>
<p>首先，他们会丢失所有有关单词顺序的信息："John likes Mary"和"Mary likes John"对应于相同的向量。有一个解决方案：n-grams模型考虑长度为n的单词短语，将文档表示为固定长度的向量，以捕获单词顺序，但遭受数据稀疏和高维度的困扰。</p>
<p>其次，该模型不会尝试学习单词的含义，因此，向量之间的距离并不总是反映出含义上的差异。  Word2Vec模型解决了第二个问题。</p>
<h2 id="word2vec_1">Word2Vec模型简介</h2>
<p>Word2Vec是一种较新的模型，它使用浅层神经网络将单词嵌入到低维向量空间中。 结果是一组词向量，在向量空间中靠在一起的词向量根据上下文具有相似的含义，而彼此远离的词向量具有不同的含义。 例如，“ strong”和“ powerful”将彼此靠近，而“ strong”和“ Paris”则相对较远。</p>
<p>该模型有两个版本，<code>~gensim.models.word2vec.Word2Vec</code>类实现了两个版本：</p>
<ol>
<li>Skip-grams (SG)</li>
<li>Continuous-bag-of-words (CBOW)</li>
</ol>
<blockquote>
<p><strong>注意：</strong>不要让下面的实现细节吓到您。它们是高级材料，如果太多，则继续进行下一部分。  </p>
</blockquote>
<p>例如，“Word2Vec Skip-gram” 模型将通过在文本数据之间进行窗口移动，生成的成对的(word1，word2)，并根据输入的多个单词对(word,word)训练一个1层隐藏层的神经网络， 为我们提供了输入附近单词的预测概率分布。 单词的one-hot 编码通过投影层（projection layer）进入隐藏层；这些投影的权重被解释成word embeddings。因此，如果隐藏层具有300个神经元，则此网络将为我们提供300维的word embeddings。</p>
<p>Continuous-bag-of-words Word2vec与skip-gram model非常相似。 它也是一个含有1层隐藏层的神经网络。 合成训练任务现在使用多个输入上下文单词的平均值来预测目标单词，而不是像skip-gram model中使用单个单词的值。 同样，将one-hot编码转换为和隐藏层相同维度的平均值向量的投影权重，也被解释为word embeddings。</p>
<h2 id="word2vec_2">Word2Vec 演示</h2>
<p>让我们下载一个预先训练好的模型并进行试用，看看Word2Vec可以做什么。我们将获取的Word2Vec模型使用Google新闻数据训练，该模型涵盖大约300万个单词和短语。这样的模型可能需要花费数小时来训练，但是由于已经可用，因此使用Gensim进行下载和加载需要几分钟。</p>
<blockquote>
<p><strong>注意</strong>：该模型大约为2GB，因此你需要一个不错的网络连接才能继续。 否则，请跳至下面的“训练自己的模型”部分。</p>
</blockquote>
<p>您也可以查看“<a href="http://radimrehurek.com/2014/02/word2vec-tutorial/#app">在线word2vec演示</a>”，在那里您可以自己尝试使用向量代数。该演示在整个Google新闻数据集 (<strong>约1000亿个单词</strong>) 上运行word2vec。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">gensim.downloader</span> <span class="k">as</span> <span class="nn">api</span>
<span class="n">wv</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;word2vec-google-news-300&#39;</span><span class="p">)</span>
</code></pre></div>

<p>如果你本地已经下载好了<code>GoogleNews-vectors-negative300.bin</code>模型，那么可以这样导入模型：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">gensim</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;C:\Users\two\Desktop\GoogleNews-vectors-negative300.bin&quot;</span>
<span class="n">wv</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c">C:\Users\two\AppData\Roaming\Python\Python36\site-packages\gensim\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial</span>
<span class="c">  warnings.warn(&quot;detected Windows; aliasing chunkize to chunkize_serial&quot;)</span>
<span class="err">2020-01-21 15:28:51,172 : INFO : &#39;pattern&#39; package not found; tag filters are not available for English</span>
<span class="err">2020-01-21 15:28:51,179 : INFO : loading projection weights from C:\Users\two\Desktop\GoogleNews-vectors-negative300.bin</span>
<span class="c">C:\Users\two\AppData\Roaming\Python\Python36\site-packages\smart_open\smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function</span>
<span class="c">  &#39;See the migration notes for details: %s&#39; % _MIGRATION_NOTES_URL</span>
<span class="err">2020-01-21 15:29:25,376 : INFO : loaded (3000000, 300) matrix from C:\Users\two\Desktop\GoogleNews-vectors-negative300.bin</span>
</code></pre></div>


<p>如果加载入完整的模型，可以看到提示：</p>
<div class="highlight"><pre><span></span><code> INFO : loaded (3000000, 300) matrix from GoogleNews-vectors-negative300.bin
</code></pre></div>

<p>该word2vec模型的词库包含3000000个单词，每个单词的词向量有300维。</p>
<h3 id="_1">获取词库</h3>
<p>常见的操作是检索模型的词汇表。 这很简单：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># .vocab  return dict {word:class  gensim.models.keyedvectors.Vocab}</span>
<span class="c1"># gensim.models.keyedvectors.Vocab: A single vocabulary item, used internally for collecting per-word frequency/sampling info,</span>
<span class="c1"># and for constructing binary trees (incl. both word leaves and inner nodes).</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">vocab</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;当前词库有&quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">vocab</span><span class="p">),</span><span class="s2">&quot;个单词&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">&lt;/s&gt;</span>
<span class="err">in</span>
<span class="err">for</span>
<span class="err">that</span>
<span class="err">is</span>
<span class="err">on</span>
<span class="err">##</span>
<span class="err">The</span>
<span class="err">with</span>
<span class="err">said</span>
<span class="err">当前词库有 3000000 个单词</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="c1"># property </span>
<span class="c1"># list of all words</span>
<span class="n">wv</span><span class="o">.</span><span class="n">index2word</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;当前词库有&quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index2word</span><span class="p">),</span><span class="s2">&quot;个单词&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">当前词库有 3000000 个单词</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="c1"># property </span>
<span class="c1"># list of all entities (words)</span>
<span class="n">wv</span><span class="o">.</span><span class="n">index2entity</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;当前词库有&quot;</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">index2entity</span><span class="p">),</span><span class="s2">&quot;个单词&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">当前词库有 3000000 个单词</span>
</code></pre></div>


<h3 id="_2">获取词向量</h3>
<p>获取词向量的维度信息：</p>
<div class="highlight"><pre><span></span><code><span class="n">wv</span><span class="o">.</span><span class="n">vector_size</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">300</span>
</code></pre></div>


<p>该 word2vec 模型的词向量有300维。</p>
<p>可以轻松地获取全部词向量：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># property</span>
<span class="c1"># 全部的词向量</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;完整词向量矩阵的维度信息：&quot;</span><span class="p">,</span><span class="n">wv</span><span class="o">.</span><span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">wv</span><span class="o">.</span><span class="n">vectors</span>
<span class="c1"># 也可以使用 .syn0 属性获取完整的词向量</span>
<span class="c1"># 但 .syn0 属性在gensim4.0.0版本将会被移除，建议使用 .vectors</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">完整词向量矩阵的维度信息：</span> <span class="p">(</span><span class="mi">3000000</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>

<span class="nb">array</span><span class="p">([[</span> <span class="mi">1</span><span class="p">.</span><span class="mi">1291504</span><span class="n">e</span><span class="o">-</span><span class="mi">03</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">.</span><span class="mi">9645386</span><span class="n">e</span><span class="o">-</span><span class="mi">04</span><span class="p">,</span>  <span class="mi">3</span><span class="p">.</span><span class="mi">1852722</span><span class="n">e</span><span class="o">-</span><span class="mi">04</span><span class="p">,</span> <span class="p">...,</span>
        <span class="o">-</span><span class="mi">1</span><span class="p">.</span><span class="mi">5640259</span><span class="n">e</span><span class="o">-</span><span class="mi">03</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">.</span><span class="mi">2302399</span><span class="n">e</span><span class="o">-</span><span class="mi">04</span><span class="p">,</span> <span class="o">-</span><span class="mi">8</span><span class="p">.</span><span class="mi">6307526</span><span class="n">e</span><span class="o">-</span><span class="mi">05</span><span class="p">],</span>
       <span class="p">[</span> <span class="mi">7</span><span class="p">.</span><span class="mi">0312500</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">8</span><span class="p">.</span><span class="mi">6914062</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">8</span><span class="p">.</span><span class="mi">7890625</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="p">...,</span>
        <span class="o">-</span><span class="mi">4</span><span class="p">.</span><span class="mi">7607422</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">4465332</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">.</span><span class="mi">2500000</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">],</span>
       <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">.</span><span class="mi">1779785</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">.</span><span class="mi">7363281</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">4</span><span class="p">.</span><span class="mi">4677734</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="p">...,</span>
         <span class="mi">7</span><span class="p">.</span><span class="mi">1289062</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">.</span><span class="mi">4912109</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">4169922</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">],</span>
       <span class="p">...,</span>
       <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">.</span><span class="mi">9653320</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">9</span><span class="p">.</span><span class="mi">0820312</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">.</span><span class="mi">9409180</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="p">...,</span>
        <span class="o">-</span><span class="mi">1</span><span class="p">.</span><span class="mi">6357422</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">.</span><span class="mi">3427734</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">4</span><span class="p">.</span><span class="mi">6630859</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">],</span>
       <span class="p">[</span> <span class="mi">3</span><span class="p">.</span><span class="mi">2714844</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">.</span><span class="mi">2226562</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">3</span><span class="p">.</span><span class="mi">6132812</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="p">...,</span>
        <span class="o">-</span><span class="mi">8</span><span class="p">.</span><span class="mi">8500977</span><span class="n">e</span><span class="o">-</span><span class="mi">03</span><span class="p">,</span>  <span class="mi">2</span><span class="p">.</span><span class="mi">6977539</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">9042969</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">],</span>
       <span class="p">[</span> <span class="mi">4</span><span class="p">.</span><span class="mi">5166016</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">.</span><span class="mi">5166016</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">.</span><span class="mi">9367676</span><span class="n">e</span><span class="o">-</span><span class="mi">03</span><span class="p">,</span> <span class="p">...,</span>
         <span class="mi">7</span><span class="p">.</span><span class="mi">9589844</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">7</span><span class="p">.</span><span class="mi">2265625</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">,</span>  <span class="mi">1</span><span class="p">.</span><span class="mi">3000488</span><span class="n">e</span><span class="o">-</span><span class="mi">02</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
</code></pre></div>


<p>获取标准化之后的词向量矩阵（但预训练模型没有这个属性，因此会抛出错误）：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># wv.vector_size</span>
<span class="c1"># property</span>
<span class="c1"># 全部的词向量</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;完整词向量矩阵的维度信息：&quot;</span><span class="p">,</span><span class="n">wv</span><span class="o">.</span><span class="n">vectors_norm</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">wv</span><span class="o">.</span><span class="n">vectors_norm</span>
<span class="c1"># 也可以使用 .syn0norm 属性获取完整的词向量</span>
<span class="c1"># 但 .syn0norm 属性在gensim4.0.0版本将会被移除，建议使用 .vectors_norm</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="c">AttributeError: &#39;NoneType&#39; object has no attribute &#39;shape&#39;</span>
</code></pre></div>


<p>对于出现在模型词库中的词，我们可以轻松获得它的向量表示：</p>
<div class="highlight"><pre><span></span><code><span class="n">vec_king</span> <span class="o">=</span> <span class="n">wv</span><span class="p">[</span><span class="s1">&#39;king&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;词向量的维度：&quot;</span><span class="p">,</span><span class="n">vec_king</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">pprint</span><span class="o">.</span><span class="n">pprint</span><span class="p">(</span><span class="n">vec_king</span><span class="p">)</span>
<span class="c1"># 可以这样获取多个单词的词向量</span>
<span class="c1"># wv[[&#39;king&#39;,&#39;car&#39;]]</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">词向量的维度： (300,)</span>
<span class="err">array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,</span>
<span class="err">       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,</span>
<span class="err">        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,</span>
<span class="err">       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,</span>
<span class="err">        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,</span>
<span class="err">        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,</span>
<span class="err">        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,</span>
<span class="err">        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,</span>
<span class="err">        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,</span>
<span class="err">        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,</span>
<span class="err">        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,</span>
<span class="err">        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,</span>
<span class="err">       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,</span>
<span class="err">       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,</span>
<span class="err">       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,</span>
<span class="err">        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,</span>
<span class="err">        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,</span>
<span class="err">       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,</span>
<span class="err">       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,</span>
<span class="err">       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,</span>
<span class="err">        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,</span>
<span class="err">        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,</span>
<span class="err">        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,</span>
<span class="err">       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,</span>
<span class="err">       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,</span>
<span class="err">        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,</span>
<span class="err">       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,</span>
<span class="err">        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,</span>
<span class="err">       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,</span>
<span class="err">       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,</span>
<span class="err">        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,</span>
<span class="err">       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,</span>
<span class="err">       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,</span>
<span class="err">        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,</span>
<span class="err">       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,</span>
<span class="err">        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,</span>
<span class="err">        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,</span>
<span class="err">       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,</span>
<span class="err">       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,</span>
<span class="err">       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,</span>
<span class="err">       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,</span>
<span class="err">       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,</span>
<span class="err">        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,</span>
<span class="err">        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,</span>
<span class="err">        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,</span>
<span class="err">       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,</span>
<span class="err">        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,</span>
<span class="err">        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,</span>
<span class="err">       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,</span>
<span class="err">       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,</span>
<span class="err">       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,</span>
<span class="err">        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,</span>
<span class="err">        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,</span>
<span class="err">       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,</span>
<span class="err">        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,</span>
<span class="err">       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,</span>
<span class="err">        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,</span>
<span class="err">        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,</span>
<span class="err">       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,</span>
<span class="err">        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,</span>
<span class="err">        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,</span>
<span class="err">        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,</span>
<span class="err">        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,</span>
<span class="err">        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,</span>
<span class="err">       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,</span>
<span class="err">        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,</span>
<span class="err">       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,</span>
<span class="err">        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,</span>
<span class="err">        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,</span>
<span class="err">       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,</span>
<span class="err">        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,</span>
<span class="err">        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,</span>
<span class="err">        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,</span>
<span class="err">       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,</span>
<span class="err">       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],</span>
<span class="err">      dtype=float32)</span>
</code></pre></div>


<p>也可以使用<code>.get_vector()</code>方法获取词向量，但<code>.get_vector()</code>方法每一次只能获取一个词向量：</p>
<div class="highlight"><pre><span></span><code><span class="n">wv</span><span class="o">.</span><span class="n">get_vector</span><span class="p">(</span><span class="s2">&quot;king&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,</span>
<span class="err">       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,</span>
<span class="err">        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,</span>
<span class="err">       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,</span>
<span class="err">        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,</span>
<span class="err">        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,</span>
<span class="err">        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,</span>
<span class="err">        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,</span>
<span class="err">        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,</span>
<span class="err">        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,</span>
<span class="err">        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,</span>
<span class="err">        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,</span>
<span class="err">       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,</span>
<span class="err">       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,</span>
<span class="err">       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,</span>
<span class="err">        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,</span>
<span class="err">        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,</span>
<span class="err">       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,</span>
<span class="err">       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,</span>
<span class="err">       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,</span>
<span class="err">        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,</span>
<span class="err">        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,</span>
<span class="err">        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,</span>
<span class="err">       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,</span>
<span class="err">       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,</span>
<span class="err">        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,</span>
<span class="err">       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,</span>
<span class="err">        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,</span>
<span class="err">       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,</span>
<span class="err">       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,</span>
<span class="err">        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,</span>
<span class="err">       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,</span>
<span class="err">       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,</span>
<span class="err">        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,</span>
<span class="err">       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,</span>
<span class="err">        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,</span>
<span class="err">        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,</span>
<span class="err">       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,</span>
<span class="err">       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,</span>
<span class="err">       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,</span>
<span class="err">       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,</span>
<span class="err">       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,</span>
<span class="err">        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,</span>
<span class="err">        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,</span>
<span class="err">        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,</span>
<span class="err">       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,</span>
<span class="err">        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,</span>
<span class="err">        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,</span>
<span class="err">       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,</span>
<span class="err">       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,</span>
<span class="err">       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,</span>
<span class="err">        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,</span>
<span class="err">        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,</span>
<span class="err">       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,</span>
<span class="err">        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,</span>
<span class="err">       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,</span>
<span class="err">        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,</span>
<span class="err">        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,</span>
<span class="err">       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,</span>
<span class="err">        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,</span>
<span class="err">        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,</span>
<span class="err">        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,</span>
<span class="err">        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,</span>
<span class="err">        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,</span>
<span class="err">       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,</span>
<span class="err">        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,</span>
<span class="err">       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,</span>
<span class="err">        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,</span>
<span class="err">        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,</span>
<span class="err">       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,</span>
<span class="err">        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,</span>
<span class="err">        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,</span>
<span class="err">        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,</span>
<span class="err">       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,</span>
<span class="err">       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],</span>
<span class="err">      dtype=float32)</span>
</code></pre></div>


<p><code>.get_vector()</code>方法等效于<code>.word_vec(word, use_norm=False)</code>，但<code>.word_vec(word, use_norm=False)</code>方法可以通过<code>use_norm</code>参数控制是否返回L2归一化后的词向量：</p>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">use_norm (bool, optional) – If True - resulting vector will be L2-normalized (unit euclidean length).</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">wv</span><span class="o">.</span><span class="n">word_vec</span><span class="p">(</span><span class="s1">&#39;king&#39;</span><span class="p">,</span> <span class="n">use_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">array([ 1.25976562e-01,  2.97851562e-02,  8.60595703e-03,  1.39648438e-01,</span>
<span class="err">       -2.56347656e-02, -3.61328125e-02,  1.11816406e-01, -1.98242188e-01,</span>
<span class="err">        5.12695312e-02,  3.63281250e-01, -2.42187500e-01, -3.02734375e-01,</span>
<span class="err">       -1.77734375e-01, -2.49023438e-02, -1.67968750e-01, -1.69921875e-01,</span>
<span class="err">        3.46679688e-02,  5.21850586e-03,  4.63867188e-02,  1.28906250e-01,</span>
<span class="err">        1.36718750e-01,  1.12792969e-01,  5.95703125e-02,  1.36718750e-01,</span>
<span class="err">        1.01074219e-01, -1.76757812e-01, -2.51953125e-01,  5.98144531e-02,</span>
<span class="err">        3.41796875e-01, -3.11279297e-02,  1.04492188e-01,  6.17675781e-02,</span>
<span class="err">        1.24511719e-01,  4.00390625e-01, -3.22265625e-01,  8.39843750e-02,</span>
<span class="err">        3.90625000e-02,  5.85937500e-03,  7.03125000e-02,  1.72851562e-01,</span>
<span class="err">        1.38671875e-01, -2.31445312e-01,  2.83203125e-01,  1.42578125e-01,</span>
<span class="err">        3.41796875e-01, -2.39257812e-02, -1.09863281e-01,  3.32031250e-02,</span>
<span class="err">       -5.46875000e-02,  1.53198242e-02, -1.62109375e-01,  1.58203125e-01,</span>
<span class="err">       -2.59765625e-01,  2.01416016e-02, -1.63085938e-01,  1.35803223e-03,</span>
<span class="err">       -1.44531250e-01, -5.68847656e-02,  4.29687500e-02, -2.46582031e-02,</span>
<span class="err">        1.85546875e-01,  4.47265625e-01,  9.58251953e-03,  1.31835938e-01,</span>
<span class="err">        9.86328125e-02, -1.85546875e-01, -1.00097656e-01, -1.33789062e-01,</span>
<span class="err">       -1.25000000e-01,  2.83203125e-01,  1.23046875e-01,  5.32226562e-02,</span>
<span class="err">       -1.77734375e-01,  8.59375000e-02, -2.18505859e-02,  2.05078125e-02,</span>
<span class="err">       -1.39648438e-01,  2.51464844e-02,  1.38671875e-01, -1.05468750e-01,</span>
<span class="err">        1.38671875e-01,  8.88671875e-02, -7.51953125e-02, -2.13623047e-02,</span>
<span class="err">        1.72851562e-01,  4.63867188e-02, -2.65625000e-01,  8.91113281e-03,</span>
<span class="err">        1.49414062e-01,  3.78417969e-02,  2.38281250e-01, -1.24511719e-01,</span>
<span class="err">       -2.17773438e-01, -1.81640625e-01,  2.97851562e-02,  5.71289062e-02,</span>
<span class="err">       -2.89306641e-02,  1.24511719e-02,  9.66796875e-02, -2.31445312e-01,</span>
<span class="err">        5.81054688e-02,  6.68945312e-02,  7.08007812e-02, -3.08593750e-01,</span>
<span class="err">       -2.14843750e-01,  1.45507812e-01, -4.27734375e-01, -9.39941406e-03,</span>
<span class="err">        1.54296875e-01, -7.66601562e-02,  2.89062500e-01,  2.77343750e-01,</span>
<span class="err">       -4.86373901e-04, -1.36718750e-01,  3.24218750e-01, -2.46093750e-01,</span>
<span class="err">       -3.03649902e-03, -2.11914062e-01,  1.25000000e-01,  2.69531250e-01,</span>
<span class="err">        2.04101562e-01,  8.25195312e-02, -2.01171875e-01, -1.60156250e-01,</span>
<span class="err">       -3.78417969e-02, -1.20117188e-01,  1.15234375e-01, -4.10156250e-02,</span>
<span class="err">       -3.95507812e-02, -8.98437500e-02,  6.34765625e-03,  2.03125000e-01,</span>
<span class="err">        1.86523438e-01,  2.73437500e-01,  6.29882812e-02,  1.41601562e-01,</span>
<span class="err">       -9.81445312e-02,  1.38671875e-01,  1.82617188e-01,  1.73828125e-01,</span>
<span class="err">        1.73828125e-01, -2.37304688e-01,  1.78710938e-01,  6.34765625e-02,</span>
<span class="err">        2.36328125e-01, -2.08984375e-01,  8.74023438e-02, -1.66015625e-01,</span>
<span class="err">       -7.91015625e-02,  2.43164062e-01, -8.88671875e-02,  1.26953125e-01,</span>
<span class="err">       -2.16796875e-01, -1.73828125e-01, -3.59375000e-01, -8.25195312e-02,</span>
<span class="err">       -6.49414062e-02,  5.07812500e-02,  1.35742188e-01, -7.47070312e-02,</span>
<span class="err">       -1.64062500e-01,  1.15356445e-02,  4.45312500e-01, -2.15820312e-01,</span>
<span class="err">       -1.11328125e-01, -1.92382812e-01,  1.70898438e-01, -1.25000000e-01,</span>
<span class="err">        2.65502930e-03,  1.92382812e-01, -1.74804688e-01,  1.39648438e-01,</span>
<span class="err">        2.92968750e-01,  1.13281250e-01,  5.95703125e-02, -6.39648438e-02,</span>
<span class="err">        9.96093750e-02, -2.72216797e-02,  1.96533203e-02,  4.27246094e-02,</span>
<span class="err">       -2.46093750e-01,  6.39648438e-02, -2.25585938e-01, -1.68945312e-01,</span>
<span class="err">        2.89916992e-03,  8.20312500e-02,  3.41796875e-01,  4.32128906e-02,</span>
<span class="err">        1.32812500e-01,  1.42578125e-01,  7.61718750e-02,  5.98144531e-02,</span>
<span class="err">       -1.19140625e-01,  2.74658203e-03, -6.29882812e-02, -2.72216797e-02,</span>
<span class="err">       -4.82177734e-03, -8.20312500e-02, -2.49023438e-02, -4.00390625e-01,</span>
<span class="err">       -1.06933594e-01,  4.24804688e-02,  7.76367188e-02, -1.16699219e-01,</span>
<span class="err">        7.37304688e-02, -9.22851562e-02,  1.07910156e-01,  1.58203125e-01,</span>
<span class="err">        4.24804688e-02,  1.26953125e-01,  3.61328125e-02,  2.67578125e-01,</span>
<span class="err">       -1.01074219e-01, -3.02734375e-01, -5.76171875e-02,  5.05371094e-02,</span>
<span class="err">        5.26428223e-04, -2.07031250e-01, -1.38671875e-01, -8.97216797e-03,</span>
<span class="err">       -2.78320312e-02, -1.41601562e-01,  2.07031250e-01, -1.58203125e-01,</span>
<span class="err">        1.27929688e-01,  1.49414062e-01, -2.24609375e-02, -8.44726562e-02,</span>
<span class="err">        1.22558594e-01,  2.15820312e-01, -2.13867188e-01, -3.12500000e-01,</span>
<span class="err">       -3.73046875e-01,  4.08935547e-03,  1.07421875e-01,  1.06933594e-01,</span>
<span class="err">        7.32421875e-02,  8.97216797e-03, -3.88183594e-02, -1.29882812e-01,</span>
<span class="err">        1.49414062e-01, -2.14843750e-01, -1.83868408e-03,  9.91210938e-02,</span>
<span class="err">        1.57226562e-01, -1.14257812e-01, -2.05078125e-01,  9.91210938e-02,</span>
<span class="err">        3.69140625e-01, -1.97265625e-01,  3.54003906e-02,  1.09375000e-01,</span>
<span class="err">        1.31835938e-01,  1.66992188e-01,  2.35351562e-01,  1.04980469e-01,</span>
<span class="err">       -4.96093750e-01, -1.64062500e-01, -1.56250000e-01, -5.22460938e-02,</span>
<span class="err">        1.03027344e-01,  2.43164062e-01, -1.88476562e-01,  5.07812500e-02,</span>
<span class="err">       -9.37500000e-02, -6.68945312e-02,  2.27050781e-02,  7.61718750e-02,</span>
<span class="err">        2.89062500e-01,  3.10546875e-01, -5.37109375e-02,  2.28515625e-01,</span>
<span class="err">        2.51464844e-02,  6.78710938e-02, -1.21093750e-01, -2.15820312e-01,</span>
<span class="err">       -2.73437500e-01, -3.07617188e-02, -3.37890625e-01,  1.53320312e-01,</span>
<span class="err">        2.33398438e-01, -2.08007812e-01,  3.73046875e-01,  8.20312500e-02,</span>
<span class="err">        2.51953125e-01, -7.61718750e-02, -4.66308594e-02, -2.23388672e-02,</span>
<span class="err">        2.99072266e-02, -5.93261719e-02, -4.66918945e-03, -2.44140625e-01,</span>
<span class="err">       -2.09960938e-01, -2.87109375e-01, -4.54101562e-02, -1.77734375e-01,</span>
<span class="err">       -2.79296875e-01, -8.59375000e-02,  9.13085938e-02,  2.51953125e-01],</span>
<span class="err">      dtype=float32)</span>
</code></pre></div>


<p>不幸的是，该word2vec模型无法推断出陌生单词的向量。这是Word2Vec的一个局限：如果你需要这个功能，请查看FastText模型。</p>
<div class="highlight"><pre><span></span><code><span class="k">try</span><span class="p">:</span>
    <span class="n">vec_cameroon</span> <span class="o">=</span> <span class="n">wv</span><span class="p">[</span><span class="s1">&#39;cameroon&#39;</span><span class="p">]</span>
<span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The word &#39;cameroon&#39; does not appear in this model&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">The word &#39;cameroon&#39; does not appear in this model</span>
</code></pre></div>


<h3 id="_3">相似性任务</h3>
<p>Word2Vec支持多个单词相似性任务。你可以看到相似度如何随着单词变得越来越少而直观地降低。</p>
<div class="highlight"><pre><span></span><code><span class="n">pairs</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;minivan&#39;</span><span class="p">),</span>   <span class="c1"># a minivan is a kind of car</span>
    <span class="p">(</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;bicycle&#39;</span><span class="p">),</span>   <span class="c1"># still a wheeled vehicle</span>
    <span class="p">(</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;airplane&#39;</span><span class="p">),</span>  <span class="c1"># ok, no wheels, but still a vehicle</span>
    <span class="p">(</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;cereal&#39;</span><span class="p">),</span>    <span class="c1"># ... and so on</span>
    <span class="p">(</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;communism&#39;</span><span class="p">),</span>
<span class="p">]</span>
<span class="k">for</span> <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span> <span class="ow">in</span> <span class="n">pairs</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%r</span><span class="se">\t</span><span class="si">%r</span><span class="se">\t</span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">,</span> <span class="n">wv</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="n">w1</span><span class="p">,</span> <span class="n">w2</span><span class="p">)))</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">&#39;car&#39;   &#39;minivan&#39;   0.69</span>
<span class="err">&#39;car&#39;   &#39;bicycle&#39;   0.54</span>
<span class="err">&#39;car&#39;   &#39;airplane&#39;  0.42</span>
<span class="err">&#39;car&#39;   &#39;cereal&#39;    0.14</span>
<span class="err">&#39;car&#39;   &#39;communism&#39; 0.06</span>
</code></pre></div>


<p>找出5个与car或minivan最相似的词：</p>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">most_similar(positive=None, negative=None, topn=10, restrict_vocab=None, indexer=None)</span>
<span class="sd">    restrict_vocab: int 用于限制搜索最相似单词的向量范围。</span>
<span class="sd">                    例如，restrict_vocab=10000将只检查词库顺序中的前10000个词向量。</span>
<span class="sd">                    如果词库的排序是按顺序的，设置这个参数可能会有意义。</span>

<span class="sd">找出最相似（或最不相似）的前topn个单词。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;minivan&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">[(&#39;SUV&#39;, 0.8532191514968872),</span>
<span class="err"> (&#39;vehicle&#39;, 0.8175784349441528),</span>
<span class="err"> (&#39;pickup_truck&#39;, 0.7763689160346985),</span>
<span class="err"> (&#39;Jeep&#39;, 0.7567334175109863),</span>
<span class="err"> (&#39;Ford_Explorer&#39;, 0.7565719485282898)]</span>
</code></pre></div>


<p>找出5个与car或minivan最不相似的词：</p>
<div class="highlight"><pre><span></span><code><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">negative</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;car&#39;</span><span class="p">,</span><span class="s1">&#39;minivan&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">[(&#39;Philippe_Giaro_P.Geol&#39;, 0.31101420521736145),</span>
<span class="err"> (&#39;K.Kahne_###-###&#39;, 0.3042159676551819),</span>
<span class="err"> (&#39;C.Bowyer_###-###&#39;, 0.278561532497406),</span>
<span class="err"> (&#39;M.Truex_Jr._###-###&#39;, 0.27755749225616455),</span>
<span class="err"> (&#39;By_SEAN_BARRON&#39;, 0.27275702357292175)]</span>
</code></pre></div>


<p><code>.most_similar_cosmul()</code>方法与<code>.most_similar()</code>方法相似，但是<code>.most_similar_cosmul()</code>方法使用multiplicative combination objective方法去计算单词之间的距离。<code>.most_similar_cosmul()</code>返回的排名与<code>.most_similar()</code>相同。</p>
<blockquote>
<p>multiplicative combination objective计算方法出自 <a href="http://www.aclweb.org/anthology/W14-1618">Omer Levy and Yoav Goldberg “Linguistic Regularities in Sparse and Explicit Word Representations”</a></p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">most_similar_cosmul(positive=None, negative=None, topn=10)</span>
<span class="sd">找最相似的前n个单词</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">most_similar_cosmul</span><span class="p">(</span><span class="n">positive</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;minivan&#39;</span><span class="p">],</span> <span class="n">topn</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">[(&#39;SUV&#39;, 0.7949184775352478),</span>
<span class="err"> (&#39;vehicle&#39;, 0.7668868899345398),</span>
<span class="err"> (&#39;pickup_truck&#39;, 0.733077883720398),</span>
<span class="err"> (&#39;Jeep&#39;, 0.7184048891067505),</span>
<span class="err"> (&#39;Ford_Explorer&#39;, 0.7173909544944763)]</span>
</code></pre></div>


<p>单词water与列表中哪个单词最相似？</p>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">most_similar_to_given(entity1, entities_list)</span>

<span class="sd">从entities_list获取与entity1最相似的entity。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">most_similar_to_given</span><span class="p">(</span><span class="n">entity1</span><span class="o">=</span><span class="s1">&#39;air&#39;</span><span class="p">,</span> <span class="n">entities_list</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="s1">&#39;minivan&#39;</span><span class="p">,</span><span class="s1">&#39;fire&#39;</span><span class="p">,</span> <span class="s1">&#39;water&#39;</span><span class="p">,</span> <span class="s1">&#39;land&#39;</span><span class="p">,</span> <span class="s1">&#39;sea&#39;</span><span class="p">])</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">&#39;water&#39;</span>
</code></pre></div>


<p>以下哪个不属于该序列？</p>
<div class="highlight"><pre><span></span><code><span class="n">wv</span><span class="o">.</span><span class="n">doesnt_match</span><span class="p">([</span><span class="s1">&#39;fire&#39;</span><span class="p">,</span> <span class="s1">&#39;water&#39;</span><span class="p">,</span> <span class="s1">&#39;land&#39;</span><span class="p">,</span> <span class="s1">&#39;sea&#39;</span><span class="p">,</span> <span class="s1">&#39;air&#39;</span><span class="p">,</span> <span class="s1">&#39;car&#39;</span><span class="p">])</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="k">C</span><span class="p">:</span><span class="err">\</span><span class="n">Users</span><span class="err">\</span><span class="n">two</span><span class="err">\</span><span class="n">AppData</span><span class="err">\</span><span class="n">Roaming</span><span class="err">\</span><span class="n">Python</span><span class="err">\</span><span class="n">Python36</span><span class="err">\</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="err">\</span><span class="n">gensim</span><span class="err">\</span><span class="n">models</span><span class="err">\</span><span class="n">keyedvectors</span><span class="p">.</span><span class="n">py</span><span class="p">:</span><span class="mi">893</span><span class="p">:</span> <span class="n">FutureWarning</span><span class="p">:</span> <span class="n">arrays</span> <span class="k">to</span> <span class="n">stack</span> <span class="n">must</span> <span class="n">be</span> <span class="n">passed</span> <span class="k">as</span> <span class="n">a</span> <span class="ss">&quot;sequence&quot;</span> <span class="k">type</span> <span class="n">such</span> <span class="k">as</span> <span class="n">list</span> <span class="k">or</span> <span class="n">tuple</span><span class="p">.</span> <span class="n">Support</span> <span class="k">for</span> <span class="n">non</span><span class="o">-</span><span class="n">sequence</span> <span class="n">iterables</span> <span class="n">such</span> <span class="k">as</span> <span class="n">generators</span> <span class="k">is</span> <span class="n">deprecated</span> <span class="k">as</span> <span class="k">of</span> <span class="n">NumPy</span> <span class="mi">1</span><span class="p">.</span><span class="mi">16</span> <span class="k">and</span> <span class="n">will</span> <span class="n">raise</span> <span class="n">an</span> <span class="n">error</span> <span class="k">in</span> <span class="n">the</span> <span class="n">future</span><span class="p">.</span>
  <span class="n">vectors</span> <span class="o">=</span> <span class="n">vstack</span><span class="p">(</span><span class="k">self</span><span class="p">.</span><span class="n">word_vec</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">use_norm</span><span class="o">=</span><span class="k">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="k">in</span> <span class="n">used_words</span><span class="p">).</span><span class="n">astype</span><span class="p">(</span><span class="nb">REAL</span><span class="p">)</span>

<span class="s1">&#39;car&#39;</span>
</code></pre></div>


<p>在词库中，哪些单词比SUV更接近car？</p>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">words_closer_than(w1, w2)</span>
<span class="sd">    w1 (str) – Input word.</span>
<span class="sd">    w2 (str) – Input word.</span>
<span class="sd">在词库中获取所有比w2更接近w1的单词。</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">wv</span><span class="o">.</span><span class="n">words_closer_than</span><span class="p">(</span><span class="s1">&#39;car&#39;</span><span class="p">,</span><span class="s1">&#39;SUV&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">[&#39;vehicle&#39;, &#39;cars&#39;]</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">closer_than(entity1, entity2)</span>


<span class="sd">获取所有比entity2更接近entity1的entities。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">closer_than</span><span class="p">(</span><span class="s1">&#39;car&#39;</span><span class="p">,</span><span class="s1">&#39;SUV&#39;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">[&#39;vehicle&#39;, &#39;cars&#39;]</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="n">wv</span><span class="o">.</span><span class="n">get_keras_embedding</span><span class="p">()</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="k">Using</span> <span class="n">TensorFlow</span> <span class="n">backend</span><span class="p">.</span>
<span class="mi">2020</span><span class="o">-</span><span class="mi">01</span><span class="o">-</span><span class="mi">03</span> <span class="mi">11</span><span class="p">:</span><span class="mi">23</span><span class="p">:</span><span class="mi">01</span><span class="p">,</span><span class="mi">818</span> <span class="p">:</span> <span class="n">WARNING</span> <span class="p">:</span> <span class="k">From</span> <span class="k">C</span><span class="p">:</span><span class="err">\</span><span class="n">Users</span><span class="err">\</span><span class="n">two</span><span class="err">\</span><span class="n">Anaconda3</span><span class="err">\</span><span class="n">lib</span><span class="err">\</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="err">\</span><span class="n">keras</span><span class="err">\</span><span class="n">backend</span><span class="err">\</span><span class="n">tensorflow_backend</span><span class="p">.</span><span class="n">py</span><span class="p">:</span><span class="mi">74</span><span class="p">:</span> <span class="n">The</span> <span class="n">name</span> <span class="n">tf</span><span class="p">.</span><span class="n">get_default_graph</span> <span class="k">is</span> <span class="n">deprecated</span><span class="p">.</span> <span class="n">Please</span> <span class="n">use</span> <span class="n">tf</span><span class="p">.</span><span class="n">compat</span><span class="p">.</span><span class="n">v1</span><span class="p">.</span><span class="n">get_default_graph</span> <span class="k">instead</span><span class="p">.</span>


<span class="o">&lt;</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">embeddings</span><span class="p">.</span><span class="n">Embedding</span> <span class="k">at</span> <span class="mi">0</span><span class="n">x2663d025eb8</span><span class="o">&gt;</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="c1"># wv.wmdistance([&#39;car&#39;,&#39;minivan&#39;], [&#39;car&#39;]) errror:No module named &#39;pyemd&#39;</span>
</code></pre></div>

<div class="highlight"><pre><span></span><code><span class="c1"># 查看 word2vec model的全部属性</span>
<span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">dir</span><span class="p">(</span><span class="n">wv</span><span class="p">)</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">i</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">)]</span>
</code></pre></div>

<h3 id="_4">获取余弦距离</h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">distance(w1, w2) </span>
<span class="sd">    w1: str – Input word</span>
<span class="sd">    w2: str – Input word</span>
<span class="sd">计算两个单词之间的余弦距离，距离越小越相似。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">distance</span><span class="p">(</span><span class="s2">&quot;car&quot;</span><span class="p">,</span><span class="s2">&quot;vehicle&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">0.21789032220840454</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">distances(word_or_vector, other_words=())</span>
<span class="sd">    word_or_vector: str, numpy.ndarray – Word or vector from which distances are to be computed.</span>
<span class="sd">    other_words: iterable of str – 如果other_words为空，则返回word_or_vectors和vocab中所有单词之间的距离。</span>
<span class="sd">计算单词word_or_vector和other_words中所有单词的余弦距离。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">distances</span><span class="p">(</span><span class="n">word_or_vector</span><span class="o">=</span><span class="s2">&quot;car&quot;</span><span class="p">,</span><span class="n">other_words</span><span class="o">=</span><span class="p">(</span><span class="s2">&quot;vehicle&quot;</span><span class="p">,</span><span class="s1">&#39;SUV&#39;</span><span class="p">,</span><span class="s1">&#39;truck&#39;</span><span class="p">,</span><span class="s1">&#39;minivan&#39;</span><span class="p">,</span><span class="s1">&#39;car&#39;</span><span class="p">))</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">array([0.21789044, 0.28390366, 0.32642102, 0.30929637, 0.        ],</span>
<span class="err">      dtype=float32)</span>
</code></pre></div>


<h3 id="_5">获取余弦相似度</h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">similarity(w1, w2)</span>
<span class="sd">    w1 (str) – Input word.</span>
<span class="sd">    w2 (str) – Input word.</span>
<span class="sd">计算两个单词之间的余弦相似度。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">similarity</span><span class="p">(</span><span class="s2">&quot;car&quot;</span><span class="p">,</span><span class="s2">&quot;car&quot;</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">1.0</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">n_similarity(ws1, ws2)</span>
<span class="sd">    ws1 (list of str) – Sequence of words.</span>
<span class="sd">    ws2 (list of str) – Sequence of words.</span>
<span class="sd">计算两组单词之间的余弦相似度。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">n_similarity</span><span class="p">([</span><span class="s1">&#39;car&#39;</span><span class="p">,</span><span class="s1">&#39;minivan&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;car&#39;</span><span class="p">])</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">0.89490217</span>
</code></pre></div>


<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd"># 静态方法</span>
<span class="sd">cosine_similarities(vector_1, vectors_all)</span>
<span class="sd">    vector_1 (numpy.ndarray) shape (dim,).</span>
<span class="sd">    vectors_all (numpy.ndarray) shape (num_vectors, dim).</span>
<span class="sd">计算一个向量和一组其他向量之间的余弦相似度。    </span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">cosine_similarities</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">]])</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">array([1.        , 0.97463185])</span>
</code></pre></div>


<p>计算两个单词之间的相对余弦相似度：</p>
<blockquote>
<p>计算方法出自 <a href="https://ufal.mff.cuni.cz/pbml/105/art-leeuwenberg-et-al.pdf">Artuur Leeuwenberga, Mihaela Velab , Jon Dehdaribc, Josef van Genabithbc “A Minimally Supervised Approach for Synonym Extraction with Word Embeddings”</a> 的公式(1)。</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">relative_cosine_similarity(wa, wb, topn=10)</span>

<span class="sd">给定前n个相似的单词，计算两个单词之间的相对余弦相似度。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">wv</span><span class="o">.</span><span class="n">relative_cosine_similarity</span><span class="p">(</span><span class="n">wa</span><span class="o">=</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="n">wb</span><span class="o">=</span> <span class="s1">&#39;minivan&#39;</span><span class="p">,</span> <span class="n">topn</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">0.1001322352889656</span>
</code></pre></div>


<h3 id="_6">获取距离排名</h3>
<div class="highlight"><pre><span></span><code><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">rank(entity1, entity2)</span>

<span class="sd">相对于所有entitie到entity1的距离，entity2到entity1的距离的排名。</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">entity1</span><span class="o">=</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="n">entity2</span><span class="o">=</span><span class="s1">&#39;cars&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wv</span><span class="o">.</span><span class="n">rank</span><span class="p">(</span><span class="n">entity1</span><span class="o">=</span><span class="s1">&#39;car&#39;</span><span class="p">,</span> <span class="n">entity2</span><span class="o">=</span><span class="s1">&#39;car&#39;</span><span class="p">))</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">2</span>
<span class="err">1</span>
</code></pre></div>


<h2 id="_7">训练自己的模型</h2>
<p>首先，你需要一些数据来训练模型。 对于以下示例，我们将使用<a href="https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_data/lee_background.cor"><code>Lee Corpus</code>数据</a>，gensim库已带有该数据集。</p>
<p>这个语料库足够小，可以完全加载入内存中，但是我们将实现一个对内存友好的迭代器，该迭代器逐行读取它，用来演示gensim如何处理更大的语料库。</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">gensim.test.utils</span> <span class="kn">import</span> <span class="n">datapath</span>
<span class="kn">from</span> <span class="nn">gensim</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="k">class</span> <span class="nc">MyCorpus</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;产生句子（lists of str）的迭代器。&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">corpus_path</span> <span class="o">=</span> <span class="n">datapath</span><span class="p">(</span><span class="s1">&#39;lee_background.cor&#39;</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="n">corpus_path</span><span class="p">):</span>
            <span class="c1"># 假设每行有一个文档，tokens被空格分开</span>
            <span class="k">yield</span> <span class="n">utils</span><span class="o">.</span><span class="n">simple_preprocess</span><span class="p">(</span><span class="n">line</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">2020-01-02 21:16:01,714 : INFO : adding document #0 to Dictionary(0 unique tokens: [])</span>
<span class="err">2020-01-02 21:16:01,716 : INFO : built Dictionary(12 unique tokens: [&#39;computer&#39;, &#39;human&#39;, &#39;interface&#39;, &#39;response&#39;, &#39;survey&#39;]...) from 9 documents (total 29 corpus positions)</span>
</code></pre></div>


<p>如果我们想进行任何自定义的预处理，例如：解码非标准编码数据、字母小写化、删除数字、提取命名实体。所有这些都可以在<code>MyCorpus</code>迭代器内完成，而<code>word2vec</code>不需要知道这些处理。<code>word2vec</code>只需输入的迭代器产生一个又一个句子(list of utf-8 words) 。</p>
<p>让我们继续，在我们的语料库上训练模型。 暂时不必担心训练参数，我们稍后将对其进行讨论。</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">gensim.models</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">MyCorpus</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span><span class="n">sentences</span><span class="o">=</span><span class="n">sentences</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">2020-01-02 21:16:05,695 : INFO : collecting all words and their counts</span>
<span class="err">2020-01-02 21:16:05,698 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types</span>
<span class="err">2020-01-02 21:16:06,042 : INFO : collected 6981 word types from a corpus of 58152 raw words and 300 sentences</span>
<span class="err">2020-01-02 21:16:06,047 : INFO : Loading a fresh vocabulary</span>
<span class="err">2020-01-02 21:16:06,126 : INFO : effective_min_count=5 retains 1750 unique words (25% of original 6981, drops 5231)</span>
<span class="err">2020-01-02 21:16:06,128 : INFO : effective_min_count=5 leaves 49335 word corpus (84% of original 58152, drops 8817)</span>
<span class="err">2020-01-02 21:16:06,140 : INFO : deleting the raw counts dictionary of 6981 items</span>
<span class="err">2020-01-02 21:16:06,142 : INFO : sample=0.001 downsamples 51 most-common words</span>
<span class="err">2020-01-02 21:16:06,145 : INFO : downsampling leaves estimated 35935 word corpus (72.8% of prior 49335)</span>
<span class="err">2020-01-02 21:16:06,156 : INFO : estimated required memory for 1750 words and 100 dimensions: 2275000 bytes</span>
<span class="err">2020-01-02 21:16:06,157 : INFO : resetting layer weights</span>
<span class="err">2020-01-02 21:16:06,683 : INFO : training model with 3 workers on 1750 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5</span>
<span class="err">2020-01-02 21:16:06,863 : INFO : worker thread finished; awaiting finish of 2 more threads</span>
<span class="err">2020-01-02 21:16:06,877 : INFO : worker thread finished; awaiting finish of 1 more threads</span>
<span class="err">2020-01-02 21:16:06,884 : INFO : worker thread finished; awaiting finish of 0 more threads</span>
<span class="err">2020-01-02 21:16:06,886 : INFO : EPOCH - 1 : training on 58152 raw words (35883 effective words) took 0.2s, 180122 effective words/s</span>
<span class="err">2020-01-02 21:16:07,060 : INFO : worker thread finished; awaiting finish of 2 more threads</span>
<span class="err">2020-01-02 21:16:07,062 : INFO : worker thread finished; awaiting finish of 1 more threads</span>
<span class="err">2020-01-02 21:16:07,075 : INFO : worker thread finished; awaiting finish of 0 more threads</span>
<span class="err">2020-01-02 21:16:07,077 : INFO : EPOCH - 2 : training on 58152 raw words (35909 effective words) took 0.2s, 192286 effective words/s</span>
<span class="err">2020-01-02 21:16:07,249 : INFO : worker thread finished; awaiting finish of 2 more threads</span>
<span class="err">2020-01-02 21:16:07,251 : INFO : worker thread finished; awaiting finish of 1 more threads</span>
<span class="err">2020-01-02 21:16:07,268 : INFO : worker thread finished; awaiting finish of 0 more threads</span>
<span class="err">2020-01-02 21:16:07,269 : INFO : EPOCH - 3 : training on 58152 raw words (36011 effective words) took 0.2s, 190390 effective words/s</span>
<span class="err">2020-01-02 21:16:07,485 : INFO : worker thread finished; awaiting finish of 2 more threads</span>
<span class="err">2020-01-02 21:16:07,490 : INFO : worker thread finished; awaiting finish of 1 more threads</span>
<span class="err">2020-01-02 21:16:07,504 : INFO : worker thread finished; awaiting finish of 0 more threads</span>
<span class="err">2020-01-02 21:16:07,506 : INFO : EPOCH - 4 : training on 58152 raw words (35955 effective words) took 0.2s, 154656 effective words/s</span>
<span class="err">2020-01-02 21:16:07,709 : INFO : worker thread finished; awaiting finish of 2 more threads</span>
<span class="err">2020-01-02 21:16:07,711 : INFO : worker thread finished; awaiting finish of 1 more threads</span>
<span class="err">2020-01-02 21:16:07,723 : INFO : worker thread finished; awaiting finish of 0 more threads</span>
<span class="err">2020-01-02 21:16:07,724 : INFO : EPOCH - 5 : training on 58152 raw words (35937 effective words) took 0.2s, 167155 effective words/s</span>
<span class="err">2020-01-02 21:16:07,726 : INFO : training on a 290760 raw words (179695 effective words) took 1.0s, 172497 effective words/s</span>
</code></pre></div>


<p>建立模型后，我们可以使用与上面演示相同的方法。</p>
<p>模型的主要部分是<code>model.wv</code>，其中<code>wv</code>代表word vector。</p>
<div class="highlight"><pre><span></span><code><span class="n">vec_king</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="s1">&#39;king&#39;</span><span class="p">];</span><span class="n">vec_king</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">array([-0.00835394, -0.0045849 ,  0.02337644,  0.06137834,  0.03927568,</span>
<span class="err">        0.0771808 , -0.00613491,  0.04881869, -0.01778515, -0.05783534,</span>
<span class="err">        0.05000733,  0.04546838, -0.04622583,  0.02119355, -0.08289969,</span>
<span class="err">        0.06297314,  0.00819165, -0.04722812, -0.01712785, -0.06220391,</span>
<span class="err">       -0.01792748, -0.01274053,  0.03496742, -0.0297276 , -0.06460014,</span>
<span class="err">        0.04213679, -0.02229733,  0.07136393,  0.00484056, -0.00886152,</span>
<span class="err">       -0.00471885, -0.00707228,  0.00073703,  0.00370342, -0.0162351 ,</span>
<span class="err">        0.01090373,  0.02818023, -0.04841179,  0.04993173,  0.04033299,</span>
<span class="err">       -0.0018242 , -0.00435686,  0.08839191, -0.06075187, -0.00611064,</span>
<span class="err">        0.00549908, -0.00981818,  0.0147628 , -0.03261513,  0.00605273,</span>
<span class="err">        0.03322693,  0.03558705,  0.03365535, -0.01211257, -0.05132781,</span>
<span class="err">        0.00949616, -0.00190306,  0.03689624, -0.01641419, -0.00697564,</span>
<span class="err">        0.03875671,  0.01708069,  0.00355519,  0.01152966,  0.04929205,</span>
<span class="err">        0.02247121, -0.01232615,  0.0412309 ,  0.00039095, -0.01177677,</span>
<span class="err">       -0.03727527,  0.07211189, -0.02746879,  0.01342012, -0.03975392,</span>
<span class="err">        0.01483131,  0.02386127,  0.01227524, -0.01146569, -0.00367378,</span>
<span class="err">        0.00885449, -0.01065395,  0.01139999, -0.03370672, -0.00587148,</span>
<span class="err">        0.02534425,  0.01000963, -0.04751983, -0.01368179, -0.0111518 ,</span>
<span class="err">        0.03696112,  0.02186877, -0.03961398, -0.00126779,  0.02945407,</span>
<span class="err">       -0.01498374,  0.00616166, -0.01830531, -0.0072393 , -0.01315761],</span>
<span class="err">      dtype=float32)</span>
</code></pre></div>


<p>检索词汇的方法相同：</p>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vocab</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">10</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
</code></pre></div>

<div class="codehilite"><pre><span></span><code><span class="err">hundreds</span>
<span class="err">of</span>
<span class="err">people</span>
<span class="err">have</span>
<span class="err">been</span>
<span class="err">forced</span>
<span class="err">to</span>
<span class="err">their</span>
<span class="err">homes</span>
<span class="err">in</span>
</code></pre></div>


<h2 id="_8">存储和加载模型</h2>
<p>如果语料库较大，训练模型会花费不少时间。如果训练好的模型按预期工作，可以将其保存到磁盘。 这样一来，不必在以后再花时间进行训练。</p>
<p>你可以使用 gensim 的标准方法区储存和加载模型：</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tempfile</span>

<span class="k">with</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">(</span><span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;gensim-model-&#39;</span><span class="p">,</span> <span class="n">delete</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">tmp</span><span class="p">:</span>
    <span class="n">temporary_filepath</span> <span class="o">=</span> <span class="n">tmp</span><span class="o">.</span><span class="n">name</span>
<span class="hll">    <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">temporary_filepath</span><span class="p">)</span>
</span>    <span class="c1">#</span>
    <span class="c1"># The model is now safely stored in the filepath.</span>
    <span class="c1"># You can copy it to other machines, share it with others, etc.</span>
    <span class="c1">#</span>
    <span class="c1"># To load a saved model:</span>
    <span class="c1">#</span>
<span class="hll">    <span class="n">new_model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">temporary_filepath</span><span class="p">)</span>
</span></code></pre></div>

<p>这种做法将保存模型的全部信息，它在内部使用pickle，可以选择将模型的内部大型NumPy矩阵直接从磁盘文件转换到虚拟内存中，以实现进程间内存共享。</p>
<p>此外，还可以只保存模型的词嵌入层权重：</p>
<blockquote>
<p>译者注：这种保存格式应该与原始C工具的保存格式相同</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">save_word2vec_format</span><span class="p">()</span>
</code></pre></div>

<p>您可以使用文本或二进制格式加载由原始C工具创建的模型：</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;/tmp/vectors.txt&#39;</span><span class="p">,</span> 
                                                        <span class="n">binary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div>

<h2 id="gzippedbz2">也可以输入gzipped/bz2文件，无需解压缩</h2>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">KeyedVectors</span><span class="o">.</span><span class="n">load_word2vec_format</span><span class="p">(</span><span class="s1">&#39;/tmp/vectors.bin.gz&#39;</span><span class="p">,</span> 
                                                        <span class="n">binary</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<h2 id="_9">训练参数</h2>
<p><code>Word2Vec</code>接受几个同时影响训练速度和质量的参数。</p>
<h3 id="min_count">min_count</h3>
<p><code>min_count</code>用于修剪内部词汇表。在十亿个单词的语料库中仅出现一两次的单词可能是无趣的错别字和垃圾。此外，没有足够的数据来对这些单词进行任何有意义的训练，因此最好忽略它们：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># default value of min_count=5</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<h3 id="size">size</h3>
<p><code>size</code>是gensim Word2Vec将单词映射到的N维空间的维数（N）。较大的值需要更多的训练数据，但可以产生更好（更准确）的模型。合理的值在数十到数百之间。</p>
<div class="highlight"><pre><span></span><code><span class="c1"># default value of size=100</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
</code></pre></div>

<h3 id="workers">workers</h3>
<p><code>workers</code> 是最后一个主要的参数（全部参数列表见<a href="https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec%3E">这里</a>，它用于并行化训练，加快训练速度：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># default value of workers=3 (tutorial says 1...)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span><span class="n">sentences</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div>

<p><code>workers</code> 只有在使用<a href="http://cython.org/"><code>Cython</code>解析器</a>的时候才生效，如果没有Cython，因为存在<a href="https://wiki.python.org/moin/GlobalInterpreterLock">GIL</a>，所以只能使用一个cpu核心，这样的话，<a href="http://rare-technologies.com/word2vec-in-python-part-two-optimizing/">word2vec的训练速度</a>会变得很慢很慢。</p>
<h2 id="memory">Memory</h2>
<p>Word2vec 模型参数的核心是存储为矩阵(NumPy 数组)。 每个数组大小都是词汇表的长度乘以<code>size</code>参数浮点数（4字节的单精度）。</p>
<p>在RAM中保存了三个这样的矩阵（正在努力将该数目减少到两个，甚至一个）。因此，如果您的输入的词汇表有100,000唯一的单词，并且您要求的隐藏层大小为200，则该模型将需要大约
$$
100000 \times 200 \times 4 \times 3字节 \approx 229 MB
$$
存储 vocabulary tree 需要一些额外的内存（100,000个单词将花费几MB的储存）。因此，内存占用量由上述三个矩阵决定，除非您的单词是很长很长的字符串。</p>
<h2 id="evaluating">Evaluating</h2>
<p><code>Word2Vec</code> training is an unsupervised task, there’s no good way to objectively evaluate the result. Evaluation depends on your end application.</p>
<p>Google has released their testing set of about 20,000 syntactic and semantic test examples, following the “A is to B as C is to D” task. It is provided in the 'datasets' folder.</p>
<p>For example a syntactic analogy of comparative type is bad:worse;good:?. There are total of 9 types of syntactic comparisons in the dataset like plural nouns and nouns of opposite meaning.</p>
<p>The semantic questions contain five types of semantic analogies, such as capital cities (Paris:France;Tokyo:?) or family members
(brother:sister;dad:?).</p>
<p>Gensim supports the same evaluation set, in exactly the same format:</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="s1">&#39;./datasets/questions-words.txt&#39;</span><span class="p">)</span>
</code></pre></div>

<p>This <code>accuracy</code> takes an <code>optional parameter
&lt;http://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec.accuracy&gt;</code>_
<code>restrict_vocab</code> which limits which test examples are to be considered.</p>
<p>In the December 2016 release of Gensim we added a better way to evaluate semantic similarity.</p>
<p>By default it uses an academic dataset WS-353 but one can create a dataset
specific to your business based on it. It contains word pairs together with
human-assigned similarity judgments. It measures the relatedness or
co-occurrence of two words. For example, 'coast' and 'shore' are very similar
as they appear in the same context. At the same time 'clothes' and 'closet'
are less similar because they are related but not interchangeable.</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span><span class="o">.</span><span class="n">evaluate_word_pairs</span><span class="p">(</span><span class="n">datapath</span><span class="p">(</span><span class="s1">&#39;wordsim353.tsv&#39;</span><span class="p">))</span>
</code></pre></div>

<p>.. Important::
  Good performance on Google's or WS-353 test set doesn’t mean word2vec will
  work well in your application, or vice versa. It’s always best to evaluate
  directly on your intended task. For an example of how to use word2vec in a
  classifier pipeline, see this <code>tutorial
  &lt;https://github.com/RaRe-Technologies/movie-plots-by-genre&gt;</code>_.</p>
<h2 id="_10">在线训练/增量训练</h2>
<p>高级用户可以加载一个模型，并通过更多的句子来继续训练模型：</p>
<div class="highlight"><pre><span></span><code><span class="n">model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">temporary_filepath</span><span class="p">)</span>
<span class="n">more_sentences</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s1">&#39;Advanced&#39;</span><span class="p">,</span> <span class="s1">&#39;users&#39;</span><span class="p">,</span> <span class="s1">&#39;can&#39;</span><span class="p">,</span> <span class="s1">&#39;load&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span>
     <span class="s1">&#39;and&#39;</span><span class="p">,</span> <span class="s1">&#39;continue&#39;</span><span class="p">,</span> <span class="s1">&#39;training&#39;</span><span class="p">,</span> <span class="s1">&#39;it&#39;</span><span class="p">,</span> <span class="s1">&#39;with&#39;</span><span class="p">,</span> <span class="s1">&#39;more&#39;</span><span class="p">,</span> <span class="s1">&#39;sentences&#39;</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">model</span><span class="o">.</span><span class="n">build_vocab</span><span class="p">(</span><span class="n">more_sentences</span><span class="p">,</span> <span class="n">update</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">more_sentences</span><span class="p">,</span> <span class="n">total_examples</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">corpus_count</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">iter</span><span class="p">)</span>

<span class="c1"># cleaning up temporary file</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">temporary_filepath</span><span class="p">)</span>
</code></pre></div>

<p>您可能需要将<code>total_words</code>参数，具体取决于你想要的学习速率衰减。</p>
<p>请注意，无法增量训练使用C工具<code>KeyedVectors.load_word2vec_format()</code>生成的模型，但可以将它们用于查询/相似性，因为模型丢失了对训练至关重要的信息（vocab tree）。</p>
<h2 id="training-loss-computation">Training Loss Computation</h2>
<p>The parameter <code>compute_loss</code> can be used to toggle computation of loss
while training the Word2Vec model. The computed loss is stored in the model
attribute <code>running_training_loss</code> and can be retrieved using the function
<code>get_latest_training_loss</code> as follows :</p>
<div class="highlight"><pre><span></span><code><span class="c1"># instantiating and training the Word2Vec model</span>
<span class="n">model_with_loss</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span>
    <span class="n">sentences</span><span class="p">,</span>
    <span class="n">min_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">compute_loss</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">hs</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">sg</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>

<span class="c1"># getting the training loss value</span>
<span class="n">training_loss</span> <span class="o">=</span> <span class="n">model_with_loss</span><span class="o">.</span><span class="n">get_latest_training_loss</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">training_loss</span><span class="p">)</span>
</code></pre></div>

<h2 id="benchmarks">Benchmarks</h2>
<p>Let's run some benchmarks to see effect of the training loss computation code
on training time.</p>
<p>We'll use the following data for the benchmarks:</p>
<h1 id="lee-background-corpus-included-in-gensims-test-data">. Lee Background corpus: included in gensim's test data</h1>
<h1 id="text8-corpus-to-demonstrate-the-effect-of-corpus-size-well-look-at-the">. Text8 corpus.  To demonstrate the effect of corpus size, we'll look at the</h1>
<p>first 1MB, 10MB, 50MB of the corpus, as well as the entire thing.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">io</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="kn">import</span> <span class="nn">gensim.models.word2vec</span>
<span class="kn">import</span> <span class="nn">gensim.downloader</span> <span class="k">as</span> <span class="nn">api</span>
<span class="kn">import</span> <span class="nn">smart_open</span>


<span class="k">def</span> <span class="nf">head</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">smart_open</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">path</span><span class="p">)</span> <span class="k">as</span> <span class="n">fin</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">io</span><span class="o">.</span><span class="n">StringIO</span><span class="p">(</span><span class="n">fin</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">size</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">generate_input_data</span><span class="p">():</span>
    <span class="n">lee_path</span> <span class="o">=</span> <span class="n">datapath</span><span class="p">(</span><span class="s1">&#39;lee_background.cor&#39;</span><span class="p">)</span>
    <span class="n">ls</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">word2vec</span><span class="o">.</span><span class="n">LineSentence</span><span class="p">(</span><span class="n">lee_path</span><span class="p">)</span>
    <span class="n">ls</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;25kB&#39;</span>
    <span class="k">yield</span> <span class="n">ls</span>

    <span class="n">text8_path</span> <span class="o">=</span> <span class="n">api</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;text8&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fn</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;1MB&#39;</span><span class="p">,</span> <span class="s1">&#39;10MB&#39;</span><span class="p">,</span> <span class="s1">&#39;50MB&#39;</span><span class="p">,</span> <span class="s1">&#39;100MB&#39;</span><span class="p">)</span>
    <span class="n">sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1024</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">50</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="mi">1024</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">sizes</span><span class="p">):</span>
        <span class="n">ls</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">word2vec</span><span class="o">.</span><span class="n">LineSentence</span><span class="p">(</span><span class="n">head</span><span class="p">(</span><span class="n">text8_path</span><span class="p">,</span> <span class="n">s</span><span class="p">))</span>
        <span class="n">ls</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">l</span>
        <span class="k">yield</span> <span class="n">ls</span>


<span class="n">input_data</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">generate_input_data</span><span class="p">())</span>
</code></pre></div>

<p>We now compare the training time taken for different combinations of input
data and model training parameters like <code>hs</code> and <code>sg</code>.</p>
<p>For each combination, we repeat the test several times to obtain the mean and
standard deviation of the test duration.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Temporarily reduce logging verbosity</span>
<span class="n">logging</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span>

<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">train_time_values</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">seed_val</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">sg_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">hs_values</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span>

<span class="n">fast</span> <span class="o">=</span> <span class="kc">True</span>
<span class="k">if</span> <span class="n">fast</span><span class="p">:</span>
    <span class="n">input_data_subset</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">input_data_subset</span> <span class="o">=</span> <span class="n">input_data</span>


<span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">input_data_subset</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">sg_val</span> <span class="ow">in</span> <span class="n">sg_values</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">hs_val</span> <span class="ow">in</span> <span class="n">hs_values</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">loss_flag</span> <span class="ow">in</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]:</span>
                <span class="n">time_taken_list</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
                    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                    <span class="n">w2v_model</span> <span class="o">=</span> <span class="n">gensim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Word2Vec</span><span class="p">(</span>
                        <span class="n">data</span><span class="p">,</span>
                        <span class="n">compute_loss</span><span class="o">=</span><span class="n">loss_flag</span><span class="p">,</span>
                        <span class="n">sg</span><span class="o">=</span><span class="n">sg_val</span><span class="p">,</span>
                        <span class="n">hs</span><span class="o">=</span><span class="n">hs_val</span><span class="p">,</span>
                        <span class="n">seed</span><span class="o">=</span><span class="n">seed_val</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">time_taken_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>

                <span class="n">time_taken_list</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">time_taken_list</span><span class="p">)</span>
                <span class="n">time_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">time_taken_list</span><span class="p">)</span>
                <span class="n">time_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">time_taken_list</span><span class="p">)</span>

                <span class="n">model_result</span> <span class="o">=</span> <span class="p">{</span>
                    <span class="s1">&#39;train_data&#39;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                    <span class="s1">&#39;compute_loss&#39;</span><span class="p">:</span> <span class="n">loss_flag</span><span class="p">,</span>
                    <span class="s1">&#39;sg&#39;</span><span class="p">:</span> <span class="n">sg_val</span><span class="p">,</span>
                    <span class="s1">&#39;hs&#39;</span><span class="p">:</span> <span class="n">hs_val</span><span class="p">,</span>
                    <span class="s1">&#39;train_time_mean&#39;</span><span class="p">:</span> <span class="n">time_mean</span><span class="p">,</span>
                    <span class="s1">&#39;train_time_std&#39;</span><span class="p">:</span> <span class="n">time_std</span><span class="p">,</span>
                <span class="p">}</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Word2vec model #</span><span class="si">%i</span><span class="s2">: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_time_values</span><span class="p">),</span> <span class="n">model_result</span><span class="p">))</span>
                <span class="n">train_time_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model_result</span><span class="p">)</span>

<span class="n">train_times_table</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_time_values</span><span class="p">)</span>
<span class="n">train_times_table</span> <span class="o">=</span> <span class="n">train_times_table</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span>
    <span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train_data&#39;</span><span class="p">,</span> <span class="s1">&#39;sg&#39;</span><span class="p">,</span> <span class="s1">&#39;hs&#39;</span><span class="p">,</span> <span class="s1">&#39;compute_loss&#39;</span><span class="p">],</span>
    <span class="n">ascending</span><span class="o">=</span><span class="p">[</span><span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">],</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_times_table</span><span class="p">)</span>
</code></pre></div>

<h2 id="adding-word2vec-model-to-dict-method-to-production-pipeline">Adding Word2Vec "model to dict" method to production pipeline</h2>
<p>Suppose, we still want more performance improvement in production.</p>
<p>One good way is to cache all the similar words in a dictionary.</p>
<p>So that next time when we get the similar query word, we'll search it first in the dict.</p>
<p>And if it's a hit then we will show the result directly from the dictionary.</p>
<p>otherwise we will query the word and then cache it so that it doesn't miss next time.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># re-enable logging</span>
<span class="n">logging</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">level</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">INFO</span>

<span class="n">most_similars_precalc</span> <span class="o">=</span> <span class="p">{</span><span class="n">word</span> <span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">index2word</span><span class="p">}</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">most_similars_precalc</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</code></pre></div>

<h2 id="comparison-with-and-without-caching">Comparison with and without caching</h2>
<p>for time being lets take 4 words randomly</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">time</span>
<span class="n">words</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;voted&#39;</span><span class="p">,</span> <span class="s1">&#39;few&#39;</span><span class="p">,</span> <span class="s1">&#39;their&#39;</span><span class="p">,</span> <span class="s1">&#39;around&#39;</span><span class="p">]</span>
</code></pre></div>

<p>Without caching</p>
<div class="highlight"><pre><span></span><code><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</code></pre></div>

<p>Now with caching</p>
<div class="highlight"><pre><span></span><code><span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;voted&#39;</span> <span class="ow">in</span> <span class="n">most_similars_precalc</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">most_similars_precalc</span><span class="p">[</span><span class="n">word</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">most_similar</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">most_similars_precalc</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>
</code></pre></div>

<p>Clearly you can see the improvement but this difference will be even larger
when we take more words in the consideration.</p>
<h2 id="visualising-the-word-embeddings">Visualising the Word Embeddings</h2>
<p>The word embeddings made by the model can be visualised by reducing
dimensionality of the words to 2 dimensions using tSNE.</p>
<p>Visualisations can be used to notice semantic and syntactic trends in the data.</p>
<p>Example:</p>
<ul>
<li>Semantic: words like cat, dog, cow, etc. have a tendency to lie close by</li>
<li>Syntactic: words like run, running or cut, cutting lie close together.</li>
</ul>
<p>Vector relations like vKing - vMan = vQueen - vWoman can also be noticed.</p>
<p>.. Important::
  The model used for the visualisation is trained on a small corpus. Thus
  some of the relations might not be so clear.</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">IncrementalPCA</span>    <span class="c1"># inital reduction</span>
<span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">TSNE</span>                   <span class="c1"># final reduction</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>                                  <span class="c1"># array handling</span>


<span class="k">def</span> <span class="nf">reduce_dimensions</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">num_dimensions</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># final num dimensions (2D, 3D, etc)</span>

    <span class="n">vectors</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># positions in vector space</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># keep track of words to label our data again later</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="o">.</span><span class="n">vocab</span><span class="p">:</span>
        <span class="n">vectors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">wv</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="n">labels</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="c1"># convert both lists into numpy vectors for reduction</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span>

    <span class="c1"># reduce using t-SNE</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>
    <span class="n">tsne</span> <span class="o">=</span> <span class="n">TSNE</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">num_dimensions</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">vectors</span> <span class="o">=</span> <span class="n">tsne</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">vectors</span><span class="p">)</span>

    <span class="n">x_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vectors</span><span class="p">]</span>
    <span class="n">y_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vectors</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">labels</span>


<span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">reduce_dimensions</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_with_plotly</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">plot_in_notebook</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">plotly.offline</span> <span class="kn">import</span> <span class="n">init_notebook_mode</span><span class="p">,</span> <span class="n">iplot</span><span class="p">,</span> <span class="n">plot</span>
    <span class="kn">import</span> <span class="nn">plotly.graph_objs</span> <span class="k">as</span> <span class="nn">go</span>

    <span class="n">trace</span> <span class="o">=</span> <span class="n">go</span><span class="o">.</span><span class="n">Scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_vals</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;text&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">trace</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">plot_in_notebook</span><span class="p">:</span>
        <span class="n">init_notebook_mode</span><span class="p">(</span><span class="n">connected</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">iplot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;word-embedding-plot&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;word-embedding-plot.html&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_with_matplotlib</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
    <span class="kn">import</span> <span class="nn">random</span>

    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">)</span>

    <span class="c1">#</span>
    <span class="c1"># Label randomly subsampled 25 data points</span>
    <span class="c1">#</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
    <span class="n">selected_indices</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">selected_indices</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="p">(</span><span class="n">x_vals</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_vals</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>

<span class="k">try</span><span class="p">:</span>
    <span class="n">get_ipython</span><span class="p">()</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="n">plot_function</span> <span class="o">=</span> <span class="n">plot_with_matplotlib</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">plot_function</span> <span class="o">=</span> <span class="n">plot_with_plotly</span>

<span class="n">plot_function</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">y_vals</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
</code></pre></div>

<h2 id="_11">总结</h2>
<p>在本教程中，我们学习了如何在自定义数据上训练word2vec模型以及如何对其进行评估。希望您也能在机器学习任务使用这个受欢迎的工具！</p>
<h2 id="links">Links</h2>
<ul>
<li>API docs: <a href="https://radimrehurek.com/gensim/models/word2vec.html#module-gensim.models.word2vec"><code>gensim.models.word2vec</code></a></li>
<li><a href="https://code.google.com/archive/p/word2vec/">Original C toolkit and word2vec papers by Google</a>.</li>
</ul>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid" aria-label="Footer">
        
          <a href="../%E7%88%AC%E8%99%AB/13.3.pyquery.html" class="md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
            </div>
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  上一页
                </span>
                13.3.pyquery
              </div>
            </div>
          </a>
        
        
          <a href="14.2.word2vec%E5%8F%82%E6%95%B0.html" class="md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-footer-nav__title">
              <div class="md-ellipsis">
                <span class="md-footer-nav__direction">
                  下一页
                </span>
                14.2.word2vec参数
              </div>
            </div>
            <div class="md-footer-nav__button md-icon">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../assets/javascripts/vendor.7e0ee788.min.js"></script>
      <script src="../assets/javascripts/bundle.b3a72adc.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "\u590d\u5236", "clipboard.copied": "\u5df2\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\uff0c\\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}</script>
      
      <script>
        app = initialize({
          base: "..",
          features: [],
          search: Object.assign({
            worker: "../assets/javascripts/worker/search.4ac00218.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
      
        <script src="../javascript/extra.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
      
    
  </body>
</html>